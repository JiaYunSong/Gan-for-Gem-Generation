{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GAN 宝石生成\n",
    "\n",
    "### Train & Test\n",
    "\n",
    "#### 原始\n",
    "\n",
    "<img src=\"https://pic.imgdb.cn/item/60ca0b11844ef46bb2d56d6c.jpg\" height=\"500\" width=\"500\"/>\n",
    "\n",
    "#### DCGAN\n",
    "\n",
    "<img src=\"https://pic.imgdb.cn/item/60ca3848844ef46bb21c82ab.jpg\" height=\"500\" width=\"500\"/>\n",
    "\n",
    "#### WGAN-GP\n",
    "\n",
    "<img src=\"https://pic.imgdb.cn/item/60c71dc7844ef46bb206dda8.jpg\" height=\"500\" width=\"500\"/>\n",
    "\n",
    "\n",
    "* 2021/6/11 - WGAN-GP生成 \\[3x96x96\\] 宝石图像\n",
    "* 2021/6/16 - DCGAN生成 \\[3x96x96\\] 宝石图像\n",
    "## 数据加载及预处理\n",
    "### 解压数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!if [ ! -d ~/data/initial-data ];then mkdir ~/data/initial-data; unzip -oq ~/data/data54865/Gemstones.zip -d ~/data/initial-data; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 查找移动所有宝石图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!if [ ! -d ~/data/all-data ];then mkdir ~/data/all-data; find ~/data/initial-data -name \"*.jpg\" -type f -exec cp {} ~/data/all-data \\; ; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 生成低质量与高质量图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "\r\n",
    "al_path = '/home/aistudio/data/all-data'\r\n",
    "\r\n",
    "def get_imgs(size: int):\r\n",
    "    datapath = f'/home/aistudio/data/data-{size}'\r\n",
    "    if not os.path.exists(datapath):\r\n",
    "        os.mkdir(datapath)\r\n",
    "        filenames = os.listdir(al_path)\r\n",
    "        for filename in filenames:\r\n",
    "            fullname = os.path.join(al_path, filename)\r\n",
    "            dataname = os.path.join(datapath, filename)\r\n",
    "            try:\r\n",
    "                img = cv2.imread(fullname, cv2.IMREAD_COLOR)\r\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "                img = cv2.resize(img, (size, size), interpolation=cv2.INTER_LANCZOS4)\r\n",
    "                cv2.imwrite(dataname, img)\r\n",
    "            except:\r\n",
    "                ...\r\n",
    "\r\n",
    "get_imgs(96)\r\n",
    "get_imgs(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##  WGAN-GP训练生成：3x96x96\n",
    "### WGAN-GP 简介\n",
    "\n",
    "论文地址：[WGAN-GP](https://arxiv.org/pdf/1704.00028.pdf)\n",
    "\n",
    "1. 这次的模型，我们依然使用了`DCGAN`的网络结构，因为`WGAN-GP`的学习重点不在网络上\n",
    "\n",
    "2. WGAN 论文发现了 JS 散度导致 GAN 训练不稳定的问题，并引入了一种新的分布距离度量方法：Wasserstein 距离，也叫推土机距离(Earth-Mover Distance，简称 EM 距离)，它表示了从一个分布变换到另一个分布的最小代价\n",
    "\n",
    "3. 由于前WGAN并没有真正的实现`1-Lipschitz`，只有对任意输入x梯度都小于或等于1的时候，则该函数才是` 1-Lipschitz function`\n",
    "\n",
    "$$\n",
    "V(G,D)\\approx \\max\\limits_{D}\\{E_{x-P_{data}}[D(x)]-E_{x-P_{generate}}[D(x)]\\}-\\lambda E_{x-P_{penalty}}[(||\\bigtriangledown_x D(x)||-1)^2]\n",
    "$$\n",
    "\n",
    "> 也就是想尽办法的让判别器认为真实的图片得到更高的分数所以需要加上负号，让生成的图片得到更低的分数，最后加上一个梯度的惩罚项，对于惩罚项的解释(在惩罚项中希望,如果越是满足`1-Lipschitz function`，惩罚就越少。事实证明这样做的效果是非常好的),现在大量GAN都能看到WGAN-GP的身影，所以它非常的重要\n",
    "\n",
    "$$\n",
    "Loss = \\operatorname{E}\\limits_{x-P_g}[D(x)]-\\operatorname{E}\\limits_{x-P_r}[D(x)]+\\lambda \\operatorname{E}\\limits_{x-P_{ab}}[\\max\\{0, ||\\bigtriangledown_x D(x)||-1\\}]\n",
    "$$\n",
    "\n",
    "> 其中有个超参数 $\\lambda$ 表示超参数  本文设置为10\n",
    "\n",
    "### 网络结构\n",
    "* 1. 使用卷积网络进行下采样\n",
    "* ![](https://ai-studio-static-online.cdn.bcebos.com/0cb758271fde40b68d51642452f8b18f6b343dd78b8c4fc09c031c0d8db85a09)\n",
    "* 2. 使用反卷积进行上采样\n",
    "* ![](https://ai-studio-static-online.cdn.bcebos.com/addd8ef2fd7b402e9d56ea35d98b0666fa77f74feca4438f9af3d38421d01081)\n",
    "* 取消所有 pooling 层。G 网络中使用微步幅度卷积（fractionally strided convolution）\n",
    "* 代替 pooling 层，D 网络中使用步幅卷积（strided convolution）代替 pooling 层。 ·在 D 和 G 中均使用 batch normalization\n",
    "* 去掉 FC 层，使网络变为全卷积网络\n",
    "* G 网络中使用 ReLU 作为激活函数，最后一层使用 tanh\n",
    "* D 网络中使用 LeakyReLU 作为激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入包\r\n",
    "import os\r\n",
    "import cv2\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 训练执行\n",
    "#### 预设参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Wg_path = '/home/aistudio/WGAN-GP-model'\r\n",
    "d9_path = '/home/aistudio/data/data-96'\r\n",
    "\r\n",
    "use_gpu = True\r\n",
    "place = fluid.CUDAPlace(0) if use_gpu else fluid.CPUPlace()\r\n",
    "\r\n",
    "batch_size = 10   # 每批次数量\r\n",
    "z_num = 100       # 随机量维度\r\n",
    "\r\n",
    "c = 10.0          # 超参数 λ\r\n",
    "epsilon = 1e-16   # GP 梯度惩罚项\r\n",
    "\r\n",
    "epochs = 1000-885\r\n",
    "train_d = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成器 (-1, z_num, 1, 1) => (3, 96, 96)\r\n",
    "def Generator(x, name='G'):\r\n",
    "    def deconv(x, num_filters, filter_size=5,padding='SAME', stride=2, act='relu'):\r\n",
    "            x = fluid.layers.conv2d_transpose(x, num_filters=num_filters, filter_size=filter_size, stride=stride, padding=padding)\r\n",
    "            x = fluid.layers.batch_norm(x, momentum=0.8, act=act)\r\n",
    "            return x\r\n",
    "    with fluid.unique_name.guard(name+'/'):\r\n",
    "        x = fluid.layers.reshape(x, (-1, z_num, 1, 1))\r\n",
    "        x = deconv(x, num_filters=512, filter_size=6, stride=1, padding='VALID') # 6\r\n",
    "        x = deconv(x, num_filters=256)            #12\r\n",
    "        x = deconv(x, num_filters=128)            #24\r\n",
    "        x = deconv(x, num_filters=64)             #48\r\n",
    "        x = deconv(x, num_filters=3, act='tanh')  #96\r\n",
    "    return x\r\n",
    "\r\n",
    "# 判别器 (3, 96, 96) => (1) \r\n",
    "def Discriminator(x, name='D'):\r\n",
    "    def conv(x, num_filters, momentum=0.8):\r\n",
    "            x = fluid.layers.conv2d(x, num_filters=num_filters, filter_size=5, stride=2, padding='SAME')\r\n",
    "            x = fluid.layers.batch_norm(x, momentum=momentum)\r\n",
    "            x = fluid.layers.leaky_relu(x, alpha=0.2)\r\n",
    "            x = fluid.layers.dropout(x, dropout_prob=0.25)\r\n",
    "            return x\r\n",
    "    with fluid.unique_name.guard(name+'/'):\r\n",
    "        x = conv(x, num_filters=64)             # 48\r\n",
    "        x = conv(x, num_filters=128)            # 24\r\n",
    "        x = conv(x, num_filters=256)            # 12\r\n",
    "        x = conv(x, num_filters=512)            # 6\r\n",
    "        x = fluid.layers.pool2d(x, pool_type='avg', global_pooling=True)\r\n",
    "        x = fluid.layers.flatten(x)\r\n",
    "        x = fluid.layers.fc(x, size=1)\r\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 构建优化器\n",
    "##### 预设"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.enable_static()         # 构建静态图\r\n",
    "d_program = fluid.Program()    # 生成器\r\n",
    "g_program = fluid.Program()    # 判别器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 判别器优化器实现\r\n",
    "1. 生成器的超参数有噪声的数量这里固定为100\r\n",
    "2. 通过输入的噪声生成图像(`Generator`)，并将生成的图片给判别器(`Discriminator`),我们给它一个低分\r\n",
    "3. 直接将真实的图片给判别器，并给它一个高分，由于优化器是梯度下降的方向，我们想要得到上升那么就给损失一个负号用于得到高分\r\n",
    "4. 给定真实图片和生成图片，完成梯度惩罚项GP, 并让他减小损失\r\n",
    "5. 训练需要固定生成器，让判别器学习\r\n",
    "6. 优化器 beta1=0, beta2=0.9\r\n",
    "7. 关于GP梯度惩罚项的实现[参考](https://github.com/PaddlePaddle/models/blob/release/1.7/PaddleCV/gan/trainer/STGAN.py第150行的函数)\r\n",
    "8. c为梯度惩罚项的超参数默认为 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 这里的惩罚项gp是copy于paddle的github\r\n",
    "# https://github.com/PaddlePaddle/models/blob/release/1.7/PaddleCV/gan/trainer/STGAN.py第150行的函数\r\n",
    "def _interpolate(a, b=None):\r\n",
    "    alpha = fluid.layers.uniform_random_batch_size_like(input=a, shape=[a.shape[0]], min=0.0, max=1.0)\r\n",
    "    beta = fluid.layers.uniform_random_batch_size_like(input=a, shape=a.shape, min=0.0, max=1.0)\r\n",
    "    \r\n",
    "    mean = fluid.layers.reduce_mean(a, dim=list(range(len(a.shape))), keep_dim=True)\r\n",
    "    input_sub_mean = fluid.layers.elementwise_sub(a, mean, axis=0)\r\n",
    "    var = fluid.layers.reduce_mean(\r\n",
    "        fluid.layers.square(input_sub_mean),\r\n",
    "        dim=list(range(len(a.shape))),\r\n",
    "        keep_dim=True)\r\n",
    "    \r\n",
    "    b = beta * fluid.layers.sqrt(var) * 0.5 + a\r\n",
    "    inner = fluid.layers.elementwise_mul((b-a), alpha, axis=0) + a\r\n",
    "\r\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.program_guard(d_program):\r\n",
    "    fake_z_1 = fluid.data(name='fake_z', dtype='float32', shape=(None, z_num))    # 传入参数用fluid.data\r\n",
    "    img_fake_1 = Generator(fake_z_1)              # 通过生成器生成图片\r\n",
    "    fake_ret_1 = Discriminator(img_fake_1)        # 判别器判断好坏\r\n",
    "    loss_1 = fluid.layers.mean(fake_ret_1)        # 判别器损失\r\n",
    "\r\n",
    "    parameter_list = [\r\n",
    "        var.name for var in d_program.list_vars()\r\n",
    "        if fluid.io.is_parameter(var) and var.name.startswith('D')\r\n",
    "    ]\r\n",
    "    \r\n",
    "    fluid.optimizer.AdamOptimizer(learning_rate=1e-4,beta1=0, beta2=0.9).minimize(loss_1, parameter_list=parameter_list)\r\n",
    "\r\n",
    "    img_real_1 = fluid.data(name='img_real', dtype='float32', shape=(None, 3, 96, 96))  # 用fluid.data传入真实的图片\r\n",
    "    real_ret_1 = Discriminator(img_real_1)        # 用判别真实的图片\r\n",
    "    loss_2 = 1 - fluid.layers.mean(real_ret_1)    # 损失函数\r\n",
    "    \r\n",
    "    fluid.optimizer.AdamOptimizer(learning_rate=1e-4,beta1=0, beta2=0.9).minimize(loss_2, parameter_list=parameter_list)\r\n",
    "\r\n",
    "    x = _interpolate(img_real_1, img_fake_1)\r\n",
    "    pred = Discriminator(x)\r\n",
    "    \r\n",
    "    a_vars = [\r\n",
    "        var.name for var in fluid.default_main_program().list_vars()\r\n",
    "        if fluid.io.is_parameter(var) and var.name.startswith(\"D\")\r\n",
    "    ]\r\n",
    "    \r\n",
    "    grad = fluid.gradients(pred, x, no_grad_set=a_vars)[0]\r\n",
    "    grad = fluid.layers.reshape(grad, [-1, grad.shape[1] * grad.shape[2] * grad.shape[3]])\r\n",
    "    norm = fluid.layers.sqrt(fluid.layers.reduce_sum(fluid.layers.square(grad), dim=1) + epsilon)\r\n",
    "    gp = fluid.layers.reduce_mean(fluid.layers.square(norm - 1.0)) * c\r\n",
    "    d_loss = loss_1 + loss_2 + gp\r\n",
    "\r\n",
    "    # 限制梯度\r\n",
    "    # clip = fluid.clip.GradientClipByValue(min=CLIP[0], max=CLIP[1])\r\n",
    "\r\n",
    "    fluid.optimizer.AdamOptimizer(learning_rate=1e-4,beta1=0, beta2=0.9).minimize(gp, parameter_list=parameter_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 生成器优化的实现\n",
    "1. 输入噪声给生成器，因为我们想让生成器生成一张真实的图片，所以我们需要固定判别器，让生成器生成一张趋于真实的图片，所以要让他向分数高的方向走，所以也要加个负号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with fluid.program_guard(g_program):\r\n",
    "    fake_z_2 = fluid.data(name='fake_z', dtype='float32', shape=(None, z_num))\r\n",
    "    img_fake_2 = Generator(fake_z_2)\r\n",
    "    test_program = g_program.clone(for_test=True)\r\n",
    "    fake_ret_2 = Discriminator(img_fake_2)\r\n",
    "    \r\n",
    "    avg_loss_2 = 1 - fluid.layers.mean(fake_ret_2)\r\n",
    "    \r\n",
    "    parameter_list = [\r\n",
    "        var.name for var in d_program.list_vars()\r\n",
    "        if fluid.io.is_parameter(var) and var.name.startswith('G')\r\n",
    "    ]\r\n",
    "    \r\n",
    "    fluid.optimizer.AdamOptimizer(learning_rate=1e-4, beta1=0, beta2=0.9).minimize(avg_loss_2, parameter_list=parameter_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exe = fluid.executor.Executor(place=place)\r\n",
    "_ = exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 建立快照\r\n",
    "try:\r\n",
    "    fluid.io.load_params(exe, dirname=Wg_path, main_program=fluid.default_startup_program())\r\n",
    "except:\r\n",
    "    ...\r\n",
    "def get_cur():\r\n",
    "    try:\r\n",
    "        img_names = np.array([i.strip('.jpg').split('_') for i in os.listdir(Wg_path) if '.jpg' in i]).astype('int')\r\n",
    "        assert len(img_names) != 0\r\n",
    "    except:\r\n",
    "        return [0, 0]\r\n",
    "    return np.max(img_names, axis=0)+1\r\n",
    "epoch_pro, _ = get_cur()\r\n",
    "step_pro = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch():\r\n",
    "    filenames = os.listdir(d9_path)\r\n",
    "    random.shuffle(filenames)\r\n",
    "    img_list, label_list = [], []\r\n",
    "    for i, filename in enumerate(filenames):\r\n",
    "        fullname = os.path.join(d9_path, filename)\r\n",
    "        img = cv2.imread(fullname, cv2.IMREAD_COLOR)\r\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "        img = img / 255.*2 - 1\r\n",
    "        img = np.transpose(img, (2,0,1))\r\n",
    "        img_list.append(img)\r\n",
    "        label_list.append(1.)\r\n",
    "        if (i+1) % batch_size == 0:\r\n",
    "            yield np.array(img_list).astype('float32'), np.array(label_list)\r\n",
    "            img_list, label_list = [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\r\n",
    "    images = None\r\n",
    "    epoch += epoch_pro\r\n",
    "    for step,(x, y) in enumerate(get_batch()):\r\n",
    "        step += step_pro\r\n",
    "        fake_z = np.random.uniform(size=(x.shape[0], z_num), low=-1, high=1).astype('float32')\r\n",
    "        [loss_1_, loss_2_, gp_] = exe.run(program=d_program, \r\n",
    "                                          feed={'fake_z':fake_z,'img_real':x}, \r\n",
    "                                          fetch_list=[loss_1, loss_2, gp])\r\n",
    "\r\n",
    "        # 生成器训练\r\n",
    "        for _ in range(train_d):\r\n",
    "            fake_z = np.random.uniform(size=(x.shape[0], z_num), low=-1, high=1).astype('float32')\r\n",
    "            [g_loss] = exe.run(program=g_program, \r\n",
    "                               feed={'fake_z':fake_z}, \r\n",
    "                               fetch_list=[avg_loss_2])\r\n",
    "        \r\n",
    "        # 100次进行预测一次\r\n",
    "        if step % 100 == 0:\r\n",
    "            loss_1_, loss_2_, gp_, g_loss = map(float, (loss_1_, loss_2_, gp_, g_loss))\r\n",
    "            out_str = f'[Training] epoch:{epoch} step:{step} g_loss:{g_loss} d_loss:{loss_1_+loss_2_+gp_} (f_loss={loss_1_} r_loss={loss_2_} GP={gp_})'\r\n",
    "            print(out_str)\r\n",
    "            with open(f'{Wg_path}_out.txt',\"a\") as file:\r\n",
    "                file.write(out_str+\"\\n\")\r\n",
    "            # 快照\r\n",
    "            fluid.io.save_params(exe, dirname=Wg_path, main_program=fluid.default_startup_program())    \r\n",
    "            fake_z = np.random.uniform(size=(z_num, z_num), low=-1, high=1).astype('float32')\r\n",
    "            [pre_im] = exe.run(program=test_program, \r\n",
    "                               feed={'fake_z':fake_z}, \r\n",
    "                               fetch_list=[img_fake_2])\r\n",
    "            pre_im = (np.transpose(pre_im, (0, 2, 3, 1))+1) / 2\r\n",
    "            \r\n",
    "            # 准备一个画布用于存放生成的图片\r\n",
    "            images = np.zeros((960, 960, 3))\r\n",
    "            for h in range(10):\r\n",
    "                for w in range(10):\r\n",
    "                    images[h*96:(h+1)*96, w*96:(w+1)*96] = pre_im[(h*10)+w]\r\n",
    "            plt.imsave('{}/{}_{}.jpg'.format(Wg_path, epoch, step), images)\r\n",
    "        if step == 0 and epoch % 10 == 0:\r\n",
    "            plt.imshow(images, cmap='gray')\r\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\r\n",
    "fake_z1 = np.array([[ 0.1628196 ,  0.06020002, -0.2060656 , -0.2008977 ,  0.55397815,  -0.26759636, -0.36206895, -0.59165126, -0.28061983, -0.6222151 ,  -0.96598303, -0.4606206 ,  0.9854551 ,  0.9816093 , -0.32310477,  -0.11815367, -0.5434894 , -0.74145615, -0.8636268 , -0.5834029 ,  -0.07124058, -0.30142292, -0.5333166 , -0.67257905, -0.9680295 ,   0.46814537, -0.6241449 ,  0.13388671,  0.3210726 ,  0.51314497,  -0.1876392 , -0.7934325 ,  0.7071664 ,  0.41295967,  0.76740944,  -0.50664145,  0.08661275, -0.42233503,  0.95415235,  0.34426385,  -0.27813435,  0.21395077,  0.9130151 ,  0.7578369 , -0.6572961 ,  -0.0671403 ,  0.9326817 ,  0.8190068 ,  0.06983604, -0.16990714,   0.71631354, -0.60850775, -0.5150853 , -0.4799691 , -0.9335457 ,  -0.05940403, -0.6704578 ,  0.6399308 ,  0.52119714,  0.31435177,  -0.85910934,  0.40837994, -0.18065603, -0.44286138, -0.59907156,   0.8817434 , -0.8173919 , -0.82570285, -0.23782504, -0.73118174,  -0.7469359 , -0.3491494 , -0.20398776,  0.9803937 ,  0.9116375 ,  -0.2655413 , -0.0376263 , -0.02038905, -0.49076393,  0.9365829 ,  -0.6917846 ,  0.665875  , -0.25417942,  0.90112466,  0.64291835,   0.7206952 ,  0.4192555 ,  0.47273248,  0.7568629 , -0.8213731 ,  -0.7171862 ,  0.67112094,  0.5666802 ,  0.11436127, -0.7256467 ,  -0.320071  , -0.06459896, -0.24214156, -0.51376414, -0.02128822]], dtype='float32')\r\n",
    "fake_z2 = np.array([[ 1.73423752e-01, -7.69945920e-01,  3.47309746e-02,  -8.93073976e-01,  3.62380743e-01,  5.61251529e-02,   4.02133048e-01, -5.35719329e-04,  6.83315471e-02,   2.17393041e-01,  8.28237236e-02,  1.52823642e-01,  -9.85875189e-01,  3.83724898e-01,  3.32061827e-01,  -4.95688915e-01,  7.67859519e-01, -1.01901911e-01,   7.21223176e-01,  1.77856877e-01, -3.79434884e-01,  -2.11844251e-01, -2.66274273e-01,  9.90064979e-01,   8.29603255e-01,  3.94291520e-01, -1.16514340e-01,  -8.96508455e-01, -8.47046003e-02,  3.05729099e-02,   8.69425461e-02,  8.26287746e-01,  2.75682479e-01,  -1.33725196e-01,  7.49988407e-02, -4.66008186e-01,  -6.46197319e-01,  4.74357009e-01, -5.04314780e-01,  -3.02102327e-01, -4.18006957e-01,  2.08232135e-01,   1.33660734e-01,  1.63588554e-01,  1.93897516e-01,   5.56772292e-01,  7.61188447e-01,  5.67563713e-01,   7.98536837e-01,  9.79610443e-01,  2.78141707e-01,   6.32494092e-01,  8.37376297e-01,  4.99828428e-01,  -1.59887835e-01, -9.52926099e-01,  8.96628678e-01,   5.41600943e-01, -7.04732239e-01,  9.64725554e-01,   3.96280289e-01, -8.58498752e-01,  2.63351351e-01,   8.67280304e-01, -9.08607617e-02, -5.28445005e-01,  -9.70839798e-01, -5.78085065e-01, -1.11416914e-01,   4.95842934e-01,  4.53393042e-01,  7.17945039e-01,   3.73275667e-01, -5.30356169e-01,  7.64361501e-01,   9.70767558e-01,  1.94362663e-02, -4.35328662e-01,   6.61424458e-01, -4.81950119e-02, -6.80367470e-01,   5.85199833e-01,  9.59802032e-01,  9.28983808e-01,  -7.82506168e-01, -1.04114622e-01, -3.78846288e-01,  -4.60661829e-01,  9.33107734e-01,  6.71302080e-02,  -9.57123935e-01, -3.99602950e-01,  1.06667526e-01,  -2.39341632e-01,  9.59848046e-01, -6.91255629e-01,   9.10927296e-01,  9.03677702e-01,  3.43659163e-01,  -9.69704032e-01]], dtype='float32')\r\n",
    "fake_z3 = np.array([[-1.54808953e-01,  3.70797455e-01, -5.50530434e-01,   8.88798118e-01,  1.48261501e-03,  7.54083320e-02,  -3.60852331e-01,  2.43449537e-03,  4.52306420e-01,  -2.68616408e-01,  5.51057532e-02, -8.31197053e-02,  -2.49736071e-01,  6.24021709e-01,  9.88368928e-01,   1.21546052e-01,  4.77205336e-01,  7.82941282e-01,  -1.53581619e-01,  4.02827412e-01, -2.88837820e-01,  -3.87253672e-01, -9.51536000e-02,  1.67471785e-02,  -6.55421197e-01,  2.52013266e-01, -1.93831936e-01,  -9.87818241e-01,  2.24797338e-01, -1.28131136e-01,  -5.52273810e-01, -3.97933125e-01,  8.07264805e-01,  -6.31823361e-01,  2.65025795e-02,  4.88095433e-01,  -5.54655433e-01, -4.67667162e-01, -1.27145112e-01,  -4.99425173e-01,  9.96037185e-01, -9.91724610e-01,  -5.49022555e-02,  5.59283912e-01, -1.05380170e-01,  -6.43494129e-01, -5.18584549e-01,  9.71008182e-01,   3.64938766e-01, -7.27478325e-01, -1.87705070e-01,  -7.46205866e-01, -5.93074322e-01, -3.10427427e-01,  -5.14982700e-01, -9.45145935e-02,  6.63303852e-01,   3.31954628e-01, -7.68493474e-01, -6.98818147e-01,  -7.65405536e-01, -1.23112634e-01,  8.81450176e-01,   3.29640567e-01,  5.57847321e-01,  8.27734172e-01,   9.55396414e-01, -4.73707706e-01, -2.11369112e-01,   9.17738318e-01, -3.17583710e-01,  2.29109004e-01,  -2.48818994e-01, -6.75448358e-01, -3.66140872e-01,  -8.03524792e-01, -2.31833115e-01, -2.44700357e-01,   9.41398084e-01,  6.05898201e-01, -5.25917768e-01,   6.79681301e-01, -8.50292683e-01,  7.23254323e-01,   2.02767387e-01,  4.98614907e-01,  9.75749612e-01,  -2.33748749e-01,  7.47435391e-01,  2.00816706e-01,   1.55958056e-01, -1.13003649e-01,  8.70095789e-01,   2.72289995e-04, -9.05706227e-01,  1.31745622e-01,   4.41222727e-01, -3.08290869e-01, -8.77345204e-01,   7.00753391e-01]], dtype='float32')\r\n",
    "fake_z4 = np.array([[-0.19166796,  0.8518012 ,  0.145091  , -0.05993893, -0.45888463,   0.8673928 ,  0.9652282 ,  0.12726055,  0.01244434, -0.93083525,   0.43431133, -0.49930117, -0.55162716,  0.35950926,  0.7037384 ,   0.11401674, -0.28130996, -0.2928921 ,  0.72169   ,  0.16362152,  -0.5016924 ,  0.43633834,  0.11796366,  0.00219617,  0.847646  ,   0.6748598 , -0.32114825, -0.15379265,  0.70928174, -0.8728422 ,   0.31036106, -0.8250491 ,  0.43096024, -0.96281725,  0.10819924,   0.9144131 ,  0.20409475, -0.9040856 ,  0.16202451,  0.4682495 ,  -0.13104072,  0.51667684, -0.7445863 ,  0.9387579 , -0.12740219,   0.17839415, -0.8474835 , -0.28403   ,  0.7451734 ,  0.19540492,   0.49905938, -0.61591697, -0.45006886,  0.7683603 , -0.9711963 ,   0.34337667, -0.22944267,  0.5802888 ,  0.3484021 ,  0.5493261 ,  -0.28516468,  0.02338881,  0.9595401 , -0.10940923, -0.8052722 ,   0.03689744,  0.71858245, -0.43022957,  0.10462559, -0.4443373 ,   0.36294216, -0.04272104, -0.50580406,  0.1556459 ,  0.34158394,   0.921397  , -0.884857  , -0.29005402,  0.9884361 , -0.5774341 ,  -0.30703196,  0.31190208, -0.2624621 ,  0.5999602 , -0.29485407,  -0.85030997, -0.9605466 , -0.5932406 , -0.7367069 , -0.54928774,   0.14493614, -0.36576104, -0.16612104,  0.5380705 , -0.8164843 ,  -0.80553305, -0.37761232,  0.905625  ,  0.67822284, -0.47533378]], dtype='float32')\r\n",
    "fake_z5 = np.array([[-0.49124366, -0.7515978 , -0.74474436,  0.33651626, -0.02003454,  -0.49979228, -0.3460132 , -0.1082238 , -0.8632628 ,  0.32383934,   0.57275146,  0.04399857, -0.05217148,  0.1337484 ,  0.5154774 ,  -0.5780535 , -0.5374929 ,  0.3237491 , -0.8140235 , -0.23915705,   0.33803776, -0.97627527,  0.90115136,  0.66156435, -0.16090132,  -0.96128684,  0.97522634,  0.8348675 , -0.51188135, -0.28184426,  -0.6413365 , -0.7100339 ,  0.30043355,  0.42623404, -0.6104447 ,   0.2676714 , -0.4290038 ,  0.2543924 ,  0.30417633, -0.554996  ,  -0.9040517 , -0.48714116, -0.02494111,  0.74440295,  0.16304332,   0.50590354,  0.02005209, -0.27269456,  0.6572092 ,  0.73941165,  -0.8238788 , -0.43116006,  0.79212266,  0.7831773 ,  0.32471797,  -0.43271893,  0.35854793, -0.7456453 ,  0.5968816 , -0.55512017,   0.644918  ,  0.34041697, -0.49072075,  0.9913528 , -0.69197947,  -0.9509921 ,  0.63709044, -0.84002507,  0.5306693 , -0.873428  ,  -0.56814194, -0.31120738, -0.68780464,  0.4997686 ,  0.5911224 ,   0.76103264, -0.8965332 , -0.36284062,  0.96344227,  0.39664373,   0.1157234 ,  0.42655757, -0.9809847 , -0.574825  , -0.81645733,  -0.55916363,  0.44941834,  0.01480339,  0.5341408 , -0.6769514 ,   0.7752634 ,  0.29789975, -0.9451429 ,  0.35611492, -0.4459079 ,  -0.91902405, -0.5986422 , -0.9678276 ,  0.01595495,  0.75727   ]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sip = 20\r\n",
    "num = 0\r\n",
    "def app(z1, z2):\r\n",
    "    for i in range(sip):\r\n",
    "        global num\r\n",
    "        num += 1\r\n",
    "        step = (z2-z1) / sip\r\n",
    "        fake_z = z1 + step*i\r\n",
    "        [pre_im] = exe.run(program=test_program, \r\n",
    "                           feed={'fake_z':fake_z}, \r\n",
    "                           fetch_list=[img_fake_2])\r\n",
    "        pre_im = ((np.transpose(pre_im, (0, 2, 3, 1))+1) / 2).reshape(96,96,3)\r\n",
    "        plt.imshow(pre_im, cmap='gray')\r\n",
    "        plt.imsave(f'{Wg_path}_test/{num}.jpg', pre_im)\r\n",
    "        if i % 10 == 0:\r\n",
    "            plt.show()\r\n",
    "app(fake_z1, fake_z2)\r\n",
    "app(fake_z2, fake_z3)\r\n",
    "app(fake_z3, fake_z4)\r\n",
    "app(fake_z4, fake_z5)\r\n",
    "app(fake_z5, fake_z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<img src=\"https://pic.imgdb.cn/item/60c718ce844ef46bb2c31f14.gif\" height=\"200\" width=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DCGAN 训练生成：3x96x96\n",
    "-----------------------------\n",
    "### DCGAN简介\n",
    "DCGAN是深层卷积网络与 GAN 的结合，其基本原理与 GAN 相同，只是将生成网络和判别网络用两个卷积网络（CNN）替代。为了提高生成样本的质量和网络的收敛速度，论文中的 DCGAN 在网络结构上进行了一些改进：\n",
    "\n",
    "* 取消 pooling 层：在网络中，所有的pooling层使用步幅卷积（strided convolutions）(判别器)和微步幅度卷积（fractional-strided convolutions）(生成器)进行替换。\n",
    "* 加入 batch normalization：在生成器和判别器中均加入batchnorm。\n",
    "* 使用全卷积网络：去掉了FC层，以实现更深的网络结构。\n",
    "* 激活函数：在生成器（G）中，最后一层使用Tanh函数，其余层采用 ReLu 函数 ; 判别器（D）中都采用LeakyReLu。\n",
    "\n",
    "参考[Paddle2.0-通过DCGAN实现人脸图像生成](https://aistudio.baidu.com/aistudio/projectdetail/1086168?channelType=0&channel=0)进行的改进：\n",
    "* 将Adam优化器beta1参数设置为0.8，具体请参考[原论文](https://arxiv.org/abs/1412.6980)\n",
    "* 将BatchNorm批归一化中momentum参数设置为0.5\n",
    "* 将判别器(D)激活函数由elu改为leaky_relu，并将alpha参数设置为0.2\n",
    "* 生成器输出，判别器输入改为[3,128,128]\n",
    "* 损失函数选用Softmax_with_cross_entropy\n",
    "\n",
    "> **参考文献**\n",
    "> \n",
    "> [1] Goodfellow, Ian J.; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua. Generative Adversarial Networks. 2014. arXiv:1406.2661 [stat.ML].\n",
    "> \n",
    "> [2] Andrej Karpathy, Pieter Abbeel, Greg Brockman, Peter Chen, Vicki Cheung, Rocky Duan, Ian Goodfellow, Durk Kingma, Jonathan Ho, Rein Houthooft, Tim Salimans, John Schulman, Ilya Sutskever, And Wojciech Zaremba, Generative Models, OpenAI, [April 7, 2016]\n",
    "> \n",
    "> [3] alimans, Tim; Goodfellow, Ian; Zaremba, Wojciech; Cheung, Vicki; Radford, Alec; Chen, Xi. Improved Techniques for Training GANs. 2016. arXiv:1606.03498 [cs.LG].\n",
    "> \n",
    "> [4] Radford A, Metz L, Chintala S. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks[J]. Computer Science, 2015.\n",
    "> \n",
    "> [5]Kingma D , Ba J . Adam: A Method for Stochastic Optimization[J]. Computer ence, 2014.\n",
    "\n",
    "### DCGAN实现\n",
    "#### 引入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import paddle\r\n",
    "from paddle.io import Dataset\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.static import InputSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### DCGAN网络结构搭建\n",
    "##### 初始化器\n",
    "\n",
    "在 DCGAN 论文中，作者指定所有模型权重应从均值为0、标准差为0.02的正态分布中随机初始化。\n",
    "在paddle.nn中，调用fluid.nn.initializer.Normal实现initialize设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_initializer=paddle.nn.initializer.Normal(mean=0.0, std=0.02)\r\n",
    "bn_initializer=paddle.nn.initializer.Normal(mean=1.0, std=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 判别器\n",
    "如上文所述，生成器$D$是一个二进制分类网络，它以图像作为输入，输出图像是真实的（相对应$G$生成的假样本）的概率。输入$Shape$为[3,64,64]的RGB图像，通过一系列的$Conv2d$，$BatchNorm2d$和$LeakyReLU$层对其进行处理，然后通过全连接层输出的神经元个数为2，对应两个标签的预测概率。\n",
    "\n",
    "* 将BatchNorm批归一化中momentum参数设置为0.5\n",
    "* 将判别器(D)激活函数leaky_relu的alpha参数设置为0.2\n",
    "\n",
    "> 输入:  为大小64x64的RGB三通道图片  \n",
    "> 输出:  经过一层全连接层最后为shape为[batch_size,2]的Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "import paddle.nn as nn\r\n",
    "import paddle.nn.functional as F\r\n",
    "\r\n",
    "class Discriminator(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(Discriminator, self).__init__()\r\n",
    "        self.conv_1 = nn.Conv2D(     # 96\r\n",
    "            3,64,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_1_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.conv_2 = nn.Conv2D(     # 48\r\n",
    "            64,128,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_2_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_2 = nn.BatchNorm2D(\r\n",
    "            128,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_2_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_3 = nn.Conv2D(     # 24\r\n",
    "            128,256,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_3_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_3 = nn.BatchNorm2D(\r\n",
    "            256,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_3_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_4 = nn.Conv2D(     # 12\r\n",
    "            256,512,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_4_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_4 = nn.BatchNorm2D(\r\n",
    "            512,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"d_4_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_5 = nn.Conv2D(     # 6\r\n",
    "            512,1,6,1,0,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"d_conv_weight_5_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_1(x)\r\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\r\n",
    "        x = self.conv_2(x)\r\n",
    "        x = self.bn_2(x)\r\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\r\n",
    "        x = self.conv_3(x)\r\n",
    "        x = self.bn_3(x)\r\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\r\n",
    "        x = self.conv_4(x)\r\n",
    "        x = self.bn_4(x)\r\n",
    "        x = F.leaky_relu(x,negative_slope=0.2)\r\n",
    "        x = self.conv_5(x)\r\n",
    "        x = F.sigmoid(x)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 生成器\n",
    "生成器$G$旨在映射潜在空间矢量$z$到数据空间。由于我们的数据是图像，因此转换$z$到数据空间意味着最终创建具有与训练图像相同大小[3,64,64]的RGB图像。在网络设计中，这是通过一系列二维卷积转置层来完成的，每个层都与$BatchNorm$层和$ReLu$激活函数。生成器的输出通过$tanh$函数输出，以使其返回到输入数据范围[−1,1]。值得注意的是，在卷积转置层之后存在$BatchNorm$函数，因为这是DCGAN论文的关键改进。这些层有助于训练过程中的梯度更好地流动。  \n",
    "\n",
    "**生成器网络结构**  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/ca0434dd681849338b1c0c46285616f72add01ab894b4e95848daecd5a72e3cb)\n",
    "\n",
    "* 将$BatchNorm$批归一化中$momentum$参数设置为0.5\n",
    "\n",
    "> 输入:Tensor的Shape为[batch_size,100]其中每个数值大小为0~1之间的float32随机数  \n",
    "> 输出:3x64x64RGB三通道图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Generator(paddle.nn.Layer):\r\n",
    "    def __init__(self):\r\n",
    "        super(Generator, self).__init__()\r\n",
    "        self.conv_1 = nn.Conv2DTranspose(    # 6\r\n",
    "            100,512,6,1,0,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_1_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_1 = nn.BatchNorm2D(\r\n",
    "            512,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_1_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_2 = nn.Conv2DTranspose(    # 12\r\n",
    "            512,256,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_2_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_2 = nn.BatchNorm2D(\r\n",
    "            256,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_2_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_3 = nn.Conv2DTranspose(    # 24\r\n",
    "            256,128,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_3_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_3 = nn.BatchNorm2D(\r\n",
    "            128,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_3_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_4 = nn.Conv2DTranspose(    # 48\r\n",
    "            128,64,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_4_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.bn_4 = nn.BatchNorm2D(\r\n",
    "            64,\r\n",
    "            weight_attr=paddle.ParamAttr(name=\"g_4_bn_weight_\",initializer=bn_initializer),momentum=0.8\r\n",
    "            )\r\n",
    "        self.conv_5 = nn.Conv2DTranspose(    # 96\r\n",
    "            64,3,4,2,1,\r\n",
    "            bias_attr=False,weight_attr=paddle.ParamAttr(name=\"g_dconv_weight_5_\",initializer=conv_initializer)\r\n",
    "            )\r\n",
    "        self.tanh = paddle.nn.Tanh()\r\n",
    "    \r\n",
    "    def forward(self, x):\r\n",
    "        x = self.conv_1(x)\r\n",
    "        x = self.bn_1(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.conv_2(x)\r\n",
    "        x = self.bn_2(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.conv_3(x)\r\n",
    "        x = self.bn_3(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.conv_4(x)\r\n",
    "        x = self.bn_4(x)\r\n",
    "        x = F.relu(x)\r\n",
    "        x = self.conv_5(x)\r\n",
    "        x = self.tanh(x)\r\n",
    "        return x\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 模型搭建\n",
    "\n",
    "##### 参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle.optimizer as optim\r\n",
    "\r\n",
    "output = \"/home/aistudio/DCGAN-model/\"\r\n",
    "output_path = '/home/aistudio/DCGAN-model'\r\n",
    "\r\n",
    "use_gpu = True\r\n",
    "device = paddle.set_device('gpu' if use_gpu else 'cpu')\r\n",
    "\r\n",
    "img_dim = 96\r\n",
    "lr = 0.0002\r\n",
    "epoch = 1000\r\n",
    "batch_size = 128\r\n",
    "G_DIMENSION = 100\r\n",
    "beta1=0.5\r\n",
    "beta2=0.999\r\n",
    "\r\n",
    "real_label = 1.\r\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 搭建网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paddle.disable_static(device)\r\n",
    "netD = Discriminator()\r\n",
    "netG = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 损失函数与优化器设定\n",
    "选用BCELoss,公式如下:\n",
    "\n",
    "$Out = -1 * (label * log(input) + (1 - label) * log(1 - input))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###损失函数\r\n",
    "loss = paddle.nn.BCELoss()\r\n",
    "\r\n",
    "optimizerD = optim.Adam(parameters=netD.parameters(), learning_rate=lr, beta1=beta1, beta2=beta2)\r\n",
    "optimizerG = optim.Adam(parameters=netG.parameters(), learning_rate=lr, beta1=beta1, beta2=beta2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\r\n",
    "import cv2\r\n",
    "\r\n",
    "data_path = '/home/aistudio/data/data-96/'\r\n",
    "paddle.enable_static()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DataGenerater(Dataset):\r\n",
    "    def __init__(self, path=data_path):\r\n",
    "        super(DataGenerater, self).__init__()\r\n",
    "        self.dir = path\r\n",
    "        self.datalist = os.listdir(data_path)\r\n",
    "        self.image_size = (img_dim,img_dim)\r\n",
    "    \r\n",
    "    def __getitem__(self, idx):\r\n",
    "        return self._load_img(self.dir + self.datalist[idx])\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.datalist)\r\n",
    "    \r\n",
    "    def _load_img(self, path):\r\n",
    "        try:\r\n",
    "            img = cv2.imread(path, cv2.IMREAD_COLOR)\r\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "            img = np.transpose(img, (2,0,1)).astype('float32')/255*2-1\r\n",
    "        except Exception as e:\r\n",
    "            print(e)\r\n",
    "        return img\r\n",
    "\r\n",
    "train_dataset = DataGenerater()\r\n",
    "imgs = paddle.static.data(name='img', shape=[None,3,img_dim,img_dim], dtype='float32')\r\n",
    "train_loader = paddle.io.DataLoader(\r\n",
    "    train_dataset, \r\n",
    "    places=paddle.CPUPlace(), \r\n",
    "    feed_list = [imgs],\r\n",
    "    batch_size=batch_size, \r\n",
    "    shuffle=True,\r\n",
    "    num_workers=2,\r\n",
    "    use_buffer_reader=True,\r\n",
    "    use_shared_memory=False,\r\n",
    "    drop_last=True,\r\n",
    "    )\r\n",
    "\r\n",
    "# 测试Train_loader\r\n",
    "# for batch_id, data in enumerate(train_loader()):\r\n",
    "#     plt.figure(figsize=(15,15))\r\n",
    "#     try:\r\n",
    "#         for i in range(100):\r\n",
    "#             image = (np.array(data)[i].transpose((1,2,0))+1)*255/2\r\n",
    "#             image = image.astype('int32')\r\n",
    "#             plt.subplot(10, 10, i + 1)\r\n",
    "#             plt.imshow(image, vmin=-1, vmax=1)\r\n",
    "#             plt.axis('off')\r\n",
    "#             plt.xticks([])\r\n",
    "#             plt.yticks([])\r\n",
    "#             plt.subplots_adjust(wspace=0.1, hspace=0.1)\r\n",
    "#         plt.suptitle('\\n Training Images',fontsize=30)\r\n",
    "#         plt.show()\r\n",
    "#         break\r\n",
    "#     except IOError:\r\n",
    "#         print(IOError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 建立快照\r\n",
    "try:\r\n",
    "    netG.set_state_dict(paddle.load(f\"{output_path}/generator.params\"))\r\n",
    "    netD.set_state_dict(paddle.load(f\"{output_path}/discriminator.params\"))\r\n",
    "except:\r\n",
    "    ...\r\n",
    "def get_cur():\r\n",
    "    try:\r\n",
    "        img_names = np.array([i.strip('.png').split('_') for i in os.listdir(output_path) if '.png' in i]).astype('int')\r\n",
    "        assert len(img_names) != 0\r\n",
    "    except:\r\n",
    "        return [0, 0]\r\n",
    "    return np.max(img_names, axis=0)+1\r\n",
    "epoch_pro, _ = get_cur()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###训练过程\r\n",
    "paddle.disable_static(device)\r\n",
    "losses = [[], []]\r\n",
    "if not os.path.exists(output_path):\r\n",
    "    os.makedirs(output_path)\r\n",
    "\r\n",
    "for pass_id in range(epoch_pro, epoch):\r\n",
    "    for batch_id, data in enumerate(train_loader()):\r\n",
    "        #训练判别器 \r\n",
    "        optimizerD.clear_grad()\r\n",
    "        real_cpu = data\r\n",
    "        label = paddle.full((batch_size,1,1,1),real_label,dtype='float32')\r\n",
    "        output = netD(real_cpu)\r\n",
    "        errD_real = loss(output,label)\r\n",
    "        errD_real.backward()\r\n",
    "        optimizerD.step()\r\n",
    "        optimizerD.clear_grad()\r\n",
    "\r\n",
    "        noise = paddle.randn([batch_size,G_DIMENSION,1,1],'float32')\r\n",
    "        fake = netG(noise)\r\n",
    "        label = paddle.full((batch_size,1,1,1),fake_label,dtype='float32')\r\n",
    "        output = netD(fake.detach())\r\n",
    "        errD_fake = loss(output,label)\r\n",
    "        errD_fake.backward()\r\n",
    "        optimizerD.step()\r\n",
    "        optimizerD.clear_grad()\r\n",
    "\r\n",
    "        errD = errD_real + errD_fake\r\n",
    "        \r\n",
    "        losses[0].append(errD.numpy()[0])\r\n",
    "        ###训练生成器\r\n",
    "        optimizerG.clear_grad()\r\n",
    "        noise = paddle.randn([batch_size,G_DIMENSION,1,1],'float32')\r\n",
    "        fake = netG(noise)\r\n",
    "        label = paddle.full((batch_size,1,1,1),real_label,dtype=np.float32,)\r\n",
    "        output = netD(fake)\r\n",
    "        errG = loss(output,label)\r\n",
    "        errG.backward()\r\n",
    "        optimizerG.step()\r\n",
    "        optimizerG.clear_grad()\r\n",
    "        \r\n",
    "        losses[1].append(errG.numpy()[0])\r\n",
    "        if batch_id % 100 == 0:\r\n",
    "            msg = f'Epoch ID={pass_id} Batch ID={batch_id} \\n\\n D-Loss={errD.numpy()[0]} G-Loss={errG.numpy()[0]}'\r\n",
    "            print(msg.replace('\\n\\n', ':'))\r\n",
    "            with open(f'{output_path}_out.txt',\"a\") as file:\r\n",
    "                file.write(msg.replace('\\n\\n', ':')+\"\\n\")\r\n",
    "\r\n",
    "            # 每轮的生成结果\r\n",
    "            generated_image = netG(noise).numpy()\r\n",
    "            imgs = []\r\n",
    "            plt.figure(figsize=(15,15))\r\n",
    "            for i in range(100):\r\n",
    "                image = (np.array(generated_image)[i].transpose((1,2,0))+1)*255/2\r\n",
    "                image = image.astype('int32')\r\n",
    "                image = np.where(image > 0, image, 0)\r\n",
    "                plt.subplot(10, 10, i + 1)\r\n",
    "                plt.imshow(image, vmin=-1, vmax=1)\r\n",
    "                plt.axis('off')\r\n",
    "                plt.xticks([])\r\n",
    "                plt.yticks([])\r\n",
    "                plt.subplots_adjust(wspace=0.1, hspace=0.1)\r\n",
    "            plt.suptitle(msg, fontsize=20)\r\n",
    "            plt.savefig(f'{output_path}/{pass_id}_{batch_id}.png', bbox_inches='tight')\r\n",
    "            plt.close('all')\r\n",
    "    paddle.save(netG.state_dict(), f\"{output_path}/generator.params\")\r\n",
    "    paddle.save(netD.state_dict(), f\"{output_path}/discriminator.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### 绘制 LOSS 变化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\r\n",
    "x = np.arange(len(losses[0]))\r\n",
    "plt.title('Generator and Discriminator Loss During Training')\r\n",
    "plt.xlabel('Number of Batch')\r\n",
    "plt.plot(x,np.array(losses[0]),label='D Loss')\r\n",
    "plt.plot(x,np.array(losses[1]),label='G Loss')\r\n",
    "plt.yscale('log')\r\n",
    "plt.legend()\r\n",
    "plt.savefig(f'{output_path}/Generator and Discriminator Loss During Training.jpg')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_z = paddle.randn([batch_size,G_DIMENSION,1,1],'float32')\r\n",
    "pre_im = netG(fake_z)\r\n",
    "image = (np.array(pre_im)[i].transpose((1,2,0))+1)*255/2\r\n",
    "image = image.astype('int32')\r\n",
    "plt.imshow(image, cmap='gray')\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sip = 20\r\n",
    "num = 0\r\n",
    "def app(z1, z2):\r\n",
    "    for i in range(sip):\r\n",
    "        global num\r\n",
    "        num += 1\r\n",
    "        step = (z2-z1) / sip\r\n",
    "        fake_z = z1 + step*i\r\n",
    "        [pre_im] = exe.run(program=test_program, \r\n",
    "                           feed={'fake_z':fake_z}, \r\n",
    "                           fetch_list=[img_fake_2])\r\n",
    "        pre_im = ((np.transpose(pre_im, (0, 2, 3, 1))+1) / 2).reshape(96,96,3)\r\n",
    "        plt.imshow(pre_im, cmap='gray')\r\n",
    "        plt.imsave(f'{output_path}_test/{num}.jpg', pre_im)\r\n",
    "        if i % 10 == 0:\r\n",
    "            plt.show()\r\n",
    "app(fake_z1, fake_z2)\r\n",
    "app(fake_z2, fake_z3)\r\n",
    "app(fake_z3, fake_z4)\r\n",
    "app(fake_z4, fake_z5)\r\n",
    "app(fake_z5, fake_z1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
