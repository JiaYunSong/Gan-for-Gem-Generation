[Training] epoch:0 step:0 g_loss:0.5292433500289917 d_loss:5.456783980131149 (f_loss=0.4646059572696686 r_loss=0.5922613739967346 GP=4.399916648864746)
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2349: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  if isinstance(obj, collections.Iterator):
/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:2366: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  return list(data) if isinstance(data, collections.MappingView) else data

[Training] epoch:0 step:100 g_loss:0.388123095035553 d_loss:8.145230293273926 (f_loss=0.6172962188720703 r_loss=-0.049170494079589844 GP=7.577104568481445)
[Training] epoch:0 step:200 g_loss:0.3575437068939209 d_loss:5.042259573936462 (f_loss=0.6043471097946167 r_loss=0.36917972564697266 GP=4.068732738494873)
[Training] epoch:0 step:300 g_loss:0.2335902452468872 d_loss:5.60753720998764 (f_loss=0.8304508328437805 r_loss=0.16949617862701416 GP=4.607590198516846)
[Training] epoch:1 step:0 g_loss:0.2450655698776245 d_loss:5.757128477096558 (f_loss=0.7679362297058105 r_loss=0.29935765266418457 GP=4.6898345947265625)
[Training] epoch:1 step:100 g_loss:0.5074695348739624 d_loss:4.663362503051758 (f_loss=0.5513060092926025 r_loss=0.26556944847106934 GP=3.846487045288086)
[Training] epoch:1 step:200 g_loss:0.34592241048812866 d_loss:4.802071630954742 (f_loss=0.7203272581100464 r_loss=0.14528578519821167 GP=3.9364585876464844)
[Training] epoch:1 step:300 g_loss:0.3191186189651489 d_loss:5.334140658378601 (f_loss=0.7956764101982117 r_loss=0.2642142176628113 GP=4.274250030517578)
[Training] epoch:2 step:0 g_loss:0.3212815523147583 d_loss:5.374273836612701 (f_loss=0.7630163431167603 r_loss=0.16998380422592163 GP=4.4412736892700195)
[Training] epoch:2 step:100 g_loss:0.2399665117263794 d_loss:3.3557512760162354 (f_loss=0.6578288078308105 r_loss=0.30104804039001465 GP=2.39687442779541)
[Training] epoch:2 step:200 g_loss:0.4023244380950928 d_loss:4.223453879356384 (f_loss=0.6902695894241333 r_loss=0.25911593437194824 GP=3.2740683555603027)
[Training] epoch:2 step:300 g_loss:0.29939985275268555 d_loss:3.6851696968078613 (f_loss=0.7573237419128418 r_loss=0.0074825286865234375 GP=2.920363426208496)
[Training] epoch:3 step:0 g_loss:0.13392573595046997 d_loss:3.114818572998047 (f_loss=0.9022574424743652 r_loss=0.12193441390991211 GP=2.0906267166137695)
[Training] epoch:3 step:100 g_loss:0.2772759795188904 d_loss:2.880560278892517 (f_loss=0.6997995972633362 r_loss=0.21539098024368286 GP=1.965369701385498)
[Training] epoch:3 step:200 g_loss:0.42932093143463135 d_loss:3.379364013671875 (f_loss=0.6680941581726074 r_loss=0.4011108875274658 GP=2.3101589679718018)
[Training] epoch:3 step:300 g_loss:0.3276968002319336 d_loss:3.4870980978012085 (f_loss=0.7205183506011963 r_loss=0.3111163377761841 GP=2.455463409423828)
[Training] epoch:4 step:0 g_loss:0.4335263967514038 d_loss:2.795138895511627 (f_loss=0.6598198413848877 r_loss=0.3393862843513489 GP=1.7959327697753906)
[Training] epoch:4 step:100 g_loss:0.48266100883483887 d_loss:1.2313482463359833 (f_loss=0.5524855852127075 r_loss=0.41686850786209106 GP=0.2619941532611847)
[Training] epoch:4 step:200 g_loss:0.5261139869689941 d_loss:2.2949146032333374 (f_loss=0.5199897289276123 r_loss=0.48268842697143555 GP=1.2922364473342896)
[Training] epoch:4 step:300 g_loss:0.5229872465133667 d_loss:1.9936243891716003 (f_loss=0.4936242699623108 r_loss=0.3472698926925659 GP=1.1527302265167236)
[Training] epoch:5 step:0 g_loss:0.6050944924354553 d_loss:1.4640400409698486 (f_loss=0.5294420123100281 r_loss=0.2910293936729431 GP=0.6435686349868774)
[Training] epoch:5 step:100 g_loss:0.6268643736839294 d_loss:0.940544068813324 (f_loss=0.4333581328392029 r_loss=0.36118197441101074 GP=0.14600396156311035)
[Training] epoch:5 step:200 g_loss:0.4896739721298218 d_loss:1.5154650807380676 (f_loss=0.5861034393310547 r_loss=0.3875926733016968 GP=0.5417689681053162)
[Training] epoch:5 step:300 g_loss:0.5470973253250122 d_loss:1.2871270775794983 (f_loss=0.5745869874954224 r_loss=0.3363593816757202 GP=0.3761807084083557)
[Training] epoch:6 step:0 g_loss:0.47762835025787354 d_loss:0.9593007192015648 (f_loss=0.5202212929725647 r_loss=0.371918261051178 GP=0.06716116517782211)
[Training] epoch:6 step:100 g_loss:0.40142762660980225 d_loss:1.075555682182312 (f_loss=0.5512852668762207 r_loss=0.34575188159942627 GP=0.17851853370666504)
[Training] epoch:6 step:200 g_loss:0.4564394950866699 d_loss:1.0833547115325928 (f_loss=0.4503440856933594 r_loss=0.3875783681869507 GP=0.24543225765228271)
[Training] epoch:6 step:300 g_loss:0.49869388341903687 d_loss:1.156237781047821 (f_loss=0.5934005975723267 r_loss=0.36588460206985474 GP=0.19695258140563965)
[Training] epoch:7 step:0 g_loss:0.5158465504646301 d_loss:1.362044870853424 (f_loss=0.6022099256515503 r_loss=0.345986008644104 GP=0.4138489365577698)
[Training] epoch:7 step:100 g_loss:0.5316687822341919 d_loss:1.7044329643249512 (f_loss=0.5357767939567566 r_loss=0.35980433225631714 GP=0.8088518381118774)
[Training] epoch:7 step:200 g_loss:0.43100881576538086 d_loss:1.0414005815982819 (f_loss=0.5280592441558838 r_loss=0.1959143877029419 GP=0.3174269497394562)
[Training] epoch:7 step:300 g_loss:0.5311160087585449 d_loss:1.6510518789291382 (f_loss=0.5054932832717896 r_loss=0.31351208686828613 GP=0.8320465087890625)
[Training] epoch:8 step:0 g_loss:0.47596287727355957 d_loss:1.2440240383148193 (f_loss=0.5699419975280762 r_loss=0.22800952196121216 GP=0.446072518825531)
[Training] epoch:8 step:100 g_loss:0.4624784588813782 d_loss:1.374461680650711 (f_loss=0.5563791990280151 r_loss=0.34505748748779297 GP=0.47302499413490295)
[Training] epoch:8 step:200 g_loss:0.4574210047721863 d_loss:1.0445440113544464 (f_loss=0.5106765031814575 r_loss=0.36521416902542114 GP=0.16865333914756775)
[Training] epoch:8 step:300 g_loss:0.43209779262542725 d_loss:1.1471297070384026 (f_loss=0.6154354810714722 r_loss=0.4101487398147583 GP=0.12154548615217209)
[Training] epoch:9 step:0 g_loss:0.512628436088562 d_loss:1.3429826498031616 (f_loss=0.5369062423706055 r_loss=0.2743636965751648 GP=0.5317127108573914)
[Training] epoch:9 step:100 g_loss:0.515148401260376 d_loss:1.2800717651844025 (f_loss=0.5357525944709778 r_loss=0.32841956615448 GP=0.4158996045589447)
[Training] epoch:9 step:200 g_loss:0.4379298686981201 d_loss:1.8711734414100647 (f_loss=0.6257327795028687 r_loss=0.31702327728271484 GP=0.9284173846244812)
[Training] epoch:9 step:300 g_loss:0.3414570093154907 d_loss:1.0830366015434265 (f_loss=0.4697135388851166 r_loss=0.2338295578956604 GP=0.37949350476264954)
[Training] epoch:10 step:0 g_loss:0.5164212584495544 d_loss:1.5938621163368225 (f_loss=0.5594713091850281 r_loss=0.44919347763061523 GP=0.5851973295211792)

[Training] epoch:10 step:100 g_loss:0.40314579010009766 d_loss:1.3628024458885193 (f_loss=0.5007642507553101 r_loss=0.30849528312683105 GP=0.5535429120063782)
[Training] epoch:10 step:200 g_loss:0.4528045654296875 d_loss:1.1824322938919067 (f_loss=0.6026108264923096 r_loss=0.4242839813232422 GP=0.15553748607635498)
[Training] epoch:10 step:300 g_loss:0.4069083333015442 d_loss:1.1316227316856384 (f_loss=0.6020807027816772 r_loss=0.3320794701576233 GP=0.1974625587463379)
[Training] epoch:11 step:0 g_loss:0.5458550453186035 d_loss:1.481557011604309 (f_loss=0.557020902633667 r_loss=0.39813631772994995 GP=0.5263997912406921)
[Training] epoch:11 step:100 g_loss:0.44516634941101074 d_loss:1.5835058689117432 (f_loss=0.47810912132263184 r_loss=0.4546657204627991 GP=0.6507310271263123)
[Training] epoch:11 step:200 g_loss:0.6038488149642944 d_loss:1.3726901412010193 (f_loss=0.49981117248535156 r_loss=0.4234853982925415 GP=0.4493935704231262)
[Training] epoch:11 step:300 g_loss:0.5074663758277893 d_loss:1.5035622715950012 (f_loss=0.47982680797576904 r_loss=0.4185078740119934 GP=0.6052275896072388)
[Training] epoch:12 step:0 g_loss:0.49781227111816406 d_loss:1.3563578128814697 (f_loss=0.4477851390838623 r_loss=0.24539148807525635 GP=0.6631811857223511)
[Training] epoch:12 step:100 g_loss:0.48996782302856445 d_loss:1.827336847782135 (f_loss=0.43831247091293335 r_loss=0.29967808723449707 GP=1.0893462896347046)
[Training] epoch:12 step:200 g_loss:0.5240547060966492 d_loss:1.6424561142921448 (f_loss=0.5127550959587097 r_loss=0.18353122472763062 GP=0.9461697936058044)
[Training] epoch:12 step:300 g_loss:0.47843343019485474 d_loss:1.736040711402893 (f_loss=0.4675341844558716 r_loss=0.2664560079574585 GP=1.002050518989563)
[Training] epoch:13 step:0 g_loss:0.4432508945465088 d_loss:1.7426658272743225 (f_loss=0.5744836330413818 r_loss=0.37349361181259155 GP=0.7946885824203491)
[Training] epoch:13 step:100 g_loss:0.5753879547119141 d_loss:1.3394426703453064 (f_loss=0.49975043535232544 r_loss=0.41201746463775635 GP=0.4276747703552246)
[Training] epoch:13 step:200 g_loss:0.5271984934806824 d_loss:1.4522202610969543 (f_loss=0.49772512912750244 r_loss=0.3508147597312927 GP=0.6036803722381592)
[Training] epoch:13 step:300 g_loss:0.41792798042297363 d_loss:1.5592436790466309 (f_loss=0.6132291555404663 r_loss=0.2436680793762207 GP=0.7023464441299438)
[Training] epoch:14 step:0 g_loss:0.4330461025238037 d_loss:1.9079738855361938 (f_loss=0.451873779296875 r_loss=0.2736161947250366 GP=1.1824839115142822)
[Training] epoch:14 step:100 g_loss:0.5139789581298828 d_loss:1.7505881488323212 (f_loss=0.44215521216392517 r_loss=0.40270447731018066 GP=0.9057284593582153)
[Training] epoch:14 step:200 g_loss:0.34919440746307373 d_loss:1.5530943870544434 (f_loss=0.48048341274261475 r_loss=0.12360376119613647 GP=0.9490072131156921)
[Training] epoch:14 step:300 g_loss:0.5282102227210999 d_loss:1.2264391481876373 (f_loss=0.4469890296459198 r_loss=0.4252226948738098 GP=0.3542274236679077)
[Training] epoch:15 step:0 g_loss:0.5343979597091675 d_loss:1.526001125574112 (f_loss=0.48948684334754944 r_loss=0.44866716861724854 GP=0.587847113609314)
[Training] epoch:15 step:100 g_loss:0.48792970180511475 d_loss:1.3345583081245422 (f_loss=0.5635644793510437 r_loss=0.40020108222961426 GP=0.3707927465438843)
[Training] epoch:15 step:200 g_loss:0.4215431213378906 d_loss:1.4983686804771423 (f_loss=0.46015244722366333 r_loss=0.3869743347167969 GP=0.6512418985366821)
[Training] epoch:15 step:300 g_loss:0.513706624507904 d_loss:1.5765118598937988 (f_loss=0.5202910900115967 r_loss=0.23092710971832275 GP=0.8252936601638794)
[Training] epoch:16 step:0 g_loss:0.3469691872596741 d_loss:1.4266071319580078 (f_loss=0.5615760087966919 r_loss=0.23216503858566284 GP=0.6328660845756531)
[Training] epoch:16 step:100 g_loss:0.5309637188911438 d_loss:2.0399431586265564 (f_loss=0.5050022602081299 r_loss=0.4562620520591736 GP=1.078678846359253)
[Training] epoch:16 step:200 g_loss:0.5149918794631958 d_loss:1.8809695839881897 (f_loss=0.37919092178344727 r_loss=0.4763551354408264 GP=1.025423526763916)
[Training] epoch:16 step:300 g_loss:0.5500903129577637 d_loss:1.5215156078338623 (f_loss=0.5785058736801147 r_loss=0.32878410816192627 GP=0.6142256259918213)
[Training] epoch:17 step:0 g_loss:0.6208614110946655 d_loss:1.9791686832904816 (f_loss=0.4463447630405426 r_loss=0.42824089527130127 GP=1.1045830249786377)
[Training] epoch:17 step:100 g_loss:0.5065016746520996 d_loss:1.358236014842987 (f_loss=0.48837053775787354 r_loss=0.3745521306991577 GP=0.4953133463859558)
[Training] epoch:17 step:200 g_loss:0.3972353935241699 d_loss:1.3111144304275513 (f_loss=0.6120823621749878 r_loss=0.3591587543487549 GP=0.3398733139038086)
[Training] epoch:17 step:300 g_loss:0.5865741968154907 d_loss:1.1317367553710938 (f_loss=0.4399978816509247 r_loss=0.4239802360534668 GP=0.26775863766670227)
[Training] epoch:18 step:0 g_loss:0.4849637746810913 d_loss:1.358805000782013 (f_loss=0.47290539741516113 r_loss=0.3186589479446411 GP=0.5672406554222107)
[Training] epoch:18 step:100 g_loss:0.4682999849319458 d_loss:1.355404108762741 (f_loss=0.514721155166626 r_loss=0.347378671169281 GP=0.4933042824268341)
[Training] epoch:18 step:200 g_loss:0.6012163758277893 d_loss:1.2805753350257874 (f_loss=0.42325228452682495 r_loss=0.5037764310836792 GP=0.3535466194152832)
[Training] epoch:18 step:300 g_loss:0.5917240977287292 d_loss:1.226064682006836 (f_loss=0.45893725752830505 r_loss=0.4467087984085083 GP=0.3204186260700226)
[Training] epoch:19 step:0 g_loss:0.5323549509048462 d_loss:1.395407885313034 (f_loss=0.4501746594905853 r_loss=0.3931072950363159 GP=0.5521259307861328)
[Training] epoch:19 step:100 g_loss:0.4260387420654297 d_loss:1.939560353755951 (f_loss=0.6158258318901062 r_loss=0.33222365379333496 GP=0.9915108680725098)
[Training] epoch:19 step:200 g_loss:0.4433214068412781 d_loss:1.437407910823822 (f_loss=0.47923195362091064 r_loss=0.3899421691894531 GP=0.5682337880134583)
[Training] epoch:19 step:300 g_loss:0.5237774848937988 d_loss:1.4058227837085724 (f_loss=0.4910919964313507 r_loss=0.3616623282432556 GP=0.5530684590339661)
[Training] epoch:20 step:0 g_loss:0.45252281427383423 d_loss:1.4785752594470978 (f_loss=0.4575102627277374 r_loss=0.4587774872779846 GP=0.5622875094413757)

[Training] epoch:20 step:100 g_loss:0.49814915657043457 d_loss:1.6796876192092896 (f_loss=0.5093278884887695 r_loss=0.401536226272583 GP=0.768823504447937)
[Training] epoch:20 step:200 g_loss:0.5331230759620667 d_loss:1.562076449394226 (f_loss=0.4998847246170044 r_loss=0.3488615155220032 GP=0.7133302092552185)
[Training] epoch:20 step:300 g_loss:0.4639197587966919 d_loss:1.65470951795578 (f_loss=0.5609574317932129 r_loss=0.46904122829437256 GP=0.6247108578681946)
[Training] epoch:21 step:0 g_loss:0.5652973651885986 d_loss:1.1535146534442902 (f_loss=0.43082931637763977 r_loss=0.4574882984161377 GP=0.2651970386505127)
[Training] epoch:21 step:100 g_loss:0.44340330362319946 d_loss:1.4181066453456879 (f_loss=0.5184900760650635 r_loss=0.4005088806152344 GP=0.49910768866539)
[Training] epoch:21 step:200 g_loss:0.5097600221633911 d_loss:1.0738673955202103 (f_loss=0.5460277795791626 r_loss=0.38521361351013184 GP=0.14262600243091583)
[Training] epoch:21 step:300 g_loss:0.48085612058639526 d_loss:1.294666826725006 (f_loss=0.4710966944694519 r_loss=0.4588988423347473 GP=0.3646712899208069)
[Training] epoch:22 step:0 g_loss:0.5103691816329956 d_loss:0.9414938688278198 (f_loss=0.509634256362915 r_loss=0.2706958055496216 GP=0.1611638069152832)
[Training] epoch:22 step:100 g_loss:0.478809654712677 d_loss:1.1694364547729492 (f_loss=0.489249587059021 r_loss=0.4111180305480957 GP=0.2690688371658325)
[Training] epoch:22 step:200 g_loss:0.5466731786727905 d_loss:1.9423234462738037 (f_loss=0.5429656505584717 r_loss=0.3944889307022095 GP=1.0048688650131226)
[Training] epoch:22 step:300 g_loss:0.5280904769897461 d_loss:1.6748061180114746 (f_loss=0.5206865072250366 r_loss=0.3740706443786621 GP=0.7800489664077759)
[Training] epoch:23 step:0 g_loss:0.42603880167007446 d_loss:1.4952332973480225 (f_loss=0.53886878490448 r_loss=0.30808234214782715 GP=0.6482821702957153)
[Training] epoch:23 step:100 g_loss:0.5254981517791748 d_loss:1.2332918047904968 (f_loss=0.5865098237991333 r_loss=0.3921346664428711 GP=0.25464731454849243)
[Training] epoch:23 step:200 g_loss:0.5128530263900757 d_loss:1.1103665232658386 (f_loss=0.5136541128158569 r_loss=0.32485735416412354 GP=0.27185505628585815)
[Training] epoch:23 step:300 g_loss:0.46559131145477295 d_loss:1.1235156059265137 (f_loss=0.47097519040107727 r_loss=0.38249510526657104 GP=0.27004531025886536)
[Training] epoch:24 step:0 g_loss:0.5367615818977356 d_loss:1.2027749419212341 (f_loss=0.5298792123794556 r_loss=0.3720189929008484 GP=0.3008767366409302)
[Training] epoch:24 step:100 g_loss:0.510541558265686 d_loss:1.4194223880767822 (f_loss=0.553768515586853 r_loss=0.39518487453460693 GP=0.47046899795532227)
[Training] epoch:24 step:200 g_loss:0.43531107902526855 d_loss:1.0860996097326279 (f_loss=0.5514389276504517 r_loss=0.375857949256897 GP=0.15880273282527924)
[Training] epoch:24 step:300 g_loss:0.5106274485588074 d_loss:1.2811173498630524 (f_loss=0.46576038002967834 r_loss=0.35077595710754395 GP=0.4645810127258301)
[Training] epoch:25 step:0 g_loss:0.47261834144592285 d_loss:1.2272995114326477 (f_loss=0.5764286518096924 r_loss=0.39339756965637207 GP=0.25747328996658325)
[Training] epoch:25 step:100 g_loss:0.4879673719406128 d_loss:1.5305474996566772 (f_loss=0.5001482367515564 r_loss=0.32398557662963867 GP=0.7064136862754822)
[Training] epoch:25 step:200 g_loss:0.564084529876709 d_loss:1.094579592347145 (f_loss=0.45456579327583313 r_loss=0.43966710567474365 GP=0.2003466933965683)
[Training] epoch:25 step:300 g_loss:0.43019986152648926 d_loss:1.4531433284282684 (f_loss=0.6757699251174927 r_loss=0.36948955059051514 GP=0.4078838527202606)
[Training] epoch:26 step:0 g_loss:0.5729180574417114 d_loss:1.7836514711380005 (f_loss=0.41114532947540283 r_loss=0.4736795425415039 GP=0.8988265991210938)
[Training] epoch:26 step:100 g_loss:0.5602538585662842 d_loss:1.539265751838684 (f_loss=0.4927341938018799 r_loss=0.3899638056755066 GP=0.6565677523612976)
[Training] epoch:26 step:200 g_loss:0.4518435001373291 d_loss:1.3621939420700073 (f_loss=0.576376736164093 r_loss=0.4471321702003479 GP=0.3386850357055664)
[Training] epoch:26 step:300 g_loss:0.48199015855789185 d_loss:1.089534118771553 (f_loss=0.5265154242515564 r_loss=0.36269283294677734 GP=0.2003258615732193)
[Training] epoch:27 step:0 g_loss:0.4722871780395508 d_loss:1.1459621638059616 (f_loss=0.4671769142150879 r_loss=0.46693456172943115 GP=0.21185068786144257)
[Training] epoch:27 step:100 g_loss:0.4296641945838928 d_loss:1.3732055127620697 (f_loss=0.5131990313529968 r_loss=0.4220985770225525 GP=0.4379079043865204)
[Training] epoch:27 step:200 g_loss:0.5494754314422607 d_loss:1.1995803713798523 (f_loss=0.45509999990463257 r_loss=0.4088306427001953 GP=0.3356497287750244)
[Training] epoch:27 step:300 g_loss:0.5415887832641602 d_loss:1.1487175524234772 (f_loss=0.5701988935470581 r_loss=0.35236823558807373 GP=0.22615042328834534)
[Training] epoch:28 step:0 g_loss:0.5431131720542908 d_loss:1.4451751410961151 (f_loss=0.38927820324897766 r_loss=0.4740496873855591 GP=0.5818472504615784)
[Training] epoch:28 step:100 g_loss:0.5406571626663208 d_loss:1.2115477323532104 (f_loss=0.49305206537246704 r_loss=0.3668217658996582 GP=0.3516739010810852)
[Training] epoch:28 step:200 g_loss:0.5598793029785156 d_loss:1.0347983539104462 (f_loss=0.4748362600803375 r_loss=0.4027450680732727 GP=0.15721702575683594)
[Training] epoch:28 step:300 g_loss:0.49894440174102783 d_loss:1.4690852761268616 (f_loss=0.5064592957496643 r_loss=0.512980043888092 GP=0.4496459364891052)
[Training] epoch:29 step:0 g_loss:0.48856890201568604 d_loss:1.4793956279754639 (f_loss=0.4938114583492279 r_loss=0.49801939725875854 GP=0.4875647723674774)
[Training] epoch:29 step:100 g_loss:0.533562421798706 d_loss:2.4019516706466675 (f_loss=0.4328595995903015 r_loss=0.4215936064720154 GP=1.5474984645843506)
[Training] epoch:29 step:200 g_loss:0.5658054351806641 d_loss:1.6839931011199951 (f_loss=0.5456472635269165 r_loss=0.5034685134887695 GP=0.6348773241043091)
[Training] epoch:29 step:300 g_loss:0.47197920083999634 d_loss:1.1462588161230087 (f_loss=0.5245426893234253 r_loss=0.3802495002746582 GP=0.24146662652492523)
[Training] epoch:30 step:0 g_loss:0.4955723285675049 d_loss:2.105315238237381 (f_loss=0.4279387295246124 r_loss=0.4656111001968384 GP=1.2117654085159302)

[Training] epoch:30 step:100 g_loss:0.46919530630111694 d_loss:1.1651614308357239 (f_loss=0.525374710559845 r_loss=0.3719066381454468 GP=0.26788008213043213)
[Training] epoch:30 step:200 g_loss:0.5060763359069824 d_loss:1.5710791945457458 (f_loss=0.43980884552001953 r_loss=0.4408603310585022 GP=0.6904100179672241)
[Training] epoch:30 step:300 g_loss:0.5448927879333496 d_loss:1.697601079940796 (f_loss=0.4818826913833618 r_loss=0.5025783777236938 GP=0.7131400108337402)
[Training] epoch:31 step:0 g_loss:0.46893632411956787 d_loss:1.262075662612915 (f_loss=0.4592643976211548 r_loss=0.4496629238128662 GP=0.35314834117889404)
[Training] epoch:31 step:100 g_loss:0.5765571594238281 d_loss:1.1643125414848328 (f_loss=0.45243164896965027 r_loss=0.4656869173049927 GP=0.24619397521018982)
[Training] epoch:31 step:200 g_loss:0.5317014455795288 d_loss:1.1416703909635544 (f_loss=0.4494253396987915 r_loss=0.46604281663894653 GP=0.22620223462581635)
[Training] epoch:31 step:300 g_loss:0.4593302011489868 d_loss:1.4779152274131775 (f_loss=0.463299036026001 r_loss=0.383384644985199 GP=0.6312315464019775)
[Training] epoch:32 step:0 g_loss:0.5273439884185791 d_loss:1.1468630731105804 (f_loss=0.48092564940452576 r_loss=0.42290765047073364 GP=0.24302977323532104)
[Training] epoch:32 step:100 g_loss:0.4448114037513733 d_loss:1.4464781880378723 (f_loss=0.5720640420913696 r_loss=0.40551185607910156 GP=0.4689022898674011)
[Training] epoch:32 step:200 g_loss:0.5083203315734863 d_loss:1.617612898349762 (f_loss=0.5775033235549927 r_loss=0.35550224781036377 GP=0.6846073269844055)
[Training] epoch:32 step:300 g_loss:0.46802735328674316 d_loss:1.5005218386650085 (f_loss=0.47164350748062134 r_loss=0.39690399169921875 GP=0.6319743394851685)
[Training] epoch:33 step:0 g_loss:0.44744640588760376 d_loss:1.49113330245018 (f_loss=0.48223644495010376 r_loss=0.5218385457992554 GP=0.4870583117008209)
[Training] epoch:33 step:100 g_loss:0.47204387187957764 d_loss:1.322390854358673 (f_loss=0.5230836868286133 r_loss=0.42435020208358765 GP=0.37495696544647217)
[Training] epoch:33 step:200 g_loss:0.4704452157020569 d_loss:1.1291715502738953 (f_loss=0.5635515451431274 r_loss=0.41706138849258423 GP=0.1485586166381836)
[Training] epoch:33 step:300 g_loss:0.46744322776794434 d_loss:0.9942595660686493 (f_loss=0.5565264821052551 r_loss=0.3654884099960327 GP=0.07224467396736145)
[Training] epoch:34 step:0 g_loss:0.44138383865356445 d_loss:1.3134011924266815 (f_loss=0.524668276309967 r_loss=0.365639328956604 GP=0.4230935871601105)
[Training] epoch:34 step:100 g_loss:0.5196052193641663 d_loss:1.4492771923542023 (f_loss=0.5044339299201965 r_loss=0.4758128523826599 GP=0.4690304100513458)
[Training] epoch:34 step:200 g_loss:0.40985333919525146 d_loss:1.5881001949310303 (f_loss=0.594756007194519 r_loss=0.4066689610481262 GP=0.586675226688385)
[Training] epoch:34 step:300 g_loss:0.49998384714126587 d_loss:1.4936134219169617 (f_loss=0.5341281890869141 r_loss=0.42709797620773315 GP=0.5323872566223145)
[Training] epoch:35 step:0 g_loss:0.5515845417976379 d_loss:1.048687756061554 (f_loss=0.503356397151947 r_loss=0.3913416862487793 GP=0.15398967266082764)
[Training] epoch:35 step:100 g_loss:0.5424456596374512 d_loss:1.348893404006958 (f_loss=0.4624648690223694 r_loss=0.5021452903747559 GP=0.38428324460983276)
[Training] epoch:35 step:200 g_loss:0.4066389203071594 d_loss:1.1356840431690216 (f_loss=0.5880072116851807 r_loss=0.3766072988510132 GP=0.17106953263282776)
[Training] epoch:35 step:300 g_loss:0.4148179292678833 d_loss:1.3850075006484985 (f_loss=0.5384836196899414 r_loss=0.4570894241333008 GP=0.38943445682525635)
[Training] epoch:36 step:0 g_loss:0.5489135980606079 d_loss:1.5191676616668701 (f_loss=0.4856039881706238 r_loss=0.3206574320793152 GP=0.7129062414169312)
[Training] epoch:36 step:100 g_loss:0.5333463549613953 d_loss:1.5872742533683777 (f_loss=0.5065116286277771 r_loss=0.5597079992294312 GP=0.5210546255111694)
[Training] epoch:36 step:200 g_loss:0.47933781147003174 d_loss:1.2955958843231201 (f_loss=0.4477768540382385 r_loss=0.39133626222610474 GP=0.45648276805877686)
[Training] epoch:36 step:300 g_loss:0.5527615547180176 d_loss:1.118664562702179 (f_loss=0.48685556650161743 r_loss=0.3321484923362732 GP=0.29966050386428833)
[Training] epoch:37 step:0 g_loss:0.48273730278015137 d_loss:1.136908382177353 (f_loss=0.45511168241500854 r_loss=0.45021510124206543 GP=0.23158159852027893)
[Training] epoch:37 step:100 g_loss:0.548821747303009 d_loss:1.0380388498306274 (f_loss=0.46269145607948303 r_loss=0.3886346220970154 GP=0.18671277165412903)
[Training] epoch:37 step:200 g_loss:0.5027095079421997 d_loss:1.218396544456482 (f_loss=0.4380594491958618 r_loss=0.4735782742500305 GP=0.3067588210105896)
[Training] epoch:37 step:300 g_loss:0.49756306409835815 d_loss:1.7146846055984497 (f_loss=0.5303205847740173 r_loss=0.461883544921875 GP=0.7224804759025574)
[Training] epoch:38 step:0 g_loss:0.5077404975891113 d_loss:1.1169637590646744 (f_loss=0.5425556898117065 r_loss=0.349240779876709 GP=0.22516728937625885)
[Training] epoch:38 step:100 g_loss:0.5391435027122498 d_loss:1.1663632988929749 (f_loss=0.4577518403530121 r_loss=0.43382447957992554 GP=0.27478697896003723)
[Training] epoch:38 step:200 g_loss:0.5936208367347717 d_loss:1.0393462479114532 (f_loss=0.46591898798942566 r_loss=0.37009525299072266 GP=0.20333200693130493)
[Training] epoch:38 step:300 g_loss:0.5412631034851074 d_loss:1.38637113571167 (f_loss=0.4897955656051636 r_loss=0.46414053440093994 GP=0.4324350357055664)
[Training] epoch:39 step:0 g_loss:0.4713456630706787 d_loss:1.4933542609214783 (f_loss=0.5194153785705566 r_loss=0.40025222301483154 GP=0.5736866593360901)
[Training] epoch:39 step:100 g_loss:0.534247636795044 d_loss:1.096037745475769 (f_loss=0.487395703792572 r_loss=0.441178560256958 GP=0.167463481426239)
[Training] epoch:39 step:200 g_loss:0.5524164438247681 d_loss:1.1046538949012756 (f_loss=0.4825468063354492 r_loss=0.4576239585876465 GP=0.16448312997817993)
[Training] epoch:39 step:300 g_loss:0.47600293159484863 d_loss:1.5263921022415161 (f_loss=0.4574577212333679 r_loss=0.4995359182357788 GP=0.5693984627723694)
[Training] epoch:40 step:0 g_loss:0.5450476408004761 d_loss:1.293294757604599 (f_loss=0.4727228879928589 r_loss=0.4998124837875366 GP=0.3207593858242035)

[Training] epoch:40 step:100 g_loss:0.5523143410682678 d_loss:1.2210205495357513 (f_loss=0.4348151981830597 r_loss=0.417012095451355 GP=0.36919325590133667)
[Training] epoch:40 step:200 g_loss:0.5425124168395996 d_loss:1.091217890381813 (f_loss=0.5266014337539673 r_loss=0.4360969066619873 GP=0.12851954996585846)
[Training] epoch:40 step:300 g_loss:0.5615513920783997 d_loss:1.0614809319376945 (f_loss=0.48976579308509827 r_loss=0.4894235134124756 GP=0.0822916254401207)
[Training] epoch:41 step:0 g_loss:0.4903959631919861 d_loss:1.3282630443572998 (f_loss=0.5409753322601318 r_loss=0.4173954725265503 GP=0.3698922395706177)
[Training] epoch:41 step:100 g_loss:0.4950904846191406 d_loss:1.0878244191408157 (f_loss=0.5213077664375305 r_loss=0.4485970735549927 GP=0.11791957914829254)
[Training] epoch:41 step:200 g_loss:0.5259398818016052 d_loss:1.5754157602787018 (f_loss=0.47141584753990173 r_loss=0.4768136739730835 GP=0.6271862387657166)
[Training] epoch:41 step:300 g_loss:0.4418145418167114 d_loss:1.1629768311977386 (f_loss=0.5127267241477966 r_loss=0.4853023290634155 GP=0.1649477779865265)
[Training] epoch:42 step:0 g_loss:0.49889183044433594 d_loss:1.130661979317665 (f_loss=0.5382471680641174 r_loss=0.45412468910217285 GP=0.13829012215137482)
[Training] epoch:42 step:100 g_loss:0.5193082094192505 d_loss:0.9702142477035522 (f_loss=0.4704406261444092 r_loss=0.43413859605789185 GP=0.06563502550125122)
[Training] epoch:42 step:200 g_loss:0.5534535646438599 d_loss:1.209546521306038 (f_loss=0.4894949197769165 r_loss=0.5019379258155823 GP=0.21811367571353912)
[Training] epoch:42 step:300 g_loss:0.502094030380249 d_loss:1.061792939901352 (f_loss=0.4530049264431 r_loss=0.4525046944618225 GP=0.15628331899642944)
[Training] epoch:43 step:0 g_loss:0.4482974410057068 d_loss:1.5942760109901428 (f_loss=0.5226427316665649 r_loss=0.45199525356292725 GP=0.6196380257606506)
[Training] epoch:43 step:100 g_loss:0.5007436871528625 d_loss:1.74332395195961 (f_loss=0.4884265959262848 r_loss=0.4288487434387207 GP=0.8260486125946045)
[Training] epoch:43 step:200 g_loss:0.4971783757209778 d_loss:1.2280560433864594 (f_loss=0.44839075207710266 r_loss=0.4382091164588928 GP=0.34145617485046387)
[Training] epoch:43 step:300 g_loss:0.5859524011611938 d_loss:1.456319510936737 (f_loss=0.4854760766029358 r_loss=0.4198461174964905 GP=0.5509973168373108)
[Training] epoch:44 step:0 g_loss:0.5134140253067017 d_loss:1.981865108013153 (f_loss=0.5766900777816772 r_loss=0.461780846118927 GP=0.9433941841125488)
[Training] epoch:44 step:100 g_loss:0.5154801607131958 d_loss:1.0012290105223656 (f_loss=0.455377459526062 r_loss=0.47469067573547363 GP=0.07116087526082993)
[Training] epoch:44 step:200 g_loss:0.5768883228302002 d_loss:1.1746384501457214 (f_loss=0.48732754588127136 r_loss=0.4951120615005493 GP=0.19219884276390076)
[Training] epoch:44 step:300 g_loss:0.5098771452903748 d_loss:1.4143181443214417 (f_loss=0.5322636365890503 r_loss=0.4535362124443054 GP=0.42851829528808594)
[Training] epoch:45 step:0 g_loss:0.5441650748252869 d_loss:1.7041451334953308 (f_loss=0.4952583312988281 r_loss=0.4664430618286133 GP=0.7424437403678894)
[Training] epoch:45 step:100 g_loss:0.5571364760398865 d_loss:1.286344438791275 (f_loss=0.4701727628707886 r_loss=0.47319579124450684 GP=0.3429758846759796)
[Training] epoch:45 step:200 g_loss:0.5121134519577026 d_loss:1.184979796409607 (f_loss=0.45132750272750854 r_loss=0.4665257930755615 GP=0.26712650060653687)
[Training] epoch:45 step:300 g_loss:0.52485191822052 d_loss:1.5479836463928223 (f_loss=0.4631795287132263 r_loss=0.43651360273361206 GP=0.6482905149459839)
[Training] epoch:46 step:0 g_loss:0.5119338035583496 d_loss:1.8605278730392456 (f_loss=0.511249303817749 r_loss=0.4378165006637573 GP=0.9114620685577393)
[Training] epoch:46 step:100 g_loss:0.5660565495491028 d_loss:1.3655742406845093 (f_loss=0.5424916744232178 r_loss=0.5207923054695129 GP=0.30229026079177856)
[Training] epoch:46 step:200 g_loss:0.47385549545288086 d_loss:1.1349922865629196 (f_loss=0.4779803156852722 r_loss=0.49264025688171387 GP=0.16437171399593353)
[Training] epoch:46 step:300 g_loss:0.5641355514526367 d_loss:1.1161357909440994 (f_loss=0.4624423682689667 r_loss=0.5517225861549377 GP=0.10197083652019501)
[Training] epoch:47 step:0 g_loss:0.5536267757415771 d_loss:1.4498711824417114 (f_loss=0.4698179364204407 r_loss=0.4108997583389282 GP=0.5691534876823425)
[Training] epoch:47 step:100 g_loss:0.4790303707122803 d_loss:1.3694410920143127 (f_loss=0.511089563369751 r_loss=0.5227349996566772 GP=0.3356165289878845)
[Training] epoch:47 step:200 g_loss:0.5767499208450317 d_loss:1.0280936732888222 (f_loss=0.4919329285621643 r_loss=0.4668560028076172 GP=0.06930474191904068)
[Training] epoch:47 step:300 g_loss:0.5201734304428101 d_loss:1.426048457622528 (f_loss=0.5678062438964844 r_loss=0.5224292278289795 GP=0.3358129858970642)
[Training] epoch:48 step:0 g_loss:0.45758455991744995 d_loss:1.074296995997429 (f_loss=0.5172700881958008 r_loss=0.43547552824020386 GP=0.12155137956142426)
[Training] epoch:48 step:100 g_loss:0.5244371891021729 d_loss:1.2103393375873566 (f_loss=0.5193067193031311 r_loss=0.4496062994003296 GP=0.24142631888389587)
[Training] epoch:48 step:200 g_loss:0.504595935344696 d_loss:1.0519431233406067 (f_loss=0.496528297662735 r_loss=0.44253671169281006 GP=0.11287811398506165)
[Training] epoch:48 step:300 g_loss:0.47448301315307617 d_loss:1.2487350404262543 (f_loss=0.4920724928379059 r_loss=0.40494656562805176 GP=0.35171598196029663)
[Training] epoch:49 step:0 g_loss:0.47409719228744507 d_loss:1.2415077239274979 (f_loss=0.5203284025192261 r_loss=0.49182355403900146 GP=0.22935576736927032)
[Training] epoch:49 step:100 g_loss:0.5212104320526123 d_loss:1.2009772956371307 (f_loss=0.5179607272148132 r_loss=0.5381311774253845 GP=0.14488539099693298)
[Training] epoch:49 step:200 g_loss:0.4821624159812927 d_loss:1.8702203333377838 (f_loss=0.48676666617393494 r_loss=0.5001322627067566 GP=0.8833214044570923)
[Training] epoch:49 step:300 g_loss:0.4694557189941406 d_loss:1.1058961302042007 (f_loss=0.4538579285144806 r_loss=0.5087608098983765 GP=0.1432773917913437)
[Training] epoch:50 step:0 g_loss:0.5260583162307739 d_loss:1.6346938908100128 (f_loss=0.480605810880661 r_loss=0.5195379257202148 GP=0.634550154209137)

[Training] epoch:50 step:100 g_loss:0.46535682678222656 d_loss:1.2728703320026398 (f_loss=0.5291786193847656 r_loss=0.48571866750717163 GP=0.2579730451107025)
[Training] epoch:50 step:200 g_loss:0.5077575445175171 d_loss:1.1320464611053467 (f_loss=0.49602389335632324 r_loss=0.4168633222579956 GP=0.21915924549102783)
[Training] epoch:50 step:300 g_loss:0.5082755088806152 d_loss:1.309053361415863 (f_loss=0.5483579635620117 r_loss=0.46903133392333984 GP=0.2916640639305115)
[Training] epoch:51 step:0 g_loss:0.5477423071861267 d_loss:1.7365518808364868 (f_loss=0.5063336491584778 r_loss=0.4786507487297058 GP=0.7515674829483032)
[Training] epoch:51 step:100 g_loss:0.5046866536140442 d_loss:1.0298423767089844 (f_loss=0.4645403325557709 r_loss=0.42399823665618896 GP=0.14130380749702454)
[Training] epoch:51 step:200 g_loss:0.5047715306282043 d_loss:1.1470672190189362 (f_loss=0.46827468276023865 r_loss=0.5181906223297119 GP=0.1606019139289856)
[Training] epoch:51 step:300 g_loss:0.5176953077316284 d_loss:1.121281623840332 (f_loss=0.44531774520874023 r_loss=0.5735336542129517 GP=0.10243022441864014)
[Training] epoch:52 step:0 g_loss:0.5292835831642151 d_loss:1.1641965210437775 (f_loss=0.5029646158218384 r_loss=0.38726896047592163 GP=0.27396294474601746)
[Training] epoch:52 step:100 g_loss:0.4753885865211487 d_loss:1.5415123403072357 (f_loss=0.5687857270240784 r_loss=0.48157304525375366 GP=0.4911535680294037)
[Training] epoch:52 step:200 g_loss:0.5294913053512573 d_loss:1.1595138311386108 (f_loss=0.46036583185195923 r_loss=0.4460577964782715 GP=0.2530902028083801)
[Training] epoch:52 step:300 g_loss:0.4964485764503479 d_loss:1.802415668964386 (f_loss=0.48602616786956787 r_loss=0.3972346782684326 GP=0.9191548228263855)
[Training] epoch:53 step:0 g_loss:0.5509693622589111 d_loss:1.116894170641899 (f_loss=0.5265818238258362 r_loss=0.46030473709106445 GP=0.13000760972499847)
[Training] epoch:53 step:100 g_loss:0.5214301347732544 d_loss:1.3133103251457214 (f_loss=0.45057278871536255 r_loss=0.5147488713264465 GP=0.34798866510391235)
[Training] epoch:53 step:200 g_loss:0.5251177549362183 d_loss:1.184497445821762 (f_loss=0.48441338539123535 r_loss=0.4865298867225647 GP=0.21355417370796204)
[Training] epoch:53 step:300 g_loss:0.5061506032943726 d_loss:1.4205161929130554 (f_loss=0.47310739755630493 r_loss=0.40914618968963623 GP=0.5382626056671143)
[Training] epoch:54 step:0 g_loss:0.5425235033035278 d_loss:1.194702759385109 (f_loss=0.4809853434562683 r_loss=0.5132254958152771 GP=0.20049192011356354)
[Training] epoch:54 step:100 g_loss:0.5428668856620789 d_loss:1.0731552615761757 (f_loss=0.46202850341796875 r_loss=0.49703627824783325 GP=0.11409047991037369)
[Training] epoch:54 step:200 g_loss:0.552384614944458 d_loss:1.4700159132480621 (f_loss=0.457457572221756 r_loss=0.5459866523742676 GP=0.4665716886520386)
[Training] epoch:54 step:300 g_loss:0.5833789110183716 d_loss:1.3275303542613983 (f_loss=0.4491225481033325 r_loss=0.45882511138916016 GP=0.41958269476890564)
[Training] epoch:55 step:0 g_loss:0.5451349020004272 d_loss:1.186114341020584 (f_loss=0.4611518085002899 r_loss=0.42695796489715576 GP=0.2980045676231384)
[Training] epoch:55 step:100 g_loss:0.5327582359313965 d_loss:1.0999914109706879 (f_loss=0.4582856595516205 r_loss=0.46683984994888306 GP=0.17486590147018433)
[Training] epoch:55 step:200 g_loss:0.4794660806655884 d_loss:1.1413343250751495 (f_loss=0.5071612596511841 r_loss=0.4689158797264099 GP=0.16525718569755554)
[Training] epoch:55 step:300 g_loss:0.4795374274253845 d_loss:1.1103716790676117 (f_loss=0.44051361083984375 r_loss=0.5326154232025146 GP=0.1372426450252533)
[Training] epoch:56 step:0 g_loss:0.5154074430465698 d_loss:1.304640918970108 (f_loss=0.5082072019577026 r_loss=0.3937208652496338 GP=0.4027128517627716)
[Training] epoch:56 step:100 g_loss:0.4970588684082031 d_loss:1.081761509180069 (f_loss=0.48126253485679626 r_loss=0.503442108631134 GP=0.09705686569213867)
[Training] epoch:56 step:200 g_loss:0.5317423939704895 d_loss:1.3063145577907562 (f_loss=0.49285709857940674 r_loss=0.5066264271736145 GP=0.306831032037735)
[Training] epoch:56 step:300 g_loss:0.49411505460739136 d_loss:1.5294854938983917 (f_loss=0.4848628342151642 r_loss=0.4451119303703308 GP=0.5995107293128967)
[Training] epoch:57 step:0 g_loss:0.47911638021469116 d_loss:1.2157407253980637 (f_loss=0.5178623199462891 r_loss=0.530311107635498 GP=0.16756729781627655)
[Training] epoch:57 step:100 g_loss:0.49648869037628174 d_loss:1.1931634694337845 (f_loss=0.4877202808856964 r_loss=0.45910942554473877 GP=0.2463337630033493)
[Training] epoch:57 step:200 g_loss:0.48330211639404297 d_loss:1.804005652666092 (f_loss=0.4842471182346344 r_loss=0.4565512537956238 GP=0.8632072806358337)
[Training] epoch:57 step:300 g_loss:0.5574806332588196 d_loss:1.1769693940877914 (f_loss=0.4664019048213959 r_loss=0.4816059470176697 GP=0.2289615422487259)
[Training] epoch:58 step:0 g_loss:0.5135834217071533 d_loss:1.1682987809181213 (f_loss=0.5028939247131348 r_loss=0.47507035732269287 GP=0.1903344988822937)
[Training] epoch:58 step:100 g_loss:0.5527907609939575 d_loss:1.1300219893455505 (f_loss=0.5014650821685791 r_loss=0.5236579775810242 GP=0.10489892959594727)
[Training] epoch:58 step:200 g_loss:0.46849870681762695 d_loss:1.1291163265705109 (f_loss=0.5096739530563354 r_loss=0.4591236114501953 GP=0.1603187620639801)
[Training] epoch:58 step:300 g_loss:0.49742573499679565 d_loss:0.9817148447036743 (f_loss=0.46134069561958313 r_loss=0.4259396195411682 GP=0.09443452954292297)
[Training] epoch:59 step:0 g_loss:0.46256422996520996 d_loss:1.3461066782474518 (f_loss=0.5789433717727661 r_loss=0.45985740423202515 GP=0.3073059022426605)
[Training] epoch:59 step:100 g_loss:0.5214715003967285 d_loss:1.0934405028820038 (f_loss=0.46283113956451416 r_loss=0.470298707485199 GP=0.16031065583229065)
[Training] epoch:59 step:200 g_loss:0.5660898685455322 d_loss:1.1270285248756409 (f_loss=0.48289206624031067 r_loss=0.5208804607391357 GP=0.12325599789619446)
[Training] epoch:59 step:300 g_loss:0.5414127707481384 d_loss:1.2830109596252441 (f_loss=0.45281076431274414 r_loss=0.4954395890235901 GP=0.3347606062889099)
[Training] epoch:60 step:0 g_loss:0.6359377503395081 d_loss:1.325307697057724 (f_loss=0.4978705942630768 r_loss=0.46967822313308716 GP=0.35775887966156006)

[Training] epoch:60 step:100 g_loss:0.5147996544837952 d_loss:1.1774893552064896 (f_loss=0.5070397257804871 r_loss=0.5287481546401978 GP=0.14170147478580475)
[Training] epoch:60 step:200 g_loss:0.5166672468185425 d_loss:1.221153438091278 (f_loss=0.48515182733535767 r_loss=0.5036553144454956 GP=0.2323462963104248)
[Training] epoch:60 step:300 g_loss:0.5453317761421204 d_loss:1.0120485424995422 (f_loss=0.4976082444190979 r_loss=0.45623159408569336 GP=0.05820870399475098)
[Training] epoch:61 step:0 g_loss:0.5288516879081726 d_loss:1.1084870621562004 (f_loss=0.4860328733921051 r_loss=0.5039215683937073 GP=0.11853262037038803)
[Training] epoch:61 step:100 g_loss:0.5237289071083069 d_loss:0.9861195385456085 (f_loss=0.44778284430503845 r_loss=0.4444286823272705 GP=0.09390801191329956)
[Training] epoch:61 step:200 g_loss:0.5878990888595581 d_loss:1.1393212378025055 (f_loss=0.4461050033569336 r_loss=0.45577192306518555 GP=0.23744431138038635)
[Training] epoch:61 step:300 g_loss:0.4766486883163452 d_loss:1.2373197376728058 (f_loss=0.43569397926330566 r_loss=0.49882447719573975 GP=0.3028012812137604)
[Training] epoch:62 step:0 g_loss:0.5323325991630554 d_loss:1.5029673874378204 (f_loss=0.48952850699424744 r_loss=0.5122194290161133 GP=0.5012194514274597)
[Training] epoch:62 step:100 g_loss:0.553290605545044 d_loss:1.0728666335344315 (f_loss=0.44257035851478577 r_loss=0.4268952012062073 GP=0.20340107381343842)
[Training] epoch:62 step:200 g_loss:0.5202871561050415 d_loss:1.192274272441864 (f_loss=0.5240669250488281 r_loss=0.5214468240737915 GP=0.14676052331924438)
[Training] epoch:62 step:300 g_loss:0.5554150342941284 d_loss:1.0436507388949394 (f_loss=0.4621204733848572 r_loss=0.5012441873550415 GP=0.08028607815504074)
[Training] epoch:63 step:0 g_loss:0.542273223400116 d_loss:1.0576029419898987 (f_loss=0.4509434103965759 r_loss=0.4758933186531067 GP=0.13076621294021606)
[Training] epoch:63 step:100 g_loss:0.5525965094566345 d_loss:1.412244975566864 (f_loss=0.4919286072254181 r_loss=0.506754457950592 GP=0.4135619103908539)
[Training] epoch:63 step:200 g_loss:0.5069795846939087 d_loss:1.513729751110077 (f_loss=0.47483229637145996 r_loss=0.4720802903175354 GP=0.5668171644210815)
[Training] epoch:63 step:300 g_loss:0.5736660957336426 d_loss:1.5449870824813843 (f_loss=0.48268455266952515 r_loss=0.5066136121749878 GP=0.5556889176368713)
[Training] epoch:64 step:0 g_loss:0.5542680621147156 d_loss:1.4496137201786041 (f_loss=0.4788544178009033 r_loss=0.5092234015464783 GP=0.46153590083122253)
[Training] epoch:64 step:100 g_loss:0.5244245529174805 d_loss:1.8682621717453003 (f_loss=0.4428554177284241 r_loss=0.458459734916687 GP=0.9669470191001892)
[Training] epoch:64 step:200 g_loss:0.5494703054428101 d_loss:1.249516636133194 (f_loss=0.4582218825817108 r_loss=0.5497350692749023 GP=0.2415596842765808)
[Training] epoch:64 step:300 g_loss:0.5130902528762817 d_loss:1.25231271982193 (f_loss=0.5051378011703491 r_loss=0.4856034517288208 GP=0.26157146692276)
[Training] epoch:65 step:0 g_loss:0.5205531716346741 d_loss:1.3830089271068573 (f_loss=0.47579875588417053 r_loss=0.5497828722000122 GP=0.35742729902267456)
[Training] epoch:65 step:100 g_loss:0.5446515679359436 d_loss:1.0622731894254684 (f_loss=0.4881185293197632 r_loss=0.46770691871643066 GP=0.1064477413892746)
[Training] epoch:65 step:200 g_loss:0.6034908294677734 d_loss:1.091848909854889 (f_loss=0.4563677906990051 r_loss=0.4637334942817688 GP=0.171747624874115)
[Training] epoch:65 step:300 g_loss:0.5304166078567505 d_loss:1.7185893058776855 (f_loss=0.4723550081253052 r_loss=0.4931631088256836 GP=0.7530711889266968)
[Training] epoch:66 step:0 g_loss:0.4812510013580322 d_loss:1.0217129290103912 (f_loss=0.48007112741470337 r_loss=0.3895004391670227 GP=0.15214136242866516)
[Training] epoch:66 step:100 g_loss:0.4978634715080261 d_loss:0.9499630853533745 (f_loss=0.4423259496688843 r_loss=0.3943635821342468 GP=0.11327355355024338)
[Training] epoch:66 step:200 g_loss:0.47894060611724854 d_loss:1.1781710088253021 (f_loss=0.49945491552352905 r_loss=0.5191538333892822 GP=0.15956225991249084)
[Training] epoch:66 step:300 g_loss:0.5335702896118164 d_loss:1.2577511966228485 (f_loss=0.4305664300918579 r_loss=0.5216928720474243 GP=0.3054918944835663)
[Training] epoch:67 step:0 g_loss:0.5899488925933838 d_loss:1.0410111770033836 (f_loss=0.5015050768852234 r_loss=0.4907517433166504 GP=0.04875435680150986)
[Training] epoch:67 step:100 g_loss:0.5214681625366211 d_loss:1.1026849448680878 (f_loss=0.5085657835006714 r_loss=0.4550743103027344 GP=0.139044851064682)
[Training] epoch:67 step:200 g_loss:0.49556827545166016 d_loss:1.256022423505783 (f_loss=0.47625797986984253 r_loss=0.4943666458129883 GP=0.28539779782295227)
[Training] epoch:67 step:300 g_loss:0.5436279773712158 d_loss:1.1824394911527634 (f_loss=0.4987257122993469 r_loss=0.49319595098495483 GP=0.1905178278684616)
[Training] epoch:68 step:0 g_loss:0.5892895460128784 d_loss:1.4180552661418915 (f_loss=0.39795926213264465 r_loss=0.49812597036361694 GP=0.5219700336456299)
[Training] epoch:68 step:100 g_loss:0.503664493560791 d_loss:1.3101827800273895 (f_loss=0.47168827056884766 r_loss=0.4095808267593384 GP=0.4289136826992035)
[Training] epoch:68 step:200 g_loss:0.5478312969207764 d_loss:1.4733128547668457 (f_loss=0.5472782254219055 r_loss=0.4287967085838318 GP=0.4972379207611084)
[Training] epoch:68 step:300 g_loss:0.5356253981590271 d_loss:1.0735808983445168 (f_loss=0.49279460310935974 r_loss=0.4571632742881775 GP=0.12362302094697952)
[Training] epoch:69 step:0 g_loss:0.5437950491905212 d_loss:1.225348323583603 (f_loss=0.4697152376174927 r_loss=0.505621075630188 GP=0.25001201033592224)
[Training] epoch:69 step:100 g_loss:0.5285235047340393 d_loss:1.182514801621437 (f_loss=0.5663770437240601 r_loss=0.47740256786346436 GP=0.13873519003391266)
[Training] epoch:69 step:200 g_loss:0.5359086990356445 d_loss:1.1419218182563782 (f_loss=0.47382044792175293 r_loss=0.47446584701538086 GP=0.19363552331924438)
[Training] epoch:69 step:300 g_loss:0.4984006881713867 d_loss:1.1585241258144379 (f_loss=0.4484645426273346 r_loss=0.45284712314605713 GP=0.25721246004104614)
[Training] epoch:70 step:0 g_loss:0.49115854501724243 d_loss:1.485594630241394 (f_loss=0.47477591037750244 r_loss=0.46083128452301025 GP=0.5499874353408813)

[Training] epoch:70 step:100 g_loss:0.5730879902839661 d_loss:1.1178256273269653 (f_loss=0.4850348234176636 r_loss=0.47191429138183594 GP=0.16087651252746582)
[Training] epoch:70 step:200 g_loss:0.5851804614067078 d_loss:1.0286642760038376 (f_loss=0.47744297981262207 r_loss=0.420648455619812 GP=0.1305728405714035)
[Training] epoch:70 step:300 g_loss:0.5771322250366211 d_loss:1.2600196599960327 (f_loss=0.4855908751487732 r_loss=0.46360278129577637 GP=0.31082600355148315)
[Training] epoch:71 step:0 g_loss:0.5695976614952087 d_loss:1.1279896944761276 (f_loss=0.46348705887794495 r_loss=0.5628114342689514 GP=0.10169120132923126)
[Training] epoch:71 step:100 g_loss:0.5409433841705322 d_loss:1.035695806145668 (f_loss=0.4395667314529419 r_loss=0.5114861726760864 GP=0.08464290201663971)
[Training] epoch:71 step:200 g_loss:0.5464223027229309 d_loss:1.076383888721466 (f_loss=0.48545145988464355 r_loss=0.4392560124397278 GP=0.15167641639709473)
[Training] epoch:71 step:300 g_loss:0.558619499206543 d_loss:1.0456934943795204 (f_loss=0.42764830589294434 r_loss=0.5085852146148682 GP=0.10945997387170792)
[Training] epoch:72 step:0 g_loss:0.5145313143730164 d_loss:1.380927324295044 (f_loss=0.45612281560897827 r_loss=0.47965002059936523 GP=0.44515448808670044)
[Training] epoch:72 step:100 g_loss:0.5323464870452881 d_loss:1.0940505862236023 (f_loss=0.4483972191810608 r_loss=0.5084130167961121 GP=0.13724035024642944)
[Training] epoch:72 step:200 g_loss:0.6060666441917419 d_loss:1.049055591225624 (f_loss=0.42780208587646484 r_loss=0.5351617336273193 GP=0.0860917717218399)
[Training] epoch:72 step:300 g_loss:0.49754083156585693 d_loss:1.0330829471349716 (f_loss=0.4497569501399994 r_loss=0.4610421657562256 GP=0.12228383123874664)
[Training] epoch:73 step:0 g_loss:0.4678199291229248 d_loss:1.1012216061353683 (f_loss=0.47475892305374146 r_loss=0.45888733863830566 GP=0.16757534444332123)
[Training] epoch:73 step:100 g_loss:0.5379765033721924 d_loss:1.1767161339521408 (f_loss=0.4583950340747833 r_loss=0.5403594970703125 GP=0.17796160280704498)
[Training] epoch:73 step:200 g_loss:0.5096226930618286 d_loss:1.0568546280264854 (f_loss=0.44121143221855164 r_loss=0.5289758443832397 GP=0.08666735142469406)
[Training] epoch:73 step:300 g_loss:0.6033588647842407 d_loss:1.1558462977409363 (f_loss=0.44229596853256226 r_loss=0.49725341796875 GP=0.21629691123962402)
[Training] epoch:74 step:0 g_loss:0.5345386266708374 d_loss:1.4055494666099548 (f_loss=0.47457027435302734 r_loss=0.4984181523323059 GP=0.4325610399246216)
[Training] epoch:74 step:100 g_loss:0.5427578687667847 d_loss:1.3431552350521088 (f_loss=0.47963419556617737 r_loss=0.42525970935821533 GP=0.43826133012771606)
[Training] epoch:74 step:200 g_loss:0.537473201751709 d_loss:1.518252283334732 (f_loss=0.4609476625919342 r_loss=0.4841223955154419 GP=0.573182225227356)
[Training] epoch:74 step:300 g_loss:0.48344355821609497 d_loss:1.1530891358852386 (f_loss=0.520317554473877 r_loss=0.4884415864944458 GP=0.1443299949169159)
[Training] epoch:75 step:0 g_loss:0.5653940439224243 d_loss:1.0229120776057243 (f_loss=0.4611715078353882 r_loss=0.4962282180786133 GP=0.06551235169172287)
[Training] epoch:75 step:100 g_loss:0.5822609066963196 d_loss:1.0318615697324276 (f_loss=0.4530668556690216 r_loss=0.5211923718452454 GP=0.05760234221816063)
[Training] epoch:75 step:200 g_loss:0.4837464690208435 d_loss:1.0466857701539993 (f_loss=0.4838758707046509 r_loss=0.46818846464157104 GP=0.0946214348077774)
[Training] epoch:75 step:300 g_loss:0.5173614025115967 d_loss:1.1158171147108078 (f_loss=0.45164668560028076 r_loss=0.5269014835357666 GP=0.13726894557476044)
[Training] epoch:76 step:0 g_loss:0.5065299272537231 d_loss:1.251627266407013 (f_loss=0.45491713285446167 r_loss=0.4944148063659668 GP=0.3022953271865845)
[Training] epoch:76 step:100 g_loss:0.5356786251068115 d_loss:1.015667613595724 (f_loss=0.5011903047561646 r_loss=0.47613632678985596 GP=0.0383409820497036)
[Training] epoch:76 step:200 g_loss:0.5367549061775208 d_loss:1.039594180881977 (f_loss=0.48639124631881714 r_loss=0.48687005043029785 GP=0.06633288413286209)
[Training] epoch:76 step:300 g_loss:0.5152148008346558 d_loss:1.4042234420776367 (f_loss=0.460124671459198 r_loss=0.504551887512207 GP=0.4395468831062317)
[Training] epoch:77 step:0 g_loss:0.579931378364563 d_loss:1.1959155350923538 (f_loss=0.472846120595932 r_loss=0.5655746459960938 GP=0.15749476850032806)
[Training] epoch:77 step:100 g_loss:0.497448205947876 d_loss:1.1300139427185059 (f_loss=0.47792303562164307 r_loss=0.47947418689727783 GP=0.17261672019958496)
[Training] epoch:77 step:200 g_loss:0.510244607925415 d_loss:1.18851900100708 (f_loss=0.47040414810180664 r_loss=0.5232197642326355 GP=0.19489508867263794)
[Training] epoch:77 step:300 g_loss:0.522351861000061 d_loss:1.0694217085838318 (f_loss=0.49059006571769714 r_loss=0.45147472620010376 GP=0.12735691666603088)
[Training] epoch:78 step:0 g_loss:0.5568296313285828 d_loss:1.0853001326322556 (f_loss=0.4585563838481903 r_loss=0.43464529514312744 GP=0.1920984536409378)
[Training] epoch:78 step:100 g_loss:0.5264869928359985 d_loss:1.7357844710350037 (f_loss=0.48274439573287964 r_loss=0.43603336811065674 GP=0.8170067071914673)
[Training] epoch:78 step:200 g_loss:0.5944761037826538 d_loss:1.1694671660661697 (f_loss=0.43777215480804443 r_loss=0.4955901503562927 GP=0.23610486090183258)
[Training] epoch:78 step:300 g_loss:0.5202265977859497 d_loss:1.1708010882139206 (f_loss=0.46433061361312866 r_loss=0.5269920229911804 GP=0.1794784516096115)
[Training] epoch:79 step:0 g_loss:0.6025540828704834 d_loss:1.148626983165741 (f_loss=0.42974841594696045 r_loss=0.5302263498306274 GP=0.18865221738815308)
[Training] epoch:79 step:100 g_loss:0.5046284794807434 d_loss:1.0656251981854439 (f_loss=0.4672628939151764 r_loss=0.519363284111023 GP=0.07899902015924454)
[Training] epoch:79 step:200 g_loss:0.5352332592010498 d_loss:1.4139609634876251 (f_loss=0.4911040961742401 r_loss=0.509304940700531 GP=0.413551926612854)
[Training] epoch:79 step:300 g_loss:0.5508775115013123 d_loss:1.2214554250240326 (f_loss=0.44707560539245605 r_loss=0.5746665000915527 GP=0.1997133195400238)
[Training] epoch:80 step:0 g_loss:0.5816895961761475 d_loss:1.1423581540584564 (f_loss=0.5029898881912231 r_loss=0.5057221055030823 GP=0.133646160364151)

[Training] epoch:80 step:100 g_loss:0.5445572137832642 d_loss:1.0321598909795284 (f_loss=0.4576709568500519 r_loss=0.5122417211532593 GP=0.06224721297621727)
[Training] epoch:80 step:200 g_loss:0.5327030420303345 d_loss:1.3017110377550125 (f_loss=0.521316647529602 r_loss=0.5434008836746216 GP=0.23699350655078888)
[Training] epoch:80 step:300 g_loss:0.5588998794555664 d_loss:1.140672117471695 (f_loss=0.505385160446167 r_loss=0.48848485946655273 GP=0.14680209755897522)
[Training] epoch:81 step:0 g_loss:0.5627572536468506 d_loss:1.0954292267560959 (f_loss=0.48618829250335693 r_loss=0.48753267526626587 GP=0.12170825898647308)
[Training] epoch:81 step:100 g_loss:0.5311057567596436 d_loss:1.0923268496990204 (f_loss=0.4634094834327698 r_loss=0.5242825150489807 GP=0.1046348512172699)
[Training] epoch:81 step:200 g_loss:0.5717703104019165 d_loss:1.1019268333911896 (f_loss=0.4659820795059204 r_loss=0.5389658808708191 GP=0.09697887301445007)
[Training] epoch:81 step:300 g_loss:0.5564156770706177 d_loss:1.1231961995363235 (f_loss=0.4475369453430176 r_loss=0.4629945755004883 GP=0.2126646786928177)
[Training] epoch:82 step:0 g_loss:0.5055821537971497 d_loss:1.0175922513008118 (f_loss=0.4775640368461609 r_loss=0.45656347274780273 GP=0.08346474170684814)
[Training] epoch:82 step:100 g_loss:0.5067217350006104 d_loss:1.125358447432518 (f_loss=0.44983673095703125 r_loss=0.5070680379867554 GP=0.16845367848873138)
[Training] epoch:82 step:200 g_loss:0.49173158407211304 d_loss:1.226638287305832 (f_loss=0.4622277617454529 r_loss=0.5660380721092224 GP=0.19837245345115662)
[Training] epoch:82 step:300 g_loss:0.5050777196884155 d_loss:1.3414899110794067 (f_loss=0.46467119455337524 r_loss=0.5394695401191711 GP=0.33734917640686035)
[Training] epoch:83 step:0 g_loss:0.5226762294769287 d_loss:1.3338339030742645 (f_loss=0.4887104332447052 r_loss=0.49603599309921265 GP=0.3490874767303467)
[Training] epoch:83 step:100 g_loss:0.552797794342041 d_loss:1.1288703680038452 (f_loss=0.4721542000770569 r_loss=0.5008541941642761 GP=0.1558619737625122)
[Training] epoch:83 step:200 g_loss:0.5240769386291504 d_loss:0.9555891789495945 (f_loss=0.4437403678894043 r_loss=0.4585552215576172 GP=0.05329358950257301)
[Training] epoch:83 step:300 g_loss:0.5550678968429565 d_loss:1.1551296412944794 (f_loss=0.47406211495399475 r_loss=0.5478132367134094 GP=0.1332542896270752)
[Training] epoch:84 step:0 g_loss:0.5052805542945862 d_loss:1.1070643365383148 (f_loss=0.4594264626502991 r_loss=0.43986737728118896 GP=0.20777049660682678)
[Training] epoch:84 step:100 g_loss:0.5387639999389648 d_loss:1.2636853158473969 (f_loss=0.4377909004688263 r_loss=0.5574458837509155 GP=0.26844853162765503)
[Training] epoch:84 step:200 g_loss:0.5509821176528931 d_loss:1.1107370182871819 (f_loss=0.5089036822319031 r_loss=0.49738186597824097 GP=0.10445147007703781)
[Training] epoch:84 step:300 g_loss:0.5304349660873413 d_loss:1.0171994045376778 (f_loss=0.4590454697608948 r_loss=0.45265549421310425 GP=0.10549844056367874)
[Training] epoch:85 step:0 g_loss:0.5643001794815063 d_loss:1.0349556803703308 (f_loss=0.43626338243484497 r_loss=0.5038748979568481 GP=0.0948173999786377)
[Training] epoch:85 step:100 g_loss:0.5302447080612183 d_loss:1.0515758395195007 (f_loss=0.44949284195899963 r_loss=0.46833932399749756 GP=0.13374367356300354)
[Training] epoch:85 step:200 g_loss:0.5615978837013245 d_loss:1.2809826135635376 (f_loss=0.4816156327724457 r_loss=0.4906933307647705 GP=0.3086736500263214)
[Training] epoch:85 step:300 g_loss:0.6028724908828735 d_loss:1.0593052953481674 (f_loss=0.4554404020309448 r_loss=0.4569514989852905 GP=0.14691339433193207)
[Training] epoch:86 step:0 g_loss:0.5564956068992615 d_loss:0.9996697567403316 (f_loss=0.433729350566864 r_loss=0.5457012057304382 GP=0.020239200443029404)
[Training] epoch:86 step:100 g_loss:0.4969228506088257 d_loss:1.030261069536209 (f_loss=0.4054403305053711 r_loss=0.509397029876709 GP=0.11542370915412903)
[Training] epoch:86 step:200 g_loss:0.6051278114318848 d_loss:1.1290879100561142 (f_loss=0.4402696192264557 r_loss=0.4858573079109192 GP=0.20296098291873932)
[Training] epoch:86 step:300 g_loss:0.5818397998809814 d_loss:1.0763365179300308 (f_loss=0.48859500885009766 r_loss=0.4529989957809448 GP=0.13474251329898834)
[Training] epoch:87 step:0 g_loss:0.5806261301040649 d_loss:1.0394697189331055 (f_loss=0.45966100692749023 r_loss=0.5416786670684814 GP=0.03813004493713379)
[Training] epoch:87 step:100 g_loss:0.5656330585479736 d_loss:1.2669561058282852 (f_loss=0.5142558813095093 r_loss=0.544514000415802 GP=0.20818622410297394)
[Training] epoch:87 step:200 g_loss:0.5402798652648926 d_loss:1.0595471635460854 (f_loss=0.4700656235218048 r_loss=0.49862170219421387 GP=0.09085983783006668)
[Training] epoch:87 step:300 g_loss:0.5239745378494263 d_loss:1.0951925665140152 (f_loss=0.46966052055358887 r_loss=0.47646552324295044 GP=0.1490665227174759)
[Training] epoch:88 step:0 g_loss:0.5193169713020325 d_loss:0.9473630487918854 (f_loss=0.44570469856262207 r_loss=0.4661116600036621 GP=0.035546690225601196)
[Training] epoch:88 step:100 g_loss:0.530277669429779 d_loss:1.3798500001430511 (f_loss=0.4753181040287018 r_loss=0.523259162902832 GP=0.38127273321151733)
[Training] epoch:88 step:200 g_loss:0.5719728469848633 d_loss:1.3079375624656677 (f_loss=0.4772401452064514 r_loss=0.5218368768692017 GP=0.30886054039001465)
[Training] epoch:88 step:300 g_loss:0.5553197860717773 d_loss:1.0342458225786686 (f_loss=0.49389776587486267 r_loss=0.5003081560134888 GP=0.040039900690317154)
[Training] epoch:89 step:0 g_loss:0.5474398136138916 d_loss:1.1694350391626358 (f_loss=0.4757561981678009 r_loss=0.5333915948867798 GP=0.16028724610805511)
[Training] epoch:89 step:100 g_loss:0.5176008343696594 d_loss:1.271530270576477 (f_loss=0.4699925184249878 r_loss=0.5167902112007141 GP=0.28474754095077515)
[Training] epoch:89 step:200 g_loss:0.5626398324966431 d_loss:1.0949678048491478 (f_loss=0.4865391254425049 r_loss=0.5558842420578003 GP=0.05254443734884262)
[Training] epoch:89 step:300 g_loss:0.5397761464118958 d_loss:1.2821316421031952 (f_loss=0.43582651019096375 r_loss=0.4837808609008789 GP=0.36252427101135254)
[Training] epoch:90 step:0 g_loss:0.48840630054473877 d_loss:1.142813190817833 (f_loss=0.5019441246986389 r_loss=0.5208234786987305 GP=0.12004558742046356)

[Training] epoch:90 step:100 g_loss:0.569352388381958 d_loss:1.1169029772281647 (f_loss=0.45198342204093933 r_loss=0.4948405623435974 GP=0.17007899284362793)
[Training] epoch:90 step:200 g_loss:0.5233725309371948 d_loss:1.0421070903539658 (f_loss=0.42541763186454773 r_loss=0.5459500551223755 GP=0.07073940336704254)
[Training] epoch:90 step:300 g_loss:0.5293779373168945 d_loss:1.303660273551941 (f_loss=0.43539440631866455 r_loss=0.5098756551742554 GP=0.358390212059021)
[Training] epoch:91 step:0 g_loss:0.5650634765625 d_loss:1.1503053307533264 (f_loss=0.4974777400493622 r_loss=0.4899723529815674 GP=0.16285523772239685)
[Training] epoch:91 step:100 g_loss:0.5581197738647461 d_loss:1.1659913957118988 (f_loss=0.4596575200557709 r_loss=0.4606987237930298 GP=0.24563515186309814)
[Training] epoch:91 step:200 g_loss:0.5497486591339111 d_loss:1.1328723430633545 (f_loss=0.4258440136909485 r_loss=0.5175131559371948 GP=0.18951517343521118)
[Training] epoch:91 step:300 g_loss:0.47516781091690063 d_loss:0.9576282799243927 (f_loss=0.43275243043899536 r_loss=0.4249451756477356 GP=0.09993067383766174)
[Training] epoch:92 step:0 g_loss:0.5476169586181641 d_loss:0.952451691031456 (f_loss=0.4488826394081116 r_loss=0.45295119285583496 GP=0.05061785876750946)
[Training] epoch:92 step:100 g_loss:0.5518629550933838 d_loss:1.281340628862381 (f_loss=0.39716148376464844 r_loss=0.5167379379272461 GP=0.36744120717048645)
[Training] epoch:92 step:200 g_loss:0.5314489603042603 d_loss:1.1128747463226318 (f_loss=0.4582796096801758 r_loss=0.49741119146347046 GP=0.1571839451789856)
[Training] epoch:92 step:300 g_loss:0.5878860354423523 d_loss:1.2126618325710297 (f_loss=0.4246414601802826 r_loss=0.5014742612838745 GP=0.28654611110687256)
[Training] epoch:93 step:0 g_loss:0.6427816152572632 d_loss:1.036737710237503 (f_loss=0.42453131079673767 r_loss=0.48823463916778564 GP=0.12397176027297974)
[Training] epoch:93 step:100 g_loss:0.539697527885437 d_loss:1.16254723072052 (f_loss=0.464701771736145 r_loss=0.5161349773406982 GP=0.18171048164367676)
[Training] epoch:93 step:200 g_loss:0.5363452434539795 d_loss:1.0415209084749222 (f_loss=0.4428199231624603 r_loss=0.49697285890579224 GP=0.10172812640666962)
[Training] epoch:93 step:300 g_loss:0.5848020315170288 d_loss:1.101779267191887 (f_loss=0.4591684341430664 r_loss=0.5150700807571411 GP=0.12754075229167938)
[Training] epoch:94 step:0 g_loss:0.5664398670196533 d_loss:1.107835292816162 (f_loss=0.43937310576438904 r_loss=0.4519156217575073 GP=0.21654656529426575)
[Training] epoch:94 step:100 g_loss:0.5964846611022949 d_loss:1.0547635853290558 (f_loss=0.42779797315597534 r_loss=0.4909207224845886 GP=0.13604488968849182)
[Training] epoch:94 step:200 g_loss:0.5203820466995239 d_loss:1.172832414507866 (f_loss=0.4593774676322937 r_loss=0.5118566155433655 GP=0.20159833133220673)
[Training] epoch:94 step:300 g_loss:0.6189985871315002 d_loss:1.019924558699131 (f_loss=0.4914983808994293 r_loss=0.4760652780532837 GP=0.052360899746418)
[Training] epoch:95 step:0 g_loss:0.5314955115318298 d_loss:1.1699695587158203 (f_loss=0.4229763448238373 r_loss=0.5146301984786987 GP=0.2323630154132843)
[Training] epoch:95 step:100 g_loss:0.5657651424407959 d_loss:1.0838306844234467 (f_loss=0.47552603483200073 r_loss=0.47557932138442993 GP=0.132725328207016)
[Training] epoch:95 step:200 g_loss:0.601137101650238 d_loss:1.1061613857746124 (f_loss=0.4403538703918457 r_loss=0.5278047323226929 GP=0.13800278306007385)
[Training] epoch:95 step:300 g_loss:0.5164439678192139 d_loss:1.2111712247133255 (f_loss=0.41551604866981506 r_loss=0.5640933513641357 GP=0.2315618246793747)
[Training] epoch:96 step:0 g_loss:0.5624191761016846 d_loss:0.8908482789993286 (f_loss=0.3879234194755554 r_loss=0.4102410078048706 GP=0.09268385171890259)
[Training] epoch:96 step:100 g_loss:0.5748791098594666 d_loss:1.469463050365448 (f_loss=0.45672720670700073 r_loss=0.49150049686431885 GP=0.5212353467941284)
[Training] epoch:96 step:200 g_loss:0.5309405326843262 d_loss:1.0113109946250916 (f_loss=0.418438583612442 r_loss=0.5378193259239197 GP=0.05505308508872986)
[Training] epoch:96 step:300 g_loss:0.6311012506484985 d_loss:1.1565486639738083 (f_loss=0.4611567556858063 r_loss=0.6062800288200378 GP=0.08911187946796417)
[Training] epoch:97 step:0 g_loss:0.6332535743713379 d_loss:1.0560896769165993 (f_loss=0.4128277599811554 r_loss=0.5486539602279663 GP=0.09460795670747757)
[Training] epoch:97 step:100 g_loss:0.5641545057296753 d_loss:0.9918128550052643 (f_loss=0.43915483355522156 r_loss=0.48618996143341064 GP=0.06646806001663208)
[Training] epoch:97 step:200 g_loss:0.564324676990509 d_loss:1.146734669804573 (f_loss=0.4568024277687073 r_loss=0.4829061031341553 GP=0.2070261389017105)
[Training] epoch:97 step:300 g_loss:0.6090031266212463 d_loss:1.3171676993370056 (f_loss=0.43285268545150757 r_loss=0.5246835947036743 GP=0.35963141918182373)
[Training] epoch:98 step:0 g_loss:0.5422663688659668 d_loss:1.1908864676952362 (f_loss=0.42749840021133423 r_loss=0.5300975441932678 GP=0.23329052329063416)
[Training] epoch:98 step:100 g_loss:0.5818548202514648 d_loss:1.2012075185775757 (f_loss=0.3846566081047058 r_loss=0.5407753586769104 GP=0.2757755517959595)
[Training] epoch:98 step:200 g_loss:0.540217936038971 d_loss:1.0099234879016876 (f_loss=0.3858184218406677 r_loss=0.5157523155212402 GP=0.10835275053977966)
[Training] epoch:98 step:300 g_loss:0.5833154916763306 d_loss:1.131963849067688 (f_loss=0.40692371129989624 r_loss=0.5355933904647827 GP=0.18944674730300903)
[Training] epoch:99 step:0 g_loss:0.5432253479957581 d_loss:1.685145914554596 (f_loss=0.4050803780555725 r_loss=0.43654054403305054 GP=0.8435249924659729)
[Training] epoch:99 step:100 g_loss:0.5641355514526367 d_loss:1.1477651447057724 (f_loss=0.4709446132183075 r_loss=0.5574080944061279 GP=0.11941243708133698)
[Training] epoch:99 step:200 g_loss:0.5455437898635864 d_loss:1.0153026282787323 (f_loss=0.41304537653923035 r_loss=0.5321051478385925 GP=0.07015210390090942)
[Training] epoch:99 step:300 g_loss:0.5689059495925903 d_loss:1.0074666514992714 (f_loss=0.46746453642845154 r_loss=0.49110090732574463 GP=0.048901207745075226)
[Training] epoch:100 step:0 g_loss:0.5579941272735596 d_loss:1.4231609404087067 (f_loss=0.44513168931007385 r_loss=0.4694216251373291 GP=0.5086076259613037)

[Training] epoch:100 step:100 g_loss:0.5587285757064819 d_loss:1.090958595275879 (f_loss=0.4574645757675171 r_loss=0.5476680994033813 GP=0.08582592010498047)
[Training] epoch:100 step:200 g_loss:0.5986588001251221 d_loss:1.0348937436938286 (f_loss=0.4593905210494995 r_loss=0.5390702486038208 GP=0.03643297404050827)
[Training] epoch:100 step:300 g_loss:0.6267765164375305 d_loss:1.0711577013134956 (f_loss=0.48711442947387695 r_loss=0.5039432644844055 GP=0.08010000735521317)
[Training] epoch:101 step:0 g_loss:0.5937027931213379 d_loss:1.11017245054245 (f_loss=0.42488232254981995 r_loss=0.5372116565704346 GP=0.14807847142219543)
[Training] epoch:101 step:100 g_loss:0.6100549101829529 d_loss:1.0230413675308228 (f_loss=0.43952906131744385 r_loss=0.46925127506256104 GP=0.11426103115081787)
[Training] epoch:101 step:200 g_loss:0.5907031297683716 d_loss:1.1028362959623337 (f_loss=0.46213269233703613 r_loss=0.4791380763053894 GP=0.16156552731990814)
[Training] epoch:101 step:300 g_loss:0.5240808129310608 d_loss:1.1265887394547462 (f_loss=0.46375125646591187 r_loss=0.617816686630249 GP=0.04502079635858536)
[Training] epoch:102 step:0 g_loss:0.5669618844985962 d_loss:1.0325623601675034 (f_loss=0.4338342547416687 r_loss=0.512559711933136 GP=0.08616839349269867)
[Training] epoch:102 step:100 g_loss:0.5424442291259766 d_loss:1.1607174277305603 (f_loss=0.4695125222206116 r_loss=0.5632888078689575 GP=0.1279160976409912)
[Training] epoch:102 step:200 g_loss:0.5395798087120056 d_loss:0.9395900741219521 (f_loss=0.43604835867881775 r_loss=0.4640166759490967 GP=0.03952503949403763)
[Training] epoch:102 step:300 g_loss:0.5425109267234802 d_loss:1.533533900976181 (f_loss=0.4528210461139679 r_loss=0.5132635235786438 GP=0.5674493312835693)
[Training] epoch:103 step:0 g_loss:0.5016897916793823 d_loss:1.1548748165369034 (f_loss=0.4430314898490906 r_loss=0.4797431230545044 GP=0.2321002036333084)
[Training] epoch:103 step:100 g_loss:0.5177443027496338 d_loss:1.044532522559166 (f_loss=0.3967657685279846 r_loss=0.5177614092826843 GP=0.130005344748497)
[Training] epoch:103 step:200 g_loss:0.55210280418396 d_loss:1.0065849423408508 (f_loss=0.46217530965805054 r_loss=0.4428505301475525 GP=0.1015591025352478)
[Training] epoch:103 step:300 g_loss:0.6234514713287354 d_loss:0.9827611073851585 (f_loss=0.4018835425376892 r_loss=0.5410717725753784 GP=0.03980579227209091)
[Training] epoch:104 step:0 g_loss:0.5863285064697266 d_loss:1.0744650214910507 (f_loss=0.4535105228424072 r_loss=0.4867511987686157 GP=0.13420329988002777)
[Training] epoch:104 step:100 g_loss:0.5314421653747559 d_loss:1.038305088877678 (f_loss=0.4312112629413605 r_loss=0.5219439268112183 GP=0.08514989912509918)
[Training] epoch:104 step:200 g_loss:0.5940245389938354 d_loss:1.1608623266220093 (f_loss=0.44158804416656494 r_loss=0.5471503734588623 GP=0.17212390899658203)
[Training] epoch:104 step:300 g_loss:0.5311467051506042 d_loss:0.9460417032241821 (f_loss=0.4172685146331787 r_loss=0.4597269296646118 GP=0.0690462589263916)
[Training] epoch:105 step:0 g_loss:0.5634049773216248 d_loss:0.9864329993724823 (f_loss=0.4627174437046051 r_loss=0.46138566732406616 GP=0.062329888343811035)
[Training] epoch:105 step:100 g_loss:0.5607245564460754 d_loss:0.9928491562604904 (f_loss=0.42901134490966797 r_loss=0.5054176449775696 GP=0.05842016637325287)
[Training] epoch:105 step:200 g_loss:0.5566651821136475 d_loss:1.0303852036595345 (f_loss=0.44545504450798035 r_loss=0.5378631353378296 GP=0.04706702381372452)
[Training] epoch:105 step:300 g_loss:0.5870462656021118 d_loss:0.9907445013523102 (f_loss=0.45990118384361267 r_loss=0.499902606010437 GP=0.030940711498260498)
[Training] epoch:106 step:0 g_loss:0.593075692653656 d_loss:1.7637614011764526 (f_loss=0.39141571521759033 r_loss=0.4867624044418335 GP=0.8855832815170288)
[Training] epoch:106 step:100 g_loss:0.5411473512649536 d_loss:1.087551012635231 (f_loss=0.48360776901245117 r_loss=0.5396834015846252 GP=0.0642598420381546)
[Training] epoch:106 step:200 g_loss:0.5471201539039612 d_loss:1.0929589420557022 (f_loss=0.4560850262641907 r_loss=0.48305726051330566 GP=0.15381665527820587)
[Training] epoch:106 step:300 g_loss:0.5621019005775452 d_loss:0.994824580848217 (f_loss=0.39282330870628357 r_loss=0.5272008776664734 GP=0.07480039447546005)
[Training] epoch:107 step:0 g_loss:0.4911550283432007 d_loss:1.1291134357452393 (f_loss=0.4459325671195984 r_loss=0.5197770595550537 GP=0.16340380907058716)
[Training] epoch:107 step:100 g_loss:0.5658782720565796 d_loss:1.1021100878715515 (f_loss=0.4230119585990906 r_loss=0.5202710032463074 GP=0.15882712602615356)
[Training] epoch:107 step:200 g_loss:0.5415563583374023 d_loss:1.091225042939186 (f_loss=0.4079194962978363 r_loss=0.5061174035072327 GP=0.17718814313411713)
[Training] epoch:107 step:300 g_loss:0.5726569890975952 d_loss:1.0639222711324692 (f_loss=0.43512412905693054 r_loss=0.477161705493927 GP=0.15163643658161163)
[Training] epoch:108 step:0 g_loss:0.6126616597175598 d_loss:0.9154257550835609 (f_loss=0.38636547327041626 r_loss=0.44756537675857544 GP=0.08149490505456924)
[Training] epoch:108 step:100 g_loss:0.5224841833114624 d_loss:1.087880328297615 (f_loss=0.4279128611087799 r_loss=0.5177339315414429 GP=0.14223353564739227)
[Training] epoch:108 step:200 g_loss:0.580062747001648 d_loss:1.060618869960308 (f_loss=0.41662582755088806 r_loss=0.5199406147003174 GP=0.12405242770910263)
[Training] epoch:108 step:300 g_loss:0.544498860836029 d_loss:1.168365240097046 (f_loss=0.3923916220664978 r_loss=0.4846920967102051 GP=0.291281521320343)
[Training] epoch:109 step:0 g_loss:0.5244876146316528 d_loss:1.1909784376621246 (f_loss=0.408531129360199 r_loss=0.5245161056518555 GP=0.2579312026500702)
[Training] epoch:109 step:100 g_loss:0.5593301057815552 d_loss:0.9931426048278809 (f_loss=0.4223334491252899 r_loss=0.4671207666397095 GP=0.10368838906288147)
[Training] epoch:109 step:200 g_loss:0.5629781484603882 d_loss:1.3098104000091553 (f_loss=0.41766172647476196 r_loss=0.4979265332221985 GP=0.3942221403121948)
[Training] epoch:109 step:300 g_loss:0.5993812084197998 d_loss:1.0791615098714828 (f_loss=0.4790491461753845 r_loss=0.5188940763473511 GP=0.08121828734874725)
[Training] epoch:110 step:0 g_loss:0.542724609375 d_loss:1.086827889084816 (f_loss=0.4404435157775879 r_loss=0.5705395936965942 GP=0.07584477961063385)

[Training] epoch:110 step:100 g_loss:0.5307239294052124 d_loss:1.1031750440597534 (f_loss=0.4201064109802246 r_loss=0.5701155066490173 GP=0.11295312643051147)
[Training] epoch:110 step:200 g_loss:0.5867549180984497 d_loss:1.116221185773611 (f_loss=0.49631819128990173 r_loss=0.5605913400650024 GP=0.059311654418706894)
[Training] epoch:110 step:300 g_loss:0.5069804191589355 d_loss:1.1643082797527313 (f_loss=0.462150514125824 r_loss=0.5073292255401611 GP=0.19482854008674622)
[Training] epoch:111 step:0 g_loss:0.6140822172164917 d_loss:1.0611935034394264 (f_loss=0.48267844319343567 r_loss=0.518186092376709 GP=0.06032896786928177)
[Training] epoch:111 step:100 g_loss:0.5663105249404907 d_loss:1.4322222471237183 (f_loss=0.4395195245742798 r_loss=0.5270386338233948 GP=0.4656640887260437)
[Training] epoch:111 step:200 g_loss:0.5703123211860657 d_loss:1.0513985753059387 (f_loss=0.41606950759887695 r_loss=0.5148518085479736 GP=0.12047725915908813)
[Training] epoch:111 step:300 g_loss:0.5495837926864624 d_loss:1.0423446297645569 (f_loss=0.45641982555389404 r_loss=0.4681466221809387 GP=0.11777818202972412)
[Training] epoch:112 step:0 g_loss:0.545331597328186 d_loss:0.9632665142416954 (f_loss=0.39239436388015747 r_loss=0.45617109537124634 GP=0.1147010549902916)
[Training] epoch:112 step:100 g_loss:0.5536661744117737 d_loss:1.0709919184446335 (f_loss=0.4077942371368408 r_loss=0.4725063443183899 GP=0.19069133698940277)
[Training] epoch:112 step:200 g_loss:0.5353167057037354 d_loss:1.439330369234085 (f_loss=0.4592874050140381 r_loss=0.5116313695907593 GP=0.4684115946292877)
[Training] epoch:112 step:300 g_loss:0.5070359706878662 d_loss:0.9827727749943733 (f_loss=0.424475759267807 r_loss=0.5128477215766907 GP=0.04544929414987564)
[Training] epoch:113 step:0 g_loss:0.5388975143432617 d_loss:1.068778993561864 (f_loss=0.47975483536720276 r_loss=0.5734317302703857 GP=0.015592427924275398)
[Training] epoch:113 step:100 g_loss:0.5898833274841309 d_loss:1.2561843991279602 (f_loss=0.46606332063674927 r_loss=0.5386550426483154 GP=0.2514660358428955)
[Training] epoch:113 step:200 g_loss:0.5530992746353149 d_loss:0.9722576513886452 (f_loss=0.41854947805404663 r_loss=0.4798622727394104 GP=0.07384590059518814)
[Training] epoch:113 step:300 g_loss:0.5946651101112366 d_loss:0.9751882180571556 (f_loss=0.3896472454071045 r_loss=0.5380947589874268 GP=0.04744621366262436)
[Training] epoch:114 step:0 g_loss:0.5886983871459961 d_loss:1.0768483132123947 (f_loss=0.4629178047180176 r_loss=0.535538911819458 GP=0.07839159667491913)
[Training] epoch:114 step:100 g_loss:0.5396355986595154 d_loss:1.0515042543411255 (f_loss=0.4504597783088684 r_loss=0.38375163078308105 GP=0.21729284524917603)
[Training] epoch:114 step:200 g_loss:0.5841108560562134 d_loss:1.0426211059093475 (f_loss=0.4213961958885193 r_loss=0.4766591787338257 GP=0.14456573128700256)
[Training] epoch:114 step:300 g_loss:0.5469462275505066 d_loss:0.9384399130940437 (f_loss=0.41870516538619995 r_loss=0.4570137858390808 GP=0.06272096186876297)
[Training] epoch:115 step:0 g_loss:0.5807282328605652 d_loss:0.9339323528110981 (f_loss=0.4445783793926239 r_loss=0.460868239402771 GP=0.0284857340157032)
[Training] epoch:115 step:100 g_loss:0.5681333541870117 d_loss:1.0001881793141365 (f_loss=0.45769932866096497 r_loss=0.4771568775177002 GP=0.06533197313547134)
[Training] epoch:115 step:200 g_loss:0.5538191795349121 d_loss:1.1867248862981796 (f_loss=0.508302628993988 r_loss=0.5006089210510254 GP=0.1778133362531662)
[Training] epoch:115 step:300 g_loss:0.536001980304718 d_loss:1.0855815261602402 (f_loss=0.43461793661117554 r_loss=0.5681724548339844 GP=0.08279113471508026)
[Training] epoch:116 step:0 g_loss:0.531147301197052 d_loss:1.10230253636837 (f_loss=0.4253157377243042 r_loss=0.517066478729248 GP=0.1599203199148178)
[Training] epoch:116 step:100 g_loss:0.5725899934768677 d_loss:0.973139476031065 (f_loss=0.397399365901947 r_loss=0.5360033512115479 GP=0.039736758917570114)
[Training] epoch:116 step:200 g_loss:0.5751864314079285 d_loss:1.173779010772705 (f_loss=0.46152615547180176 r_loss=0.497178316116333 GP=0.2150745391845703)
[Training] epoch:116 step:300 g_loss:0.5703885555267334 d_loss:1.0759848058223724 (f_loss=0.4281730651855469 r_loss=0.5033318996429443 GP=0.14447984099388123)
[Training] epoch:117 step:0 g_loss:0.5664502382278442 d_loss:1.1596600115299225 (f_loss=0.4432348310947418 r_loss=0.490032434463501 GP=0.2263927459716797)
[Training] epoch:117 step:100 g_loss:0.5601285099983215 d_loss:1.558709979057312 (f_loss=0.47133421897888184 r_loss=0.5042529106140137 GP=0.5831228494644165)
[Training] epoch:117 step:200 g_loss:0.565364420413971 d_loss:0.9817235246300697 (f_loss=0.39190685749053955 r_loss=0.5158900022506714 GP=0.0739266648888588)
[Training] epoch:117 step:300 g_loss:0.5917938947677612 d_loss:1.2910248339176178 (f_loss=0.4464806318283081 r_loss=0.49859291315078735 GP=0.34595128893852234)
[Training] epoch:118 step:0 g_loss:0.5630979537963867 d_loss:1.114806279540062 (f_loss=0.40552017092704773 r_loss=0.5254242420196533 GP=0.1838618665933609)
[Training] epoch:118 step:100 g_loss:0.5073899030685425 d_loss:1.0099806934595108 (f_loss=0.4314950704574585 r_loss=0.5130559206008911 GP=0.0654297024011612)
[Training] epoch:118 step:200 g_loss:0.5353528261184692 d_loss:1.4671341180801392 (f_loss=0.39209145307540894 r_loss=0.44706785678863525 GP=0.627974808216095)
[Training] epoch:118 step:300 g_loss:0.5922833681106567 d_loss:1.2142954170703888 (f_loss=0.4104507863521576 r_loss=0.5770705342292786 GP=0.22677409648895264)
[Training] epoch:119 step:0 g_loss:0.5289843678474426 d_loss:2.3562138080596924 (f_loss=0.4999769926071167 r_loss=0.46684515476226807 GP=1.3893916606903076)
[Training] epoch:119 step:100 g_loss:0.5672533512115479 d_loss:1.1343443840742111 (f_loss=0.4276397228240967 r_loss=0.5236332416534424 GP=0.18307141959667206)
[Training] epoch:119 step:200 g_loss:0.4806908965110779 d_loss:1.0402011573314667 (f_loss=0.43746453523635864 r_loss=0.5113855600357056 GP=0.09135106205940247)
[Training] epoch:119 step:300 g_loss:0.6376317739486694 d_loss:1.983387440443039 (f_loss=0.40984371304512024 r_loss=0.5408570170402527 GP=1.032686710357666)
[Training] epoch:120 step:0 g_loss:0.6609870195388794 d_loss:1.0835209339857101 (f_loss=0.41095104813575745 r_loss=0.5309369564056396 GP=0.14163292944431305)

[Training] epoch:120 step:100 g_loss:0.5820601582527161 d_loss:1.0588665828108788 (f_loss=0.45107826590538025 r_loss=0.5470317602157593 GP=0.06075655668973923)
[Training] epoch:120 step:200 g_loss:0.5886937379837036 d_loss:1.0538195073604584 (f_loss=0.37545913457870483 r_loss=0.4968606233596802 GP=0.18149974942207336)
[Training] epoch:120 step:300 g_loss:0.5457928776741028 d_loss:1.267373502254486 (f_loss=0.4508626461029053 r_loss=0.5320278406143188 GP=0.28448301553726196)
[Training] epoch:121 step:0 g_loss:0.5902020931243896 d_loss:1.2385276705026627 (f_loss=0.45763978362083435 r_loss=0.5331114530563354 GP=0.24777643382549286)
[Training] epoch:121 step:100 g_loss:0.5856461524963379 d_loss:1.3249907493591309 (f_loss=0.4101253151893616 r_loss=0.48314720392227173 GP=0.43171823024749756)
[Training] epoch:121 step:200 g_loss:0.555350661277771 d_loss:1.073749266564846 (f_loss=0.459200382232666 r_loss=0.5125178098678589 GP=0.10203107446432114)
[Training] epoch:121 step:300 g_loss:0.6242750287055969 d_loss:0.9757615365087986 (f_loss=0.44120413064956665 r_loss=0.4773900508880615 GP=0.057167354971170425)
[Training] epoch:122 step:0 g_loss:0.5832201242446899 d_loss:1.1214986592531204 (f_loss=0.4221169352531433 r_loss=0.5351434946060181 GP=0.16423822939395905)
[Training] epoch:122 step:100 g_loss:0.5355226397514343 d_loss:1.4441452324390411 (f_loss=0.42483919858932495 r_loss=0.537270724773407 GP=0.4820353090763092)
[Training] epoch:122 step:200 g_loss:0.5114785432815552 d_loss:1.154863178730011 (f_loss=0.48691505193710327 r_loss=0.5154134035110474 GP=0.15253472328186035)
[Training] epoch:122 step:300 g_loss:0.5633664131164551 d_loss:1.140590563416481 (f_loss=0.42905735969543457 r_loss=0.5616083741188049 GP=0.14992482960224152)
[Training] epoch:123 step:0 g_loss:0.6199662089347839 d_loss:1.1281000077724457 (f_loss=0.3922715485095978 r_loss=0.5637608766555786 GP=0.1720675826072693)
[Training] epoch:123 step:100 g_loss:0.6302775740623474 d_loss:1.1286709159612656 (f_loss=0.44022732973098755 r_loss=0.5628147125244141 GP=0.12562887370586395)
[Training] epoch:123 step:200 g_loss:0.587833046913147 d_loss:1.124183714389801 (f_loss=0.40710175037384033 r_loss=0.514305830001831 GP=0.20277613401412964)
[Training] epoch:123 step:300 g_loss:0.639130711555481 d_loss:1.0117681920528412 (f_loss=0.3993666172027588 r_loss=0.545514702796936 GP=0.06688687205314636)
[Training] epoch:124 step:0 g_loss:0.548865556716919 d_loss:1.1686271131038666 (f_loss=0.4156661629676819 r_loss=0.5355598330497742 GP=0.21740111708641052)
[Training] epoch:124 step:100 g_loss:0.6133513450622559 d_loss:1.017675794661045 (f_loss=0.39160600304603577 r_loss=0.5245016813278198 GP=0.10156811028718948)
[Training] epoch:124 step:200 g_loss:0.5008136034011841 d_loss:1.0303938761353493 (f_loss=0.4606437683105469 r_loss=0.5253640413284302 GP=0.04438606649637222)
[Training] epoch:124 step:300 g_loss:0.5391714572906494 d_loss:1.1768558770418167 (f_loss=0.41239285469055176 r_loss=0.5246546864509583 GP=0.2398083359003067)
[Training] epoch:125 step:0 g_loss:0.5948197841644287 d_loss:1.2844284176826477 (f_loss=0.45865321159362793 r_loss=0.47095948457717896 GP=0.3548157215118408)
[Training] epoch:125 step:100 g_loss:0.5746098756790161 d_loss:1.433319240808487 (f_loss=0.4271703064441681 r_loss=0.507517397403717 GP=0.4986315369606018)
[Training] epoch:125 step:200 g_loss:0.6059600710868835 d_loss:1.0132616087794304 (f_loss=0.43032437562942505 r_loss=0.5237945318222046 GP=0.05914270132780075)
[Training] epoch:125 step:300 g_loss:0.5765788555145264 d_loss:1.3282459080219269 (f_loss=0.4391132891178131 r_loss=0.5346293449401855 GP=0.3545032739639282)
[Training] epoch:126 step:0 g_loss:0.6254539489746094 d_loss:1.0407158806920052 (f_loss=0.4225902855396271 r_loss=0.514585554599762 GP=0.10354004055261612)
[Training] epoch:126 step:100 g_loss:0.5354629755020142 d_loss:1.3596859872341156 (f_loss=0.432638943195343 r_loss=0.5215737819671631 GP=0.4054732620716095)
[Training] epoch:126 step:200 g_loss:0.6009500026702881 d_loss:0.9760533794760704 (f_loss=0.3803589940071106 r_loss=0.5494898557662964 GP=0.04620452970266342)
[Training] epoch:126 step:300 g_loss:0.5530344247817993 d_loss:1.2366164922714233 (f_loss=0.45005542039871216 r_loss=0.4733983278274536 GP=0.31316274404525757)
[Training] epoch:127 step:0 g_loss:0.566614031791687 d_loss:1.3460531532764435 (f_loss=0.40433698892593384 r_loss=0.5431864261627197 GP=0.3985297381877899)
[Training] epoch:127 step:100 g_loss:0.5641830563545227 d_loss:1.0921686962246895 (f_loss=0.48361730575561523 r_loss=0.50121009349823 GP=0.10734129697084427)
[Training] epoch:127 step:200 g_loss:0.6140772104263306 d_loss:1.4293562173843384 (f_loss=0.3820810914039612 r_loss=0.45060521364212036 GP=0.5966699123382568)
[Training] epoch:127 step:300 g_loss:0.5766990780830383 d_loss:1.03187445551157 (f_loss=0.41026443243026733 r_loss=0.520172119140625 GP=0.10143790394067764)
[Training] epoch:128 step:0 g_loss:0.6288092136383057 d_loss:1.0471630729734898 (f_loss=0.46160486340522766 r_loss=0.5251791477203369 GP=0.060379061847925186)
[Training] epoch:128 step:100 g_loss:0.5821276307106018 d_loss:1.9130292236804962 (f_loss=0.4251073896884918 r_loss=0.5378291606903076 GP=0.9500926733016968)
[Training] epoch:128 step:200 g_loss:0.526236891746521 d_loss:1.0413708537817001 (f_loss=0.41283249855041504 r_loss=0.507764458656311 GP=0.12077389657497406)
[Training] epoch:128 step:300 g_loss:0.5391833782196045 d_loss:1.1179309785366058 (f_loss=0.47128230333328247 r_loss=0.5130225419998169 GP=0.13362613320350647)
[Training] epoch:129 step:0 g_loss:0.5538312196731567 d_loss:2.1870990693569183 (f_loss=0.4991320073604584 r_loss=0.45532846450805664 GP=1.2326385974884033)
[Training] epoch:129 step:100 g_loss:0.5415499210357666 d_loss:1.0667573437094688 (f_loss=0.4195162057876587 r_loss=0.5364800691604614 GP=0.11076106876134872)
[Training] epoch:129 step:200 g_loss:0.5420236587524414 d_loss:1.0053091943264008 (f_loss=0.45198914408683777 r_loss=0.45685428380966187 GP=0.09646576642990112)
[Training] epoch:129 step:300 g_loss:0.5609681010246277 d_loss:1.08159039914608 (f_loss=0.45439863204956055 r_loss=0.5101074576377869 GP=0.1170843094587326)
[Training] epoch:130 step:0 g_loss:0.5605082511901855 d_loss:1.1113680973649025 (f_loss=0.44509679079055786 r_loss=0.5736198425292969 GP=0.09265146404504776)

[Training] epoch:130 step:100 g_loss:0.605807900428772 d_loss:1.1016896665096283 (f_loss=0.4281238317489624 r_loss=0.5669556856155396 GP=0.10661014914512634)
[Training] epoch:130 step:200 g_loss:0.5394741892814636 d_loss:1.0385113656520844 (f_loss=0.41801366209983826 r_loss=0.5123460292816162 GP=0.10815167427062988)
[Training] epoch:130 step:300 g_loss:0.5546334981918335 d_loss:1.0191661342978477 (f_loss=0.46034687757492065 r_loss=0.4916132688522339 GP=0.0672059878706932)
[Training] epoch:131 step:0 g_loss:0.5402282476425171 d_loss:1.328211784362793 (f_loss=0.3664134740829468 r_loss=0.47174370288848877 GP=0.4900546073913574)
[Training] epoch:131 step:100 g_loss:0.5408434867858887 d_loss:2.5318499207496643 (f_loss=0.4510180950164795 r_loss=0.5592820048332214 GP=1.5215498208999634)
[Training] epoch:131 step:200 g_loss:0.5963774919509888 d_loss:1.2182535976171494 (f_loss=0.4339188039302826 r_loss=0.5479183197021484 GP=0.23641647398471832)
[Training] epoch:131 step:300 g_loss:0.5572319030761719 d_loss:1.102344661951065 (f_loss=0.41177645325660706 r_loss=0.5302307605743408 GP=0.1603374481201172)
[Training] epoch:132 step:0 g_loss:0.5693516731262207 d_loss:1.2419427633285522 (f_loss=0.41130566596984863 r_loss=0.5393862724304199 GP=0.2912508249282837)
[Training] epoch:132 step:100 g_loss:0.5247143507003784 d_loss:1.0473864376544952 (f_loss=0.4831206500530243 r_loss=0.48847496509552 GP=0.07579082250595093)
[Training] epoch:132 step:200 g_loss:0.5584052801132202 d_loss:1.0620056986808777 (f_loss=0.452384889125824 r_loss=0.5634452700614929 GP=0.04617553949356079)
[Training] epoch:132 step:300 g_loss:0.6006397604942322 d_loss:1.6878963112831116 (f_loss=0.44302648305892944 r_loss=0.5458729267120361 GP=0.698996901512146)
[Training] epoch:133 step:0 g_loss:0.5809169411659241 d_loss:1.1012403070926666 (f_loss=0.41113272309303284 r_loss=0.5800718069076538 GP=0.11003577709197998)
[Training] epoch:133 step:100 g_loss:0.625856876373291 d_loss:0.952727735042572 (f_loss=0.41488000750541687 r_loss=0.4994145631790161 GP=0.03843316435813904)
[Training] epoch:133 step:200 g_loss:0.5815134644508362 d_loss:1.0200339555740356 (f_loss=0.4103400707244873 r_loss=0.5038647651672363 GP=0.10582911968231201)
[Training] epoch:133 step:300 g_loss:0.5672014951705933 d_loss:0.9835525564849377 (f_loss=0.4754202663898468 r_loss=0.4535662531852722 GP=0.05456603690981865)
[Training] epoch:134 step:0 g_loss:0.5486000776290894 d_loss:1.2627338767051697 (f_loss=0.47329840064048767 r_loss=0.5204743146896362 GP=0.2689611613750458)
[Training] epoch:134 step:100 g_loss:0.6084071397781372 d_loss:0.992257259786129 (f_loss=0.39148569107055664 r_loss=0.5447120666503906 GP=0.05605950206518173)
[Training] epoch:134 step:200 g_loss:0.5679658651351929 d_loss:1.1148510128259659 (f_loss=0.4240861237049103 r_loss=0.5380704402923584 GP=0.1526944488286972)
[Training] epoch:134 step:300 g_loss:0.5730034112930298 d_loss:1.1533136665821075 (f_loss=0.4320966601371765 r_loss=0.5484245419502258 GP=0.1727924644947052)
[Training] epoch:135 step:0 g_loss:0.524367094039917 d_loss:0.9873331561684608 (f_loss=0.4006205201148987 r_loss=0.47642242908477783 GP=0.11029020696878433)
[Training] epoch:135 step:100 g_loss:0.5483835339546204 d_loss:1.4214483797550201 (f_loss=0.3369719088077545 r_loss=0.5037131309509277 GP=0.5807633399963379)
[Training] epoch:135 step:200 g_loss:0.589653491973877 d_loss:1.0526937395334244 (f_loss=0.3779902756214142 r_loss=0.5932578444480896 GP=0.0814456194639206)
[Training] epoch:135 step:300 g_loss:0.622109055519104 d_loss:1.0351674258708954 (f_loss=0.449371874332428 r_loss=0.5415016412734985 GP=0.04429391026496887)
[Training] epoch:136 step:0 g_loss:0.5680777430534363 d_loss:1.0869764238595963 (f_loss=0.4057668447494507 r_loss=0.5783230066299438 GP=0.10288657248020172)
[Training] epoch:136 step:100 g_loss:0.5579285621643066 d_loss:1.0959835648536682 (f_loss=0.37350884079933167 r_loss=0.5130821466445923 GP=0.20939257740974426)
[Training] epoch:136 step:200 g_loss:0.6007131338119507 d_loss:1.4004455506801605 (f_loss=0.4325207769870758 r_loss=0.5299917459487915 GP=0.4379330277442932)
[Training] epoch:136 step:300 g_loss:0.591890811920166 d_loss:1.4263644516468048 (f_loss=0.45627158880233765 r_loss=0.4780423641204834 GP=0.49205049872398376)
[Training] epoch:137 step:0 g_loss:0.5650601387023926 d_loss:1.0039502680301666 (f_loss=0.40320539474487305 r_loss=0.537480890750885 GP=0.06326398253440857)
[Training] epoch:137 step:100 g_loss:0.5564810633659363 d_loss:1.0300932824611664 (f_loss=0.39768651127815247 r_loss=0.5280991792678833 GP=0.10430759191513062)
[Training] epoch:137 step:200 g_loss:0.5857275128364563 d_loss:1.1009417697787285 (f_loss=0.4590557813644409 r_loss=0.5269007682800293 GP=0.11498522013425827)
[Training] epoch:137 step:300 g_loss:0.5704651474952698 d_loss:1.2279973030090332 (f_loss=0.42557886242866516 r_loss=0.5399518013000488 GP=0.2624666392803192)
[Training] epoch:138 step:0 g_loss:0.6324816346168518 d_loss:0.9277455508708954 (f_loss=0.41558676958084106 r_loss=0.48070061206817627 GP=0.03145816922187805)
[Training] epoch:138 step:100 g_loss:0.6191642880439758 d_loss:1.656029850244522 (f_loss=0.47327956557273865 r_loss=0.627274215221405 GP=0.5554760694503784)
[Training] epoch:138 step:200 g_loss:0.5719778537750244 d_loss:1.096370317041874 (f_loss=0.4446529448032379 r_loss=0.5611230134963989 GP=0.09059435874223709)
[Training] epoch:138 step:300 g_loss:0.5576623678207397 d_loss:1.0188807770609856 (f_loss=0.38780859112739563 r_loss=0.5396418571472168 GP=0.09143032878637314)
[Training] epoch:139 step:0 g_loss:0.5670487284660339 d_loss:1.0013768896460533 (f_loss=0.387338250875473 r_loss=0.54496169090271 GP=0.06907694786787033)
[Training] epoch:139 step:100 g_loss:0.5712723731994629 d_loss:1.0295751690864563 (f_loss=0.3707082271575928 r_loss=0.5003277063369751 GP=0.15853923559188843)
[Training] epoch:139 step:200 g_loss:0.5482639074325562 d_loss:1.1225854754447937 (f_loss=0.43715500831604004 r_loss=0.5253461599349976 GP=0.1600843071937561)
[Training] epoch:139 step:300 g_loss:0.5803511142730713 d_loss:1.7270057499408722 (f_loss=0.4130501449108124 r_loss=0.5370323657989502 GP=0.7769232392311096)
[Training] epoch:140 step:0 g_loss:0.5169695019721985 d_loss:1.1428485214710236 (f_loss=0.47048401832580566 r_loss=0.5040671229362488 GP=0.16829738020896912)

[Training] epoch:140 step:100 g_loss:0.5169234275817871 d_loss:1.4799391031265259 (f_loss=0.43974411487579346 r_loss=0.4825199842453003 GP=0.5576750040054321)
[Training] epoch:140 step:200 g_loss:0.6131898164749146 d_loss:1.1713237762451172 (f_loss=0.450633704662323 r_loss=0.584251880645752 GP=0.13643819093704224)
[Training] epoch:140 step:300 g_loss:0.5903642177581787 d_loss:1.023481398820877 (f_loss=0.42740315198898315 r_loss=0.54624342918396 GP=0.04983481764793396)
[Training] epoch:141 step:0 g_loss:0.5599864721298218 d_loss:0.9821164682507515 (f_loss=0.38392388820648193 r_loss=0.5484877228736877 GP=0.04970485717058182)
[Training] epoch:141 step:100 g_loss:0.5359839200973511 d_loss:1.1389462351799011 (f_loss=0.4640142321586609 r_loss=0.609752893447876 GP=0.06517910957336426)
[Training] epoch:141 step:200 g_loss:0.6192137002944946 d_loss:1.0671218931674957 (f_loss=0.43070104718208313 r_loss=0.5378157496452332 GP=0.09860509634017944)
[Training] epoch:141 step:300 g_loss:0.6164836883544922 d_loss:1.0212539583444595 (f_loss=0.4027169942855835 r_loss=0.4692770838737488 GP=0.14925988018512726)
[Training] epoch:142 step:0 g_loss:0.6198577880859375 d_loss:1.0988532304763794 (f_loss=0.44466304779052734 r_loss=0.5435777902603149 GP=0.11061239242553711)
[Training] epoch:142 step:100 g_loss:0.5379055738449097 d_loss:1.3210172057151794 (f_loss=0.41885656118392944 r_loss=0.5617325901985168 GP=0.34042805433273315)
[Training] epoch:142 step:200 g_loss:0.5971816778182983 d_loss:0.9646726325154305 (f_loss=0.3787465989589691 r_loss=0.49289608001708984 GP=0.09302995353937149)
[Training] epoch:142 step:300 g_loss:0.6028679013252258 d_loss:1.047449141740799 (f_loss=0.3861669898033142 r_loss=0.5879415273666382 GP=0.07334062457084656)
[Training] epoch:143 step:0 g_loss:0.59859699010849 d_loss:1.1542328000068665 (f_loss=0.38563433289527893 r_loss=0.5045177340507507 GP=0.2640807330608368)
[Training] epoch:143 step:100 g_loss:0.561835527420044 d_loss:1.0117661133408546 (f_loss=0.4137398600578308 r_loss=0.5265190601348877 GP=0.07150719314813614)
[Training] epoch:143 step:200 g_loss:0.6132947206497192 d_loss:0.9230484962463379 (f_loss=0.3721945881843567 r_loss=0.49668729305267334 GP=0.05416661500930786)
[Training] epoch:143 step:300 g_loss:0.6236421465873718 d_loss:2.075651615858078 (f_loss=0.3745562732219696 r_loss=0.5600048303604126 GP=1.1410905122756958)
[Training] epoch:144 step:0 g_loss:0.6211053133010864 d_loss:0.9802272915840149 (f_loss=0.3954777717590332 r_loss=0.5451865792274475 GP=0.03956294059753418)
[Training] epoch:144 step:100 g_loss:0.609066367149353 d_loss:0.9810587279498577 (f_loss=0.4373719394207001 r_loss=0.4897940754890442 GP=0.05389271304011345)
[Training] epoch:144 step:200 g_loss:0.6490355730056763 d_loss:1.0889947563409805 (f_loss=0.3842857778072357 r_loss=0.4941333532333374 GP=0.2105756253004074)
[Training] epoch:144 step:300 g_loss:0.5702195167541504 d_loss:0.9714271873235703 (f_loss=0.39212414622306824 r_loss=0.5162414312362671 GP=0.06306160986423492)
[Training] epoch:145 step:0 g_loss:0.577424943447113 d_loss:1.0451322942972183 (f_loss=0.4144599139690399 r_loss=0.5425487160682678 GP=0.08812366425991058)
[Training] epoch:145 step:100 g_loss:0.59796541929245 d_loss:0.9604350030422211 (f_loss=0.366890013217926 r_loss=0.5335069894790649 GP=0.0600380003452301)
[Training] epoch:145 step:200 g_loss:0.6349657773971558 d_loss:1.2405992150306702 (f_loss=0.4233953356742859 r_loss=0.47066909074783325 GP=0.346534788608551)
[Training] epoch:145 step:300 g_loss:0.5833137035369873 d_loss:1.6789809465408325 (f_loss=0.38379770517349243 r_loss=0.49965131282806396 GP=0.7955319285392761)
[Training] epoch:146 step:0 g_loss:0.5967956781387329 d_loss:1.037591427564621 (f_loss=0.3817276954650879 r_loss=0.5658275485038757 GP=0.09003618359565735)
[Training] epoch:146 step:100 g_loss:0.6230535507202148 d_loss:1.0065332800149918 (f_loss=0.38707149028778076 r_loss=0.5312113761901855 GP=0.08825041353702545)
[Training] epoch:146 step:200 g_loss:0.5788500308990479 d_loss:1.592038780450821 (f_loss=0.3882773220539093 r_loss=0.5482231378555298 GP=0.6555383205413818)
[Training] epoch:146 step:300 g_loss:0.6196606159210205 d_loss:1.0931721329689026 (f_loss=0.4260934591293335 r_loss=0.5367943048477173 GP=0.1302843689918518)
[Training] epoch:147 step:0 g_loss:0.605183482170105 d_loss:1.0363451391458511 (f_loss=0.4536779522895813 r_loss=0.5431222915649414 GP=0.03954489529132843)
[Training] epoch:147 step:100 g_loss:0.6714821457862854 d_loss:1.0698556303977966 (f_loss=0.42510879039764404 r_loss=0.49796009063720703 GP=0.14678674936294556)
[Training] epoch:147 step:200 g_loss:0.5672640204429626 d_loss:0.9582511857151985 (f_loss=0.36792901158332825 r_loss=0.5354184508323669 GP=0.054903723299503326)
[Training] epoch:147 step:300 g_loss:0.6189137101173401 d_loss:1.1584929525852203 (f_loss=0.4030488133430481 r_loss=0.5152528285980225 GP=0.24019131064414978)
[Training] epoch:148 step:0 g_loss:0.5604931712150574 d_loss:0.9383696913719177 (f_loss=0.3690248131752014 r_loss=0.48785918951034546 GP=0.08148568868637085)
[Training] epoch:148 step:100 g_loss:0.5759477615356445 d_loss:1.3033203184604645 (f_loss=0.45999348163604736 r_loss=0.5549553632736206 GP=0.2883714735507965)
[Training] epoch:148 step:200 g_loss:0.5945246815681458 d_loss:1.0534064956009388 (f_loss=0.4220520257949829 r_loss=0.5723249912261963 GP=0.0590294785797596)
[Training] epoch:148 step:300 g_loss:0.6388292908668518 d_loss:1.3719945847988129 (f_loss=0.3765954077243805 r_loss=0.5004574656486511 GP=0.49494171142578125)
[Training] epoch:149 step:0 g_loss:0.613166332244873 d_loss:1.0603087544441223 (f_loss=0.4017992615699768 r_loss=0.5614770650863647 GP=0.09703242778778076)
[Training] epoch:149 step:100 g_loss:0.5749627351760864 d_loss:0.9765035659074783 (f_loss=0.3929842412471771 r_loss=0.4120386838912964 GP=0.17148064076900482)
[Training] epoch:149 step:200 g_loss:0.6388651132583618 d_loss:0.9685434177517891 (f_loss=0.4032115042209625 r_loss=0.5192343592643738 GP=0.04609755426645279)
[Training] epoch:149 step:300 g_loss:0.6009573340415955 d_loss:1.077493041753769 (f_loss=0.43684425950050354 r_loss=0.5208750367164612 GP=0.1197737455368042)
[Training] epoch:150 step:0 g_loss:0.5891361236572266 d_loss:1.3375604450702667 (f_loss=0.3866966962814331 r_loss=0.5822731256484985 GP=0.3685906231403351)

[Training] epoch:150 step:100 g_loss:0.540521502494812 d_loss:1.1911031603813171 (f_loss=0.44126611948013306 r_loss=0.5862849950790405 GP=0.16355204582214355)
[Training] epoch:150 step:200 g_loss:0.6243944764137268 d_loss:1.0109436213970184 (f_loss=0.43865644931793213 r_loss=0.5040146112442017 GP=0.06827256083488464)
[Training] epoch:150 step:300 g_loss:0.5999433994293213 d_loss:0.9498765841126442 (f_loss=0.4222351312637329 r_loss=0.48027515411376953 GP=0.047366298735141754)
[Training] epoch:151 step:0 g_loss:0.5217750072479248 d_loss:1.0261700451374054 (f_loss=0.4018159806728363 r_loss=0.5120166540145874 GP=0.11233741044998169)
[Training] epoch:151 step:100 g_loss:0.6103402376174927 d_loss:1.0021273829042912 (f_loss=0.49275341629981995 r_loss=0.4596405029296875 GP=0.04973346367478371)
[Training] epoch:151 step:200 g_loss:0.5814767479896545 d_loss:0.9628601744771004 (f_loss=0.4028976857662201 r_loss=0.5219998359680176 GP=0.0379626527428627)
[Training] epoch:151 step:300 g_loss:0.5149149894714355 d_loss:1.1599768698215485 (f_loss=0.4351504445075989 r_loss=0.5828046202659607 GP=0.1420218050479889)
[Training] epoch:152 step:0 g_loss:0.619613766670227 d_loss:1.0297364220023155 (f_loss=0.4181480407714844 r_loss=0.5132644772529602 GP=0.09832390397787094)
[Training] epoch:152 step:100 g_loss:0.5695117115974426 d_loss:1.2786024808883667 (f_loss=0.3919501006603241 r_loss=0.5989735126495361 GP=0.28767886757850647)
[Training] epoch:152 step:200 g_loss:0.5900219678878784 d_loss:1.0801589787006378 (f_loss=0.42090320587158203 r_loss=0.45487481355667114 GP=0.20438095927238464)
[Training] epoch:152 step:300 g_loss:0.5901521444320679 d_loss:1.0602356642484665 (f_loss=0.43659842014312744 r_loss=0.5756994485855103 GP=0.047937795519828796)
[Training] epoch:153 step:0 g_loss:0.5742989778518677 d_loss:1.172055959701538 (f_loss=0.3992120027542114 r_loss=0.5252506732940674 GP=0.24759328365325928)
[Training] epoch:153 step:100 g_loss:0.5659834742546082 d_loss:1.2559757828712463 (f_loss=0.46939951181411743 r_loss=0.5244266986846924 GP=0.2621495723724365)
[Training] epoch:153 step:200 g_loss:0.5297625660896301 d_loss:1.066532239317894 (f_loss=0.38766971230506897 r_loss=0.5436846017837524 GP=0.13517792522907257)
[Training] epoch:153 step:300 g_loss:0.5885376334190369 d_loss:1.1914254128932953 (f_loss=0.373066246509552 r_loss=0.5703524947166443 GP=0.248006671667099)
[Training] epoch:154 step:0 g_loss:0.5914479494094849 d_loss:1.249693751335144 (f_loss=0.3548135757446289 r_loss=0.4865463376045227 GP=0.40833383798599243)
[Training] epoch:154 step:100 g_loss:0.6230645179748535 d_loss:1.0355799943208694 (f_loss=0.35531073808670044 r_loss=0.5403354167938232 GP=0.13993383944034576)
[Training] epoch:154 step:200 g_loss:0.614969789981842 d_loss:1.030774101614952 (f_loss=0.3607860803604126 r_loss=0.5684360265731812 GP=0.10155199468135834)
[Training] epoch:154 step:300 g_loss:0.5781880617141724 d_loss:1.0383467003703117 (f_loss=0.4180639982223511 r_loss=0.560073733329773 GP=0.060208968818187714)
[Training] epoch:155 step:0 g_loss:0.5914021730422974 d_loss:1.1716879159212112 (f_loss=0.3801938593387604 r_loss=0.5867342352867126 GP=0.20475982129573822)
[Training] epoch:155 step:100 g_loss:0.629391074180603 d_loss:1.0410632267594337 (f_loss=0.4436696767807007 r_loss=0.5050179362297058 GP=0.09237561374902725)
[Training] epoch:155 step:200 g_loss:0.6140531301498413 d_loss:0.9943579137325287 (f_loss=0.37698256969451904 r_loss=0.523895263671875 GP=0.09348008036613464)
[Training] epoch:155 step:300 g_loss:0.5249046087265015 d_loss:1.1086535900831223 (f_loss=0.3851962983608246 r_loss=0.5886491537094116 GP=0.13480813801288605)
[Training] epoch:156 step:0 g_loss:0.6425309777259827 d_loss:1.0004807189106941 (f_loss=0.3777700364589691 r_loss=0.5779122114181519 GP=0.04479847103357315)
[Training] epoch:156 step:100 g_loss:0.5631523728370667 d_loss:1.204050362110138 (f_loss=0.39442116022109985 r_loss=0.5208467245101929 GP=0.2887824773788452)
[Training] epoch:156 step:200 g_loss:0.6075190901756287 d_loss:1.0046379268169403 (f_loss=0.37743955850601196 r_loss=0.5465302467346191 GP=0.0806681215763092)
[Training] epoch:156 step:300 g_loss:0.5818922519683838 d_loss:1.3307093381881714 (f_loss=0.4123256802558899 r_loss=0.5055140256881714 GP=0.4128696322441101)
[Training] epoch:157 step:0 g_loss:0.6224370002746582 d_loss:1.0952602624893188 (f_loss=0.4112387001514435 r_loss=0.49905896186828613 GP=0.18496260046958923)
[Training] epoch:157 step:100 g_loss:0.6284264326095581 d_loss:0.998371422290802 (f_loss=0.361017107963562 r_loss=0.545639157295227 GP=0.09171515703201294)
[Training] epoch:157 step:200 g_loss:0.5931072235107422 d_loss:1.0213161706924438 (f_loss=0.4030795991420746 r_loss=0.5692801475524902 GP=0.04895642399787903)
[Training] epoch:157 step:300 g_loss:0.6116785407066345 d_loss:1.20093634724617 (f_loss=0.3973385691642761 r_loss=0.5348625183105469 GP=0.26873525977134705)
[Training] epoch:158 step:0 g_loss:0.6452165842056274 d_loss:1.1818075776100159 (f_loss=0.43482333421707153 r_loss=0.4962049722671509 GP=0.25077927112579346)
[Training] epoch:158 step:100 g_loss:0.6049070954322815 d_loss:0.9813367500901222 (f_loss=0.3884824216365814 r_loss=0.5526866912841797 GP=0.040167637169361115)
[Training] epoch:158 step:200 g_loss:0.5757365226745605 d_loss:1.3717396259307861 (f_loss=0.38078033924102783 r_loss=0.5933828353881836 GP=0.3975764513015747)
[Training] epoch:158 step:300 g_loss:0.5814603567123413 d_loss:1.1862923502922058 (f_loss=0.3799523413181305 r_loss=0.5283100008964539 GP=0.27803000807762146)
[Training] epoch:159 step:0 g_loss:0.6148287057876587 d_loss:1.013590283691883 (f_loss=0.39771509170532227 r_loss=0.5219897627830505 GP=0.09388542920351028)
[Training] epoch:159 step:100 g_loss:0.5723564624786377 d_loss:1.0111718475818634 (f_loss=0.40935537219047546 r_loss=0.5087205767631531 GP=0.09309589862823486)
[Training] epoch:159 step:200 g_loss:0.6245731115341187 d_loss:0.9914884231984615 (f_loss=0.3622397482395172 r_loss=0.5736613273620605 GP=0.055587347596883774)
[Training] epoch:159 step:300 g_loss:0.549607515335083 d_loss:1.3901883363723755 (f_loss=0.46229374408721924 r_loss=0.5337504744529724 GP=0.39414411783218384)
[Training] epoch:160 step:0 g_loss:0.5385072231292725 d_loss:0.9631638070568442 (f_loss=0.41865772008895874 r_loss=0.5310676693916321 GP=0.013438417576253414)

[Training] epoch:160 step:100 g_loss:0.5855671763420105 d_loss:0.9813724383711815 (f_loss=0.34697389602661133 r_loss=0.5301985144615173 GP=0.10420002788305283)
[Training] epoch:160 step:200 g_loss:0.618552565574646 d_loss:1.0392165407538414 (f_loss=0.40123990178108215 r_loss=0.5843502283096313 GP=0.0536264106631279)
[Training] epoch:160 step:300 g_loss:0.5829992890357971 d_loss:1.1743311882019043 (f_loss=0.41825437545776367 r_loss=0.45963841676712036 GP=0.29643839597702026)
[Training] epoch:161 step:0 g_loss:0.5706102252006531 d_loss:0.9124824814498425 (f_loss=0.3635093569755554 r_loss=0.5035669207572937 GP=0.04540620371699333)
[Training] epoch:161 step:100 g_loss:0.6221826076507568 d_loss:1.012744501233101 (f_loss=0.3856161832809448 r_loss=0.4873952269554138 GP=0.13973309099674225)
[Training] epoch:161 step:200 g_loss:0.5746023654937744 d_loss:1.04242742061615 (f_loss=0.37549543380737305 r_loss=0.5225550532341003 GP=0.1443769335746765)
[Training] epoch:161 step:300 g_loss:0.5691397786140442 d_loss:1.0223461538553238 (f_loss=0.3858075737953186 r_loss=0.5623645186424255 GP=0.07417406141757965)
[Training] epoch:162 step:0 g_loss:0.6775810122489929 d_loss:1.171939879655838 (f_loss=0.3630495071411133 r_loss=0.5283330678939819 GP=0.2805573046207428)
[Training] epoch:162 step:100 g_loss:0.6303009986877441 d_loss:0.9803256578743458 (f_loss=0.3478730320930481 r_loss=0.5743470191955566 GP=0.05810560658574104)
[Training] epoch:162 step:200 g_loss:0.6259077787399292 d_loss:1.1895171105861664 (f_loss=0.4315236210823059 r_loss=0.5778405666351318 GP=0.18015292286872864)
[Training] epoch:162 step:300 g_loss:0.5841190218925476 d_loss:1.3534495532512665 (f_loss=0.38471749424934387 r_loss=0.5406465530395508 GP=0.4280855059623718)
[Training] epoch:163 step:0 g_loss:0.5900741815567017 d_loss:0.9515025429427624 (f_loss=0.3605124354362488 r_loss=0.540188193321228 GP=0.05080191418528557)
[Training] epoch:163 step:100 g_loss:0.6009534597396851 d_loss:0.9098001308739185 (f_loss=0.39325469732284546 r_loss=0.48739391565322876 GP=0.029151517897844315)
[Training] epoch:163 step:200 g_loss:0.6005146503448486 d_loss:0.9477892369031906 (f_loss=0.36670249700546265 r_loss=0.5199501514434814 GP=0.06113658845424652)
[Training] epoch:163 step:300 g_loss:0.5823004245758057 d_loss:1.0714828968048096 (f_loss=0.4126497209072113 r_loss=0.536815881729126 GP=0.12201729416847229)
[Training] epoch:164 step:0 g_loss:0.5981746912002563 d_loss:0.9874340668320656 (f_loss=0.4017595648765564 r_loss=0.549980640411377 GP=0.03569386154413223)
[Training] epoch:164 step:100 g_loss:0.5823686122894287 d_loss:1.042130310088396 (f_loss=0.43171408772468567 r_loss=0.5503695011138916 GP=0.0600467212498188)
[Training] epoch:164 step:200 g_loss:0.6279412508010864 d_loss:1.0639500170946121 (f_loss=0.3814013600349426 r_loss=0.5328372716903687 GP=0.14971138536930084)
[Training] epoch:164 step:300 g_loss:0.5940372943878174 d_loss:1.0466798692941666 (f_loss=0.3959115743637085 r_loss=0.5139095783233643 GP=0.1368587166070938)
[Training] epoch:165 step:0 g_loss:0.5674408674240112 d_loss:1.0395151674747467 (f_loss=0.38577553629875183 r_loss=0.547881543636322 GP=0.10585808753967285)
[Training] epoch:165 step:100 g_loss:0.5715687274932861 d_loss:1.0805144719779491 (f_loss=0.41787487268447876 r_loss=0.6065937280654907 GP=0.05604587122797966)
[Training] epoch:165 step:200 g_loss:0.5660232305526733 d_loss:0.9508783146739006 (f_loss=0.361926794052124 r_loss=0.5431923866271973 GP=0.045759133994579315)
[Training] epoch:165 step:300 g_loss:0.6068724393844604 d_loss:0.9444502219557762 (f_loss=0.42236995697021484 r_loss=0.4855615496635437 GP=0.03651871532201767)
[Training] epoch:166 step:0 g_loss:0.6281535625457764 d_loss:0.979799211025238 (f_loss=0.3837604224681854 r_loss=0.5271632075309753 GP=0.06887558102607727)
[Training] epoch:166 step:100 g_loss:0.5944544076919556 d_loss:1.3206031024456024 (f_loss=0.38923272490501404 r_loss=0.5688624978065491 GP=0.3625078797340393)
[Training] epoch:166 step:200 g_loss:0.5859202146530151 d_loss:1.0379900187253952 (f_loss=0.3949781656265259 r_loss=0.5037641525268555 GP=0.13924770057201385)
[Training] epoch:166 step:300 g_loss:0.5567228198051453 d_loss:1.0874505937099457 (f_loss=0.40419161319732666 r_loss=0.5412899851799011 GP=0.1419689953327179)
[Training] epoch:167 step:0 g_loss:0.632061779499054 d_loss:1.3602735102176666 (f_loss=0.39798688888549805 r_loss=0.49049651622772217 GP=0.4717901051044464)
[Training] epoch:167 step:100 g_loss:0.6532424688339233 d_loss:1.0898400396108627 (f_loss=0.41624653339385986 r_loss=0.5366369485855103 GP=0.13695655763149261)
[Training] epoch:167 step:200 g_loss:0.6014022827148438 d_loss:1.0127503387629986 (f_loss=0.42228350043296814 r_loss=0.5416590571403503 GP=0.0488077811896801)
[Training] epoch:167 step:300 g_loss:0.5911737084388733 d_loss:0.970051534473896 (f_loss=0.3710596263408661 r_loss=0.5568303465843201 GP=0.04216156154870987)
[Training] epoch:168 step:0 g_loss:0.6161227226257324 d_loss:1.0769028961658478 (f_loss=0.38366732001304626 r_loss=0.5208876132965088 GP=0.17234796285629272)
[Training] epoch:168 step:100 g_loss:0.6519073247909546 d_loss:1.5470108687877655 (f_loss=0.3515804708003998 r_loss=0.5992095470428467 GP=0.596220850944519)
[Training] epoch:168 step:200 g_loss:0.5935086011886597 d_loss:1.0360850095748901 (f_loss=0.3722606599330902 r_loss=0.5457974672317505 GP=0.11802688241004944)
[Training] epoch:168 step:300 g_loss:0.5808477401733398 d_loss:1.148400902748108 (f_loss=0.3973745107650757 r_loss=0.4344255328178406 GP=0.31660085916519165)
[Training] epoch:169 step:0 g_loss:0.6097879409790039 d_loss:0.9477298967540264 (f_loss=0.4114540219306946 r_loss=0.4995034337043762 GP=0.03677244111895561)
[Training] epoch:169 step:100 g_loss:0.6824183464050293 d_loss:0.9681553766131401 (f_loss=0.4104502201080322 r_loss=0.5266559720039368 GP=0.031049184501171112)
[Training] epoch:169 step:200 g_loss:0.6037835478782654 d_loss:1.1839172095060349 (f_loss=0.4701225161552429 r_loss=0.5170074105262756 GP=0.1967872828245163)
[Training] epoch:169 step:300 g_loss:0.6307485699653625 d_loss:1.0830995738506317 (f_loss=0.4135696291923523 r_loss=0.5172141790390015 GP=0.15231576561927795)
[Training] epoch:170 step:0 g_loss:0.6264159083366394 d_loss:1.0089800357818604 (f_loss=0.3840543031692505 r_loss=0.5907430648803711 GP=0.03418266773223877)

[Training] epoch:170 step:100 g_loss:0.6075494289398193 d_loss:0.9981910511851311 (f_loss=0.38237524032592773 r_loss=0.5671400427818298 GP=0.048675768077373505)
[Training] epoch:170 step:200 g_loss:0.5971755981445312 d_loss:1.0102650448679924 (f_loss=0.37861141562461853 r_loss=0.5940507650375366 GP=0.03760286420583725)
[Training] epoch:170 step:300 g_loss:0.5916211009025574 d_loss:0.9787784963846207 (f_loss=0.33495664596557617 r_loss=0.6004785895347595 GP=0.04334326088428497)
[Training] epoch:171 step:0 g_loss:0.5964292287826538 d_loss:1.0119926109910011 (f_loss=0.3795832693576813 r_loss=0.5458468198776245 GP=0.08656252175569534)
[Training] epoch:171 step:100 g_loss:0.6490390300750732 d_loss:1.1737227737903595 (f_loss=0.36995765566825867 r_loss=0.564739465713501 GP=0.23902565240859985)
[Training] epoch:171 step:200 g_loss:0.6570267081260681 d_loss:1.005459625273943 (f_loss=0.3793412446975708 r_loss=0.5972167253494263 GP=0.028901655226945877)
[Training] epoch:171 step:300 g_loss:0.617209792137146 d_loss:1.0472881123423576 (f_loss=0.37599360942840576 r_loss=0.5531617403030396 GP=0.11813276261091232)
[Training] epoch:172 step:0 g_loss:0.6524792313575745 d_loss:1.0560275465250015 (f_loss=0.41883960366249084 r_loss=0.5441175699234009 GP=0.0930703729391098)
[Training] epoch:172 step:100 g_loss:0.6593994498252869 d_loss:1.1024377793073654 (f_loss=0.41204971075057983 r_loss=0.5767168998718262 GP=0.11367116868495941)
[Training] epoch:172 step:200 g_loss:0.6418112516403198 d_loss:1.082507774233818 (f_loss=0.3825435936450958 r_loss=0.5737465620040894 GP=0.12621761858463287)
[Training] epoch:172 step:300 g_loss:0.6299081444740295 d_loss:1.0617830157279968 (f_loss=0.37623488903045654 r_loss=0.5418603420257568 GP=0.14368778467178345)
[Training] epoch:173 step:0 g_loss:0.671674370765686 d_loss:1.1670580804347992 (f_loss=0.3480524718761444 r_loss=0.5171267986297607 GP=0.30187880992889404)
[Training] epoch:173 step:100 g_loss:0.6555813550949097 d_loss:1.0539740920066833 (f_loss=0.39729827642440796 r_loss=0.5727843046188354 GP=0.08389151096343994)
[Training] epoch:173 step:200 g_loss:0.5897505283355713 d_loss:1.041903294622898 (f_loss=0.4065585136413574 r_loss=0.5464973449707031 GP=0.08884743601083755)
[Training] epoch:173 step:300 g_loss:0.6700276732444763 d_loss:0.9810679033398628 (f_loss=0.3399398624897003 r_loss=0.5417368412017822 GP=0.09939119964838028)
[Training] epoch:174 step:0 g_loss:0.5741206407546997 d_loss:0.9852265119552612 (f_loss=0.3732178509235382 r_loss=0.5322606563568115 GP=0.0797480046749115)
[Training] epoch:174 step:100 g_loss:0.5889462232589722 d_loss:0.9970294237136841 (f_loss=0.28897324204444885 r_loss=0.5727354288101196 GP=0.1353207528591156)
[Training] epoch:174 step:200 g_loss:0.5904785990715027 d_loss:1.174036756157875 (f_loss=0.4051780104637146 r_loss=0.5504943132400513 GP=0.2183644324541092)
[Training] epoch:174 step:300 g_loss:0.5991649031639099 d_loss:1.115258201956749 (f_loss=0.4052867293357849 r_loss=0.5427256226539612 GP=0.16724584996700287)
[Training] epoch:175 step:0 g_loss:0.615863025188446 d_loss:0.9709534905850887 (f_loss=0.3373432457447052 r_loss=0.5883798599243164 GP=0.04523038491606712)
[Training] epoch:175 step:100 g_loss:0.6297919750213623 d_loss:1.0640984028577805 (f_loss=0.4124601483345032 r_loss=0.5198330283164978 GP=0.13180522620677948)
[Training] epoch:175 step:200 g_loss:0.6089544296264648 d_loss:0.9931154139339924 (f_loss=0.37664085626602173 r_loss=0.5564014911651611 GP=0.060073066502809525)
[Training] epoch:175 step:300 g_loss:0.5995575785636902 d_loss:1.4627443253993988 (f_loss=0.43813708424568176 r_loss=0.5346169471740723 GP=0.4899902939796448)
[Training] epoch:176 step:0 g_loss:0.6039673089981079 d_loss:1.135167557746172 (f_loss=0.44799429178237915 r_loss=0.6261181235313416 GP=0.06105514243245125)
[Training] epoch:176 step:100 g_loss:0.6398183107376099 d_loss:0.9644181542098522 (f_loss=0.37470221519470215 r_loss=0.5541442036628723 GP=0.035571735352277756)
[Training] epoch:176 step:200 g_loss:0.6532949209213257 d_loss:1.0395710207521915 (f_loss=0.4204520583152771 r_loss=0.5764660835266113 GP=0.042652878910303116)
[Training] epoch:176 step:300 g_loss:0.5863823890686035 d_loss:1.039939396083355 (f_loss=0.41537582874298096 r_loss=0.5122580528259277 GP=0.11230551451444626)
[Training] epoch:177 step:0 g_loss:0.5604872107505798 d_loss:1.0307621210813522 (f_loss=0.4220992922782898 r_loss=0.5516634583473206 GP=0.05699937045574188)
[Training] epoch:177 step:100 g_loss:0.61809241771698 d_loss:1.085776150226593 (f_loss=0.39676856994628906 r_loss=0.5404082536697388 GP=0.14859932661056519)
[Training] epoch:177 step:200 g_loss:0.6534994840621948 d_loss:1.8452220559120178 (f_loss=0.3797328472137451 r_loss=0.6069890856742859 GP=0.8585001230239868)
[Training] epoch:177 step:300 g_loss:0.5858650207519531 d_loss:1.3337925970554352 (f_loss=0.44170695543289185 r_loss=0.5588194131851196 GP=0.3332662284374237)
[Training] epoch:178 step:0 g_loss:0.5786991119384766 d_loss:0.9109382331371307 (f_loss=0.3918668031692505 r_loss=0.44885730743408203 GP=0.07021412253379822)
[Training] epoch:178 step:100 g_loss:0.64352947473526 d_loss:1.0724545866250992 (f_loss=0.42107194662094116 r_loss=0.5149692296981812 GP=0.13641341030597687)
[Training] epoch:178 step:200 g_loss:0.5998426675796509 d_loss:1.2801151871681213 (f_loss=0.4105169177055359 r_loss=0.5504010915756226 GP=0.3191971778869629)
[Training] epoch:178 step:300 g_loss:0.5982094407081604 d_loss:1.2711856663227081 (f_loss=0.4138144254684448 r_loss=0.5714737176895142 GP=0.28589752316474915)
[Training] epoch:179 step:0 g_loss:0.5991280674934387 d_loss:1.068274050951004 (f_loss=0.3865141272544861 r_loss=0.5566587448120117 GP=0.12510117888450623)
[Training] epoch:179 step:100 g_loss:0.6215663552284241 d_loss:1.132896512746811 (f_loss=0.42366018891334534 r_loss=0.5581982731819153 GP=0.1510380506515503)
[Training] epoch:179 step:200 g_loss:0.6457513570785522 d_loss:0.9100564196705818 (f_loss=0.2968881130218506 r_loss=0.571199357509613 GP=0.041968949139118195)
[Training] epoch:179 step:300 g_loss:0.6501613259315491 d_loss:1.0997407212853432 (f_loss=0.3878503441810608 r_loss=0.5962503552436829 GP=0.11564002186059952)
[Training] epoch:180 step:0 g_loss:0.6100194454193115 d_loss:0.9863563030958176 (f_loss=0.34362050890922546 r_loss=0.5447880625724792 GP=0.09794773161411285)

[Training] epoch:180 step:100 g_loss:0.6263092160224915 d_loss:1.4738695323467255 (f_loss=0.43236446380615234 r_loss=0.5426350235939026 GP=0.49887004494667053)
[Training] epoch:180 step:200 g_loss:0.5980064868927002 d_loss:1.046119600534439 (f_loss=0.33439281582832336 r_loss=0.5375752449035645 GP=0.17415153980255127)
[Training] epoch:180 step:300 g_loss:0.5808725953102112 d_loss:0.9817900881171227 (f_loss=0.3659437298774719 r_loss=0.5608780384063721 GP=0.054968319833278656)
[Training] epoch:181 step:0 g_loss:0.6500207185745239 d_loss:1.0807656794786453 (f_loss=0.3897133767604828 r_loss=0.5473358035087585 GP=0.143716499209404)
[Training] epoch:181 step:100 g_loss:0.6453633904457092 d_loss:0.955793209373951 (f_loss=0.39579010009765625 r_loss=0.49211347103118896 GP=0.06788963824510574)
[Training] epoch:181 step:200 g_loss:0.6575040817260742 d_loss:1.1255225837230682 (f_loss=0.456077516078949 r_loss=0.5419795513153076 GP=0.12746551632881165)
[Training] epoch:181 step:300 g_loss:0.6107860803604126 d_loss:1.0053175427019596 (f_loss=0.3842698633670807 r_loss=0.5700955986976624 GP=0.05095208063721657)
[Training] epoch:182 step:0 g_loss:0.6267469525337219 d_loss:0.9007608946412802 (f_loss=0.36238962411880493 r_loss=0.5250888466835022 GP=0.013282423838973045)
[Training] epoch:182 step:100 g_loss:0.6701651811599731 d_loss:1.1618042588233948 (f_loss=0.3857555687427521 r_loss=0.6157232522964478 GP=0.16032543778419495)
[Training] epoch:182 step:200 g_loss:0.6764339208602905 d_loss:1.192089170217514 (f_loss=0.3871372640132904 r_loss=0.5325150489807129 GP=0.27243685722351074)
[Training] epoch:182 step:300 g_loss:0.5775725245475769 d_loss:1.0761562585830688 (f_loss=0.37901628017425537 r_loss=0.5802524089813232 GP=0.11688756942749023)
[Training] epoch:183 step:0 g_loss:0.6568021178245544 d_loss:1.2333924770355225 (f_loss=0.3407188355922699 r_loss=0.4943302869796753 GP=0.39834335446357727)
[Training] epoch:183 step:100 g_loss:0.6510874032974243 d_loss:1.005117017775774 (f_loss=0.3782634437084198 r_loss=0.577299952507019 GP=0.04955362156033516)
[Training] epoch:183 step:200 g_loss:0.6148961186408997 d_loss:1.1723894476890564 (f_loss=0.3845100998878479 r_loss=0.5916919708251953 GP=0.19618737697601318)
[Training] epoch:183 step:300 g_loss:0.5967098474502563 d_loss:1.0540101379156113 (f_loss=0.381632536649704 r_loss=0.5779286026954651 GP=0.0944489985704422)
[Training] epoch:184 step:0 g_loss:0.6464645862579346 d_loss:1.2744682133197784 (f_loss=0.4427773952484131 r_loss=0.5851466655731201 GP=0.24654415249824524)
[Training] epoch:184 step:100 g_loss:0.6195182204246521 d_loss:1.005228716880083 (f_loss=0.39583247900009155 r_loss=0.5601681470870972 GP=0.04922809079289436)
[Training] epoch:184 step:200 g_loss:0.590355634689331 d_loss:1.1298046708106995 (f_loss=0.3920615017414093 r_loss=0.5900468826293945 GP=0.14769628643989563)
[Training] epoch:184 step:300 g_loss:0.6116441488265991 d_loss:1.0302879065275192 (f_loss=0.3970842957496643 r_loss=0.510409951210022 GP=0.12279365956783295)
[Training] epoch:185 step:0 g_loss:0.6597615480422974 d_loss:0.9863866809755564 (f_loss=0.38075512647628784 r_loss=0.5846930742263794 GP=0.020938480272889137)
[Training] epoch:185 step:100 g_loss:0.6493127942085266 d_loss:1.0015492588281631 (f_loss=0.3161303997039795 r_loss=0.5578198432922363 GP=0.12759901583194733)
[Training] epoch:185 step:200 g_loss:0.6616309881210327 d_loss:0.9774910435080528 (f_loss=0.34489724040031433 r_loss=0.5232986211776733 GP=0.10929518193006516)
[Training] epoch:185 step:300 g_loss:0.7158856391906738 d_loss:1.1255374550819397 (f_loss=0.3586251139640808 r_loss=0.5253828763961792 GP=0.2415294647216797)
[Training] epoch:186 step:0 g_loss:0.6731070280075073 d_loss:1.1314064860343933 (f_loss=0.37197375297546387 r_loss=0.5312092900276184 GP=0.22822344303131104)
[Training] epoch:186 step:100 g_loss:0.6200464963912964 d_loss:1.0785060077905655 (f_loss=0.3488754630088806 r_loss=0.5580692291259766 GP=0.1715613156557083)
[Training] epoch:186 step:200 g_loss:0.6118594408035278 d_loss:1.1733609735965729 (f_loss=0.3254634141921997 r_loss=0.600114107131958 GP=0.24778345227241516)
[Training] epoch:186 step:300 g_loss:0.6551487445831299 d_loss:1.0846746861934662 (f_loss=0.3393939137458801 r_loss=0.5803415775299072 GP=0.16493919491767883)
[Training] epoch:187 step:0 g_loss:0.6094774603843689 d_loss:1.233687698841095 (f_loss=0.4017511010169983 r_loss=0.5706899166107178 GP=0.2612466812133789)
[Training] epoch:187 step:100 g_loss:0.5537512302398682 d_loss:1.1425314098596573 (f_loss=0.4105404317378998 r_loss=0.4924136996269226 GP=0.2395772784948349)
[Training] epoch:187 step:200 g_loss:0.6123883128166199 d_loss:0.962656244635582 (f_loss=0.3583415150642395 r_loss=0.5360633730888367 GP=0.0682513564825058)
[Training] epoch:187 step:300 g_loss:0.633984386920929 d_loss:1.1465872824192047 (f_loss=0.3466579020023346 r_loss=0.5219131708145142 GP=0.27801620960235596)
[Training] epoch:188 step:0 g_loss:0.6438336372375488 d_loss:1.014495074748993 (f_loss=0.34712129831314087 r_loss=0.5949825644493103 GP=0.07239121198654175)
[Training] epoch:188 step:100 g_loss:0.5847899913787842 d_loss:1.5355235636234283 (f_loss=0.35847708582878113 r_loss=0.5744526982307434 GP=0.6025937795639038)
[Training] epoch:188 step:200 g_loss:0.6178480982780457 d_loss:1.1363104581832886 (f_loss=0.41671115159988403 r_loss=0.6461296677589417 GP=0.07346963882446289)
[Training] epoch:188 step:300 g_loss:0.650272011756897 d_loss:1.2334900349378586 (f_loss=0.40873366594314575 r_loss=0.6264798641204834 GP=0.19827650487422943)
[Training] epoch:189 step:0 g_loss:0.6385496258735657 d_loss:1.300913155078888 (f_loss=0.33652281761169434 r_loss=0.5942648649215698 GP=0.3701254725456238)
[Training] epoch:189 step:100 g_loss:0.6020139455795288 d_loss:1.0886072739958763 (f_loss=0.37090039253234863 r_loss=0.6164848208427429 GP=0.10122206062078476)
[Training] epoch:189 step:200 g_loss:0.6334483623504639 d_loss:1.0332159399986267 (f_loss=0.3567039966583252 r_loss=0.6059370040893555 GP=0.07057493925094604)
[Training] epoch:189 step:300 g_loss:0.6131465435028076 d_loss:1.6565505266189575 (f_loss=0.3298202157020569 r_loss=0.49772268533706665 GP=0.829007625579834)
[Training] epoch:190 step:0 g_loss:0.6878783702850342 d_loss:1.1127293109893799 (f_loss=0.3644568622112274 r_loss=0.5655236840248108 GP=0.18274876475334167)

[Training] epoch:190 step:100 g_loss:0.5637311935424805 d_loss:1.2078658044338226 (f_loss=0.4033131003379822 r_loss=0.573045015335083 GP=0.23150768876075745)
[Training] epoch:190 step:200 g_loss:0.7177236080169678 d_loss:1.113536536693573 (f_loss=0.39172953367233276 r_loss=0.5298269987106323 GP=0.1919800043106079)
[Training] epoch:190 step:300 g_loss:0.6298981308937073 d_loss:1.054166778922081 (f_loss=0.40207746624946594 r_loss=0.5553383827209473 GP=0.09675092995166779)
[Training] epoch:191 step:0 g_loss:0.6187490820884705 d_loss:1.1651050746440887 (f_loss=0.4419458508491516 r_loss=0.5422155857086182 GP=0.18094363808631897)
[Training] epoch:191 step:100 g_loss:0.633277952671051 d_loss:1.3747215270996094 (f_loss=0.3708685338497162 r_loss=0.5374062657356262 GP=0.46644672751426697)
[Training] epoch:191 step:200 g_loss:0.6553341150283813 d_loss:0.9096639528870583 (f_loss=0.3261856734752655 r_loss=0.48887479305267334 GP=0.09460348635911942)
[Training] epoch:191 step:300 g_loss:0.6078237295150757 d_loss:1.2084834277629852 (f_loss=0.38088127970695496 r_loss=0.5443940162658691 GP=0.28320813179016113)
[Training] epoch:192 step:0 g_loss:0.6324658393859863 d_loss:1.0631610304117203 (f_loss=0.3541642427444458 r_loss=0.49365293979644775 GP=0.21534384787082672)
[Training] epoch:192 step:100 g_loss:0.625532329082489 d_loss:1.0595090687274933 (f_loss=0.36593008041381836 r_loss=0.4985814094543457 GP=0.19499757885932922)
[Training] epoch:192 step:200 g_loss:0.5452050566673279 d_loss:1.1312334388494492 (f_loss=0.43634137511253357 r_loss=0.5507867336273193 GP=0.14410533010959625)
[Training] epoch:192 step:300 g_loss:0.6179408431053162 d_loss:0.9216357581317425 (f_loss=0.3689393401145935 r_loss=0.5227925777435303 GP=0.029903840273618698)
[Training] epoch:193 step:0 g_loss:0.6124395132064819 d_loss:1.757348895072937 (f_loss=0.37138187885284424 r_loss=0.5022106170654297 GP=0.8837563991546631)
[Training] epoch:193 step:100 g_loss:0.6488407254219055 d_loss:1.0100326389074326 (f_loss=0.3594367206096649 r_loss=0.5221124291419983 GP=0.12848348915576935)
[Training] epoch:193 step:200 g_loss:0.6081172227859497 d_loss:1.0341850332915783 (f_loss=0.40951067209243774 r_loss=0.6081757545471191 GP=0.016498606652021408)
[Training] epoch:193 step:300 g_loss:0.607364296913147 d_loss:1.4548408687114716 (f_loss=0.37910526990890503 r_loss=0.6077041625976562 GP=0.4680314362049103)
[Training] epoch:194 step:0 g_loss:0.5907814502716064 d_loss:1.1327218040823936 (f_loss=0.40418457984924316 r_loss=0.6401431560516357 GP=0.08839406818151474)
[Training] epoch:194 step:100 g_loss:0.6873365640640259 d_loss:0.9998963922262192 (f_loss=0.37744784355163574 r_loss=0.6057413220405579 GP=0.016707226634025574)
[Training] epoch:194 step:200 g_loss:0.5902300477027893 d_loss:1.3315131068229675 (f_loss=0.3299115002155304 r_loss=0.6154115200042725 GP=0.3861900866031647)
[Training] epoch:194 step:300 g_loss:0.6323261260986328 d_loss:1.0742437466979027 (f_loss=0.36657774448394775 r_loss=0.6114651560783386 GP=0.0962008461356163)
[Training] epoch:195 step:0 g_loss:0.6824769973754883 d_loss:1.4346979558467865 (f_loss=0.35193392634391785 r_loss=0.502704381942749 GP=0.5800596475601196)
[Training] epoch:195 step:100 g_loss:0.639728307723999 d_loss:1.0312125533819199 (f_loss=0.4064924120903015 r_loss=0.5601509809494019 GP=0.06456916034221649)
[Training] epoch:195 step:200 g_loss:0.6316370964050293 d_loss:1.0811506062746048 (f_loss=0.3988521099090576 r_loss=0.5910145044326782 GP=0.09128399193286896)
[Training] epoch:195 step:300 g_loss:0.6454734206199646 d_loss:1.058715257793665 (f_loss=0.36629390716552734 r_loss=0.6345207691192627 GP=0.05790058150887489)
[Training] epoch:196 step:0 g_loss:0.6662037372589111 d_loss:1.0677120387554169 (f_loss=0.33652880787849426 r_loss=0.6350144147872925 GP=0.09616881608963013)
[Training] epoch:196 step:100 g_loss:0.5663100481033325 d_loss:1.130463719367981 (f_loss=0.3711232542991638 r_loss=0.5741752982139587 GP=0.1851651668548584)
[Training] epoch:196 step:200 g_loss:0.6084599494934082 d_loss:1.0448400899767876 (f_loss=0.403096079826355 r_loss=0.6123788356781006 GP=0.029365174472332)
[Training] epoch:196 step:300 g_loss:0.6519178152084351 d_loss:1.1335531771183014 (f_loss=0.3859986662864685 r_loss=0.5694805383682251 GP=0.1780739724636078)
[Training] epoch:197 step:0 g_loss:0.6270760893821716 d_loss:1.1138242930173874 (f_loss=0.3370603621006012 r_loss=0.5742753148078918 GP=0.20248861610889435)
[Training] epoch:197 step:100 g_loss:0.6209995746612549 d_loss:1.013972483575344 (f_loss=0.3304978013038635 r_loss=0.5960546731948853 GP=0.0874200090765953)
[Training] epoch:197 step:200 g_loss:0.6871455907821655 d_loss:1.0760050117969513 (f_loss=0.3779536485671997 r_loss=0.5166040062904358 GP=0.1814473569393158)
[Training] epoch:197 step:300 g_loss:0.6367381811141968 d_loss:1.33151313662529 (f_loss=0.31046974658966064 r_loss=0.5517264008522034 GP=0.4693169891834259)
[Training] epoch:198 step:0 g_loss:0.6154811978340149 d_loss:1.0176012739539146 (f_loss=0.32176288962364197 r_loss=0.6076785326004028 GP=0.08815985172986984)
[Training] epoch:198 step:100 g_loss:0.6143540143966675 d_loss:1.2206524014472961 (f_loss=0.3655644953250885 r_loss=0.5905972719192505 GP=0.26449063420295715)
[Training] epoch:198 step:200 g_loss:0.654498815536499 d_loss:1.1375030353665352 (f_loss=0.34353628754615784 r_loss=0.6904547214508057 GP=0.10351202636957169)
[Training] epoch:198 step:300 g_loss:0.7018872499465942 d_loss:1.0546528697013855 (f_loss=0.33043205738067627 r_loss=0.5677205324172974 GP=0.15650027990341187)
[Training] epoch:199 step:0 g_loss:0.6935449838638306 d_loss:1.1045696586370468 (f_loss=0.40545329451560974 r_loss=0.6170185804367065 GP=0.08209778368473053)
[Training] epoch:199 step:100 g_loss:0.6489331722259521 d_loss:1.033173307776451 (f_loss=0.33553844690322876 r_loss=0.5298011302947998 GP=0.16783373057842255)
[Training] epoch:199 step:200 g_loss:0.6361484527587891 d_loss:1.0484746843576431 (f_loss=0.389100581407547 r_loss=0.5299792885780334 GP=0.12939481437206268)
[Training] epoch:199 step:300 g_loss:0.672476589679718 d_loss:0.9910294413566589 (f_loss=0.3575909733772278 r_loss=0.5696916580200195 GP=0.06374680995941162)
[Training] epoch:200 step:0 g_loss:0.6100988984107971 d_loss:1.1243436336517334 (f_loss=0.34576329588890076 r_loss=0.5982351899147034 GP=0.18034514784812927)

[Training] epoch:200 step:100 g_loss:0.62984299659729 d_loss:1.0521285831928253 (f_loss=0.34417036175727844 r_loss=0.6153697371482849 GP=0.09258848428726196)
[Training] epoch:200 step:200 g_loss:0.6360741853713989 d_loss:1.0700513124465942 (f_loss=0.33901509642601013 r_loss=0.5996347069740295 GP=0.13140150904655457)
[Training] epoch:200 step:300 g_loss:0.6641282439231873 d_loss:0.9908771738409996 (f_loss=0.32585591077804565 r_loss=0.6204805970191956 GP=0.04454066604375839)
[Training] epoch:201 step:0 g_loss:0.6671358346939087 d_loss:1.0156128108501434 (f_loss=0.35928207635879517 r_loss=0.5425708889961243 GP=0.113759845495224)
[Training] epoch:201 step:100 g_loss:0.6594744920730591 d_loss:1.014741875231266 (f_loss=0.3499735891819 r_loss=0.6081314086914062 GP=0.05663687735795975)
[Training] epoch:201 step:200 g_loss:0.6284034848213196 d_loss:1.1022811383008957 (f_loss=0.3581671416759491 r_loss=0.6601696014404297 GP=0.0839443951845169)
[Training] epoch:201 step:300 g_loss:0.685990035533905 d_loss:1.2248295545578003 (f_loss=0.376356303691864 r_loss=0.5664898753166199 GP=0.2819833755493164)
[Training] epoch:202 step:0 g_loss:0.6307662725448608 d_loss:1.2223378121852875 (f_loss=0.33631667494773865 r_loss=0.5803865790367126 GP=0.3056345582008362)
[Training] epoch:202 step:100 g_loss:0.6339089870452881 d_loss:1.0093665719032288 (f_loss=0.3460398018360138 r_loss=0.5915209650993347 GP=0.07180580496788025)
[Training] epoch:202 step:200 g_loss:0.5969269275665283 d_loss:1.3490431904792786 (f_loss=0.40513932704925537 r_loss=0.5669063329696655 GP=0.37699753046035767)
[Training] epoch:202 step:300 g_loss:0.6544408798217773 d_loss:0.9102736040949821 (f_loss=0.3228173851966858 r_loss=0.5453492403030396 GP=0.042106978595256805)
[Training] epoch:203 step:0 g_loss:0.6499514579772949 d_loss:1.0035022534430027 (f_loss=0.3571871817111969 r_loss=0.5864403247833252 GP=0.059874746948480606)
[Training] epoch:203 step:100 g_loss:0.6423375606536865 d_loss:1.1283691376447678 (f_loss=0.35694408416748047 r_loss=0.6017154455184937 GP=0.16970960795879364)
[Training] epoch:203 step:200 g_loss:0.6505361795425415 d_loss:0.968609593808651 (f_loss=0.3286397457122803 r_loss=0.521327018737793 GP=0.11864282935857773)
[Training] epoch:203 step:300 g_loss:0.6675949692726135 d_loss:0.9492098912596703 (f_loss=0.3332458436489105 r_loss=0.5231090188026428 GP=0.09285502880811691)
[Training] epoch:204 step:0 g_loss:0.6239103674888611 d_loss:1.0079729929566383 (f_loss=0.3658507466316223 r_loss=0.5999530553817749 GP=0.04216919094324112)
[Training] epoch:204 step:100 g_loss:0.6984833478927612 d_loss:1.2120097875595093 (f_loss=0.348069429397583 r_loss=0.5645656585693359 GP=0.29937469959259033)
[Training] epoch:204 step:200 g_loss:0.6278377771377563 d_loss:1.0887699276208878 (f_loss=0.3525983691215515 r_loss=0.5686279535293579 GP=0.16754360496997833)
[Training] epoch:204 step:300 g_loss:0.6734793186187744 d_loss:1.049982525408268 (f_loss=0.39776429533958435 r_loss=0.5664550065994263 GP=0.08576322346925735)
[Training] epoch:205 step:0 g_loss:0.6618711948394775 d_loss:1.0856156945228577 (f_loss=0.3553779423236847 r_loss=0.5932514667510986 GP=0.13698628544807434)
[Training] epoch:205 step:100 g_loss:0.6761182546615601 d_loss:0.9543057978153229 (f_loss=0.3243686556816101 r_loss=0.516021728515625 GP=0.11391541361808777)
[Training] epoch:205 step:200 g_loss:0.6511983275413513 d_loss:1.0362965762615204 (f_loss=0.3357623219490051 r_loss=0.5483201742172241 GP=0.15221408009529114)
[Training] epoch:205 step:300 g_loss:0.6740593910217285 d_loss:1.0322372168302536 (f_loss=0.32328730821609497 r_loss=0.5616273283958435 GP=0.14732258021831512)
[Training] epoch:206 step:0 g_loss:0.716771125793457 d_loss:1.2249589264392853 (f_loss=0.3801088035106659 r_loss=0.6223177313804626 GP=0.22253239154815674)
[Training] epoch:206 step:100 g_loss:0.6427894830703735 d_loss:1.366368591785431 (f_loss=0.37914711236953735 r_loss=0.583073616027832 GP=0.4041478633880615)
[Training] epoch:206 step:200 g_loss:0.6239213943481445 d_loss:1.2808080911636353 (f_loss=0.3441125154495239 r_loss=0.5728655457496643 GP=0.363830029964447)
[Training] epoch:206 step:300 g_loss:0.6587817668914795 d_loss:1.0100091993808746 (f_loss=0.36551618576049805 r_loss=0.5842168927192688 GP=0.06027612090110779)
[Training] epoch:207 step:0 g_loss:0.6219104528427124 d_loss:1.0299110114574432 (f_loss=0.3571568727493286 r_loss=0.5519082546234131 GP=0.12084588408470154)
[Training] epoch:207 step:100 g_loss:0.6569434404373169 d_loss:0.9918667413294315 (f_loss=0.4002496600151062 r_loss=0.5802321434020996 GP=0.011384937912225723)
[Training] epoch:207 step:200 g_loss:0.66410231590271 d_loss:1.238088995218277 (f_loss=0.32211634516716003 r_loss=0.5735266804695129 GP=0.342445969581604)
[Training] epoch:207 step:300 g_loss:0.678546667098999 d_loss:1.0387090966105461 (f_loss=0.37945064902305603 r_loss=0.5532079339027405 GP=0.1060505136847496)
[Training] epoch:208 step:0 g_loss:0.6176133751869202 d_loss:1.2444305121898651 (f_loss=0.3537417948246002 r_loss=0.6190143823623657 GP=0.27167433500289917)
[Training] epoch:208 step:100 g_loss:0.6507376432418823 d_loss:1.0103429406881332 (f_loss=0.3566991090774536 r_loss=0.5489231944084167 GP=0.10472063720226288)
[Training] epoch:208 step:200 g_loss:0.6681902408599854 d_loss:1.0957802385091782 (f_loss=0.339233934879303 r_loss=0.6460480690002441 GP=0.11049823462963104)
[Training] epoch:208 step:300 g_loss:0.7018134593963623 d_loss:1.040155053138733 (f_loss=0.35524430871009827 r_loss=0.6028594970703125 GP=0.08205124735832214)
[Training] epoch:209 step:0 g_loss:0.6852219104766846 d_loss:1.245673879981041 (f_loss=0.3991526961326599 r_loss=0.6406134366989136 GP=0.20590774714946747)
[Training] epoch:209 step:100 g_loss:0.6408072710037231 d_loss:1.3123653829097748 (f_loss=0.3794827163219452 r_loss=0.5926060080528259 GP=0.34027665853500366)
[Training] epoch:209 step:200 g_loss:0.6908256411552429 d_loss:1.0845947563648224 (f_loss=0.37501761317253113 r_loss=0.5739959478378296 GP=0.13558119535446167)
[Training] epoch:209 step:300 g_loss:0.6644245982170105 d_loss:1.0284370258450508 (f_loss=0.33734941482543945 r_loss=0.5904386043548584 GP=0.10064900666475296)
[Training] epoch:210 step:0 g_loss:0.6009915471076965 d_loss:1.1240154504776 (f_loss=0.3637425899505615 r_loss=0.6311402320861816 GP=0.12913262844085693)

[Training] epoch:210 step:100 g_loss:0.5879576802253723 d_loss:1.2286930680274963 (f_loss=0.3506866693496704 r_loss=0.5426793098449707 GP=0.3353270888328552)
[Training] epoch:210 step:200 g_loss:0.6700688600540161 d_loss:1.317684292793274 (f_loss=0.4219338595867157 r_loss=0.6102325916290283 GP=0.2855178415775299)
[Training] epoch:210 step:300 g_loss:0.5953608751296997 d_loss:1.0440839007496834 (f_loss=0.35882943868637085 r_loss=0.6249203681945801 GP=0.06033409386873245)
[Training] epoch:211 step:0 g_loss:0.6604472398757935 d_loss:1.3571027219295502 (f_loss=0.4008921682834625 r_loss=0.6246894598007202 GP=0.33152109384536743)
[Training] epoch:211 step:100 g_loss:0.6555565595626831 d_loss:1.1219209730625153 (f_loss=0.340082049369812 r_loss=0.6443473100662231 GP=0.1374916136264801)
[Training] epoch:211 step:200 g_loss:0.7175394892692566 d_loss:0.9426127672195435 (f_loss=0.2971717417240143 r_loss=0.568185031414032 GP=0.07725599408149719)
[Training] epoch:211 step:300 g_loss:0.5753557682037354 d_loss:1.1326528638601303 (f_loss=0.35519570112228394 r_loss=0.622043251991272 GP=0.1554139107465744)
[Training] epoch:212 step:0 g_loss:0.6474194526672363 d_loss:1.0752126947045326 (f_loss=0.3658439815044403 r_loss=0.6159379482269287 GP=0.0934307649731636)
[Training] epoch:212 step:100 g_loss:0.6312832832336426 d_loss:1.0727743208408356 (f_loss=0.3510276973247528 r_loss=0.640633761882782 GP=0.08111286163330078)
[Training] epoch:212 step:200 g_loss:0.6015584468841553 d_loss:1.1592628955841064 (f_loss=0.34231245517730713 r_loss=0.6440523862838745 GP=0.1728980541229248)
[Training] epoch:212 step:300 g_loss:0.670241117477417 d_loss:1.1911741197109222 (f_loss=0.3724694848060608 r_loss=0.6458845138549805 GP=0.17282012104988098)
[Training] epoch:213 step:0 g_loss:0.6591743230819702 d_loss:1.0610680878162384 (f_loss=0.3466119170188904 r_loss=0.6232782602310181 GP=0.09117791056632996)
[Training] epoch:213 step:100 g_loss:0.6737507581710815 d_loss:1.1251704394817352 (f_loss=0.33901527523994446 r_loss=0.5439853072166443 GP=0.24216985702514648)
[Training] epoch:213 step:200 g_loss:0.62900310754776 d_loss:0.9566840156912804 (f_loss=0.3132036626338959 r_loss=0.53017258644104 GP=0.11330776661634445)
[Training] epoch:213 step:300 g_loss:0.6622252464294434 d_loss:1.0761265754699707 (f_loss=0.3355070650577545 r_loss=0.6159789562225342 GP=0.124640554189682)
[Training] epoch:214 step:0 g_loss:0.5960527658462524 d_loss:1.148914873600006 (f_loss=0.39114683866500854 r_loss=0.5025084018707275 GP=0.25525963306427)
[Training] epoch:214 step:100 g_loss:0.6123928427696228 d_loss:1.212627351284027 (f_loss=0.37419241666793823 r_loss=0.5536138415336609 GP=0.284821093082428)
[Training] epoch:214 step:200 g_loss:0.6684731245040894 d_loss:1.175816297531128 (f_loss=0.4258856177330017 r_loss=0.566411018371582 GP=0.1835196614265442)
[Training] epoch:214 step:300 g_loss:0.6519525647163391 d_loss:1.2632245421409607 (f_loss=0.3172401785850525 r_loss=0.5777841210365295 GP=0.36820024251937866)
[Training] epoch:215 step:0 g_loss:0.6488768458366394 d_loss:0.9526029042899609 (f_loss=0.3390199542045593 r_loss=0.5612661242485046 GP=0.052316825836896896)
[Training] epoch:215 step:100 g_loss:0.6723199486732483 d_loss:1.0600379258394241 (f_loss=0.32967543601989746 r_loss=0.6351566910743713 GP=0.09520579874515533)
[Training] epoch:215 step:200 g_loss:0.6403974890708923 d_loss:1.1329818964004517 (f_loss=0.33096054196357727 r_loss=0.6172783374786377 GP=0.1847430169582367)
[Training] epoch:215 step:300 g_loss:0.6530892252922058 d_loss:0.944593220949173 (f_loss=0.30631840229034424 r_loss=0.5198290348052979 GP=0.11844578385353088)
[Training] epoch:216 step:0 g_loss:0.6437819004058838 d_loss:1.2766155898571014 (f_loss=0.34088245034217834 r_loss=0.474295973777771 GP=0.4614371657371521)
[Training] epoch:216 step:100 g_loss:0.6698809862136841 d_loss:1.1163147538900375 (f_loss=0.36863741278648376 r_loss=0.5933108329772949 GP=0.15436650812625885)
[Training] epoch:216 step:200 g_loss:0.6820939779281616 d_loss:1.3161877691745758 (f_loss=0.3551464080810547 r_loss=0.5205873250961304 GP=0.44045403599739075)
[Training] epoch:216 step:300 g_loss:0.6540902853012085 d_loss:0.9863423109054565 (f_loss=0.3635595738887787 r_loss=0.5829983949661255 GP=0.03978434205055237)
[Training] epoch:217 step:0 g_loss:0.6547546982765198 d_loss:0.9945455640554428 (f_loss=0.280173122882843 r_loss=0.5986196994781494 GP=0.11575274169445038)
[Training] epoch:217 step:100 g_loss:0.7043493986129761 d_loss:1.1252717226743698 (f_loss=0.3473031520843506 r_loss=0.5689181685447693 GP=0.20905040204524994)
[Training] epoch:217 step:200 g_loss:0.6828566789627075 d_loss:1.0455922931432724 (f_loss=0.3407065272331238 r_loss=0.6250863075256348 GP=0.07979945838451385)
[Training] epoch:217 step:300 g_loss:0.6617230772972107 d_loss:1.0528929829597473 (f_loss=0.3454824686050415 r_loss=0.5872182846069336 GP=0.12019222974777222)
[Training] epoch:218 step:0 g_loss:0.7004109621047974 d_loss:0.9184282571077347 (f_loss=0.3359597325325012 r_loss=0.5462567806243896 GP=0.03621174395084381)
[Training] epoch:218 step:100 g_loss:0.6710867881774902 d_loss:1.2692528665065765 (f_loss=0.31601643562316895 r_loss=0.561079740524292 GP=0.3921566903591156)
[Training] epoch:218 step:200 g_loss:0.6480604410171509 d_loss:1.2295487523078918 (f_loss=0.3075239956378937 r_loss=0.5740705728530884 GP=0.3479541838169098)
[Training] epoch:218 step:300 g_loss:0.6488563418388367 d_loss:1.0710196495056152 (f_loss=0.30295729637145996 r_loss=0.5922048687934875 GP=0.17585748434066772)
[Training] epoch:219 step:0 g_loss:0.6594737768173218 d_loss:0.978369690477848 (f_loss=0.3341468870639801 r_loss=0.5653511881828308 GP=0.07887161523103714)
[Training] epoch:219 step:100 g_loss:0.6465530395507812 d_loss:1.163123905658722 (f_loss=0.32513466477394104 r_loss=0.5893112421035767 GP=0.24867799878120422)
[Training] epoch:219 step:200 g_loss:0.6400319933891296 d_loss:1.1193146407604218 (f_loss=0.3626379370689392 r_loss=0.5407791137695312 GP=0.2158975899219513)
[Training] epoch:219 step:300 g_loss:0.6125578880310059 d_loss:1.039048109203577 (f_loss=0.34636586904525757 r_loss=0.6612087488174438 GP=0.031473491340875626)
[Training] epoch:220 step:0 g_loss:0.6937110424041748 d_loss:1.1300306171178818 (f_loss=0.3212844133377075 r_loss=0.6367651224136353 GP=0.171981081366539)

[Training] epoch:220 step:100 g_loss:0.6826550960540771 d_loss:0.9536372870206833 (f_loss=0.2994370758533478 r_loss=0.5448334217071533 GP=0.10936678946018219)
[Training] epoch:220 step:200 g_loss:0.6622806787490845 d_loss:1.2319059371948242 (f_loss=0.3061767816543579 r_loss=0.6345301866531372 GP=0.2911989688873291)
[Training] epoch:220 step:300 g_loss:0.6801375150680542 d_loss:0.9326643124222755 (f_loss=0.29855814576148987 r_loss=0.5917669534683228 GP=0.04233921319246292)
[Training] epoch:221 step:0 g_loss:0.6986788511276245 d_loss:0.9558543413877487 (f_loss=0.32445424795150757 r_loss=0.5183819532394409 GP=0.11301814019680023)
[Training] epoch:221 step:100 g_loss:0.683452308177948 d_loss:1.093914419412613 (f_loss=0.35036537051200867 r_loss=0.5893361568450928 GP=0.15421289205551147)
[Training] epoch:221 step:200 g_loss:0.654484748840332 d_loss:0.9808712750673294 (f_loss=0.29486343264579773 r_loss=0.6260924339294434 GP=0.05991540849208832)
[Training] epoch:221 step:300 g_loss:0.6643111109733582 d_loss:1.065385140478611 (f_loss=0.35707658529281616 r_loss=0.6318808794021606 GP=0.07642767578363419)
[Training] epoch:222 step:0 g_loss:0.6620303392410278 d_loss:1.1100916415452957 (f_loss=0.345650315284729 r_loss=0.5764333009719849 GP=0.18800802528858185)
[Training] epoch:222 step:100 g_loss:0.6584384441375732 d_loss:1.1766467988491058 (f_loss=0.3644397258758545 r_loss=0.6350875496864319 GP=0.17711952328681946)
[Training] epoch:222 step:200 g_loss:0.6817126870155334 d_loss:1.2114600390195847 (f_loss=0.33957988023757935 r_loss=0.6520720720291138 GP=0.21980808675289154)
[Training] epoch:222 step:300 g_loss:0.6672425270080566 d_loss:1.0439146608114243 (f_loss=0.3476293087005615 r_loss=0.5642189979553223 GP=0.13206635415554047)
[Training] epoch:223 step:0 g_loss:0.6528782248497009 d_loss:0.9474426507949829 (f_loss=0.3138953745365143 r_loss=0.5324698686599731 GP=0.10107740759849548)
[Training] epoch:223 step:100 g_loss:0.6609386205673218 d_loss:1.2231082916259766 (f_loss=0.32617098093032837 r_loss=0.6023396253585815 GP=0.29459768533706665)
[Training] epoch:223 step:200 g_loss:0.6470608711242676 d_loss:1.0716554373502731 (f_loss=0.3034060597419739 r_loss=0.5731050968170166 GP=0.19514428079128265)
[Training] epoch:223 step:300 g_loss:0.7114888429641724 d_loss:1.080092079937458 (f_loss=0.3144102394580841 r_loss=0.6836127638816833 GP=0.08206907659769058)
[Training] epoch:224 step:0 g_loss:0.6473737955093384 d_loss:1.1321497857570648 (f_loss=0.388486385345459 r_loss=0.6342297792434692 GP=0.1094336211681366)
[Training] epoch:224 step:100 g_loss:0.6684457063674927 d_loss:1.1546592861413956 (f_loss=0.38011592626571655 r_loss=0.6723076701164246 GP=0.10223568975925446)
[Training] epoch:224 step:200 g_loss:0.668010413646698 d_loss:1.0405500531196594 (f_loss=0.32995498180389404 r_loss=0.5474802255630493 GP=0.16311484575271606)
[Training] epoch:224 step:300 g_loss:0.6738024950027466 d_loss:1.071463942527771 (f_loss=0.36418527364730835 r_loss=0.5702670812606812 GP=0.1370115876197815)
[Training] epoch:225 step:0 g_loss:0.6361476182937622 d_loss:0.9888946264982224 (f_loss=0.31842392683029175 r_loss=0.5318243503570557 GP=0.13864634931087494)
[Training] epoch:225 step:100 g_loss:0.6802744269371033 d_loss:0.9413794651627541 (f_loss=0.31499987840652466 r_loss=0.5632904171943665 GP=0.06308916956186295)
[Training] epoch:225 step:200 g_loss:0.6517924070358276 d_loss:0.9563531428575516 (f_loss=0.31611257791519165 r_loss=0.5393998622894287 GP=0.10084070265293121)
[Training] epoch:225 step:300 g_loss:0.6604008674621582 d_loss:1.1344298869371414 (f_loss=0.3690895140171051 r_loss=0.5867226123809814 GP=0.17861776053905487)
[Training] epoch:226 step:0 g_loss:0.6799691915512085 d_loss:0.9523961655795574 (f_loss=0.31521570682525635 r_loss=0.6000598669052124 GP=0.03712059184908867)
[Training] epoch:226 step:100 g_loss:0.6753681898117065 d_loss:1.1159485876560211 (f_loss=0.33153867721557617 r_loss=0.5568955540657043 GP=0.2275143563747406)
[Training] epoch:226 step:200 g_loss:0.620876133441925 d_loss:1.0101735070347786 (f_loss=0.3640987277030945 r_loss=0.5984289050102234 GP=0.047645874321460724)
[Training] epoch:226 step:300 g_loss:0.6556829214096069 d_loss:1.1525580286979675 (f_loss=0.36663591861724854 r_loss=0.5794621706008911 GP=0.20645993947982788)
[Training] epoch:227 step:0 g_loss:0.6553082466125488 d_loss:1.028163492679596 (f_loss=0.31395596265792847 r_loss=0.5927872657775879 GP=0.12142026424407959)
[Training] epoch:227 step:100 g_loss:0.667932391166687 d_loss:1.2574289441108704 (f_loss=0.35147324204444885 r_loss=0.558312177658081 GP=0.34764352440834045)
[Training] epoch:227 step:200 g_loss:0.6206274032592773 d_loss:1.116821527481079 (f_loss=0.3632420003414154 r_loss=0.6046717166900635 GP=0.14890781044960022)
[Training] epoch:227 step:300 g_loss:0.7042070627212524 d_loss:1.3031339347362518 (f_loss=0.3427787721157074 r_loss=0.6414071321487427 GP=0.31894803047180176)
[Training] epoch:228 step:0 g_loss:0.7020249962806702 d_loss:1.1300378739833832 (f_loss=0.3940439820289612 r_loss=0.5098075270652771 GP=0.2261863648891449)
[Training] epoch:228 step:100 g_loss:0.6759430170059204 d_loss:1.0858010947704315 (f_loss=0.33639058470726013 r_loss=0.5759117603302002 GP=0.1734987497329712)
[Training] epoch:228 step:200 g_loss:0.6479576230049133 d_loss:1.4391210973262787 (f_loss=0.3085285723209381 r_loss=0.4946866035461426 GP=0.635905921459198)
[Training] epoch:228 step:300 g_loss:0.6471590995788574 d_loss:0.9106751456856728 (f_loss=0.29257869720458984 r_loss=0.5432766675949097 GP=0.07481978088617325)
[Training] epoch:229 step:0 g_loss:0.6640304923057556 d_loss:1.3599720001220703 (f_loss=0.3671530485153198 r_loss=0.634694516658783 GP=0.35812443494796753)
[Training] epoch:229 step:100 g_loss:0.6609745025634766 d_loss:1.0243457555770874 (f_loss=0.3006446957588196 r_loss=0.5687671899795532 GP=0.1549338698387146)
[Training] epoch:229 step:200 g_loss:0.667110025882721 d_loss:1.0130774788558483 (f_loss=0.3509402871131897 r_loss=0.6166437268257141 GP=0.045493464916944504)
[Training] epoch:229 step:300 g_loss:0.6863868236541748 d_loss:1.0854925066232681 (f_loss=0.33546966314315796 r_loss=0.5857517719268799 GP=0.16427107155323029)
[Training] epoch:230 step:0 g_loss:0.7134571075439453 d_loss:1.161243587732315 (f_loss=0.3571424186229706 r_loss=0.6176855564117432 GP=0.18641561269760132)

[Training] epoch:230 step:100 g_loss:0.6679954528808594 d_loss:1.036933422088623 (f_loss=0.33961719274520874 r_loss=0.6113331317901611 GP=0.08598309755325317)
[Training] epoch:230 step:200 g_loss:0.7260470986366272 d_loss:1.1983216404914856 (f_loss=0.36297184228897095 r_loss=0.5774274468421936 GP=0.25792235136032104)
[Training] epoch:230 step:300 g_loss:0.6727396249771118 d_loss:1.0515621155500412 (f_loss=0.34101179242134094 r_loss=0.5868596434593201 GP=0.12369067966938019)
[Training] epoch:231 step:0 g_loss:0.6698188781738281 d_loss:1.0581534057855606 (f_loss=0.3706650733947754 r_loss=0.6210982799530029 GP=0.06639005243778229)
[Training] epoch:231 step:100 g_loss:0.6588361263275146 d_loss:0.9748955741524696 (f_loss=0.30332785844802856 r_loss=0.5994828939437866 GP=0.07208482176065445)
[Training] epoch:231 step:200 g_loss:0.6508232951164246 d_loss:1.0215263217687607 (f_loss=0.3172680735588074 r_loss=0.5998760461807251 GP=0.10438220202922821)
[Training] epoch:231 step:300 g_loss:0.6446858048439026 d_loss:1.1508136093616486 (f_loss=0.30978256464004517 r_loss=0.5678787231445312 GP=0.27315232157707214)
[Training] epoch:232 step:0 g_loss:0.7128175497055054 d_loss:1.0501859933137894 (f_loss=0.3456652760505676 r_loss=0.5986121296882629 GP=0.1059085875749588)
[Training] epoch:232 step:100 g_loss:0.6702417135238647 d_loss:1.1293598413467407 (f_loss=0.3862055540084839 r_loss=0.5678058862686157 GP=0.1753484010696411)
[Training] epoch:232 step:200 g_loss:0.6687064170837402 d_loss:1.0214481055736542 (f_loss=0.32316261529922485 r_loss=0.6239258050918579 GP=0.07435968518257141)
[Training] epoch:232 step:300 g_loss:0.7061678171157837 d_loss:1.141762137413025 (f_loss=0.3683544993400574 r_loss=0.5646575689315796 GP=0.20875006914138794)
[Training] epoch:233 step:0 g_loss:0.7197951078414917 d_loss:1.0469724386930466 (f_loss=0.3210422694683075 r_loss=0.5983062982559204 GP=0.12762387096881866)
[Training] epoch:233 step:100 g_loss:0.6643495559692383 d_loss:1.0330120250582695 (f_loss=0.3168528378009796 r_loss=0.6258479356765747 GP=0.09031125158071518)
[Training] epoch:233 step:200 g_loss:0.6650943756103516 d_loss:1.189085990190506 (f_loss=0.27029818296432495 r_loss=0.5836547613143921 GP=0.33513304591178894)
[Training] epoch:233 step:300 g_loss:0.6403660774230957 d_loss:1.2614451050758362 (f_loss=0.3932514190673828 r_loss=0.5613079071044922 GP=0.3068857789039612)
[Training] epoch:234 step:0 g_loss:0.663843035697937 d_loss:1.1354736983776093 (f_loss=0.2970987856388092 r_loss=0.6262689828872681 GP=0.21210592985153198)
[Training] epoch:234 step:100 g_loss:0.7040491104125977 d_loss:0.9783855676651001 (f_loss=0.3186926543712616 r_loss=0.6086553931236267 GP=0.05103752017021179)
[Training] epoch:234 step:200 g_loss:0.6698708534240723 d_loss:1.0057007372379303 (f_loss=0.34092986583709717 r_loss=0.5994435548782349 GP=0.06532731652259827)
[Training] epoch:234 step:300 g_loss:0.6066436767578125 d_loss:1.0428566187620163 (f_loss=0.3380318880081177 r_loss=0.6442774534225464 GP=0.060547277331352234)
[Training] epoch:235 step:0 g_loss:0.6475503444671631 d_loss:1.1197256296873093 (f_loss=0.3446516990661621 r_loss=0.5454816222190857 GP=0.22959230840206146)
[Training] epoch:235 step:100 g_loss:0.6799843907356262 d_loss:1.12473663687706 (f_loss=0.37190091609954834 r_loss=0.5942493081092834 GP=0.15858641266822815)
[Training] epoch:235 step:200 g_loss:0.6854074597358704 d_loss:1.0300352573394775 (f_loss=0.30721452832221985 r_loss=0.5959490537643433 GP=0.12687167525291443)
[Training] epoch:235 step:300 g_loss:0.6356219053268433 d_loss:1.090438961982727 (f_loss=0.3639039397239685 r_loss=0.6255811452865601 GP=0.10095387697219849)
[Training] epoch:236 step:0 g_loss:0.721184492111206 d_loss:1.2999848425388336 (f_loss=0.30956512689590454 r_loss=0.6004542112350464 GP=0.3899655044078827)
[Training] epoch:236 step:100 g_loss:0.6725831031799316 d_loss:1.0354593805968761 (f_loss=0.33618226647377014 r_loss=0.636863112449646 GP=0.06241400167346001)
[Training] epoch:236 step:200 g_loss:0.6665554046630859 d_loss:1.0395202115178108 (f_loss=0.3462528586387634 r_loss=0.6224311590194702 GP=0.07083619385957718)
[Training] epoch:236 step:300 g_loss:0.7535281777381897 d_loss:1.3981572091579437 (f_loss=0.33385881781578064 r_loss=0.5865888595581055 GP=0.4777095317840576)
[Training] epoch:237 step:0 g_loss:0.7019146680831909 d_loss:1.2134796977043152 (f_loss=0.30261659622192383 r_loss=0.5206202268600464 GP=0.39024287462234497)
[Training] epoch:237 step:100 g_loss:0.6305861473083496 d_loss:0.9410511888563633 (f_loss=0.3040131628513336 r_loss=0.6036768555641174 GP=0.03336117044091225)
[Training] epoch:237 step:200 g_loss:0.639348566532135 d_loss:1.0914346724748611 (f_loss=0.30493366718292236 r_loss=0.5991897583007812 GP=0.18731124699115753)
[Training] epoch:237 step:300 g_loss:0.6930074691772461 d_loss:1.0481926947832108 (f_loss=0.29033130407333374 r_loss=0.6025197505950928 GP=0.15534164011478424)
[Training] epoch:238 step:0 g_loss:0.6873277425765991 d_loss:1.1116920858621597 (f_loss=0.354239284992218 r_loss=0.6575954556465149 GP=0.09985734522342682)
[Training] epoch:238 step:100 g_loss:0.6760482788085938 d_loss:1.0893492996692657 (f_loss=0.30223870277404785 r_loss=0.5482228994369507 GP=0.2388876974582672)
[Training] epoch:238 step:200 g_loss:0.7203860282897949 d_loss:1.5374384820461273 (f_loss=0.27795735001564026 r_loss=0.548511266708374 GP=0.710969865322113)
[Training] epoch:238 step:300 g_loss:0.6884962320327759 d_loss:1.2487753927707672 (f_loss=0.3977801501750946 r_loss=0.6057183742523193 GP=0.24527686834335327)
[Training] epoch:239 step:0 g_loss:0.6241439580917358 d_loss:1.0025591179728508 (f_loss=0.333963543176651 r_loss=0.6278258562088013 GP=0.04076971858739853)
[Training] epoch:239 step:100 g_loss:0.6319935321807861 d_loss:1.228001356124878 (f_loss=0.29432398080825806 r_loss=0.5835659503936768 GP=0.3501114249229431)
[Training] epoch:239 step:200 g_loss:0.6671725511550903 d_loss:1.049044817686081 (f_loss=0.35013851523399353 r_loss=0.5668752789497375 GP=0.13203102350234985)
[Training] epoch:239 step:300 g_loss:0.7280032634735107 d_loss:1.0715359821915627 (f_loss=0.3086029887199402 r_loss=0.6420243382453918 GP=0.12090865522623062)
[Training] epoch:240 step:0 g_loss:0.7119224071502686 d_loss:1.0597480535507202 (f_loss=0.2670407295227051 r_loss=0.6240793466567993 GP=0.16862797737121582)

[Training] epoch:240 step:100 g_loss:0.6477346420288086 d_loss:0.9990254193544388 (f_loss=0.34776952862739563 r_loss=0.5704764127731323 GP=0.08077947795391083)
[Training] epoch:240 step:200 g_loss:0.6753678321838379 d_loss:1.0738428235054016 (f_loss=0.34597247838974 r_loss=0.5189576745033264 GP=0.2089126706123352)
[Training] epoch:240 step:300 g_loss:0.6716718673706055 d_loss:1.2544289231300354 (f_loss=0.38478946685791016 r_loss=0.6685699224472046 GP=0.20106953382492065)
[Training] epoch:241 step:0 g_loss:0.6605944633483887 d_loss:1.15690515935421 (f_loss=0.30964139103889465 r_loss=0.6723297238349915 GP=0.1749340444803238)
[Training] epoch:241 step:100 g_loss:0.6462963223457336 d_loss:1.0559957325458527 (f_loss=0.30808892846107483 r_loss=0.5949162244796753 GP=0.15299057960510254)
[Training] epoch:241 step:200 g_loss:0.6574040055274963 d_loss:1.092944249510765 (f_loss=0.29159969091415405 r_loss=0.6242839097976685 GP=0.17706064879894257)
[Training] epoch:241 step:300 g_loss:0.6232748627662659 d_loss:1.0248074233531952 (f_loss=0.28699296712875366 r_loss=0.6319409012794495 GP=0.10587355494499207)
[Training] epoch:242 step:0 g_loss:0.67380690574646 d_loss:1.3701026141643524 (f_loss=0.3231419026851654 r_loss=0.4538615345954895 GP=0.5930991768836975)
[Training] epoch:242 step:100 g_loss:0.6579400300979614 d_loss:1.0420845225453377 (f_loss=0.2964344620704651 r_loss=0.6305654048919678 GP=0.11508465558290482)
[Training] epoch:242 step:200 g_loss:0.6885924935340881 d_loss:1.1117340177297592 (f_loss=0.32929912209510803 r_loss=0.595320999622345 GP=0.1871138960123062)
[Training] epoch:242 step:300 g_loss:0.7187432050704956 d_loss:1.2453964054584503 (f_loss=0.3791547417640686 r_loss=0.6460496187210083 GP=0.2201920449733734)
[Training] epoch:243 step:0 g_loss:0.6104896068572998 d_loss:1.2784664034843445 (f_loss=0.37073343992233276 r_loss=0.575739860534668 GP=0.33199310302734375)
[Training] epoch:243 step:100 g_loss:0.7041204571723938 d_loss:1.1209516003727913 (f_loss=0.32441195845603943 r_loss=0.6851961612701416 GP=0.11134348064661026)
[Training] epoch:243 step:200 g_loss:0.6576615571975708 d_loss:0.9882924184203148 (f_loss=0.3313649296760559 r_loss=0.574570894241333 GP=0.08235659450292587)
[Training] epoch:243 step:300 g_loss:0.6961238980293274 d_loss:0.9915155172348022 (f_loss=0.34336742758750916 r_loss=0.5818994045257568 GP=0.06624868512153625)
[Training] epoch:244 step:0 g_loss:0.6300064325332642 d_loss:1.1503758877515793 (f_loss=0.3811790347099304 r_loss=0.6312654614448547 GP=0.13793139159679413)
[Training] epoch:244 step:100 g_loss:0.6703733205795288 d_loss:1.177637755870819 (f_loss=0.2950512766838074 r_loss=0.6003219485282898 GP=0.2822645306587219)
[Training] epoch:244 step:200 g_loss:0.6908873319625854 d_loss:1.0832199156284332 (f_loss=0.3605485260486603 r_loss=0.5528245568275452 GP=0.16984683275222778)
[Training] epoch:244 step:300 g_loss:0.6618852615356445 d_loss:1.1630929708480835 (f_loss=0.3120388090610504 r_loss=0.6216492652893066 GP=0.22940489649772644)
[Training] epoch:245 step:0 g_loss:0.6879098415374756 d_loss:2.0443277955055237 (f_loss=0.34282881021499634 r_loss=0.6178348064422607 GP=1.0836641788482666)
[Training] epoch:245 step:100 g_loss:0.6772400140762329 d_loss:1.3516926765441895 (f_loss=0.38845497369766235 r_loss=0.6313220858573914 GP=0.33191561698913574)
[Training] epoch:245 step:200 g_loss:0.6842862963676453 d_loss:1.0004474148154259 (f_loss=0.27496033906936646 r_loss=0.6012109518051147 GP=0.12427612394094467)
[Training] epoch:245 step:300 g_loss:0.6526116132736206 d_loss:1.0752525478601456 (f_loss=0.312980592250824 r_loss=0.6361986994743347 GP=0.12607325613498688)
[Training] epoch:246 step:0 g_loss:0.6403273344039917 d_loss:1.1866731941699982 (f_loss=0.3360745906829834 r_loss=0.6068724393844604 GP=0.24372616410255432)
[Training] epoch:246 step:100 g_loss:0.7384760975837708 d_loss:0.9578967951238155 (f_loss=0.28133442997932434 r_loss=0.6322819590568542 GP=0.04428040608763695)
[Training] epoch:246 step:200 g_loss:0.6328328847885132 d_loss:0.9953929036855698 (f_loss=0.31530845165252686 r_loss=0.6111580729484558 GP=0.0689263790845871)
[Training] epoch:246 step:300 g_loss:0.6954163312911987 d_loss:0.9427560567855835 (f_loss=0.29468709230422974 r_loss=0.6187673211097717 GP=0.02930164337158203)
[Training] epoch:247 step:0 g_loss:0.647771954536438 d_loss:1.352695345878601 (f_loss=0.34440767765045166 r_loss=0.5977402925491333 GP=0.4105473756790161)
[Training] epoch:247 step:100 g_loss:0.7042953968048096 d_loss:1.1547660529613495 (f_loss=0.3041304349899292 r_loss=0.5951429605484009 GP=0.2554926574230194)
[Training] epoch:247 step:200 g_loss:0.6875618100166321 d_loss:1.1833783686161041 (f_loss=0.34906521439552307 r_loss=0.6608792543411255 GP=0.17343389987945557)
[Training] epoch:247 step:300 g_loss:0.7072153091430664 d_loss:1.1275151073932648 (f_loss=0.36603567004203796 r_loss=0.6463424563407898 GP=0.11513698101043701)
[Training] epoch:248 step:0 g_loss:0.6888549327850342 d_loss:0.9885179102420807 (f_loss=0.30393582582473755 r_loss=0.6329243779182434 GP=0.05165770649909973)
[Training] epoch:248 step:100 g_loss:0.7139060497283936 d_loss:1.1031067967414856 (f_loss=0.2914588451385498 r_loss=0.6357226371765137 GP=0.17592531442642212)
[Training] epoch:248 step:200 g_loss:0.6938063502311707 d_loss:1.054671972990036 (f_loss=0.3199698328971863 r_loss=0.6206743717193604 GP=0.11402776837348938)
[Training] epoch:248 step:300 g_loss:0.7241858243942261 d_loss:1.0121970735490322 (f_loss=0.30870991945266724 r_loss=0.6465265154838562 GP=0.056960638612508774)
[Training] epoch:249 step:0 g_loss:0.651455819606781 d_loss:1.2481785416603088 (f_loss=0.3251529335975647 r_loss=0.6348892450332642 GP=0.28813636302948)
[Training] epoch:249 step:100 g_loss:0.7079892158508301 d_loss:0.9401269033551216 (f_loss=0.2561672329902649 r_loss=0.6419238448143005 GP=0.04203582555055618)
[Training] epoch:249 step:200 g_loss:0.6531462669372559 d_loss:0.9984538033604622 (f_loss=0.2924950420856476 r_loss=0.5932654142379761 GP=0.11269334703683853)
[Training] epoch:249 step:300 g_loss:0.6684872508049011 d_loss:1.5444334149360657 (f_loss=0.3090015649795532 r_loss=0.5803975462913513 GP=0.6550343036651611)
[Training] epoch:250 step:0 g_loss:0.6891036033630371 d_loss:1.0263167023658752 (f_loss=0.32166555523872375 r_loss=0.6290072202682495 GP=0.07564392685890198)

[Training] epoch:250 step:100 g_loss:0.6832473278045654 d_loss:1.0817776024341583 (f_loss=0.3378695845603943 r_loss=0.5885711908340454 GP=0.15533682703971863)
[Training] epoch:250 step:200 g_loss:0.6921520829200745 d_loss:1.2050663232803345 (f_loss=0.3028504252433777 r_loss=0.6048010587692261 GP=0.2974148392677307)
[Training] epoch:250 step:300 g_loss:0.6878473162651062 d_loss:0.9993441849946976 (f_loss=0.28954094648361206 r_loss=0.6363893151283264 GP=0.0734139233827591)
[Training] epoch:251 step:0 g_loss:0.6589809656143188 d_loss:1.016665942966938 (f_loss=0.2723493278026581 r_loss=0.6529121398925781 GP=0.09140447527170181)
[Training] epoch:251 step:100 g_loss:0.7244532108306885 d_loss:1.7712603509426117 (f_loss=0.3141383230686188 r_loss=0.5418477058410645 GP=0.9152743220329285)
[Training] epoch:251 step:200 g_loss:0.6791093349456787 d_loss:1.2235899865627289 (f_loss=0.2838190495967865 r_loss=0.6408745050430298 GP=0.2988964319229126)
[Training] epoch:251 step:300 g_loss:0.7412413358688354 d_loss:0.9944101795554161 (f_loss=0.29780837893486023 r_loss=0.6553771495819092 GP=0.0412246510386467)
[Training] epoch:252 step:0 g_loss:0.7455102205276489 d_loss:1.5720010995864868 (f_loss=0.2778618335723877 r_loss=0.6406242847442627 GP=0.6535149812698364)
[Training] epoch:252 step:100 g_loss:0.6991598010063171 d_loss:1.0893594920635223 (f_loss=0.2667182385921478 r_loss=0.5834776163101196 GP=0.23916363716125488)
[Training] epoch:252 step:200 g_loss:0.7324977517127991 d_loss:1.2926250100135803 (f_loss=0.2920043468475342 r_loss=0.5659534931182861 GP=0.43466717004776)
[Training] epoch:252 step:300 g_loss:0.666175901889801 d_loss:1.2308927476406097 (f_loss=0.31950241327285767 r_loss=0.6475733518600464 GP=0.2638169825077057)
[Training] epoch:253 step:0 g_loss:0.6967076063156128 d_loss:1.0696427822113037 (f_loss=0.25422537326812744 r_loss=0.5814048051834106 GP=0.23401260375976562)
[Training] epoch:253 step:100 g_loss:0.7513296604156494 d_loss:1.1724733412265778 (f_loss=0.32548192143440247 r_loss=0.6190561056137085 GP=0.2279353141784668)
[Training] epoch:253 step:200 g_loss:0.6825010776519775 d_loss:1.0012377128005028 (f_loss=0.27255895733833313 r_loss=0.6177849173545837 GP=0.11089383810758591)
[Training] epoch:253 step:300 g_loss:0.6501789093017578 d_loss:1.1097252070903778 (f_loss=0.27193939685821533 r_loss=0.6094973087310791 GP=0.22828850150108337)
[Training] epoch:254 step:0 g_loss:0.6684532761573792 d_loss:1.1292186677455902 (f_loss=0.32853204011917114 r_loss=0.5144830346107483 GP=0.2862035930156708)
[Training] epoch:254 step:100 g_loss:0.6488908529281616 d_loss:1.0622304379940033 (f_loss=0.3613482415676117 r_loss=0.5571582913398743 GP=0.14372390508651733)
[Training] epoch:254 step:200 g_loss:0.7456517815589905 d_loss:1.1358859241008759 (f_loss=0.287669837474823 r_loss=0.5405434370040894 GP=0.3076726496219635)
[Training] epoch:254 step:300 g_loss:0.7145638465881348 d_loss:1.1150886043906212 (f_loss=0.31002241373062134 r_loss=0.6874516606330872 GP=0.11761453002691269)
[Training] epoch:255 step:0 g_loss:0.6463412046432495 d_loss:1.0787020921707153 (f_loss=0.3239111602306366 r_loss=0.6695567965507507 GP=0.085234135389328)
[Training] epoch:255 step:100 g_loss:0.7181145548820496 d_loss:1.1218836456537247 (f_loss=0.33295685052871704 r_loss=0.6638795137405396 GP=0.12504728138446808)
[Training] epoch:255 step:200 g_loss:0.7034621834754944 d_loss:1.0125862658023834 (f_loss=0.28228265047073364 r_loss=0.6019248962402344 GP=0.1283787190914154)
[Training] epoch:255 step:300 g_loss:0.6890174150466919 d_loss:1.2725500166416168 (f_loss=0.3451549708843231 r_loss=0.6124350428581238 GP=0.3149600028991699)
[Training] epoch:256 step:0 g_loss:0.6275746822357178 d_loss:0.9159935228526592 (f_loss=0.27406996488571167 r_loss=0.610474169254303 GP=0.03144938871264458)
[Training] epoch:256 step:100 g_loss:0.7272388339042664 d_loss:1.0702018588781357 (f_loss=0.2962150573730469 r_loss=0.5941280126571655 GP=0.17985878884792328)
[Training] epoch:256 step:200 g_loss:0.7070724964141846 d_loss:1.1048278659582138 (f_loss=0.2815314531326294 r_loss=0.613804280757904 GP=0.20949213206768036)
[Training] epoch:256 step:300 g_loss:0.6636605858802795 d_loss:1.1919869184494019 (f_loss=0.2679367661476135 r_loss=0.6131982803344727 GP=0.3108518719673157)
[Training] epoch:257 step:0 g_loss:0.7063722610473633 d_loss:1.1544885635375977 (f_loss=0.34041500091552734 r_loss=0.5401611328125 GP=0.2739124298095703)
[Training] epoch:257 step:100 g_loss:0.6975350975990295 d_loss:1.211750090122223 (f_loss=0.35029006004333496 r_loss=0.6373561024665833 GP=0.2241039276123047)
[Training] epoch:257 step:200 g_loss:0.6900265216827393 d_loss:1.2906887829303741 (f_loss=0.32851406931877136 r_loss=0.668114423751831 GP=0.29406028985977173)
[Training] epoch:257 step:300 g_loss:0.724444568157196 d_loss:1.4274503886699677 (f_loss=0.30340704321861267 r_loss=0.6034224033355713 GP=0.5206209421157837)
[Training] epoch:258 step:0 g_loss:0.6866710186004639 d_loss:1.1133089065551758 (f_loss=0.30979040265083313 r_loss=0.6191860437393188 GP=0.1843324601650238)
[Training] epoch:258 step:100 g_loss:0.7045707702636719 d_loss:1.1952291131019592 (f_loss=0.3040846586227417 r_loss=0.607084333896637 GP=0.28406012058258057)
[Training] epoch:258 step:200 g_loss:0.7187899351119995 d_loss:1.5718774795532227 (f_loss=0.2975154519081116 r_loss=0.5535176992416382 GP=0.7208443284034729)
[Training] epoch:258 step:300 g_loss:0.7153315544128418 d_loss:1.2364863455295563 (f_loss=0.3110214173793793 r_loss=0.6560993194580078 GP=0.2693656086921692)
[Training] epoch:259 step:0 g_loss:0.6884150505065918 d_loss:0.9952802360057831 (f_loss=0.3158746361732483 r_loss=0.6069649457931519 GP=0.07244065403938293)
[Training] epoch:259 step:100 g_loss:0.6806637048721313 d_loss:1.0240994095802307 (f_loss=0.26307421922683716 r_loss=0.5279120802879333 GP=0.2331131100654602)
[Training] epoch:259 step:200 g_loss:0.7611974477767944 d_loss:1.0145945362746716 (f_loss=0.32493534684181213 r_loss=0.6513118743896484 GP=0.03834731504321098)
[Training] epoch:259 step:300 g_loss:0.6644697785377502 d_loss:1.3009938597679138 (f_loss=0.309709370136261 r_loss=0.6797141432762146 GP=0.31157034635543823)
[Training] epoch:260 step:0 g_loss:0.7051785588264465 d_loss:1.0541045516729355 (f_loss=0.3247873783111572 r_loss=0.5532111525535583 GP=0.1761060208082199)

[Training] epoch:260 step:100 g_loss:0.7001005411148071 d_loss:1.4466692507266998 (f_loss=0.30973395705223083 r_loss=0.5126148462295532 GP=0.6243204474449158)
[Training] epoch:260 step:200 g_loss:0.6941606998443604 d_loss:1.223027691245079 (f_loss=0.3139660656452179 r_loss=0.6638323068618774 GP=0.2452293187379837)
[Training] epoch:260 step:300 g_loss:0.6713593006134033 d_loss:1.1929293274879456 (f_loss=0.28727540373802185 r_loss=0.6605751514434814 GP=0.24507877230644226)
[Training] epoch:261 step:0 g_loss:0.6901904940605164 d_loss:1.1707893908023834 (f_loss=0.30892470479011536 r_loss=0.7072479724884033 GP=0.15461671352386475)
[Training] epoch:261 step:100 g_loss:0.700278639793396 d_loss:1.09094899892807 (f_loss=0.25603431463241577 r_loss=0.5831896066665649 GP=0.25172507762908936)
[Training] epoch:261 step:200 g_loss:0.7085341215133667 d_loss:1.206715703010559 (f_loss=0.34866929054260254 r_loss=0.6637929677963257 GP=0.19425344467163086)
[Training] epoch:261 step:300 g_loss:0.7166125774383545 d_loss:1.0323904603719711 (f_loss=0.2728557288646698 r_loss=0.6486109495162964 GP=0.11092378199100494)
[Training] epoch:262 step:0 g_loss:0.716852068901062 d_loss:1.263445883989334 (f_loss=0.29850655794143677 r_loss=0.6587666869163513 GP=0.306172639131546)
[Training] epoch:262 step:100 g_loss:0.7015625834465027 d_loss:1.0463119149208069 (f_loss=0.25840169191360474 r_loss=0.6665821075439453 GP=0.12132811546325684)
[Training] epoch:262 step:200 g_loss:0.6907134652137756 d_loss:1.1857211589813232 (f_loss=0.24923253059387207 r_loss=0.5698405504226685 GP=0.3666480779647827)
[Training] epoch:262 step:300 g_loss:0.7231923341751099 d_loss:1.3205337226390839 (f_loss=0.32094016671180725 r_loss=0.6385985016822815 GP=0.3609950542449951)
[Training] epoch:263 step:0 g_loss:0.7365670204162598 d_loss:1.341327428817749 (f_loss=0.3132634460926056 r_loss=0.6173088550567627 GP=0.41075512766838074)
[Training] epoch:263 step:100 g_loss:0.7258191108703613 d_loss:1.3555887937545776 (f_loss=0.3073900640010834 r_loss=0.6202579736709595 GP=0.4279407560825348)
[Training] epoch:263 step:200 g_loss:0.6721600294113159 d_loss:1.1472326517105103 (f_loss=0.33384889364242554 r_loss=0.6602012515068054 GP=0.1531825065612793)
[Training] epoch:263 step:300 g_loss:0.6656737327575684 d_loss:1.1451278328895569 (f_loss=0.29892635345458984 r_loss=0.6495757699012756 GP=0.1966257095336914)
[Training] epoch:264 step:0 g_loss:0.6954363584518433 d_loss:1.0597857162356377 (f_loss=0.3128955364227295 r_loss=0.6834782958030701 GP=0.0634118840098381)
[Training] epoch:264 step:100 g_loss:0.6621372699737549 d_loss:1.0115042999386787 (f_loss=0.28944554924964905 r_loss=0.6594273447990417 GP=0.06263140588998795)
[Training] epoch:264 step:200 g_loss:0.6858125329017639 d_loss:1.0239287316799164 (f_loss=0.3009149432182312 r_loss=0.6126622557640076 GP=0.11035153269767761)
[Training] epoch:264 step:300 g_loss:0.7131484746932983 d_loss:1.1801129430532455 (f_loss=0.3023456335067749 r_loss=0.6340510845184326 GP=0.24371622502803802)
[Training] epoch:265 step:0 g_loss:0.7020054459571838 d_loss:0.9427125044167042 (f_loss=0.2891901433467865 r_loss=0.592093288898468 GP=0.06142907217144966)
[Training] epoch:265 step:100 g_loss:0.758604109287262 d_loss:1.2669894397258759 (f_loss=0.35567179322242737 r_loss=0.5768688321113586 GP=0.33444881439208984)
[Training] epoch:265 step:200 g_loss:0.695496141910553 d_loss:1.562640756368637 (f_loss=0.25343504548072815 r_loss=0.6331917643547058 GP=0.6760139465332031)
[Training] epoch:265 step:300 g_loss:0.6686049103736877 d_loss:1.3582809269428253 (f_loss=0.29012054204940796 r_loss=0.6423227190971375 GP=0.4258376657962799)
[Training] epoch:266 step:0 g_loss:0.7237844467163086 d_loss:1.0336845591664314 (f_loss=0.2838616669178009 r_loss=0.6356666684150696 GP=0.11415622383356094)
[Training] epoch:266 step:100 g_loss:0.6569132208824158 d_loss:1.3891679644584656 (f_loss=0.27937746047973633 r_loss=0.7317260503768921 GP=0.37806445360183716)
[Training] epoch:266 step:200 g_loss:0.720817506313324 d_loss:1.1244130432605743 (f_loss=0.262465238571167 r_loss=0.6400372982025146 GP=0.2219105064868927)
[Training] epoch:266 step:300 g_loss:0.7275343537330627 d_loss:1.273806780576706 (f_loss=0.3045179843902588 r_loss=0.6847174167633057 GP=0.2845713794231415)
[Training] epoch:267 step:0 g_loss:0.701731264591217 d_loss:1.0843495428562164 (f_loss=0.34951457381248474 r_loss=0.642684817314148 GP=0.09215015172958374)
[Training] epoch:267 step:100 g_loss:0.6594159603118896 d_loss:1.4810676574707031 (f_loss=0.32686764001846313 r_loss=0.549168050289154 GP=0.6050319671630859)
[Training] epoch:267 step:200 g_loss:0.7303991317749023 d_loss:1.0961605161428452 (f_loss=0.3030657470226288 r_loss=0.5946332812309265 GP=0.19846148788928986)
[Training] epoch:267 step:300 g_loss:0.7716264128684998 d_loss:0.9402991011738777 (f_loss=0.2781149744987488 r_loss=0.5427870750427246 GP=0.11939705163240433)
[Training] epoch:268 step:0 g_loss:0.7213160991668701 d_loss:1.147729605436325 (f_loss=0.28898635506629944 r_loss=0.4396390914916992 GP=0.4191041588783264)
[Training] epoch:268 step:100 g_loss:0.6642967462539673 d_loss:1.1576498746871948 (f_loss=0.2969092130661011 r_loss=0.6783751845359802 GP=0.18236547708511353)
[Training] epoch:268 step:200 g_loss:0.7061692476272583 d_loss:1.0475232303142548 (f_loss=0.2772256135940552 r_loss=0.6340752840042114 GP=0.13622233271598816)
[Training] epoch:268 step:300 g_loss:0.7136926651000977 d_loss:0.9805092662572861 (f_loss=0.23350168764591217 r_loss=0.6583366394042969 GP=0.08867093920707703)
[Training] epoch:269 step:0 g_loss:0.7225887775421143 d_loss:1.0941838026046753 (f_loss=0.2633383870124817 r_loss=0.5915960073471069 GP=0.23924940824508667)
[Training] epoch:269 step:100 g_loss:0.6966063380241394 d_loss:1.0081941671669483 (f_loss=0.2899032235145569 r_loss=0.659311830997467 GP=0.05897911265492439)
[Training] epoch:269 step:200 g_loss:0.7338242530822754 d_loss:1.0846685320138931 (f_loss=0.2828309237957001 r_loss=0.5940133333206177 GP=0.20782427489757538)
[Training] epoch:269 step:300 g_loss:0.7599399089813232 d_loss:0.9778974279761314 (f_loss=0.27663207054138184 r_loss=0.6459054350852966 GP=0.05535992234945297)
[Training] epoch:270 step:0 g_loss:0.6986889839172363 d_loss:1.196356177330017 (f_loss=0.348538339138031 r_loss=0.616667628288269 GP=0.23115020990371704)

[Training] epoch:270 step:100 g_loss:0.7099988460540771 d_loss:1.042335033416748 (f_loss=0.22806072235107422 r_loss=0.5909693837165833 GP=0.22330492734909058)
[Training] epoch:270 step:200 g_loss:0.7157303690910339 d_loss:0.9854947626590729 (f_loss=0.2961578071117401 r_loss=0.6342781186103821 GP=0.055058836936950684)
[Training] epoch:270 step:300 g_loss:0.70723956823349 d_loss:1.1355944871902466 (f_loss=0.3372197449207306 r_loss=0.6656359434127808 GP=0.13273879885673523)
[Training] epoch:271 step:0 g_loss:0.6859318614006042 d_loss:1.2462699115276337 (f_loss=0.2862904369831085 r_loss=0.5905653834342957 GP=0.3694140911102295)
[Training] epoch:271 step:100 g_loss:0.7543597221374512 d_loss:1.0611795037984848 (f_loss=0.298331081867218 r_loss=0.6289588212966919 GP=0.1338896006345749)
[Training] epoch:271 step:200 g_loss:0.7522463798522949 d_loss:1.1205223053693771 (f_loss=0.23365268111228943 r_loss=0.6839801669120789 GP=0.20288945734500885)
[Training] epoch:271 step:300 g_loss:0.7006248235702515 d_loss:1.1873973906040192 (f_loss=0.34605228900909424 r_loss=0.6411203145980835 GP=0.20022478699684143)
[Training] epoch:272 step:0 g_loss:0.7164204120635986 d_loss:1.2970623075962067 (f_loss=0.3199097514152527 r_loss=0.6623360514640808 GP=0.31481650471687317)
[Training] epoch:272 step:100 g_loss:0.7468682527542114 d_loss:1.0709451138973236 (f_loss=0.27129948139190674 r_loss=0.6638005971908569 GP=0.13584503531455994)
[Training] epoch:272 step:200 g_loss:0.7515592575073242 d_loss:0.9328175522387028 (f_loss=0.25311774015426636 r_loss=0.6498393416404724 GP=0.029860470443964005)
[Training] epoch:272 step:300 g_loss:0.7165752649307251 d_loss:1.0770515501499176 (f_loss=0.2791832387447357 r_loss=0.6286929845809937 GP=0.16917532682418823)
[Training] epoch:273 step:0 g_loss:0.7418293952941895 d_loss:1.2639617919921875 (f_loss=0.3078145980834961 r_loss=0.5927852392196655 GP=0.3633619546890259)
[Training] epoch:273 step:100 g_loss:0.6847657561302185 d_loss:1.576228678226471 (f_loss=0.26550883054733276 r_loss=0.6261014938354492 GP=0.684618353843689)
[Training] epoch:273 step:200 g_loss:0.6819607019424438 d_loss:1.2059053778648376 (f_loss=0.279013067483902 r_loss=0.6093846559524536 GP=0.31750765442848206)
[Training] epoch:273 step:300 g_loss:0.7208577394485474 d_loss:1.0944435000419617 (f_loss=0.25805410742759705 r_loss=0.5545254945755005 GP=0.28186389803886414)
[Training] epoch:274 step:0 g_loss:0.7307195067405701 d_loss:1.0686587691307068 (f_loss=0.23156379163265228 r_loss=0.6206334233283997 GP=0.21646155416965485)
[Training] epoch:274 step:100 g_loss:0.7363114356994629 d_loss:1.1500121802091599 (f_loss=0.3495277762413025 r_loss=0.5892518758773804 GP=0.211232528090477)
[Training] epoch:274 step:200 g_loss:0.7042191028594971 d_loss:1.2453995048999786 (f_loss=0.2782424986362457 r_loss=0.6190140247344971 GP=0.34814298152923584)
[Training] epoch:274 step:300 g_loss:0.6877285242080688 d_loss:1.2286118865013123 (f_loss=0.30284878611564636 r_loss=0.6729652881622314 GP=0.25279781222343445)
[Training] epoch:275 step:0 g_loss:0.6841757893562317 d_loss:1.1130776107311249 (f_loss=0.2679252028465271 r_loss=0.5511012673377991 GP=0.2940511405467987)
[Training] epoch:275 step:100 g_loss:0.6962719559669495 d_loss:1.3087631464004517 (f_loss=0.2614902853965759 r_loss=0.7103044986724854 GP=0.3369683623313904)
[Training] epoch:275 step:200 g_loss:0.7408106327056885 d_loss:1.1553503572940826 (f_loss=0.3002002239227295 r_loss=0.6256906986236572 GP=0.22945943474769592)
[Training] epoch:275 step:300 g_loss:0.6960651874542236 d_loss:1.044153481721878 (f_loss=0.3177410364151001 r_loss=0.6139763593673706 GP=0.11243608593940735)
[Training] epoch:276 step:0 g_loss:0.7425621747970581 d_loss:1.2651230692863464 (f_loss=0.3818327486515045 r_loss=0.5832310318946838 GP=0.3000592887401581)
[Training] epoch:276 step:100 g_loss:0.698652982711792 d_loss:1.297306627035141 (f_loss=0.2702883183956146 r_loss=0.7078083753585815 GP=0.3192099332809448)
[Training] epoch:276 step:200 g_loss:0.7450767755508423 d_loss:1.144035428762436 (f_loss=0.3163752257823944 r_loss=0.5360470414161682 GP=0.2916131615638733)
[Training] epoch:276 step:300 g_loss:0.7066679000854492 d_loss:1.176491141319275 (f_loss=0.32666945457458496 r_loss=0.6644075512886047 GP=0.1854141354560852)
[Training] epoch:277 step:0 g_loss:0.7248793840408325 d_loss:1.0446981489658356 (f_loss=0.267360657453537 r_loss=0.6743221282958984 GP=0.10301536321640015)
[Training] epoch:277 step:100 g_loss:0.7081800699234009 d_loss:1.6483483910560608 (f_loss=0.27582108974456787 r_loss=0.5824511051177979 GP=0.7900761961936951)
[Training] epoch:277 step:200 g_loss:0.6492910981178284 d_loss:1.1293054819107056 (f_loss=0.29876646399497986 r_loss=0.5580590963363647 GP=0.27247992157936096)
[Training] epoch:277 step:300 g_loss:0.7118317484855652 d_loss:1.0499737858772278 (f_loss=0.28181520104408264 r_loss=0.6385494470596313 GP=0.1296091377735138)
[Training] epoch:278 step:0 g_loss:0.6891202330589294 d_loss:1.8504223227500916 (f_loss=0.29479479789733887 r_loss=0.3962225317955017 GP=1.159404993057251)
[Training] epoch:278 step:100 g_loss:0.6768243312835693 d_loss:1.0547710284590721 (f_loss=0.3029017746448517 r_loss=0.6459982991218567 GP=0.10587095469236374)
[Training] epoch:278 step:200 g_loss:0.7304919958114624 d_loss:1.118911623954773 (f_loss=0.34491050243377686 r_loss=0.582560122013092 GP=0.19144099950790405)
[Training] epoch:278 step:300 g_loss:0.7742266654968262 d_loss:1.3431549072265625 (f_loss=0.31883519887924194 r_loss=0.61984783411026 GP=0.40447187423706055)
[Training] epoch:279 step:0 g_loss:0.727317214012146 d_loss:1.1656008064746857 (f_loss=0.2531888782978058 r_loss=0.6407343149185181 GP=0.2716776132583618)
[Training] epoch:279 step:100 g_loss:0.7195926904678345 d_loss:1.0518104135990143 (f_loss=0.2690211534500122 r_loss=0.6332541108131409 GP=0.1495351493358612)
[Training] epoch:279 step:200 g_loss:0.7615829110145569 d_loss:1.1297355145215988 (f_loss=0.23942002654075623 r_loss=0.740323543548584 GP=0.1499919444322586)
[Training] epoch:279 step:300 g_loss:0.7071533203125 d_loss:1.5702684819698334 (f_loss=0.2709827721118927 r_loss=0.6514872312545776 GP=0.647798478603363)
[Training] epoch:280 step:0 g_loss:0.6927915811538696 d_loss:1.1912692189216614 (f_loss=0.2594083249568939 r_loss=0.6373224258422852 GP=0.2945384681224823)

[Training] epoch:280 step:100 g_loss:0.6992689371109009 d_loss:1.1551433503627777 (f_loss=0.2698298990726471 r_loss=0.6608794927597046 GP=0.22443395853042603)
[Training] epoch:280 step:200 g_loss:0.6916612982749939 d_loss:1.1132469028234482 (f_loss=0.26228785514831543 r_loss=0.6654742360115051 GP=0.18548481166362762)
[Training] epoch:280 step:300 g_loss:0.7169390916824341 d_loss:1.14308962225914 (f_loss=0.3109387159347534 r_loss=0.6543616056442261 GP=0.17778930068016052)
[Training] epoch:281 step:0 g_loss:0.6885193586349487 d_loss:1.2501305043697357 (f_loss=0.27658963203430176 r_loss=0.65188068151474 GP=0.32166019082069397)
[Training] epoch:281 step:100 g_loss:0.7100059390068054 d_loss:0.9993043094873428 (f_loss=0.2518937885761261 r_loss=0.6680986285209656 GP=0.07931189239025116)
[Training] epoch:281 step:200 g_loss:0.7394002676010132 d_loss:1.1984342336654663 (f_loss=0.2458157241344452 r_loss=0.554313600063324 GP=0.39830490946769714)
[Training] epoch:281 step:300 g_loss:0.7347750067710876 d_loss:1.0835039168596268 (f_loss=0.23675605654716492 r_loss=0.6587917804718018 GP=0.1879560798406601)
[Training] epoch:282 step:0 g_loss:0.71564120054245 d_loss:1.0845906883478165 (f_loss=0.23586125671863556 r_loss=0.6735813617706299 GP=0.17514806985855103)
[Training] epoch:282 step:100 g_loss:0.6754559278488159 d_loss:1.1154626160860062 (f_loss=0.25314584374427795 r_loss=0.6823105812072754 GP=0.18000619113445282)
[Training] epoch:282 step:200 g_loss:0.7478988170623779 d_loss:1.0726736187934875 (f_loss=0.28267765045166016 r_loss=0.617794930934906 GP=0.1722010374069214)
[Training] epoch:282 step:300 g_loss:0.6690399646759033 d_loss:1.048476755619049 (f_loss=0.22369202971458435 r_loss=0.6420083045959473 GP=0.18277642130851746)
[Training] epoch:283 step:0 g_loss:0.752798855304718 d_loss:1.10748490691185 (f_loss=0.3147357404232025 r_loss=0.7061053514480591 GP=0.08664381504058838)
[Training] epoch:283 step:100 g_loss:0.7322078943252563 d_loss:1.102432519197464 (f_loss=0.3103106915950775 r_loss=0.6359033584594727 GP=0.15621846914291382)
[Training] epoch:283 step:200 g_loss:0.7343622446060181 d_loss:1.4881979525089264 (f_loss=0.2529887855052948 r_loss=0.6659197807312012 GP=0.5692893862724304)
[Training] epoch:283 step:300 g_loss:0.7319526672363281 d_loss:1.3965331763029099 (f_loss=0.22929616272449493 r_loss=0.7378745079040527 GP=0.4293625056743622)
[Training] epoch:284 step:0 g_loss:0.7363060712814331 d_loss:1.0795206427574158 (f_loss=0.27980825304985046 r_loss=0.6093795895576477 GP=0.1903328001499176)
[Training] epoch:284 step:100 g_loss:0.7863527536392212 d_loss:1.2960640490055084 (f_loss=0.2641947269439697 r_loss=0.6494590044021606 GP=0.38241031765937805)
[Training] epoch:284 step:200 g_loss:0.8172841668128967 d_loss:1.1345337629318237 (f_loss=0.2562754452228546 r_loss=0.6517181396484375 GP=0.22654017806053162)
[Training] epoch:284 step:300 g_loss:0.7449060678482056 d_loss:0.9532679617404938 (f_loss=0.24714341759681702 r_loss=0.5860117673873901 GP=0.12011277675628662)
[Training] epoch:285 step:0 g_loss:0.7569549679756165 d_loss:1.040618784725666 (f_loss=0.24736279249191284 r_loss=0.6840526461601257 GP=0.10920334607362747)
[Training] epoch:285 step:100 g_loss:0.724645733833313 d_loss:1.086508646607399 (f_loss=0.207469642162323 r_loss=0.6369105577468872 GP=0.24212844669818878)
[Training] epoch:285 step:200 g_loss:0.779439389705658 d_loss:0.9636404290795326 (f_loss=0.23225995898246765 r_loss=0.6294876337051392 GP=0.10189283639192581)
[Training] epoch:285 step:300 g_loss:0.7452151775360107 d_loss:1.0060180947184563 (f_loss=0.22519883513450623 r_loss=0.6878933906555176 GP=0.09292586892843246)
[Training] epoch:286 step:0 g_loss:0.7336543202400208 d_loss:1.5112282037734985 (f_loss=0.2746954560279846 r_loss=0.7253563404083252 GP=0.5111764073371887)
[Training] epoch:286 step:100 g_loss:0.7387707233428955 d_loss:1.0019972026348114 (f_loss=0.2461806833744049 r_loss=0.6939178705215454 GP=0.061898648738861084)
[Training] epoch:286 step:200 g_loss:0.7191174030303955 d_loss:1.1113731563091278 (f_loss=0.2825332283973694 r_loss=0.6643522381782532 GP=0.16448768973350525)
[Training] epoch:286 step:300 g_loss:0.7283263206481934 d_loss:1.0402260571718216 (f_loss=0.2986692190170288 r_loss=0.6410104036331177 GP=0.10054643452167511)
[Training] epoch:287 step:0 g_loss:0.7071161866188049 d_loss:1.2554330229759216 (f_loss=0.27378174662590027 r_loss=0.6244657039642334 GP=0.35718557238578796)
[Training] epoch:287 step:100 g_loss:0.7576912641525269 d_loss:1.2051097452640533 (f_loss=0.26411768794059753 r_loss=0.6064636707305908 GP=0.334528386592865)
[Training] epoch:287 step:200 g_loss:0.7080451846122742 d_loss:1.3938058614730835 (f_loss=0.25158435106277466 r_loss=0.6707445979118347 GP=0.4714769124984741)
[Training] epoch:287 step:300 g_loss:0.7552766799926758 d_loss:1.2071960419416428 (f_loss=0.284519761800766 r_loss=0.6830336451530457 GP=0.23964263498783112)
[Training] epoch:288 step:0 g_loss:0.7058764696121216 d_loss:1.070882648229599 (f_loss=0.2691626250743866 r_loss=0.6173154711723328 GP=0.18440455198287964)
[Training] epoch:288 step:100 g_loss:0.7289400100708008 d_loss:1.1173433884978294 (f_loss=0.2803025245666504 r_loss=0.7275835275650024 GP=0.1094573363661766)
[Training] epoch:288 step:200 g_loss:0.7747083902359009 d_loss:1.2556620836257935 (f_loss=0.2934741675853729 r_loss=0.6756019592285156 GP=0.2865859568119049)
[Training] epoch:288 step:300 g_loss:0.6572558283805847 d_loss:1.1418553292751312 (f_loss=0.3207395076751709 r_loss=0.6669232249259949 GP=0.15419259667396545)
[Training] epoch:289 step:0 g_loss:0.7691680788993835 d_loss:0.9746176302433014 (f_loss=0.23182982206344604 r_loss=0.6340879201889038 GP=0.10869988799095154)
[Training] epoch:289 step:100 g_loss:0.7716477513313293 d_loss:0.9850687384605408 (f_loss=0.24834463000297546 r_loss=0.6514195203781128 GP=0.08530458807945251)
[Training] epoch:289 step:200 g_loss:0.7292453050613403 d_loss:1.4236819297075272 (f_loss=0.2295035570859909 r_loss=0.7068085074424744 GP=0.4873698651790619)
[Training] epoch:289 step:300 g_loss:0.7377163171768188 d_loss:1.2502305209636688 (f_loss=0.27428552508354187 r_loss=0.535124659538269 GP=0.4408203363418579)
[Training] epoch:290 step:0 g_loss:0.7626433968544006 d_loss:1.1301795840263367 (f_loss=0.2901536822319031 r_loss=0.7258296012878418 GP=0.1141963005065918)

[Training] epoch:290 step:100 g_loss:0.7997191548347473 d_loss:1.273572713136673 (f_loss=0.2518998980522156 r_loss=0.5500759482383728 GP=0.4715968668460846)
[Training] epoch:290 step:200 g_loss:0.7786794900894165 d_loss:1.015247955918312 (f_loss=0.2729755640029907 r_loss=0.6333124041557312 GP=0.10895998775959015)
[Training] epoch:290 step:300 g_loss:0.729543924331665 d_loss:1.5126981288194656 (f_loss=0.2461899071931839 r_loss=0.6564602851867676 GP=0.6100479364395142)
[Training] epoch:291 step:0 g_loss:0.7903534770011902 d_loss:1.0978727638721466 (f_loss=0.2220497876405716 r_loss=0.6724303960800171 GP=0.20339258015155792)
[Training] epoch:291 step:100 g_loss:0.7488193511962891 d_loss:1.3154370486736298 (f_loss=0.21757104992866516 r_loss=0.6195491552352905 GP=0.4783168435096741)
[Training] epoch:291 step:200 g_loss:0.7930694222450256 d_loss:1.12720787525177 (f_loss=0.24106918275356293 r_loss=0.7116472721099854 GP=0.17449142038822174)
[Training] epoch:291 step:300 g_loss:0.7229381799697876 d_loss:1.1742838025093079 (f_loss=0.23211361467838287 r_loss=0.7278090119361877 GP=0.21436117589473724)
[Training] epoch:292 step:0 g_loss:0.7168890833854675 d_loss:1.384560078382492 (f_loss=0.25468316674232483 r_loss=0.567034900188446 GP=0.5628420114517212)
[Training] epoch:292 step:100 g_loss:0.7525826096534729 d_loss:1.0339450240135193 (f_loss=0.2439795732498169 r_loss=0.6033397316932678 GP=0.18662571907043457)
[Training] epoch:292 step:200 g_loss:0.6994783878326416 d_loss:1.0528880953788757 (f_loss=0.2695345878601074 r_loss=0.694270670413971 GP=0.08908283710479736)
[Training] epoch:292 step:300 g_loss:0.7870519161224365 d_loss:1.1213078498840332 (f_loss=0.23397329449653625 r_loss=0.6636123657226562 GP=0.2237221896648407)
[Training] epoch:293 step:0 g_loss:0.7642220258712769 d_loss:1.0675819292664528 (f_loss=0.26348182559013367 r_loss=0.6818391680717468 GP=0.1222609356045723)
[Training] epoch:293 step:100 g_loss:0.7064657807350159 d_loss:1.073617860674858 (f_loss=0.2696691155433655 r_loss=0.6236251592636108 GP=0.18032358586788177)
[Training] epoch:293 step:200 g_loss:0.6922692060470581 d_loss:0.9724200218915939 (f_loss=0.2054373174905777 r_loss=0.6362289786338806 GP=0.13075372576713562)
[Training] epoch:293 step:300 g_loss:0.7540576457977295 d_loss:1.2593354880809784 (f_loss=0.31098422408103943 r_loss=0.698016345500946 GP=0.2503349184989929)
[Training] epoch:294 step:0 g_loss:0.7485208511352539 d_loss:1.136152297258377 (f_loss=0.32489365339279175 r_loss=0.6015651822090149 GP=0.20969346165657043)
[Training] epoch:294 step:100 g_loss:0.7373905181884766 d_loss:1.2180452644824982 (f_loss=0.24467909336090088 r_loss=0.6348248720169067 GP=0.33854129910469055)
[Training] epoch:294 step:200 g_loss:0.74656742811203 d_loss:1.1916167438030243 (f_loss=0.2577406167984009 r_loss=0.7068586349487305 GP=0.22701749205589294)
[Training] epoch:294 step:300 g_loss:0.7513501048088074 d_loss:1.8254284113645554 (f_loss=0.23963801562786102 r_loss=0.7145247459411621 GP=0.8712656497955322)
[Training] epoch:295 step:0 g_loss:0.7193779945373535 d_loss:1.145705834031105 (f_loss=0.252219557762146 r_loss=0.689146876335144 GP=0.204339399933815)
[Training] epoch:295 step:100 g_loss:0.7575725317001343 d_loss:1.0336413830518723 (f_loss=0.24404452741146088 r_loss=0.6440064907073975 GP=0.14559036493301392)
[Training] epoch:295 step:200 g_loss:0.7247086763381958 d_loss:1.1806871592998505 (f_loss=0.28189682960510254 r_loss=0.7020419239997864 GP=0.19674840569496155)
[Training] epoch:295 step:300 g_loss:0.718681812286377 d_loss:1.3096078038215637 (f_loss=0.2615811824798584 r_loss=0.6622244715690613 GP=0.38580214977264404)
[Training] epoch:296 step:0 g_loss:0.770322859287262 d_loss:1.1920939534902573 (f_loss=0.20061543583869934 r_loss=0.7454041838645935 GP=0.24607433378696442)
[Training] epoch:296 step:100 g_loss:0.7377760410308838 d_loss:1.1531416028738022 (f_loss=0.2784249186515808 r_loss=0.6773830056190491 GP=0.1973336786031723)
[Training] epoch:296 step:200 g_loss:0.7810605764389038 d_loss:1.1510739028453827 (f_loss=0.28485530614852905 r_loss=0.6282595992088318 GP=0.23795899748802185)
[Training] epoch:296 step:300 g_loss:0.6855725646018982 d_loss:1.4387894570827484 (f_loss=0.24835845828056335 r_loss=0.630280613899231 GP=0.5601503849029541)
[Training] epoch:297 step:0 g_loss:0.7211265563964844 d_loss:1.0553327463567257 (f_loss=0.24617379903793335 r_loss=0.7679445147514343 GP=0.04121443256735802)
[Training] epoch:297 step:100 g_loss:0.7579683065414429 d_loss:1.1022810712456703 (f_loss=0.2834968566894531 r_loss=0.7237908840179443 GP=0.09499333053827286)
[Training] epoch:297 step:200 g_loss:0.7879462838172913 d_loss:1.1582122594118118 (f_loss=0.2727971374988556 r_loss=0.6981555223464966 GP=0.18725959956645966)
[Training] epoch:297 step:300 g_loss:0.7122778296470642 d_loss:1.122616097331047 (f_loss=0.23877917230129242 r_loss=0.6502704620361328 GP=0.23356646299362183)
[Training] epoch:298 step:0 g_loss:0.7522902488708496 d_loss:2.0133626013994217 (f_loss=0.21358437836170197 r_loss=0.7378063201904297 GP=1.06197190284729)
[Training] epoch:298 step:100 g_loss:0.7610907554626465 d_loss:1.2915621101856232 (f_loss=0.22612550854682922 r_loss=0.6096267700195312 GP=0.4558098316192627)
[Training] epoch:298 step:200 g_loss:0.6772900223731995 d_loss:1.1342742443084717 (f_loss=0.2639598548412323 r_loss=0.6496515274047852 GP=0.22066286206245422)
[Training] epoch:298 step:300 g_loss:0.711331844329834 d_loss:1.2939416766166687 (f_loss=0.3077501952648163 r_loss=0.5925916433334351 GP=0.39359983801841736)
[Training] epoch:299 step:0 g_loss:0.7458940744400024 d_loss:1.0458283722400665 (f_loss=0.26881447434425354 r_loss=0.5973868370056152 GP=0.17962706089019775)
[Training] epoch:299 step:100 g_loss:0.7599277496337891 d_loss:1.4173385798931122 (f_loss=0.26839467883110046 r_loss=0.5676082372665405 GP=0.5813356637954712)
[Training] epoch:299 step:200 g_loss:0.7964020371437073 d_loss:1.1990638077259064 (f_loss=0.2696340084075928 r_loss=0.6692922115325928 GP=0.2601375877857208)
[Training] epoch:299 step:300 g_loss:0.7623097896575928 d_loss:1.370941087603569 (f_loss=0.21737079322338104 r_loss=0.6379773020744324 GP=0.5155929923057556)
[Training] epoch:300 step:0 g_loss:0.781090497970581 d_loss:1.2896932065486908 (f_loss=0.21419012546539307 r_loss=0.6252762675285339 GP=0.4502268135547638)

[Training] epoch:300 step:100 g_loss:0.7416609525680542 d_loss:1.0619319677352905 (f_loss=0.2308204621076584 r_loss=0.7411543130874634 GP=0.08995719254016876)
[Training] epoch:300 step:200 g_loss:0.7480320334434509 d_loss:1.1943021416664124 (f_loss=0.21375826001167297 r_loss=0.6539747714996338 GP=0.3265691101551056)
[Training] epoch:300 step:300 g_loss:0.7892305850982666 d_loss:1.6134627610445023 (f_loss=0.23979194462299347 r_loss=0.5331562757492065 GP=0.8405145406723022)
[Training] epoch:301 step:0 g_loss:0.7373857498168945 d_loss:1.0460058003664017 (f_loss=0.24508801102638245 r_loss=0.6415574550628662 GP=0.15936033427715302)
[Training] epoch:301 step:100 g_loss:0.7219598889350891 d_loss:1.4707101583480835 (f_loss=0.26226067543029785 r_loss=0.6739022731781006 GP=0.5345472097396851)
[Training] epoch:301 step:200 g_loss:0.7485910654067993 d_loss:1.0676530450582504 (f_loss=0.23220692574977875 r_loss=0.6944597363471985 GP=0.1409863829612732)
[Training] epoch:301 step:300 g_loss:0.81931471824646 d_loss:1.0859754234552383 (f_loss=0.22856703400611877 r_loss=0.672754168510437 GP=0.18465422093868256)
[Training] epoch:302 step:0 g_loss:0.7706904411315918 d_loss:1.261374682188034 (f_loss=0.26187753677368164 r_loss=0.7470360398292542 GP=0.25246110558509827)
[Training] epoch:302 step:100 g_loss:0.7230350375175476 d_loss:1.3032614290714264 (f_loss=0.28472501039505005 r_loss=0.7560861110687256 GP=0.26245030760765076)
[Training] epoch:302 step:200 g_loss:0.7137048840522766 d_loss:1.0725573264062405 (f_loss=0.252969354391098 r_loss=0.772537350654602 GP=0.04705062136054039)
[Training] epoch:302 step:300 g_loss:0.7445686459541321 d_loss:1.1736485362052917 (f_loss=0.21928811073303223 r_loss=0.674623966217041 GP=0.2797364592552185)
[Training] epoch:303 step:0 g_loss:0.7854963541030884 d_loss:1.0685105323791504 (f_loss=0.23749257624149323 r_loss=0.7450352311134338 GP=0.08598272502422333)
[Training] epoch:303 step:100 g_loss:0.73209547996521 d_loss:1.0998487025499344 (f_loss=0.28212088346481323 r_loss=0.6800145506858826 GP=0.1377132683992386)
[Training] epoch:303 step:200 g_loss:0.754035472869873 d_loss:1.1069154143333435 (f_loss=0.24380937218666077 r_loss=0.6906008124351501 GP=0.1725052297115326)
[Training] epoch:303 step:300 g_loss:0.7546675205230713 d_loss:1.1039107590913773 (f_loss=0.2236284613609314 r_loss=0.7950820326805115 GP=0.08520026504993439)
[Training] epoch:304 step:0 g_loss:0.7298673391342163 d_loss:1.1703849136829376 (f_loss=0.19931790232658386 r_loss=0.6800026893615723 GP=0.2910643219947815)
[Training] epoch:304 step:100 g_loss:0.7770581245422363 d_loss:1.1414670944213867 (f_loss=0.24162402749061584 r_loss=0.6664726734161377 GP=0.23337039351463318)
[Training] epoch:304 step:200 g_loss:0.7990453839302063 d_loss:1.0572504848241806 (f_loss=0.22573503851890564 r_loss=0.6703277826309204 GP=0.16118766367435455)
[Training] epoch:304 step:300 g_loss:0.7511872053146362 d_loss:1.1609145402908325 (f_loss=0.23088526725769043 r_loss=0.6763067841529846 GP=0.25372248888015747)
[Training] epoch:305 step:0 g_loss:0.757655143737793 d_loss:1.3212359249591827 (f_loss=0.2765257954597473 r_loss=0.6327182054519653 GP=0.4119919240474701)
[Training] epoch:305 step:100 g_loss:0.7326327562332153 d_loss:1.2300077676773071 (f_loss=0.2666415572166443 r_loss=0.6214193105697632 GP=0.34194689989089966)
[Training] epoch:305 step:200 g_loss:0.7383503913879395 d_loss:1.2158604264259338 (f_loss=0.26546594500541687 r_loss=0.6559997797012329 GP=0.29439470171928406)
[Training] epoch:305 step:300 g_loss:0.8224117755889893 d_loss:1.1170879900455475 (f_loss=0.24996283650398254 r_loss=0.6276404857635498 GP=0.23948466777801514)
[Training] epoch:306 step:0 g_loss:0.7590717077255249 d_loss:1.1156222224235535 (f_loss=0.20109665393829346 r_loss=0.6966567039489746 GP=0.2178688645362854)
[Training] epoch:306 step:100 g_loss:0.7583935260772705 d_loss:1.291311264038086 (f_loss=0.22372674942016602 r_loss=0.678398847579956 GP=0.38918566703796387)
[Training] epoch:306 step:200 g_loss:0.7546201348304749 d_loss:1.0760424733161926 (f_loss=0.23376776278018951 r_loss=0.6442261934280396 GP=0.19804851710796356)
[Training] epoch:306 step:300 g_loss:0.7658066749572754 d_loss:1.076257437467575 (f_loss=0.22198346257209778 r_loss=0.7329443693161011 GP=0.12132960557937622)
[Training] epoch:307 step:0 g_loss:0.7072123289108276 d_loss:0.9891901984810829 (f_loss=0.22241684794425964 r_loss=0.6933073997497559 GP=0.07346595078706741)
[Training] epoch:307 step:100 g_loss:0.7547649145126343 d_loss:1.058657094836235 (f_loss=0.2516666054725647 r_loss=0.6965155601501465 GP=0.11047492921352386)
[Training] epoch:307 step:200 g_loss:0.768519401550293 d_loss:1.1271788775920868 (f_loss=0.20089921355247498 r_loss=0.6446762681007385 GP=0.2816033959388733)
[Training] epoch:307 step:300 g_loss:0.7537870407104492 d_loss:1.2239316403865814 (f_loss=0.21904435753822327 r_loss=0.7407872676849365 GP=0.26410001516342163)
[Training] epoch:308 step:0 g_loss:0.77527916431427 d_loss:1.8786586225032806 (f_loss=0.2512374222278595 r_loss=0.7065843343734741 GP=0.920836865901947)
[Training] epoch:308 step:100 g_loss:0.7673783302307129 d_loss:1.4460016787052155 (f_loss=0.25785472989082336 r_loss=0.7193078994750977 GP=0.46883904933929443)
[Training] epoch:308 step:200 g_loss:0.8041475415229797 d_loss:1.676631897687912 (f_loss=0.22410038113594055 r_loss=0.6351755261421204 GP=0.8173559904098511)
[Training] epoch:308 step:300 g_loss:0.7788515686988831 d_loss:1.1448823660612106 (f_loss=0.2638360261917114 r_loss=0.689308762550354 GP=0.1917375773191452)
[Training] epoch:309 step:0 g_loss:0.7670789361000061 d_loss:1.0449696481227875 (f_loss=0.2513124644756317 r_loss=0.6174584627151489 GP=0.17619872093200684)
[Training] epoch:309 step:100 g_loss:0.8159976005554199 d_loss:1.3954554051160812 (f_loss=0.1952979415655136 r_loss=0.6346149444580078 GP=0.5655425190925598)
[Training] epoch:309 step:200 g_loss:0.8236017227172852 d_loss:1.1475164592266083 (f_loss=0.2652076184749603 r_loss=0.589407205581665 GP=0.2929016351699829)
[Training] epoch:309 step:300 g_loss:0.7785655856132507 d_loss:1.0076204687356949 (f_loss=0.25510042905807495 r_loss=0.6284189224243164 GP=0.12410111725330353)
[Training] epoch:310 step:0 g_loss:0.7893474102020264 d_loss:1.0599642544984818 (f_loss=0.22701412439346313 r_loss=0.622748076915741 GP=0.21020205318927765)

[Training] epoch:310 step:100 g_loss:0.7484216690063477 d_loss:1.2539393305778503 (f_loss=0.22864800691604614 r_loss=0.5547338128089905 GP=0.4705575108528137)
[Training] epoch:310 step:200 g_loss:0.7203596234321594 d_loss:1.366493672132492 (f_loss=0.23605558276176453 r_loss=0.628374457359314 GP=0.5020636320114136)
[Training] epoch:310 step:300 g_loss:0.7457191944122314 d_loss:1.7243705689907074 (f_loss=0.2513257563114166 r_loss=0.5796874165534973 GP=0.8933573961257935)
[Training] epoch:311 step:0 g_loss:0.7844537496566772 d_loss:1.1171107590198517 (f_loss=0.25971633195877075 r_loss=0.6645268201828003 GP=0.19286760687828064)
[Training] epoch:311 step:100 g_loss:0.787211000919342 d_loss:1.0288503095507622 (f_loss=0.24151760339736938 r_loss=0.6879208087921143 GP=0.09941189736127853)
[Training] epoch:311 step:200 g_loss:0.7879574298858643 d_loss:1.1086060255765915 (f_loss=0.2290773093700409 r_loss=0.7254113554954529 GP=0.15411736071109772)
[Training] epoch:311 step:300 g_loss:0.7693299055099487 d_loss:1.3240233063697815 (f_loss=0.2562510073184967 r_loss=0.7315660119056702 GP=0.3362062871456146)
[Training] epoch:312 step:0 g_loss:0.779737114906311 d_loss:1.1170986741781235 (f_loss=0.25372621417045593 r_loss=0.7177119851112366 GP=0.14566047489643097)
[Training] epoch:312 step:100 g_loss:0.7743017673492432 d_loss:1.097275823354721 (f_loss=0.2537812292575836 r_loss=0.678114116191864 GP=0.16538047790527344)
[Training] epoch:312 step:200 g_loss:0.775157630443573 d_loss:1.3771830201148987 (f_loss=0.23223483562469482 r_loss=0.5766957402229309 GP=0.568252444267273)
[Training] epoch:312 step:300 g_loss:0.758110761642456 d_loss:1.2102356404066086 (f_loss=0.22973142564296722 r_loss=0.6661391854286194 GP=0.314365029335022)
[Training] epoch:313 step:0 g_loss:0.7448023557662964 d_loss:1.5249056816101074 (f_loss=0.2572471499443054 r_loss=0.7040569186210632 GP=0.5636016130447388)
[Training] epoch:313 step:100 g_loss:0.7504899501800537 d_loss:1.1970115303993225 (f_loss=0.275377482175827 r_loss=0.7089483141899109 GP=0.2126857340335846)
[Training] epoch:313 step:200 g_loss:0.7681471705436707 d_loss:1.437311202287674 (f_loss=0.240296870470047 r_loss=0.621616005897522 GP=0.575398325920105)
[Training] epoch:313 step:300 g_loss:0.757849931716919 d_loss:1.3176757097244263 (f_loss=0.23630735278129578 r_loss=0.6208406686782837 GP=0.4605276882648468)
[Training] epoch:314 step:0 g_loss:0.7606096267700195 d_loss:1.3006063401699066 (f_loss=0.2507396340370178 r_loss=0.6888905167579651 GP=0.3609761893749237)
[Training] epoch:314 step:100 g_loss:0.7977562546730042 d_loss:1.0596080124378204 (f_loss=0.23640087246894836 r_loss=0.6398955583572388 GP=0.1833115816116333)
[Training] epoch:314 step:200 g_loss:0.7631126642227173 d_loss:1.1037543565034866 (f_loss=0.24063614010810852 r_loss=0.725816547870636 GP=0.13730166852474213)
[Training] epoch:314 step:300 g_loss:0.7302855253219604 d_loss:1.1710302829742432 (f_loss=0.23011893033981323 r_loss=0.6726589798927307 GP=0.2682523727416992)
[Training] epoch:315 step:0 g_loss:0.7753953337669373 d_loss:1.0640474259853363 (f_loss=0.18933230638504028 r_loss=0.6782894730567932 GP=0.1964256465435028)
[Training] epoch:315 step:100 g_loss:0.7498151063919067 d_loss:1.1132783591747284 (f_loss=0.1994236409664154 r_loss=0.7749238014221191 GP=0.13893091678619385)
[Training] epoch:315 step:200 g_loss:0.7821893692016602 d_loss:2.2258082926273346 (f_loss=0.20652726292610168 r_loss=0.5568457841873169 GP=1.462435245513916)
[Training] epoch:315 step:300 g_loss:0.7947107553482056 d_loss:1.2712294459342957 (f_loss=0.2179824411869049 r_loss=0.7509188652038574 GP=0.3023281395435333)
[Training] epoch:316 step:0 g_loss:0.7955058813095093 d_loss:0.9621985629200935 (f_loss=0.20456235110759735 r_loss=0.6667302250862122 GP=0.09090598672628403)
[Training] epoch:316 step:100 g_loss:0.7096807360649109 d_loss:0.9955059289932251 (f_loss=0.2263876050710678 r_loss=0.6650180816650391 GP=0.10410024225711823)
[Training] epoch:316 step:200 g_loss:0.7814600467681885 d_loss:0.9835494384169579 (f_loss=0.20533402264118195 r_loss=0.6869542598724365 GP=0.09126115590333939)
[Training] epoch:316 step:300 g_loss:0.7670211791992188 d_loss:1.0643979907035828 (f_loss=0.2341458797454834 r_loss=0.6852859854698181 GP=0.14496612548828125)
[Training] epoch:317 step:0 g_loss:0.7974994778633118 d_loss:1.1570572555065155 (f_loss=0.24650590121746063 r_loss=0.6748595237731934 GP=0.2356918305158615)
[Training] epoch:317 step:100 g_loss:0.7786024808883667 d_loss:1.4213895350694656 (f_loss=0.23110540211200714 r_loss=0.5830495953559875 GP=0.607234537601471)
[Training] epoch:317 step:200 g_loss:0.715129554271698 d_loss:1.1944692134857178 (f_loss=0.21781575679779053 r_loss=0.6139342784881592 GP=0.36271917819976807)
[Training] epoch:317 step:300 g_loss:0.7372100353240967 d_loss:1.1004769206047058 (f_loss=0.1814868152141571 r_loss=0.6961124539375305 GP=0.2228776514530182)
[Training] epoch:318 step:0 g_loss:0.7851654291152954 d_loss:1.0469854027032852 (f_loss=0.23405295610427856 r_loss=0.6795399188995361 GP=0.13339252769947052)
[Training] epoch:318 step:100 g_loss:0.7909538745880127 d_loss:1.0829333811998367 (f_loss=0.24825717508792877 r_loss=0.7058768272399902 GP=0.12879937887191772)
[Training] epoch:318 step:200 g_loss:0.7330200672149658 d_loss:1.0095327347517014 (f_loss=0.23406022787094116 r_loss=0.6361124515533447 GP=0.13936005532741547)
[Training] epoch:318 step:300 g_loss:0.7734769582748413 d_loss:1.4746708869934082 (f_loss=0.2096114158630371 r_loss=0.7321234345436096 GP=0.5329360365867615)
[Training] epoch:319 step:0 g_loss:0.7358838319778442 d_loss:1.0463254749774933 (f_loss=0.21409684419631958 r_loss=0.6518816947937012 GP=0.18034693598747253)
[Training] epoch:319 step:100 g_loss:0.7562209367752075 d_loss:1.0736887082457542 (f_loss=0.24732869863510132 r_loss=0.756105363368988 GP=0.07025464624166489)
[Training] epoch:319 step:200 g_loss:0.8473244905471802 d_loss:1.1680482476949692 (f_loss=0.22130237519741058 r_loss=0.6536381244659424 GP=0.2931077480316162)
[Training] epoch:319 step:300 g_loss:0.7338081002235413 d_loss:1.1528923213481903 (f_loss=0.21117249131202698 r_loss=0.6306203603744507 GP=0.31109946966171265)
[Training] epoch:320 step:0 g_loss:0.7917115092277527 d_loss:1.4129275977611542 (f_loss=0.2559450566768646 r_loss=0.6062057018280029 GP=0.5507768392562866)

[Training] epoch:320 step:100 g_loss:0.785707950592041 d_loss:1.2486505806446075 (f_loss=0.20388931035995483 r_loss=0.6937170028686523 GP=0.35104426741600037)
[Training] epoch:320 step:200 g_loss:0.7790882587432861 d_loss:1.004057914018631 (f_loss=0.18676543235778809 r_loss=0.6565605401992798 GP=0.1607319414615631)
[Training] epoch:320 step:300 g_loss:0.831150233745575 d_loss:1.1332858353853226 (f_loss=0.18187732994556427 r_loss=0.6547220945358276 GP=0.29668641090393066)
[Training] epoch:321 step:0 g_loss:0.8077238202095032 d_loss:0.9754488617181778 (f_loss=0.16600120067596436 r_loss=0.691807746887207 GP=0.11763991415500641)
[Training] epoch:321 step:100 g_loss:0.7618951797485352 d_loss:1.0335977226495743 (f_loss=0.2534503638744354 r_loss=0.6854240298271179 GP=0.09472332894802094)
[Training] epoch:321 step:200 g_loss:0.7777979969978333 d_loss:1.0501830577850342 (f_loss=0.20341630280017853 r_loss=0.6690618991851807 GP=0.177704855799675)
[Training] epoch:321 step:300 g_loss:0.783123254776001 d_loss:1.033070646226406 (f_loss=0.24802710115909576 r_loss=0.6900215148925781 GP=0.09502203017473221)
[Training] epoch:322 step:0 g_loss:0.779726505279541 d_loss:1.3492481708526611 (f_loss=0.26136109232902527 r_loss=0.6756380796432495 GP=0.41224899888038635)
[Training] epoch:322 step:100 g_loss:0.7537803649902344 d_loss:1.231674388051033 (f_loss=0.22308595478534698 r_loss=0.6933420896530151 GP=0.3152463436126709)
[Training] epoch:322 step:200 g_loss:0.7424885630607605 d_loss:1.167891025543213 (f_loss=0.15585771203041077 r_loss=0.5856468677520752 GP=0.42638644576072693)
[Training] epoch:322 step:300 g_loss:0.7704742550849915 d_loss:1.194350004196167 (f_loss=0.25101691484451294 r_loss=0.6765952110290527 GP=0.2667378783226013)
[Training] epoch:323 step:0 g_loss:0.7949713468551636 d_loss:1.046090081334114 (f_loss=0.22645476460456848 r_loss=0.6712963581085205 GP=0.14833895862102509)
[Training] epoch:323 step:100 g_loss:0.7824551463127136 d_loss:1.059519812464714 (f_loss=0.2834382951259613 r_loss=0.7229823470115662 GP=0.053099170327186584)
[Training] epoch:323 step:200 g_loss:0.7451758980751038 d_loss:1.536941945552826 (f_loss=0.22068023681640625 r_loss=0.8009426593780518 GP=0.5153190493583679)
[Training] epoch:323 step:300 g_loss:0.7923489212989807 d_loss:1.6541067063808441 (f_loss=0.1826840341091156 r_loss=0.650265097618103 GP=0.8211575746536255)
[Training] epoch:324 step:0 g_loss:0.7746244072914124 d_loss:1.0740571171045303 (f_loss=0.2587815225124359 r_loss=0.7026957273483276 GP=0.11257986724376678)
[Training] epoch:324 step:100 g_loss:0.7275318503379822 d_loss:1.1626498103141785 (f_loss=0.21714499592781067 r_loss=0.6674597263336182 GP=0.27804508805274963)
[Training] epoch:324 step:200 g_loss:0.7517715096473694 d_loss:0.9796042256057262 (f_loss=0.19658908247947693 r_loss=0.723975658416748 GP=0.059039484709501266)
[Training] epoch:324 step:300 g_loss:0.8221171498298645 d_loss:1.1346660405397415 (f_loss=0.18747785687446594 r_loss=0.7154024839401245 GP=0.23178569972515106)
[Training] epoch:325 step:0 g_loss:0.8087748885154724 d_loss:1.2525272369384766 (f_loss=0.23198282718658447 r_loss=0.6795504689216614 GP=0.3409939408302307)
[Training] epoch:325 step:100 g_loss:0.7626602649688721 d_loss:1.7013720571994781 (f_loss=0.23358014225959778 r_loss=0.6786726713180542 GP=0.7891192436218262)
[Training] epoch:325 step:200 g_loss:0.8266433477401733 d_loss:1.1175534576177597 (f_loss=0.17452606558799744 r_loss=0.7332782745361328 GP=0.20974911749362946)
[Training] epoch:325 step:300 g_loss:0.7561066746711731 d_loss:1.082276001572609 (f_loss=0.22616903483867645 r_loss=0.683099091053009 GP=0.17300787568092346)
[Training] epoch:326 step:0 g_loss:0.7328193187713623 d_loss:1.2687808573246002 (f_loss=0.2618732154369354 r_loss=0.72366863489151 GP=0.2832390069961548)
[Training] epoch:326 step:100 g_loss:0.8463157415390015 d_loss:1.0025928914546967 (f_loss=0.14257287979125977 r_loss=0.6047709584236145 GP=0.2552490532398224)
[Training] epoch:326 step:200 g_loss:0.7254204750061035 d_loss:1.4809919893741608 (f_loss=0.2166447937488556 r_loss=0.7021005153656006 GP=0.5622466802597046)
[Training] epoch:326 step:300 g_loss:0.7794184684753418 d_loss:1.5233167707920074 (f_loss=0.23103263974189758 r_loss=0.6983665227890015 GP=0.5939176082611084)
[Training] epoch:327 step:0 g_loss:0.7994853258132935 d_loss:1.0219176262617111 (f_loss=0.1886436641216278 r_loss=0.7297993898391724 GP=0.10347457230091095)
[Training] epoch:327 step:100 g_loss:0.7276971340179443 d_loss:1.3006487488746643 (f_loss=0.2521795928478241 r_loss=0.7014069557189941 GP=0.34706220030784607)
[Training] epoch:327 step:200 g_loss:0.7435044050216675 d_loss:1.1333955228328705 (f_loss=0.17956291139125824 r_loss=0.7420394420623779 GP=0.21179316937923431)
[Training] epoch:327 step:300 g_loss:0.8202155828475952 d_loss:1.6681386679410934 (f_loss=0.2481236308813095 r_loss=0.6955008506774902 GP=0.7245141863822937)
[Training] epoch:328 step:0 g_loss:0.7388277649879456 d_loss:1.2305156886577606 (f_loss=0.19860777258872986 r_loss=0.626450777053833 GP=0.40545713901519775)
[Training] epoch:328 step:100 g_loss:0.7409389019012451 d_loss:1.0412534847855568 (f_loss=0.22154501080513 r_loss=0.7236722111701965 GP=0.09603626281023026)
[Training] epoch:328 step:200 g_loss:0.8222688436508179 d_loss:1.1226004660129547 (f_loss=0.22193631529808044 r_loss=0.718532919883728 GP=0.18213123083114624)
[Training] epoch:328 step:300 g_loss:0.7937374114990234 d_loss:1.3297084867954254 (f_loss=0.24761754274368286 r_loss=0.7771556377410889 GP=0.3049353063106537)
[Training] epoch:329 step:0 g_loss:0.7681319117546082 d_loss:1.2431021928787231 (f_loss=0.15262705087661743 r_loss=0.7732422351837158 GP=0.3172329068183899)
[Training] epoch:329 step:100 g_loss:0.7437698245048523 d_loss:1.3527542352676392 (f_loss=0.25067996978759766 r_loss=0.6963741779327393 GP=0.40570008754730225)
[Training] epoch:329 step:200 g_loss:0.7594486474990845 d_loss:1.3273509442806244 (f_loss=0.169545978307724 r_loss=0.6736795902252197 GP=0.48412537574768066)
[Training] epoch:329 step:300 g_loss:0.8545346260070801 d_loss:1.0029564052820206 (f_loss=0.18162302672863007 r_loss=0.5906676650047302 GP=0.23066571354866028)
[Training] epoch:330 step:0 g_loss:0.7859883904457092 d_loss:2.328438565135002 (f_loss=0.15024058520793915 r_loss=0.3732203245162964 GP=1.8049776554107666)

[Training] epoch:330 step:100 g_loss:0.8082548379898071 d_loss:1.2845510244369507 (f_loss=0.261119544506073 r_loss=0.6939132213592529 GP=0.32951825857162476)
[Training] epoch:330 step:200 g_loss:0.7604952454566956 d_loss:1.0777132213115692 (f_loss=0.2103833258152008 r_loss=0.730691134929657 GP=0.13663876056671143)
[Training] epoch:330 step:300 g_loss:0.8129902482032776 d_loss:1.1535675823688507 (f_loss=0.22057916224002838 r_loss=0.7993144989013672 GP=0.13367392122745514)
[Training] epoch:331 step:0 g_loss:0.8168072700500488 d_loss:1.0166413187980652 (f_loss=0.19850075244903564 r_loss=0.6830326914787292 GP=0.1351078748703003)
[Training] epoch:331 step:100 g_loss:0.7983941435813904 d_loss:1.3163497149944305 (f_loss=0.1813349425792694 r_loss=0.7131222486495972 GP=0.42189252376556396)
[Training] epoch:331 step:200 g_loss:0.806357204914093 d_loss:1.1155402213335037 (f_loss=0.18320901691913605 r_loss=0.7075894474983215 GP=0.22474175691604614)
[Training] epoch:331 step:300 g_loss:0.7892995476722717 d_loss:1.0466853007674217 (f_loss=0.2098069041967392 r_loss=0.7324275970458984 GP=0.10445079952478409)
[Training] epoch:332 step:0 g_loss:0.8255149722099304 d_loss:1.3606356084346771 (f_loss=0.20625916123390198 r_loss=0.7528058290481567 GP=0.4015706181526184)
[Training] epoch:332 step:100 g_loss:0.7160685062408447 d_loss:1.2664814591407776 (f_loss=0.23765289783477783 r_loss=0.7122615575790405 GP=0.31656700372695923)
[Training] epoch:332 step:200 g_loss:0.7149927616119385 d_loss:1.2043809741735458 (f_loss=0.19169388711452484 r_loss=0.616424560546875 GP=0.396262526512146)
[Training] epoch:332 step:300 g_loss:0.7828342914581299 d_loss:1.3033522963523865 (f_loss=0.22579464316368103 r_loss=0.7803922891616821 GP=0.2971653640270233)
[Training] epoch:333 step:0 g_loss:0.8125385046005249 d_loss:1.07366943359375 (f_loss=0.18671965599060059 r_loss=0.742251992225647 GP=0.14469778537750244)
[Training] epoch:333 step:100 g_loss:0.7942368984222412 d_loss:1.1737628877162933 (f_loss=0.16298705339431763 r_loss=0.647169291973114 GP=0.3636065423488617)
[Training] epoch:333 step:200 g_loss:0.8119142651557922 d_loss:1.1004533767700195 (f_loss=0.22109851241111755 r_loss=0.6636819243431091 GP=0.21567294001579285)
[Training] epoch:333 step:300 g_loss:0.7630308866500854 d_loss:1.3128068447113037 (f_loss=0.23714736104011536 r_loss=0.714252233505249 GP=0.36140725016593933)
[Training] epoch:334 step:0 g_loss:0.7882497310638428 d_loss:1.017504796385765 (f_loss=0.19529442489147186 r_loss=0.7008609771728516 GP=0.12134939432144165)
[Training] epoch:334 step:100 g_loss:0.7987384796142578 d_loss:1.1028355956077576 (f_loss=0.21560874581336975 r_loss=0.6137081384658813 GP=0.27351871132850647)
[Training] epoch:334 step:200 g_loss:0.8180687427520752 d_loss:1.1305982321500778 (f_loss=0.21111902594566345 r_loss=0.7434410452842712 GP=0.17603816092014313)
[Training] epoch:334 step:300 g_loss:0.8077397346496582 d_loss:1.0993002504110336 (f_loss=0.14833486080169678 r_loss=0.7190202474594116 GP=0.23194514214992523)
[Training] epoch:335 step:0 g_loss:0.8124744892120361 d_loss:1.2066113352775574 (f_loss=0.1779138147830963 r_loss=0.7367516160011292 GP=0.2919459044933319)
[Training] epoch:335 step:100 g_loss:0.8213695287704468 d_loss:1.196542426943779 (f_loss=0.1950179785490036 r_loss=0.7262085676193237 GP=0.27531588077545166)
[Training] epoch:335 step:200 g_loss:0.791602373123169 d_loss:1.1343727111816406 (f_loss=0.22558218240737915 r_loss=0.7650318145751953 GP=0.14375871419906616)
[Training] epoch:335 step:300 g_loss:0.817974328994751 d_loss:1.0636955872178078 (f_loss=0.2237551510334015 r_loss=0.7633094191551208 GP=0.07663101702928543)
[Training] epoch:336 step:0 g_loss:0.7937137484550476 d_loss:1.3491805791854858 (f_loss=0.1920672059059143 r_loss=0.6765589118003845 GP=0.480554461479187)
[Training] epoch:336 step:100 g_loss:0.8241335153579712 d_loss:1.0164602063596249 (f_loss=0.2447044551372528 r_loss=0.7147674560546875 GP=0.056988295167684555)
[Training] epoch:336 step:200 g_loss:0.7886092662811279 d_loss:1.0941713750362396 (f_loss=0.19299465417861938 r_loss=0.7131630778312683 GP=0.18801364302635193)
[Training] epoch:336 step:300 g_loss:0.7665237188339233 d_loss:1.1393040269613266 (f_loss=0.20421536266803741 r_loss=0.7530378103256226 GP=0.18205085396766663)
[Training] epoch:337 step:0 g_loss:0.8103537559509277 d_loss:1.0716232508420944 (f_loss=0.20892895758152008 r_loss=0.7264025211334229 GP=0.1362917721271515)
[Training] epoch:337 step:100 g_loss:0.8206644058227539 d_loss:0.9889829456806183 (f_loss=0.1711527705192566 r_loss=0.7337824702262878 GP=0.08404770493507385)
[Training] epoch:337 step:200 g_loss:0.7850085496902466 d_loss:1.1548318564891815 (f_loss=0.21346449851989746 r_loss=0.7043749094009399 GP=0.23699244856834412)
[Training] epoch:337 step:300 g_loss:0.7824119329452515 d_loss:1.1787154972553253 (f_loss=0.24734342098236084 r_loss=0.7762994766235352 GP=0.15507259964942932)
[Training] epoch:338 step:0 g_loss:0.7852377891540527 d_loss:1.7806143760681152 (f_loss=0.137387216091156 r_loss=0.5362891554832458 GP=1.1069380044937134)
[Training] epoch:338 step:100 g_loss:0.7742576599121094 d_loss:1.0845148414373398 (f_loss=0.19768354296684265 r_loss=0.7495707273483276 GP=0.1372605711221695)
[Training] epoch:338 step:200 g_loss:0.8043786883354187 d_loss:1.4071607291698456 (f_loss=0.19311854243278503 r_loss=0.6615423560142517 GP=0.5524998307228088)
[Training] epoch:338 step:300 g_loss:0.8119301795959473 d_loss:1.1606154888868332 (f_loss=0.20646028220653534 r_loss=0.7360498905181885 GP=0.21810531616210938)
[Training] epoch:339 step:0 g_loss:0.7909483909606934 d_loss:1.0807608887553215 (f_loss=0.2116633653640747 r_loss=0.7649188041687012 GP=0.10417871922254562)
[Training] epoch:339 step:100 g_loss:0.8314393758773804 d_loss:1.1664607301354408 (f_loss=0.2392003983259201 r_loss=0.8048223257064819 GP=0.12243800610303879)
[Training] epoch:339 step:200 g_loss:0.8049727082252502 d_loss:1.0279076397418976 (f_loss=0.2041979283094406 r_loss=0.712181568145752 GP=0.11152814328670502)
[Training] epoch:339 step:300 g_loss:0.7658482193946838 d_loss:1.292679250240326 (f_loss=0.22552341222763062 r_loss=0.6392198801040649 GP=0.42793595790863037)
[Training] epoch:340 step:0 g_loss:0.8023920059204102 d_loss:0.9973837733268738 (f_loss=0.1881018877029419 r_loss=0.7186142802238464 GP=0.09066760540008545)

[Training] epoch:340 step:100 g_loss:0.8312640190124512 d_loss:1.073324665427208 (f_loss=0.1920919567346573 r_loss=0.7298166751861572 GP=0.15141603350639343)
[Training] epoch:340 step:200 g_loss:0.866127073764801 d_loss:1.0380240455269814 (f_loss=0.20169539749622345 r_loss=0.7531933188438416 GP=0.08313532918691635)
[Training] epoch:340 step:300 g_loss:0.758758544921875 d_loss:1.235578253865242 (f_loss=0.2151767462491989 r_loss=0.7706388235092163 GP=0.24976268410682678)
[Training] epoch:341 step:0 g_loss:0.7747515439987183 d_loss:1.3053770512342453 (f_loss=0.20972611010074615 r_loss=0.6156715750694275 GP=0.47997936606407166)
[Training] epoch:341 step:100 g_loss:0.8341732025146484 d_loss:1.0964105725288391 (f_loss=0.13602936267852783 r_loss=0.696577250957489 GP=0.26380395889282227)
[Training] epoch:341 step:200 g_loss:0.8126463890075684 d_loss:1.2256155014038086 (f_loss=0.21470367908477783 r_loss=0.7267846465110779 GP=0.2841271758079529)
[Training] epoch:341 step:300 g_loss:0.821245551109314 d_loss:1.420295849442482 (f_loss=0.18870456516742706 r_loss=0.706003725528717 GP=0.5255875587463379)
[Training] epoch:342 step:0 g_loss:0.8313145041465759 d_loss:1.0950427651405334 (f_loss=0.24370861053466797 r_loss=0.7262003421783447 GP=0.12513381242752075)
[Training] epoch:342 step:100 g_loss:0.8621137142181396 d_loss:1.8611137121915817 (f_loss=0.22676078975200653 r_loss=0.576647162437439 GP=1.0577057600021362)
[Training] epoch:342 step:200 g_loss:0.8381537795066833 d_loss:1.2997583746910095 (f_loss=0.1652427613735199 r_loss=0.6919000148773193 GP=0.4426155984401703)
[Training] epoch:342 step:300 g_loss:0.870064377784729 d_loss:1.4994858503341675 (f_loss=0.15063059329986572 r_loss=0.7351264953613281 GP=0.6137287616729736)
[Training] epoch:343 step:0 g_loss:0.7603745460510254 d_loss:1.395432472229004 (f_loss=0.21866941452026367 r_loss=0.696393609046936 GP=0.4803694486618042)
[Training] epoch:343 step:100 g_loss:0.7958904504776001 d_loss:1.1815120875835419 (f_loss=0.21285274624824524 r_loss=0.6971806287765503 GP=0.27147871255874634)
[Training] epoch:343 step:200 g_loss:0.8032405376434326 d_loss:0.9559661895036697 (f_loss=0.14601796865463257 r_loss=0.7348971366882324 GP=0.07505108416080475)
[Training] epoch:343 step:300 g_loss:0.7840369343757629 d_loss:1.5084089636802673 (f_loss=0.19608831405639648 r_loss=0.678604006767273 GP=0.6337166428565979)
[Training] epoch:344 step:0 g_loss:0.7848398685455322 d_loss:1.006780669093132 (f_loss=0.1766737699508667 r_loss=0.6733046770095825 GP=0.1568022221326828)
[Training] epoch:344 step:100 g_loss:0.8140155076980591 d_loss:1.1227407455444336 (f_loss=0.1736503690481186 r_loss=0.7234533429145813 GP=0.2256370335817337)
[Training] epoch:344 step:200 g_loss:0.8397310376167297 d_loss:1.0985455363988876 (f_loss=0.2269149273633957 r_loss=0.7165262699127197 GP=0.15510433912277222)
[Training] epoch:344 step:300 g_loss:0.7686095833778381 d_loss:1.064857542514801 (f_loss=0.14371299743652344 r_loss=0.6943040490150452 GP=0.22684049606323242)
[Training] epoch:345 step:0 g_loss:0.8423780202865601 d_loss:1.216623529791832 (f_loss=0.17421235144138336 r_loss=0.8119032382965088 GP=0.23050794005393982)
[Training] epoch:345 step:100 g_loss:0.7567731738090515 d_loss:1.273210495710373 (f_loss=0.19595882296562195 r_loss=0.7408654689788818 GP=0.33638620376586914)
[Training] epoch:345 step:200 g_loss:0.8258861303329468 d_loss:1.02295783162117 (f_loss=0.1314086616039276 r_loss=0.777367115020752 GP=0.11418205499649048)
[Training] epoch:345 step:300 g_loss:0.8110198974609375 d_loss:1.3480447232723236 (f_loss=0.20347395539283752 r_loss=0.6566787958145142 GP=0.4878919720649719)
[Training] epoch:346 step:0 g_loss:0.8070611357688904 d_loss:1.1249069720506668 (f_loss=0.19841139018535614 r_loss=0.761466920375824 GP=0.1650286614894867)
[Training] epoch:346 step:100 g_loss:0.8556884527206421 d_loss:1.8773453831672668 (f_loss=0.14456766843795776 r_loss=0.4759547710418701 GP=1.256822943687439)
[Training] epoch:346 step:200 g_loss:0.7768298387527466 d_loss:1.2627753168344498 (f_loss=0.14246462285518646 r_loss=0.7361894845962524 GP=0.38412120938301086)
[Training] epoch:346 step:300 g_loss:0.8516316413879395 d_loss:1.3673595488071442 (f_loss=0.15700307488441467 r_loss=0.7316159009933472 GP=0.4787405729293823)
[Training] epoch:347 step:0 g_loss:0.8217279314994812 d_loss:1.1061666905879974 (f_loss=0.19508296251296997 r_loss=0.7737350463867188 GP=0.13734868168830872)
[Training] epoch:347 step:100 g_loss:0.8222407102584839 d_loss:1.2753443121910095 (f_loss=0.2071307897567749 r_loss=0.6852205991744995 GP=0.3829929232597351)
[Training] epoch:347 step:200 g_loss:0.8211020231246948 d_loss:1.157000869512558 (f_loss=0.1989326775074005 r_loss=0.7668785452842712 GP=0.19118964672088623)
[Training] epoch:347 step:300 g_loss:0.8456437587738037 d_loss:1.4897005409002304 (f_loss=0.14059095084667206 r_loss=0.6998432874679565 GP=0.6492663025856018)
[Training] epoch:348 step:0 g_loss:0.8217406272888184 d_loss:1.4927639216184616 (f_loss=0.14479254186153412 r_loss=0.6316156387329102 GP=0.7163557410240173)
[Training] epoch:348 step:100 g_loss:0.889210045337677 d_loss:1.5962684154510498 (f_loss=0.17250603437423706 r_loss=0.6896005272865295 GP=0.7341618537902832)
[Training] epoch:348 step:200 g_loss:0.8338571786880493 d_loss:1.2383899241685867 (f_loss=0.1884334534406662 r_loss=0.7266021370887756 GP=0.3233543336391449)
[Training] epoch:348 step:300 g_loss:0.8072127103805542 d_loss:1.286757841706276 (f_loss=0.18360550701618195 r_loss=0.7340312600135803 GP=0.36912107467651367)
[Training] epoch:349 step:0 g_loss:0.823078453540802 d_loss:1.23607936501503 (f_loss=0.20259162783622742 r_loss=0.7452998161315918 GP=0.2881879210472107)
[Training] epoch:349 step:100 g_loss:0.796927273273468 d_loss:1.0192985460162163 (f_loss=0.17148086428642273 r_loss=0.7375179529190063 GP=0.1102997288107872)
[Training] epoch:349 step:200 g_loss:0.7849159240722656 d_loss:1.427673026919365 (f_loss=0.2203296273946762 r_loss=0.7357621192932129 GP=0.47158128023147583)
[Training] epoch:349 step:300 g_loss:0.8427047729492188 d_loss:1.1829468607902527 (f_loss=0.16573452949523926 r_loss=0.750126838684082 GP=0.2670854926109314)
[Training] epoch:350 step:0 g_loss:0.8369123935699463 d_loss:1.3651052117347717 (f_loss=0.1967984139919281 r_loss=0.7034027576446533 GP=0.4649040400981903)

[Training] epoch:350 step:100 g_loss:0.8126217126846313 d_loss:1.2331089675426483 (f_loss=0.23813268542289734 r_loss=0.6550915837287903 GP=0.3398846983909607)
[Training] epoch:350 step:200 g_loss:0.8699831366539001 d_loss:1.2262341678142548 (f_loss=0.17317655682563782 r_loss=0.7168632745742798 GP=0.33619433641433716)
[Training] epoch:350 step:300 g_loss:0.7955695390701294 d_loss:1.2733972817659378 (f_loss=0.16544412076473236 r_loss=0.7263315916061401 GP=0.3816215693950653)
[Training] epoch:351 step:0 g_loss:0.8170071244239807 d_loss:1.0996779948472977 (f_loss=0.1746901422739029 r_loss=0.7574235796928406 GP=0.1675642728805542)
[Training] epoch:351 step:100 g_loss:0.809906005859375 d_loss:1.1922184526920319 (f_loss=0.16286450624465942 r_loss=0.6114343404769897 GP=0.4179196059703827)
[Training] epoch:351 step:200 g_loss:0.850788950920105 d_loss:1.1869689226150513 (f_loss=0.17451317608356476 r_loss=0.7853609323501587 GP=0.22709481418132782)
[Training] epoch:351 step:300 g_loss:0.8231515288352966 d_loss:1.346471756696701 (f_loss=0.1311732828617096 r_loss=0.6571902632713318 GP=0.5581082105636597)
[Training] epoch:352 step:0 g_loss:0.8573447465896606 d_loss:1.0281588658690453 (f_loss=0.20969969034194946 r_loss=0.7036596536636353 GP=0.11479952186346054)
[Training] epoch:352 step:100 g_loss:0.8075584769248962 d_loss:1.2248003035783768 (f_loss=0.1399259716272354 r_loss=0.6992401480674744 GP=0.385634183883667)
[Training] epoch:352 step:200 g_loss:0.7854705452919006 d_loss:1.1559683233499527 (f_loss=0.13077570497989655 r_loss=0.6264206171035767 GP=0.3987720012664795)
[Training] epoch:352 step:300 g_loss:0.8338407874107361 d_loss:1.7783839851617813 (f_loss=0.24098695814609528 r_loss=0.6120592951774597 GP=0.9253377318382263)
[Training] epoch:353 step:0 g_loss:0.7934948205947876 d_loss:1.4630813598632812 (f_loss=0.16781091690063477 r_loss=0.5726067423820496 GP=0.7226637005805969)
[Training] epoch:353 step:100 g_loss:0.8284984230995178 d_loss:1.3130776584148407 (f_loss=0.14567336440086365 r_loss=0.6674032807350159 GP=0.5000010132789612)
[Training] epoch:353 step:200 g_loss:0.7997310757637024 d_loss:1.8656232953071594 (f_loss=0.14774805307388306 r_loss=0.7192507982254028 GP=0.9986244440078735)
[Training] epoch:353 step:300 g_loss:0.8029245734214783 d_loss:1.1454353779554367 (f_loss=0.21716974675655365 r_loss=0.7254976630210876 GP=0.2027679681777954)
[Training] epoch:354 step:0 g_loss:0.8322385549545288 d_loss:1.573560118675232 (f_loss=0.17529219388961792 r_loss=0.6414754986763 GP=0.756792426109314)
[Training] epoch:354 step:100 g_loss:0.84824538230896 d_loss:1.1893577128648758 (f_loss=0.16732122004032135 r_loss=0.7145578265190125 GP=0.307478666305542)
[Training] epoch:354 step:200 g_loss:0.8135986328125 d_loss:1.1942082345485687 (f_loss=0.15793153643608093 r_loss=0.6702237725257874 GP=0.36605292558670044)
[Training] epoch:354 step:300 g_loss:0.810706615447998 d_loss:2.207762449979782 (f_loss=0.14234277606010437 r_loss=0.7778192758560181 GP=1.2876003980636597)
[Training] epoch:355 step:0 g_loss:0.714291512966156 d_loss:1.1291213035583496 (f_loss=0.1918908655643463 r_loss=0.7843842506408691 GP=0.15284618735313416)
[Training] epoch:355 step:100 g_loss:0.8250748515129089 d_loss:1.07310950756073 (f_loss=0.09603306651115417 r_loss=0.6878052949905396 GP=0.28927114605903625)
[Training] epoch:355 step:200 g_loss:0.8095195889472961 d_loss:1.0699816644191742 (f_loss=0.11349508166313171 r_loss=0.7033983469009399 GP=0.25308823585510254)
[Training] epoch:355 step:300 g_loss:0.8188292384147644 d_loss:0.9754028543829918 (f_loss=0.1063094213604927 r_loss=0.7159432172775269 GP=0.15315021574497223)
[Training] epoch:356 step:0 g_loss:0.8676118850708008 d_loss:1.2190728783607483 (f_loss=0.14874160289764404 r_loss=0.7607812285423279 GP=0.30955004692077637)
[Training] epoch:356 step:100 g_loss:0.8663883209228516 d_loss:0.9470081180334091 (f_loss=0.09103532135486603 r_loss=0.719492495059967 GP=0.13648030161857605)
[Training] epoch:356 step:200 g_loss:0.8277988433837891 d_loss:1.2008857876062393 (f_loss=0.18881390988826752 r_loss=0.7342731356620789 GP=0.27779874205589294)
[Training] epoch:356 step:300 g_loss:0.8364864587783813 d_loss:1.4864074438810349 (f_loss=0.13452456891536713 r_loss=0.7437267899513245 GP=0.6081560850143433)
[Training] epoch:357 step:0 g_loss:0.7724012136459351 d_loss:2.0279102325439453 (f_loss=0.17669081687927246 r_loss=0.6773031949996948 GP=1.173916220664978)
[Training] epoch:357 step:100 g_loss:0.7972912192344666 d_loss:1.0691095739603043 (f_loss=0.18698790669441223 r_loss=0.7919195890426636 GP=0.09020207822322845)
[Training] epoch:357 step:200 g_loss:0.8269216418266296 d_loss:1.384226679801941 (f_loss=0.1747499704360962 r_loss=0.6945629715919495 GP=0.5149137377738953)
[Training] epoch:357 step:300 g_loss:0.8517945408821106 d_loss:1.316781610250473 (f_loss=0.1822112500667572 r_loss=0.695730447769165 GP=0.4388399124145508)
[Training] epoch:358 step:0 g_loss:0.8420975804328918 d_loss:1.1832423210144043 (f_loss=0.21193867921829224 r_loss=0.6762835383415222 GP=0.29502010345458984)
[Training] epoch:358 step:100 g_loss:0.8531430959701538 d_loss:1.5238273739814758 (f_loss=0.1669355034828186 r_loss=0.6178694367408752 GP=0.739022433757782)
[Training] epoch:358 step:200 g_loss:0.8743615746498108 d_loss:0.9433985352516174 (f_loss=0.11500707268714905 r_loss=0.7163007855415344 GP=0.11209067702293396)
[Training] epoch:358 step:300 g_loss:0.8394008874893188 d_loss:1.5749506205320358 (f_loss=0.21516232192516327 r_loss=0.6927700042724609 GP=0.6670182943344116)
[Training] epoch:359 step:0 g_loss:0.8446624279022217 d_loss:1.6740205138921738 (f_loss=0.19041089713573456 r_loss=0.6685799360275269 GP=0.8150296807289124)
[Training] epoch:359 step:100 g_loss:0.8287997841835022 d_loss:1.0000045895576477 (f_loss=0.1391269564628601 r_loss=0.6780653595924377 GP=0.18281227350234985)
[Training] epoch:359 step:200 g_loss:0.7842363715171814 d_loss:1.1383716613054276 (f_loss=0.20922492444515228 r_loss=0.8373181223869324 GP=0.0918286144733429)
[Training] epoch:359 step:300 g_loss:0.8409480452537537 d_loss:1.2001611143350601 (f_loss=0.12507455050945282 r_loss=0.7635549902915955 GP=0.31153157353401184)
[Training] epoch:360 step:0 g_loss:0.8297150135040283 d_loss:1.1235343515872955 (f_loss=0.17534753680229187 r_loss=0.7363570928573608 GP=0.21182972192764282)

[Training] epoch:360 step:100 g_loss:0.8499313592910767 d_loss:1.2873613089323044 (f_loss=0.19427667558193207 r_loss=0.6722404360771179 GP=0.4208441972732544)
[Training] epoch:360 step:200 g_loss:0.8224895000457764 d_loss:1.1119087785482407 (f_loss=0.16755324602127075 r_loss=0.7321240305900574 GP=0.21223150193691254)
[Training] epoch:360 step:300 g_loss:0.8631287217140198 d_loss:1.3218005895614624 (f_loss=0.17833560705184937 r_loss=0.6895524859428406 GP=0.45391249656677246)
[Training] epoch:361 step:0 g_loss:0.8559991121292114 d_loss:1.2279302775859833 (f_loss=0.21028566360473633 r_loss=0.673579216003418 GP=0.344065397977829)
[Training] epoch:361 step:100 g_loss:0.80413818359375 d_loss:1.1870247721672058 (f_loss=0.17444467544555664 r_loss=0.7160837650299072 GP=0.29649633169174194)
[Training] epoch:361 step:200 g_loss:0.8215850591659546 d_loss:1.56772843003273 (f_loss=0.14332982897758484 r_loss=0.6558488607406616 GP=0.7685497403144836)
[Training] epoch:361 step:300 g_loss:0.8538699150085449 d_loss:1.220207929611206 (f_loss=0.16837555170059204 r_loss=0.7745233774185181 GP=0.27730900049209595)
[Training] epoch:362 step:0 g_loss:0.8205941915512085 d_loss:1.1421914547681808 (f_loss=0.1944035440683365 r_loss=0.7344461679458618 GP=0.21334174275398254)
[Training] epoch:362 step:100 g_loss:0.8449146151542664 d_loss:1.1301727443933487 (f_loss=0.17459741234779358 r_loss=0.7191262245178223 GP=0.23644910752773285)
[Training] epoch:362 step:200 g_loss:0.8413596749305725 d_loss:1.147930532693863 (f_loss=0.1660403311252594 r_loss=0.7296907901763916 GP=0.2521994113922119)
[Training] epoch:362 step:300 g_loss:0.8571422100067139 d_loss:1.2369756549596786 (f_loss=0.18749023973941803 r_loss=0.7562904357910156 GP=0.293194979429245)
[Training] epoch:363 step:0 g_loss:0.773662805557251 d_loss:1.5441433042287827 (f_loss=0.10020260512828827 r_loss=0.7227906584739685 GP=0.7211500406265259)
[Training] epoch:363 step:100 g_loss:0.8706986904144287 d_loss:1.5001247823238373 (f_loss=0.15170595049858093 r_loss=0.7199153900146484 GP=0.6285034418106079)
[Training] epoch:363 step:200 g_loss:0.7900252342224121 d_loss:1.4307215511798859 (f_loss=0.15943047404289246 r_loss=0.7690631747245789 GP=0.5022279024124146)
[Training] epoch:363 step:300 g_loss:0.8493988513946533 d_loss:1.6082759499549866 (f_loss=0.2067810297012329 r_loss=0.7938814163208008 GP=0.6076135039329529)
[Training] epoch:364 step:0 g_loss:0.8141129612922668 d_loss:1.5856399089097977 (f_loss=0.21595831215381622 r_loss=0.7533214092254639 GP=0.6163601875305176)
[Training] epoch:364 step:100 g_loss:0.8419986367225647 d_loss:1.037473052740097 (f_loss=0.17514900863170624 r_loss=0.6717858910560608 GP=0.19053815305233002)
[Training] epoch:364 step:200 g_loss:0.8674123883247375 d_loss:1.0951400846242905 (f_loss=0.14333604276180267 r_loss=0.7511188387870789 GP=0.20068520307540894)
[Training] epoch:364 step:300 g_loss:0.8982418775558472 d_loss:1.1485003232955933 (f_loss=0.1650279015302658 r_loss=0.7561668157577515 GP=0.227305606007576)
[Training] epoch:365 step:0 g_loss:0.8608874082565308 d_loss:1.7187966406345367 (f_loss=0.13955673575401306 r_loss=0.6661825180053711 GP=0.9130573868751526)
[Training] epoch:365 step:100 g_loss:0.8388278484344482 d_loss:1.094887062907219 (f_loss=0.1559602916240692 r_loss=0.7607982158660889 GP=0.17812855541706085)
[Training] epoch:365 step:200 g_loss:0.884253203868866 d_loss:1.320761039853096 (f_loss=0.16574157774448395 r_loss=0.6772348880767822 GP=0.47778457403182983)
[Training] epoch:365 step:300 g_loss:0.7914029955863953 d_loss:1.2300342321395874 (f_loss=0.12916427850723267 r_loss=0.6602068543434143 GP=0.44066309928894043)
[Training] epoch:366 step:0 g_loss:0.8529744744300842 d_loss:1.0607835799455643 (f_loss=0.11805813014507294 r_loss=0.781566858291626 GP=0.16115859150886536)
[Training] epoch:366 step:100 g_loss:0.8419123291969299 d_loss:1.8873581439256668 (f_loss=0.17599578201770782 r_loss=0.7628501653671265 GP=0.9485121965408325)
[Training] epoch:366 step:200 g_loss:0.8350345492362976 d_loss:1.2739537060260773 (f_loss=0.10679540038108826 r_loss=0.733701229095459 GP=0.43345707654953003)
[Training] epoch:366 step:300 g_loss:0.8690899014472961 d_loss:1.3732140809297562 (f_loss=0.20390821993350983 r_loss=0.702131986618042 GP=0.46717387437820435)
[Training] epoch:367 step:0 g_loss:0.8860814571380615 d_loss:1.3186360001564026 (f_loss=0.1839238405227661 r_loss=0.7425720691680908 GP=0.39214009046554565)
[Training] epoch:367 step:100 g_loss:0.863311231136322 d_loss:1.1597775220870972 (f_loss=0.15717455744743347 r_loss=0.7416567206382751 GP=0.26094624400138855)
[Training] epoch:367 step:200 g_loss:0.8315861821174622 d_loss:1.123931109905243 (f_loss=0.1467202603816986 r_loss=0.8281186819076538 GP=0.1490921676158905)
[Training] epoch:367 step:300 g_loss:0.8905089497566223 d_loss:1.2621600478887558 (f_loss=0.15968237817287445 r_loss=0.7951094508171082 GP=0.3073682188987732)
[Training] epoch:368 step:0 g_loss:0.8954730033874512 d_loss:1.35579015314579 (f_loss=0.15655584633350372 r_loss=0.6282644867897034 GP=0.570969820022583)
[Training] epoch:368 step:100 g_loss:0.878250002861023 d_loss:1.0835416316986084 (f_loss=0.1316540241241455 r_loss=0.7045037746429443 GP=0.24738383293151855)
[Training] epoch:368 step:200 g_loss:0.801424503326416 d_loss:1.128393366932869 (f_loss=0.21066483855247498 r_loss=0.7880744934082031 GP=0.12965403497219086)
[Training] epoch:368 step:300 g_loss:0.8428741097450256 d_loss:1.412891298532486 (f_loss=0.16678819060325623 r_loss=0.6985738277435303 GP=0.5475292801856995)
[Training] epoch:369 step:0 g_loss:0.8682299852371216 d_loss:1.2965101450681686 (f_loss=0.13711191713809967 r_loss=0.8134621381759644 GP=0.3459360897541046)
[Training] epoch:369 step:100 g_loss:0.8631451725959778 d_loss:1.192954033613205 (f_loss=0.1670984923839569 r_loss=0.7672300338745117 GP=0.25862550735473633)
[Training] epoch:369 step:200 g_loss:0.8370336890220642 d_loss:1.5619413927197456 (f_loss=0.12461114674806595 r_loss=0.6389570236206055 GP=0.7983732223510742)
[Training] epoch:369 step:300 g_loss:0.8767536878585815 d_loss:1.7086200416088104 (f_loss=0.174966961145401 r_loss=0.7931200861930847 GP=0.7405329942703247)
[Training] epoch:370 step:0 g_loss:0.8806719183921814 d_loss:1.2729769796133041 (f_loss=0.1848573535680771 r_loss=0.7177620530128479 GP=0.37035757303237915)

[Training] epoch:370 step:100 g_loss:0.8107625246047974 d_loss:1.2164628356695175 (f_loss=0.1360197812318802 r_loss=0.790217936038971 GP=0.2902251183986664)
[Training] epoch:370 step:200 g_loss:0.8342974185943604 d_loss:1.309615969657898 (f_loss=0.16145944595336914 r_loss=0.7507635951042175 GP=0.3973929286003113)
[Training] epoch:370 step:300 g_loss:0.8473576903343201 d_loss:1.1293704807758331 (f_loss=0.14346380531787872 r_loss=0.7995736002922058 GP=0.1863330751657486)
[Training] epoch:371 step:0 g_loss:0.8204933404922485 d_loss:0.9809582680463791 (f_loss=0.12260060012340546 r_loss=0.6525954008102417 GP=0.20576226711273193)
[Training] epoch:371 step:100 g_loss:0.8605209589004517 d_loss:1.2164743542671204 (f_loss=0.16523608565330505 r_loss=0.7660509943962097 GP=0.2851872742176056)
[Training] epoch:371 step:200 g_loss:0.8395410776138306 d_loss:1.4217245876789093 (f_loss=0.17484602332115173 r_loss=0.7070217132568359 GP=0.5398568511009216)
[Training] epoch:371 step:300 g_loss:0.9179895520210266 d_loss:1.1830590963363647 (f_loss=0.16384053230285645 r_loss=0.7521217465400696 GP=0.2670968174934387)
[Training] epoch:372 step:0 g_loss:0.8969082236289978 d_loss:1.1317416429519653 (f_loss=0.1745087206363678 r_loss=0.7518179416656494 GP=0.20541498064994812)
[Training] epoch:372 step:100 g_loss:0.8397325873374939 d_loss:1.3529223501682281 (f_loss=0.08600226044654846 r_loss=0.8295906782150269 GP=0.43732941150665283)
[Training] epoch:372 step:200 g_loss:0.786536693572998 d_loss:1.1007667630910873 (f_loss=0.1634802222251892 r_loss=0.7221585512161255 GP=0.21512798964977264)
[Training] epoch:372 step:300 g_loss:0.8364508152008057 d_loss:1.4266287684440613 (f_loss=0.13701903820037842 r_loss=0.586759626865387 GP=0.7028501033782959)
[Training] epoch:373 step:0 g_loss:0.8133821487426758 d_loss:1.0386801213026047 (f_loss=0.1335231214761734 r_loss=0.6924011707305908 GP=0.21275582909584045)
[Training] epoch:373 step:100 g_loss:0.8407436609268188 d_loss:1.1429705321788788 (f_loss=0.1861388087272644 r_loss=0.7309797406196594 GP=0.22585198283195496)
[Training] epoch:373 step:200 g_loss:0.8733117580413818 d_loss:1.1767939329147339 (f_loss=0.14901918172836304 r_loss=0.7668284177780151 GP=0.2609463334083557)
[Training] epoch:373 step:300 g_loss:0.8359841704368591 d_loss:1.1588478684425354 (f_loss=0.16586947441101074 r_loss=0.6994386911392212 GP=0.29353970289230347)
[Training] epoch:374 step:0 g_loss:0.8634078502655029 d_loss:1.189180165529251 (f_loss=0.1517373025417328 r_loss=0.7440656423568726 GP=0.29337722063064575)
[Training] epoch:374 step:100 g_loss:0.8342974781990051 d_loss:1.637912854552269 (f_loss=0.16356180608272552 r_loss=0.6585651636123657 GP=0.8157858848571777)
[Training] epoch:374 step:200 g_loss:0.8632203936576843 d_loss:1.2323568165302277 (f_loss=0.13816338777542114 r_loss=0.8067491054534912 GP=0.2874443233013153)
[Training] epoch:374 step:300 g_loss:0.8585498929023743 d_loss:1.3257610499858856 (f_loss=0.16877779364585876 r_loss=0.7487748861312866 GP=0.40820837020874023)
[Training] epoch:375 step:0 g_loss:0.8569457530975342 d_loss:1.1069400683045387 (f_loss=0.11546387523412704 r_loss=0.7609676122665405 GP=0.23050858080387115)
[Training] epoch:375 step:100 g_loss:0.8366283774375916 d_loss:1.1036951914429665 (f_loss=0.10462091118097305 r_loss=0.7410717010498047 GP=0.2580025792121887)
[Training] epoch:375 step:200 g_loss:0.8657354712486267 d_loss:1.2189268693327904 (f_loss=0.11419948190450668 r_loss=0.7853960394859314 GP=0.3193313479423523)
[Training] epoch:375 step:300 g_loss:0.9008057117462158 d_loss:1.1590242683887482 (f_loss=0.20455728471279144 r_loss=0.7165064811706543 GP=0.23796050250530243)
[Training] epoch:376 step:0 g_loss:0.8655918836593628 d_loss:1.1254000663757324 (f_loss=0.17569154500961304 r_loss=0.7744909524917603 GP=0.17521756887435913)
[Training] epoch:376 step:100 g_loss:0.8554812073707581 d_loss:1.3977117389440536 (f_loss=0.2095097154378891 r_loss=0.8100456595420837 GP=0.3781563639640808)
[Training] epoch:376 step:200 g_loss:0.8542627096176147 d_loss:1.7379081100225449 (f_loss=0.11440406739711761 r_loss=0.8984617590904236 GP=0.7250422835350037)
[Training] epoch:376 step:300 g_loss:0.8925950527191162 d_loss:1.5756603628396988 (f_loss=0.16761060059070587 r_loss=0.7009539008140564 GP=0.7070958614349365)
[Training] epoch:377 step:0 g_loss:0.77772057056427 d_loss:1.1444627195596695 (f_loss=0.13641731441020966 r_loss=0.7686774730682373 GP=0.23936793208122253)
[Training] epoch:377 step:100 g_loss:0.8007912635803223 d_loss:1.1651263386011124 (f_loss=0.12358157336711884 r_loss=0.6230148077011108 GP=0.4185299575328827)
[Training] epoch:377 step:200 g_loss:0.7965530753135681 d_loss:1.0746779218316078 (f_loss=0.12149069458246231 r_loss=0.8172938823699951 GP=0.1358933448791504)
[Training] epoch:377 step:300 g_loss:0.8521100282669067 d_loss:1.100836232304573 (f_loss=0.11747127771377563 r_loss=0.7520837187767029 GP=0.23128123581409454)
[Training] epoch:378 step:0 g_loss:0.8646109104156494 d_loss:1.235947072505951 (f_loss=0.15634998679161072 r_loss=0.8038791418075562 GP=0.27571794390678406)
[Training] epoch:378 step:100 g_loss:0.86066073179245 d_loss:1.1195940524339676 (f_loss=0.09175001084804535 r_loss=0.7735729813575745 GP=0.2542710602283478)
[Training] epoch:378 step:200 g_loss:0.8632402420043945 d_loss:1.301008552312851 (f_loss=0.15700942277908325 r_loss=0.8196108341217041 GP=0.3243882954120636)
[Training] epoch:378 step:300 g_loss:0.9093183875083923 d_loss:1.1890479288995266 (f_loss=0.061327751725912094 r_loss=0.8179801106452942 GP=0.3097400665283203)
[Training] epoch:379 step:0 g_loss:0.8323755264282227 d_loss:1.4030902981758118 (f_loss=0.17484748363494873 r_loss=0.7923882603645325 GP=0.43585455417633057)
[Training] epoch:379 step:100 g_loss:0.8418266773223877 d_loss:1.4257436692714691 (f_loss=0.17796820402145386 r_loss=0.8272098898887634 GP=0.42056557536125183)
[Training] epoch:379 step:200 g_loss:0.8461637496948242 d_loss:1.3106296956539154 (f_loss=0.1769571602344513 r_loss=0.7608762383460999 GP=0.37279629707336426)
[Training] epoch:379 step:300 g_loss:0.881991982460022 d_loss:1.437627911567688 (f_loss=0.11928313970565796 r_loss=0.6705737113952637 GP=0.6477710604667664)
[Training] epoch:380 step:0 g_loss:0.8325377702713013 d_loss:1.3902954906225204 (f_loss=0.18288232386112213 r_loss=0.8240576982498169 GP=0.3833554685115814)

[Training] epoch:380 step:100 g_loss:0.8342049717903137 d_loss:1.1724279075860977 (f_loss=0.17393741011619568 r_loss=0.8423510789871216 GP=0.15613941848278046)
[Training] epoch:380 step:200 g_loss:0.9302896857261658 d_loss:1.2495212256908417 (f_loss=0.1584760546684265 r_loss=0.8404420018196106 GP=0.25060316920280457)
[Training] epoch:380 step:300 g_loss:0.833618700504303 d_loss:1.2366435378789902 (f_loss=0.14228983223438263 r_loss=0.7541009187698364 GP=0.3402527868747711)
[Training] epoch:381 step:0 g_loss:0.8326905965805054 d_loss:1.1637600511312485 (f_loss=0.12734095752239227 r_loss=0.7083057165145874 GP=0.3281133770942688)
[Training] epoch:381 step:100 g_loss:0.8741469383239746 d_loss:1.2321691066026688 (f_loss=0.14554812014102936 r_loss=0.8050545454025269 GP=0.28156644105911255)
[Training] epoch:381 step:200 g_loss:0.847733736038208 d_loss:1.2246170341968536 (f_loss=0.16105762124061584 r_loss=0.8224021196365356 GP=0.24115729331970215)
[Training] epoch:381 step:300 g_loss:0.8448379039764404 d_loss:1.6222032755613327 (f_loss=0.11896161735057831 r_loss=0.8207710981369019 GP=0.6824705600738525)
[Training] epoch:382 step:0 g_loss:0.9028904438018799 d_loss:1.0672086626291275 (f_loss=0.10970829427242279 r_loss=0.7495128512382507 GP=0.20798751711845398)
[Training] epoch:382 step:100 g_loss:0.88730388879776 d_loss:1.2874144315719604 (f_loss=0.10741370916366577 r_loss=0.744509756565094 GP=0.4354909658432007)
[Training] epoch:382 step:200 g_loss:0.9031268954277039 d_loss:1.1285866051912308 (f_loss=0.153758242726326 r_loss=0.7512166500091553 GP=0.2236117124557495)
[Training] epoch:382 step:300 g_loss:0.8508445620536804 d_loss:1.0705595090985298 (f_loss=0.07501370459794998 r_loss=0.6844573020935059 GP=0.311088502407074)
[Training] epoch:383 step:0 g_loss:0.8260305523872375 d_loss:1.3110780715942383 (f_loss=0.19548970460891724 r_loss=0.7247278094291687 GP=0.39086055755615234)
[Training] epoch:383 step:100 g_loss:0.8543703556060791 d_loss:1.3381585478782654 (f_loss=0.10650700330734253 r_loss=0.8124997615814209 GP=0.41915178298950195)
[Training] epoch:383 step:200 g_loss:0.8435409069061279 d_loss:1.3613553941249847 (f_loss=0.1385275423526764 r_loss=0.664676308631897 GP=0.5581515431404114)
[Training] epoch:383 step:300 g_loss:0.900593638420105 d_loss:1.5240815579891205 (f_loss=0.17343130707740784 r_loss=0.6814906001091003 GP=0.6691596508026123)
[Training] epoch:384 step:0 g_loss:0.8988522887229919 d_loss:1.2803418040275574 (f_loss=0.14037883281707764 r_loss=0.7603329420089722 GP=0.37963002920150757)
[Training] epoch:384 step:100 g_loss:0.8696016669273376 d_loss:1.3203487172722816 (f_loss=0.12362466007471085 r_loss=0.6648202538490295 GP=0.5319038033485413)
[Training] epoch:384 step:200 g_loss:0.8184934854507446 d_loss:1.1517627239227295 (f_loss=0.16099858283996582 r_loss=0.7491843700408936 GP=0.24157977104187012)
[Training] epoch:384 step:300 g_loss:0.8478017449378967 d_loss:1.1628167778253555 (f_loss=0.08315922319889069 r_loss=0.8019658327102661 GP=0.27769172191619873)
[Training] epoch:385 step:0 g_loss:0.8710803985595703 d_loss:1.2914660573005676 (f_loss=0.14040151238441467 r_loss=0.8157472610473633 GP=0.3353172838687897)
[Training] epoch:385 step:100 g_loss:0.9482757449150085 d_loss:1.1912772059440613 (f_loss=0.1394529938697815 r_loss=0.7651941776275635 GP=0.2866300344467163)
[Training] epoch:385 step:200 g_loss:0.9057955145835876 d_loss:1.0959004759788513 (f_loss=0.146420419216156 r_loss=0.7993017435073853 GP=0.15017831325531006)
[Training] epoch:385 step:300 g_loss:0.7824516296386719 d_loss:1.2017600983381271 (f_loss=0.12943924963474274 r_loss=0.7887559533119202 GP=0.28356489539146423)
[Training] epoch:386 step:0 g_loss:0.8464608788490295 d_loss:1.201636180281639 (f_loss=0.1300094574689865 r_loss=0.75731360912323 GP=0.3143131136894226)
[Training] epoch:386 step:100 g_loss:0.867719292640686 d_loss:1.1060101091861725 (f_loss=0.1620539277791977 r_loss=0.8377517461776733 GP=0.10620443522930145)
[Training] epoch:386 step:200 g_loss:0.9013034701347351 d_loss:1.208813615143299 (f_loss=0.10414958745241165 r_loss=0.8591984510421753 GP=0.24546557664871216)
[Training] epoch:386 step:300 g_loss:0.8708655834197998 d_loss:1.4145845174789429 (f_loss=0.1283910870552063 r_loss=0.7704516649246216 GP=0.515741765499115)
[Training] epoch:387 step:0 g_loss:0.9126948714256287 d_loss:1.0396056845784187 (f_loss=0.08056279271841049 r_loss=0.7619178295135498 GP=0.19712506234645844)
[Training] epoch:387 step:100 g_loss:0.8724459409713745 d_loss:1.1957407593727112 (f_loss=0.13158190250396729 r_loss=0.764976978302002 GP=0.29918187856674194)
[Training] epoch:387 step:200 g_loss:0.8593659400939941 d_loss:1.2004596292972565 (f_loss=0.14278939366340637 r_loss=0.7986336350440979 GP=0.2590366005897522)
[Training] epoch:387 step:300 g_loss:0.8670705556869507 d_loss:1.2226809561252594 (f_loss=0.15404777228832245 r_loss=0.8448729515075684 GP=0.2237602323293686)
[Training] epoch:388 step:0 g_loss:0.9049285054206848 d_loss:1.2711156457662582 (f_loss=0.183314710855484 r_loss=0.8601456880569458 GP=0.22765524685382843)
[Training] epoch:388 step:100 g_loss:0.8637707829475403 d_loss:1.1697691679000854 (f_loss=0.08228468894958496 r_loss=0.8174641132354736 GP=0.27002036571502686)
[Training] epoch:388 step:200 g_loss:0.9065271019935608 d_loss:1.0455735623836517 (f_loss=0.11829009652137756 r_loss=0.817130982875824 GP=0.1101524829864502)
[Training] epoch:388 step:300 g_loss:0.9201180934906006 d_loss:1.5375260412693024 (f_loss=0.10016003251075745 r_loss=0.8007866740226746 GP=0.6365793347358704)
[Training] epoch:389 step:0 g_loss:0.8688220381736755 d_loss:1.5493535101413727 (f_loss=0.15084943175315857 r_loss=0.6963074803352356 GP=0.7021965980529785)
[Training] epoch:389 step:100 g_loss:0.9103848338127136 d_loss:1.3394367843866348 (f_loss=0.19376052916049957 r_loss=0.8350733518600464 GP=0.31060290336608887)
[Training] epoch:389 step:200 g_loss:0.857637882232666 d_loss:1.0914163142442703 (f_loss=0.13753563165664673 r_loss=0.8091027736663818 GP=0.14477790892124176)
[Training] epoch:389 step:300 g_loss:0.8615731000900269 d_loss:1.249685525894165 (f_loss=0.13415426015853882 r_loss=0.7468574643135071 GP=0.36867380142211914)
[Training] epoch:390 step:0 g_loss:0.898321270942688 d_loss:1.4356686621904373 (f_loss=0.15464170277118683 r_loss=0.8087294697761536 GP=0.4722974896430969)

[Training] epoch:390 step:100 g_loss:0.9002209305763245 d_loss:1.3755747973918915 (f_loss=0.1591797173023224 r_loss=0.7788507342338562 GP=0.4375443458557129)
[Training] epoch:390 step:200 g_loss:0.9063418507575989 d_loss:1.3147407174110413 (f_loss=0.10663014650344849 r_loss=0.7956874370574951 GP=0.41242313385009766)
[Training] epoch:390 step:300 g_loss:0.9077773690223694 d_loss:1.2048700004816055 (f_loss=0.09788982570171356 r_loss=0.8508336544036865 GP=0.25614652037620544)
[Training] epoch:391 step:0 g_loss:0.9123804569244385 d_loss:1.4698441326618195 (f_loss=0.14510217308998108 r_loss=0.6840749382972717 GP=0.6406670212745667)
[Training] epoch:391 step:100 g_loss:0.8760741949081421 d_loss:1.9541743397712708 (f_loss=0.1527535319328308 r_loss=0.6833456754684448 GP=1.1180751323699951)
[Training] epoch:391 step:200 g_loss:0.8958380222320557 d_loss:1.5734751224517822 (f_loss=0.16199058294296265 r_loss=0.713776707649231 GP=0.6977078318595886)
[Training] epoch:391 step:300 g_loss:0.8755643367767334 d_loss:1.3297844529151917 (f_loss=0.14047467708587646 r_loss=0.7886109352111816 GP=0.40069884061813354)
[Training] epoch:392 step:0 g_loss:0.901669979095459 d_loss:1.2389250844717026 (f_loss=0.19617655873298645 r_loss=0.8479077816009521 GP=0.19484074413776398)
[Training] epoch:392 step:100 g_loss:0.8299083709716797 d_loss:1.309296689927578 (f_loss=0.12386196106672287 r_loss=0.8116312026977539 GP=0.3738035261631012)
[Training] epoch:392 step:200 g_loss:0.8398998379707336 d_loss:1.0386233180761337 (f_loss=0.1267038881778717 r_loss=0.794223427772522 GP=0.11769600212574005)
[Training] epoch:392 step:300 g_loss:0.9166941046714783 d_loss:1.248865157365799 (f_loss=0.1291564702987671 r_loss=0.8552929759025574 GP=0.2644157111644745)
[Training] epoch:393 step:0 g_loss:0.8875846266746521 d_loss:1.1300159692764282 (f_loss=0.1318596601486206 r_loss=0.730776846408844 GP=0.2673794627189636)
[Training] epoch:393 step:100 g_loss:0.8606783747673035 d_loss:1.253213256597519 (f_loss=0.1303216814994812 r_loss=0.8193315267562866 GP=0.3035600483417511)
[Training] epoch:393 step:200 g_loss:0.8609682321548462 d_loss:1.283148005604744 (f_loss=0.13030345737934113 r_loss=0.815399706363678 GP=0.33744484186172485)
[Training] epoch:393 step:300 g_loss:0.9365585446357727 d_loss:1.6325064450502396 (f_loss=0.1268121749162674 r_loss=0.7210496664047241 GP=0.784644603729248)
[Training] epoch:394 step:0 g_loss:0.8666660785675049 d_loss:1.3008989989757538 (f_loss=0.14504393935203552 r_loss=0.7515434622764587 GP=0.4043115973472595)
[Training] epoch:394 step:100 g_loss:0.8880587220191956 d_loss:1.130406178534031 (f_loss=0.10775033384561539 r_loss=0.8084227442741394 GP=0.21423310041427612)
[Training] epoch:394 step:200 g_loss:0.8878809213638306 d_loss:1.3261575102806091 (f_loss=0.14969655871391296 r_loss=0.8767255544662476 GP=0.2997353971004486)
[Training] epoch:394 step:300 g_loss:0.8938083648681641 d_loss:1.5078696310520172 (f_loss=0.10904106497764587 r_loss=0.7652879357337952 GP=0.6335406303405762)
[Training] epoch:395 step:0 g_loss:0.8670581579208374 d_loss:1.223429650068283 (f_loss=0.14922502636909485 r_loss=0.891991138458252 GP=0.18221348524093628)
[Training] epoch:395 step:100 g_loss:0.8955520391464233 d_loss:1.0293951481580734 (f_loss=0.09894998371601105 r_loss=0.78679358959198 GP=0.1436515748500824)
[Training] epoch:395 step:200 g_loss:0.9103862643241882 d_loss:1.40700563788414 (f_loss=0.14727649092674255 r_loss=0.7688426971435547 GP=0.4908864498138428)
[Training] epoch:395 step:300 g_loss:0.9660585522651672 d_loss:1.2701178640127182 (f_loss=0.06468747556209564 r_loss=0.7659047842025757 GP=0.4395256042480469)
[Training] epoch:396 step:0 g_loss:0.8838802576065063 d_loss:1.09842037409544 (f_loss=0.044131360948085785 r_loss=0.8721820712089539 GP=0.18210694193840027)
[Training] epoch:396 step:100 g_loss:0.9098190665245056 d_loss:1.3746944814920425 (f_loss=0.0933399349451065 r_loss=0.772887110710144 GP=0.508467435836792)
[Training] epoch:396 step:200 g_loss:0.9107894897460938 d_loss:1.1866984814405441 (f_loss=0.09218788146972656 r_loss=0.8802672028541565 GP=0.21424339711666107)
[Training] epoch:396 step:300 g_loss:0.9134041666984558 d_loss:1.680697076022625 (f_loss=0.059303395450115204 r_loss=0.6794586181640625 GP=0.9419350624084473)
[Training] epoch:397 step:0 g_loss:0.8930953145027161 d_loss:1.139991395175457 (f_loss=0.07336732000112534 r_loss=0.662783682346344 GP=0.40384039282798767)
[Training] epoch:397 step:100 g_loss:0.9209721088409424 d_loss:1.2356093674898148 (f_loss=0.10096542537212372 r_loss=0.8632379174232483 GP=0.27140602469444275)
[Training] epoch:397 step:200 g_loss:0.8865723609924316 d_loss:1.3843760788440704 (f_loss=0.13536229729652405 r_loss=0.814487636089325 GP=0.43452614545822144)
[Training] epoch:397 step:300 g_loss:0.8651272058486938 d_loss:1.3644378185272217 (f_loss=0.1423986256122589 r_loss=0.7930539846420288 GP=0.42898520827293396)
[Training] epoch:398 step:0 g_loss:0.8822685480117798 d_loss:1.3239895477890968 (f_loss=0.04471001774072647 r_loss=0.8354430794715881 GP=0.4438364505767822)
[Training] epoch:398 step:100 g_loss:0.9199321866035461 d_loss:1.4837450981140137 (f_loss=0.07008779048919678 r_loss=0.7129510641098022 GP=0.7007062435150146)
[Training] epoch:398 step:200 g_loss:0.9099674224853516 d_loss:1.2251720130443573 (f_loss=0.10282203555107117 r_loss=0.841107964515686 GP=0.2812420129776001)
[Training] epoch:398 step:300 g_loss:0.8796078562736511 d_loss:1.5505392625927925 (f_loss=0.1187594011425972 r_loss=0.847612738609314 GP=0.5841671228408813)
[Training] epoch:399 step:0 g_loss:0.9392886757850647 d_loss:1.4990778714418411 (f_loss=0.10491295158863068 r_loss=0.8161851167678833 GP=0.5779798030853271)
[Training] epoch:399 step:100 g_loss:0.8734169006347656 d_loss:1.2984359189867973 (f_loss=0.07086049765348434 r_loss=0.8073554039001465 GP=0.4202200174331665)
[Training] epoch:399 step:200 g_loss:0.902035653591156 d_loss:1.1284871995449066 (f_loss=0.11554810404777527 r_loss=0.7844482660293579 GP=0.22849082946777344)
[Training] epoch:399 step:300 g_loss:0.8952721357345581 d_loss:1.2823344767093658 (f_loss=0.09152212738990784 r_loss=0.8699589967727661 GP=0.3208533525466919)
[Training] epoch:400 step:0 g_loss:0.871910035610199 d_loss:1.0311879068613052 (f_loss=0.11560896039009094 r_loss=0.8105300664901733 GP=0.10504887998104095)

[Training] epoch:400 step:100 g_loss:0.913478434085846 d_loss:1.2228942438960075 (f_loss=0.07201790064573288 r_loss=0.7719983458518982 GP=0.37887799739837646)
[Training] epoch:400 step:200 g_loss:0.8781746625900269 d_loss:1.236742451786995 (f_loss=0.06471766531467438 r_loss=0.7822115421295166 GP=0.38981324434280396)
[Training] epoch:400 step:300 g_loss:0.8629863262176514 d_loss:1.111785426735878 (f_loss=0.1199987381696701 r_loss=0.7094508409500122 GP=0.2823358476161957)
[Training] epoch:401 step:0 g_loss:0.9063060283660889 d_loss:1.571254439651966 (f_loss=0.10735446959733963 r_loss=0.684609055519104 GP=0.7792909145355225)
[Training] epoch:401 step:100 g_loss:0.888820469379425 d_loss:1.493213266134262 (f_loss=0.09133777022361755 r_loss=0.7375156283378601 GP=0.6643598675727844)
[Training] epoch:401 step:200 g_loss:0.8582005500793457 d_loss:1.2361629158258438 (f_loss=0.12779909372329712 r_loss=0.8977173566818237 GP=0.21064646542072296)
[Training] epoch:401 step:300 g_loss:0.8935040235519409 d_loss:1.0523795261979103 (f_loss=0.06713319569826126 r_loss=0.8539791107177734 GP=0.1312672197818756)
[Training] epoch:402 step:0 g_loss:0.8630331754684448 d_loss:1.8946156799793243 (f_loss=0.10391947627067566 r_loss=0.766143262386322 GP=1.0245529413223267)
[Training] epoch:402 step:100 g_loss:0.8554432988166809 d_loss:1.3806126862764359 (f_loss=0.141790971159935 r_loss=0.8052117824554443 GP=0.4336099326610565)
[Training] epoch:402 step:200 g_loss:0.9399316906929016 d_loss:1.2830699682235718 (f_loss=0.12108060717582703 r_loss=0.8840880393981934 GP=0.2779013216495514)
[Training] epoch:402 step:300 g_loss:0.9258400797843933 d_loss:1.151058092713356 (f_loss=0.08360351622104645 r_loss=0.7836332321166992 GP=0.28382134437561035)
[Training] epoch:403 step:0 g_loss:0.8907548785209656 d_loss:1.3636399507522583 (f_loss=0.10782390832901001 r_loss=0.730010986328125 GP=0.5258050560951233)
[Training] epoch:403 step:100 g_loss:0.9197133183479309 d_loss:1.0679561272263527 (f_loss=0.04784402996301651 r_loss=0.8230765461921692 GP=0.197035551071167)
[Training] epoch:403 step:200 g_loss:0.8995260000228882 d_loss:1.3730549439787865 (f_loss=0.06387149542570114 r_loss=0.8519155383110046 GP=0.4572679102420807)
[Training] epoch:403 step:300 g_loss:0.9217885136604309 d_loss:1.3110529407858849 (f_loss=0.07440858334302902 r_loss=0.7860591411590576 GP=0.4505852162837982)
[Training] epoch:404 step:0 g_loss:0.9162827730178833 d_loss:1.5639422982931137 (f_loss=0.15671275556087494 r_loss=0.8427639007568359 GP=0.5644656419754028)
[Training] epoch:404 step:100 g_loss:0.8969534635543823 d_loss:1.48453220538795 (f_loss=0.01030692271888256 r_loss=0.866969108581543 GP=0.6072561740875244)
[Training] epoch:404 step:200 g_loss:0.9068024754524231 d_loss:1.2559509724378586 (f_loss=0.10496427118778229 r_loss=0.7317428588867188 GP=0.41924384236335754)
[Training] epoch:404 step:300 g_loss:0.909748911857605 d_loss:1.2637930810451508 (f_loss=0.14050352573394775 r_loss=0.8503433465957642 GP=0.27294620871543884)
[Training] epoch:405 step:0 g_loss:0.8893969058990479 d_loss:1.5494153052568436 (f_loss=0.13075824081897736 r_loss=0.7219680547714233 GP=0.6966890096664429)
[Training] epoch:405 step:100 g_loss:0.8844656348228455 d_loss:1.0534532964229584 (f_loss=0.0755128264427185 r_loss=0.8017501831054688 GP=0.17619028687477112)
[Training] epoch:405 step:200 g_loss:0.8756005167961121 d_loss:1.69213105738163 (f_loss=0.1422768384218216 r_loss=0.879219651222229 GP=0.6706345677375793)
[Training] epoch:405 step:300 g_loss:0.904729962348938 d_loss:1.117404654622078 (f_loss=0.12994776666164398 r_loss=0.7772649526596069 GP=0.21019193530082703)
[Training] epoch:406 step:0 g_loss:0.9168126583099365 d_loss:1.336459070444107 (f_loss=0.07680779695510864 r_loss=0.7604738473892212 GP=0.4991774260997772)
[Training] epoch:406 step:100 g_loss:0.915632426738739 d_loss:1.199258714914322 (f_loss=0.14069601893424988 r_loss=0.8158451318740845 GP=0.24271756410598755)
[Training] epoch:406 step:200 g_loss:0.9495234489440918 d_loss:1.5706651285290718 (f_loss=0.07356894761323929 r_loss=0.8179553747177124 GP=0.6791408061981201)
[Training] epoch:406 step:300 g_loss:0.9650847911834717 d_loss:1.752486377954483 (f_loss=0.07059678435325623 r_loss=0.7152285575866699 GP=0.9666610360145569)
[Training] epoch:407 step:0 g_loss:0.9421064257621765 d_loss:1.179838988929987 (f_loss=0.05955970659852028 r_loss=0.8403550386428833 GP=0.2799242436885834)
[Training] epoch:407 step:100 g_loss:0.959731936454773 d_loss:1.193467266857624 (f_loss=0.09392411261796951 r_loss=0.7588804960250854 GP=0.3406626582145691)
[Training] epoch:407 step:200 g_loss:0.920075535774231 d_loss:1.1233366876840591 (f_loss=0.10484202206134796 r_loss=0.8268766403198242 GP=0.19161802530288696)
[Training] epoch:407 step:300 g_loss:0.8390273451805115 d_loss:1.778805609792471 (f_loss=0.02662920579314232 r_loss=0.6765725612640381 GP=1.0756038427352905)
[Training] epoch:408 step:0 g_loss:0.904521107673645 d_loss:1.924226425588131 (f_loss=0.04109587520360947 r_loss=0.7331007719039917 GP=1.1500297784805298)
[Training] epoch:408 step:100 g_loss:0.8877347707748413 d_loss:2.128608137369156 (f_loss=0.07756689190864563 r_loss=0.7966513633728027 GP=1.2543898820877075)
[Training] epoch:408 step:200 g_loss:0.918440043926239 d_loss:1.6499784514307976 (f_loss=0.10554730147123337 r_loss=0.7730405926704407 GP=0.7713905572891235)
[Training] epoch:408 step:300 g_loss:0.9304429888725281 d_loss:1.4276783466339111 (f_loss=0.061911940574645996 r_loss=0.7787596583366394 GP=0.5870067477226257)
[Training] epoch:409 step:0 g_loss:0.937493622303009 d_loss:1.295488752424717 (f_loss=0.05840039998292923 r_loss=0.8455536365509033 GP=0.3915347158908844)
[Training] epoch:409 step:100 g_loss:0.8942756652832031 d_loss:1.4906306266784668 (f_loss=0.027440011501312256 r_loss=0.7947543859481812 GP=0.6684362292289734)
[Training] epoch:409 step:200 g_loss:0.9065806865692139 d_loss:1.2504576295614243 (f_loss=0.07108257710933685 r_loss=0.8053468465805054 GP=0.37402820587158203)
[Training] epoch:409 step:300 g_loss:0.9409530758857727 d_loss:1.3719467297196388 (f_loss=0.09675893932580948 r_loss=0.688493549823761 GP=0.5866942405700684)
[Training] epoch:410 step:0 g_loss:0.9167921543121338 d_loss:1.5995451509952545 (f_loss=0.10183563828468323 r_loss=0.6422186493873596 GP=0.8554908633232117)

[Training] epoch:410 step:100 g_loss:0.9116917848587036 d_loss:1.3177017346024513 (f_loss=0.09688035398721695 r_loss=0.8133955001831055 GP=0.4074258804321289)
[Training] epoch:410 step:200 g_loss:0.899013876914978 d_loss:1.434406265616417 (f_loss=0.11485867202281952 r_loss=0.6993769407272339 GP=0.6201706528663635)
[Training] epoch:410 step:300 g_loss:0.9775746464729309 d_loss:1.6562380269169807 (f_loss=0.06282628327608109 r_loss=0.7344053983688354 GP=0.8590063452720642)
[Training] epoch:411 step:0 g_loss:0.9031431078910828 d_loss:1.437147095799446 (f_loss=0.058184459805488586 r_loss=0.7419829368591309 GP=0.6369796991348267)
[Training] epoch:411 step:100 g_loss:0.8890018463134766 d_loss:1.1282081604003906 (f_loss=0.08307337760925293 r_loss=0.8018192052841187 GP=0.24331557750701904)
[Training] epoch:411 step:200 g_loss:0.9069764614105225 d_loss:1.2914865761995316 (f_loss=0.14070628583431244 r_loss=0.7212013006210327 GP=0.4295789897441864)
[Training] epoch:411 step:300 g_loss:0.8636137843132019 d_loss:1.3205655440688133 (f_loss=0.0916682705283165 r_loss=0.7630237936973572 GP=0.46587347984313965)
[Training] epoch:412 step:0 g_loss:0.9378427863121033 d_loss:1.3836691156029701 (f_loss=0.1141231432557106 r_loss=0.8428948521614075 GP=0.42665112018585205)
[Training] epoch:412 step:100 g_loss:0.9066420197486877 d_loss:1.1803309172391891 (f_loss=0.02323918044567108 r_loss=0.905303955078125 GP=0.25178778171539307)
[Training] epoch:412 step:200 g_loss:0.9132888913154602 d_loss:1.9952541589736938 (f_loss=0.08795392513275146 r_loss=0.5753939151763916 GP=1.3319063186645508)
[Training] epoch:412 step:300 g_loss:0.91622394323349 d_loss:1.8052828386425972 (f_loss=0.09535575658082962 r_loss=0.6426458358764648 GP=1.0672812461853027)
[Training] epoch:413 step:0 g_loss:0.9603456258773804 d_loss:1.45136758685112 (f_loss=0.13295713067054749 r_loss=0.78076171875 GP=0.5376487374305725)
[Training] epoch:413 step:100 g_loss:0.9012855887413025 d_loss:1.3282132372260094 (f_loss=0.1149538978934288 r_loss=0.6791448593139648 GP=0.5341144800186157)
[Training] epoch:413 step:200 g_loss:0.9331617951393127 d_loss:0.9755127653479576 (f_loss=0.05298197269439697 r_loss=0.8296704888343811 GP=0.09286030381917953)
[Training] epoch:413 step:300 g_loss:0.8929761052131653 d_loss:1.6891528815031052 (f_loss=0.154854878783226 r_loss=0.8239864110946655 GP=0.7103115916252136)
[Training] epoch:414 step:0 g_loss:0.9497353434562683 d_loss:1.508898377418518 (f_loss=0.08624601364135742 r_loss=0.7483238577842712 GP=0.6743285059928894)
[Training] epoch:414 step:100 g_loss:0.8737155199050903 d_loss:1.5761888027191162 (f_loss=0.14403176307678223 r_loss=0.8427684307098389 GP=0.5893886089324951)
[Training] epoch:414 step:200 g_loss:0.8990542888641357 d_loss:1.2681058943271637 (f_loss=0.0963602364063263 r_loss=0.8272833824157715 GP=0.3444622755050659)
[Training] epoch:414 step:300 g_loss:0.9369505643844604 d_loss:1.183916486799717 (f_loss=0.07381617277860641 r_loss=0.9203042984008789 GP=0.18979601562023163)
[Training] epoch:415 step:0 g_loss:0.9087141156196594 d_loss:2.49228148534894 (f_loss=0.04375552013516426 r_loss=0.6718253493309021 GP=1.7767006158828735)
[Training] epoch:415 step:100 g_loss:0.9417681694030762 d_loss:1.3380450904369354 (f_loss=0.053690314292907715 r_loss=0.8316929340362549 GP=0.4526618421077728)
[Training] epoch:415 step:200 g_loss:0.8899267315864563 d_loss:1.6321379765868187 (f_loss=0.05190166085958481 r_loss=0.8285120725631714 GP=0.7517242431640625)
[Training] epoch:415 step:300 g_loss:0.9505848288536072 d_loss:1.5549494102597237 (f_loss=0.03887016326189041 r_loss=0.7506184577941895 GP=0.7654607892036438)
[Training] epoch:416 step:0 g_loss:0.9175980687141418 d_loss:1.720484584569931 (f_loss=0.09591087698936462 r_loss=0.7296193838119507 GP=0.8949543237686157)
[Training] epoch:416 step:100 g_loss:0.8894954323768616 d_loss:1.3310871869325638 (f_loss=0.06908436119556427 r_loss=0.7936382293701172 GP=0.4683645963668823)
[Training] epoch:416 step:200 g_loss:0.8945748805999756 d_loss:1.1940226703882217 (f_loss=0.0052659958600997925 r_loss=0.8496553897857666 GP=0.33910128474235535)
[Training] epoch:416 step:300 g_loss:0.8853458166122437 d_loss:1.2495032399892807 (f_loss=0.05081517994403839 r_loss=0.7573007345199585 GP=0.4413873255252838)
[Training] epoch:417 step:0 g_loss:0.9122844338417053 d_loss:1.1982540115714073 (f_loss=0.11118986457586288 r_loss=0.8609932661056519 GP=0.22607088088989258)
[Training] epoch:417 step:100 g_loss:0.9140048027038574 d_loss:1.489333625882864 (f_loss=0.056553300470113754 r_loss=0.7958970665931702 GP=0.6368832588195801)
[Training] epoch:417 step:200 g_loss:0.9208562970161438 d_loss:1.146417573094368 (f_loss=0.10544486343860626 r_loss=0.694529116153717 GP=0.3464435935020447)
[Training] epoch:417 step:300 g_loss:0.8725627660751343 d_loss:1.6186534091830254 (f_loss=0.09821408241987228 r_loss=0.7953658103942871 GP=0.725073516368866)
[Training] epoch:418 step:0 g_loss:0.8687650561332703 d_loss:0.9997680932283401 (f_loss=0.07182969152927399 r_loss=0.7966419458389282 GP=0.13129645586013794)
[Training] epoch:418 step:100 g_loss:0.9024807810783386 d_loss:1.0406253263354301 (f_loss=-0.01130608469247818 r_loss=0.7481945753097534 GP=0.3037368357181549)
[Training] epoch:418 step:200 g_loss:0.8467077016830444 d_loss:1.042120523750782 (f_loss=0.11342882364988327 r_loss=0.7978876829147339 GP=0.13080401718616486)
[Training] epoch:418 step:300 g_loss:0.9447330832481384 d_loss:0.952244259417057 (f_loss=0.05206318199634552 r_loss=0.8497983813285828 GP=0.050382696092128754)
[Training] epoch:419 step:0 g_loss:0.9593865275382996 d_loss:1.1851420924067497 (f_loss=0.07300549000501633 r_loss=0.7110161185264587 GP=0.40112048387527466)
[Training] epoch:419 step:100 g_loss:0.979668140411377 d_loss:1.134493127465248 (f_loss=0.11463302373886108 r_loss=0.8312282562255859 GP=0.1886318475008011)
[Training] epoch:419 step:200 g_loss:0.9500435590744019 d_loss:1.2917512208223343 (f_loss=0.0773518830537796 r_loss=0.7372218370437622 GP=0.4771775007247925)
[Training] epoch:419 step:300 g_loss:0.9244562983512878 d_loss:1.1802584528923035 (f_loss=0.05611620843410492 r_loss=0.887712836265564 GP=0.23642940819263458)
[Training] epoch:420 step:0 g_loss:0.8912490606307983 d_loss:1.1971286684274673 (f_loss=0.12026335299015045 r_loss=0.819534182548523 GP=0.25733113288879395)

[Training] epoch:420 step:100 g_loss:0.9018692374229431 d_loss:1.6850252524018288 (f_loss=0.09628073126077652 r_loss=0.8848050236701965 GP=0.7039394974708557)
[Training] epoch:420 step:200 g_loss:0.9033462405204773 d_loss:1.350990355014801 (f_loss=0.026227355003356934 r_loss=0.7836681008338928 GP=0.5410948991775513)
[Training] epoch:420 step:300 g_loss:0.8810041546821594 d_loss:1.4722185581922531 (f_loss=0.05716203153133392 r_loss=0.7751838564872742 GP=0.639872670173645)
[Training] epoch:421 step:0 g_loss:0.9451183676719666 d_loss:1.6843974068760872 (f_loss=0.05009264498949051 r_loss=0.8977323174476624 GP=0.7365724444389343)
[Training] epoch:421 step:100 g_loss:0.9224891662597656 d_loss:1.539773341268301 (f_loss=0.05151378735899925 r_loss=0.7877429723739624 GP=0.7005165815353394)
[Training] epoch:421 step:200 g_loss:0.9689456224441528 d_loss:1.2573201656341553 (f_loss=0.09355038404464722 r_loss=0.8637685775756836 GP=0.30000120401382446)
[Training] epoch:421 step:300 g_loss:0.9034295678138733 d_loss:1.1336951479315758 (f_loss=0.08998055011034012 r_loss=0.8536823987960815 GP=0.1900321990251541)
[Training] epoch:422 step:0 g_loss:0.8764709234237671 d_loss:1.2586417570710182 (f_loss=0.08196199685335159 r_loss=0.8889292478561401 GP=0.2877505123615265)
[Training] epoch:422 step:100 g_loss:0.9829909801483154 d_loss:1.6750765964388847 (f_loss=0.10402130335569382 r_loss=0.7993745803833008 GP=0.7716807126998901)
[Training] epoch:422 step:200 g_loss:0.9664044380187988 d_loss:1.197196900844574 (f_loss=0.09549480676651001 r_loss=0.8190867304801941 GP=0.2826153635978699)
[Training] epoch:422 step:300 g_loss:0.9242676496505737 d_loss:1.296413466334343 (f_loss=0.0513223260641098 r_loss=0.8014191389083862 GP=0.4436720013618469)
[Training] epoch:423 step:0 g_loss:0.9881026148796082 d_loss:2.58114405348897 (f_loss=0.00915481522679329 r_loss=0.6321925520896912 GP=1.9397966861724854)
[Training] epoch:423 step:100 g_loss:0.9271560907363892 d_loss:1.2881347239017487 (f_loss=0.056931644678115845 r_loss=0.8328200578689575 GP=0.3983830213546753)
[Training] epoch:423 step:200 g_loss:0.8798404932022095 d_loss:1.290610522031784 (f_loss=0.08193862438201904 r_loss=0.9105167984962463 GP=0.2981550991535187)
[Training] epoch:423 step:300 g_loss:0.8993498086929321 d_loss:1.1604593358933926 (f_loss=0.04431771859526634 r_loss=0.8226015567779541 GP=0.2935400605201721)
[Training] epoch:424 step:0 g_loss:0.9868946671485901 d_loss:1.0463101044297218 (f_loss=0.05670461803674698 r_loss=0.8518535494804382 GP=0.13775193691253662)
[Training] epoch:424 step:100 g_loss:0.9375601410865784 d_loss:2.5620137453079224 (f_loss=0.08261650800704956 r_loss=0.5549140572547913 GP=1.9244831800460815)
[Training] epoch:424 step:200 g_loss:0.8877752423286438 d_loss:1.6915588527917862 (f_loss=0.04725755751132965 r_loss=0.8425872325897217 GP=0.8017140626907349)
[Training] epoch:424 step:300 g_loss:0.9120626449584961 d_loss:1.3816281259059906 (f_loss=0.0662434995174408 r_loss=0.767275333404541 GP=0.5481092929840088)
[Training] epoch:425 step:0 g_loss:0.963901937007904 d_loss:1.6511856764554977 (f_loss=0.06296537816524506 r_loss=0.768901526927948 GP=0.8193187713623047)
[Training] epoch:425 step:100 g_loss:0.9943639636039734 d_loss:0.992448627948761 (f_loss=0.05622570216655731 r_loss=0.8500401377677917 GP=0.08618278801441193)
[Training] epoch:425 step:200 g_loss:0.9125750064849854 d_loss:2.1548974737524986 (f_loss=0.08612313121557236 r_loss=0.7630940675735474 GP=1.305680274963379)
[Training] epoch:425 step:300 g_loss:0.9518105387687683 d_loss:1.416484834626317 (f_loss=0.017912449315190315 r_loss=0.8850088715553284 GP=0.5135635137557983)
[Training] epoch:426 step:0 g_loss:0.9486057758331299 d_loss:1.0781565010547638 (f_loss=0.07622981071472168 r_loss=0.786082923412323 GP=0.21584376692771912)
[Training] epoch:426 step:100 g_loss:0.9542052149772644 d_loss:0.9865953177213669 (f_loss=0.03157453238964081 r_loss=0.8076862096786499 GP=0.14733457565307617)
[Training] epoch:426 step:200 g_loss:0.9037236571311951 d_loss:1.1680432446300983 (f_loss=0.04884396865963936 r_loss=0.8482465744018555 GP=0.2709527015686035)
[Training] epoch:426 step:300 g_loss:0.9159077405929565 d_loss:1.1785862818360329 (f_loss=0.09595518559217453 r_loss=0.8783969879150391 GP=0.20423410832881927)
[Training] epoch:427 step:0 g_loss:0.9272396564483643 d_loss:1.2475285530090332 (f_loss=0.10776841640472412 r_loss=0.8007799983024597 GP=0.33898013830184937)
[Training] epoch:427 step:100 g_loss:0.9431887865066528 d_loss:1.4194506406784058 (f_loss=0.15512588620185852 r_loss=0.8184075355529785 GP=0.4459172189235687)
[Training] epoch:427 step:200 g_loss:0.9554076194763184 d_loss:2.737078845500946 (f_loss=0.04757136106491089 r_loss=0.5095198154449463 GP=2.179987668991089)
[Training] epoch:427 step:300 g_loss:0.9399272799491882 d_loss:1.84172685444355 (f_loss=0.09821738302707672 r_loss=0.7786379456520081 GP=0.9648715257644653)
[Training] epoch:428 step:0 g_loss:0.9452499151229858 d_loss:1.328183151781559 (f_loss=0.045859016478061676 r_loss=0.8681894540786743 GP=0.414134681224823)
[Training] epoch:428 step:100 g_loss:0.9088489413261414 d_loss:1.1137842535972595 (f_loss=0.0473882257938385 r_loss=0.8845696449279785 GP=0.1818263828754425)
[Training] epoch:428 step:200 g_loss:0.8399298787117004 d_loss:1.233322873711586 (f_loss=0.08718179166316986 r_loss=0.8639822006225586 GP=0.28215888142585754)
[Training] epoch:428 step:300 g_loss:0.9145205020904541 d_loss:1.2081678733229637 (f_loss=0.05873113125562668 r_loss=0.8710076808929443 GP=0.2784290611743927)
[Training] epoch:429 step:0 g_loss:0.9459756016731262 d_loss:1.4162594005465508 (f_loss=0.10187628120183945 r_loss=0.8914452195167542 GP=0.42293789982795715)
[Training] epoch:429 step:100 g_loss:0.9653053879737854 d_loss:1.2697436921298504 (f_loss=0.049149345606565475 r_loss=0.9016828536987305 GP=0.31891149282455444)
[Training] epoch:429 step:200 g_loss:1.0048531293869019 d_loss:1.2125498950481415 (f_loss=0.0716034471988678 r_loss=0.866315484046936 GP=0.27463096380233765)
[Training] epoch:429 step:300 g_loss:0.8986660242080688 d_loss:1.0613878928124905 (f_loss=0.042736928910017014 r_loss=0.8881831169128418 GP=0.13046784698963165)
[Training] epoch:430 step:0 g_loss:0.9179922342300415 d_loss:1.0097616575658321 (f_loss=0.029008109122514725 r_loss=0.8864918947219849 GP=0.09426165372133255)

[Training] epoch:430 step:100 g_loss:0.947498619556427 d_loss:1.3643970899283886 (f_loss=0.05666575953364372 r_loss=0.7549445033073425 GP=0.5527868270874023)
[Training] epoch:430 step:200 g_loss:0.9511683583259583 d_loss:1.2521063685417175 (f_loss=0.0345650315284729 r_loss=0.8520419597625732 GP=0.3654993772506714)
[Training] epoch:430 step:300 g_loss:0.8818552494049072 d_loss:1.1231464110314846 (f_loss=0.04173129424452782 r_loss=0.8399438858032227 GP=0.24147123098373413)
[Training] epoch:431 step:0 g_loss:0.9586060643196106 d_loss:1.5471044052392244 (f_loss=0.028880344703793526 r_loss=0.7734459042549133 GP=0.7447781562805176)
[Training] epoch:431 step:100 g_loss:0.904146134853363 d_loss:1.774365097284317 (f_loss=0.06261470913887024 r_loss=0.7823963165283203 GP=0.9293540716171265)
[Training] epoch:431 step:200 g_loss:0.9146988987922668 d_loss:2.5817014947533607 (f_loss=0.051755763590335846 r_loss=0.6246863603591919 GP=1.905259370803833)
[Training] epoch:431 step:300 g_loss:0.9514712691307068 d_loss:1.1300525590777397 (f_loss=0.043444059789180756 r_loss=0.8557559847831726 GP=0.23085251450538635)
[Training] epoch:432 step:0 g_loss:0.9865727424621582 d_loss:1.1776877101510763 (f_loss=0.02681342326104641 r_loss=0.8486928343772888 GP=0.3021814525127411)
[Training] epoch:432 step:100 g_loss:0.9322212338447571 d_loss:1.4305239468812943 (f_loss=0.09162797033786774 r_loss=0.89998459815979 GP=0.4389113783836365)
[Training] epoch:432 step:200 g_loss:0.8591220378875732 d_loss:1.341763362288475 (f_loss=0.07012040913105011 r_loss=0.783950924873352 GP=0.4876920282840729)
[Training] epoch:432 step:300 g_loss:0.9102806448936462 d_loss:1.7034632414579391 (f_loss=0.06147341430187225 r_loss=0.8811133503913879 GP=0.760876476764679)
[Training] epoch:433 step:0 g_loss:0.9191875457763672 d_loss:1.7216437980532646 (f_loss=0.0730934664607048 r_loss=0.795579195022583 GP=0.8529711365699768)
[Training] epoch:433 step:100 g_loss:0.9894599914550781 d_loss:1.9088623076677322 (f_loss=0.06369324028491974 r_loss=0.8264431953430176 GP=1.018725872039795)
[Training] epoch:433 step:200 g_loss:0.9907650947570801 d_loss:1.9674655050039291 (f_loss=0.062390074133872986 r_loss=0.8064881563186646 GP=1.0985872745513916)
[Training] epoch:433 step:300 g_loss:0.9190900325775146 d_loss:1.2126494944095612 (f_loss=0.0227089524269104 r_loss=0.8639562129974365 GP=0.32598432898521423)
[Training] epoch:434 step:0 g_loss:0.9062490463256836 d_loss:1.7399367690086365 (f_loss=0.1337924599647522 r_loss=0.838648796081543 GP=0.7674955129623413)
[Training] epoch:434 step:100 g_loss:0.9466270208358765 d_loss:1.1083316393196583 (f_loss=0.04981398954987526 r_loss=0.9232892990112305 GP=0.13522835075855255)
[Training] epoch:434 step:200 g_loss:0.9277306795120239 d_loss:1.648442193865776 (f_loss=0.0624038428068161 r_loss=0.8750407099723816 GP=0.7109976410865784)
[Training] epoch:434 step:300 g_loss:0.969621479511261 d_loss:1.5506935194134712 (f_loss=0.06685514003038406 r_loss=0.8244354724884033 GP=0.6594029068946838)
[Training] epoch:435 step:0 g_loss:0.9150866866111755 d_loss:2.155413195490837 (f_loss=0.04486177861690521 r_loss=0.6066904664039612 GP=1.5038609504699707)
[Training] epoch:435 step:100 g_loss:0.9282971620559692 d_loss:1.2369972094893456 (f_loss=0.0729328915476799 r_loss=0.8934308886528015 GP=0.27063342928886414)
[Training] epoch:435 step:200 g_loss:0.955600917339325 d_loss:1.4403073713183403 (f_loss=0.04415082186460495 r_loss=0.8551667928695679 GP=0.5409897565841675)
[Training] epoch:435 step:300 g_loss:0.9386321306228638 d_loss:1.436947014182806 (f_loss=0.030668046325445175 r_loss=0.8503789901733398 GP=0.555899977684021)
[Training] epoch:436 step:0 g_loss:1.0102455615997314 d_loss:2.899618722498417 (f_loss=0.03354278951883316 r_loss=0.5319213271141052 GP=2.3341546058654785)
[Training] epoch:436 step:100 g_loss:1.0204495191574097 d_loss:1.4907182641327381 (f_loss=-0.004274528473615646 r_loss=0.9011020064353943 GP=0.5938907861709595)
[Training] epoch:436 step:200 g_loss:0.9006010890007019 d_loss:1.594482433050871 (f_loss=0.043907713145017624 r_loss=0.6942940950393677 GP=0.8562806248664856)
[Training] epoch:436 step:300 g_loss:0.9383212327957153 d_loss:1.3976455479860306 (f_loss=0.04793377220630646 r_loss=0.8448977470397949 GP=0.5048140287399292)
[Training] epoch:437 step:0 g_loss:0.9492336511611938 d_loss:1.3797188699245453 (f_loss=0.055457234382629395 r_loss=0.8314821720123291 GP=0.4927794635295868)
[Training] epoch:437 step:100 g_loss:0.9730074405670166 d_loss:1.9336152262985706 (f_loss=0.04240884259343147 r_loss=0.6626459360122681 GP=1.228560447692871)
[Training] epoch:437 step:200 g_loss:0.8893288969993591 d_loss:1.2061601597815752 (f_loss=-0.0037005525082349777 r_loss=0.8449270725250244 GP=0.36493363976478577)
[Training] epoch:437 step:300 g_loss:0.9125257730484009 d_loss:1.024667039513588 (f_loss=0.01603119820356369 r_loss=0.8869337439537048 GP=0.12170209735631943)
[Training] epoch:438 step:0 g_loss:0.9764958024024963 d_loss:1.3039129953831434 (f_loss=-5.5612996220588684e-05 r_loss=0.7772560119628906 GP=0.5267125964164734)
[Training] epoch:438 step:100 g_loss:0.9233194589614868 d_loss:1.260468028485775 (f_loss=0.03489764779806137 r_loss=0.8069663643836975 GP=0.4186040163040161)
[Training] epoch:438 step:200 g_loss:0.9093614816665649 d_loss:1.1244457736611366 (f_loss=0.07084519416093826 r_loss=0.828935980796814 GP=0.2246645987033844)
[Training] epoch:438 step:300 g_loss:0.9491706490516663 d_loss:1.2198516353964806 (f_loss=0.031417809426784515 r_loss=0.9153686165809631 GP=0.2730652093887329)
[Training] epoch:439 step:0 g_loss:0.968131959438324 d_loss:1.0937764197587967 (f_loss=0.07570488750934601 r_loss=0.8796332478523254 GP=0.13843828439712524)
[Training] epoch:439 step:100 g_loss:0.9525960683822632 d_loss:1.2588243633508682 (f_loss=0.0786987692117691 r_loss=0.8929415941238403 GP=0.2871840000152588)
[Training] epoch:439 step:200 g_loss:0.9752873182296753 d_loss:1.9291165918111801 (f_loss=0.12180040776729584 r_loss=0.8256829977035522 GP=0.981633186340332)
[Training] epoch:439 step:300 g_loss:1.0235261917114258 d_loss:1.4469873793423176 (f_loss=0.05881660059094429 r_loss=0.7485501170158386 GP=0.6396206617355347)
[Training] epoch:440 step:0 g_loss:0.952095627784729 d_loss:1.7965600527822971 (f_loss=-0.03290795907378197 r_loss=0.6394370794296265 GP=1.1900309324264526)

[Training] epoch:440 step:100 g_loss:0.9371607899665833 d_loss:1.597429633140564 (f_loss=0.024605989456176758 r_loss=0.76941978931427 GP=0.8034038543701172)
[Training] epoch:440 step:200 g_loss:0.9621862769126892 d_loss:1.313127025961876 (f_loss=0.08427385985851288 r_loss=0.9717530608177185 GP=0.25710010528564453)
[Training] epoch:440 step:300 g_loss:1.0253067016601562 d_loss:1.6325610503554344 (f_loss=0.05945213884115219 r_loss=0.7981657981872559 GP=0.7749431133270264)
[Training] epoch:441 step:0 g_loss:0.9360907673835754 d_loss:1.1762573532760143 (f_loss=0.04390011355280876 r_loss=0.8475049138069153 GP=0.2848523259162903)
[Training] epoch:441 step:100 g_loss:0.9292871952056885 d_loss:1.8670577704906464 (f_loss=0.004044681787490845 r_loss=0.8204430937767029 GP=1.0425699949264526)
[Training] epoch:441 step:200 g_loss:0.9393665790557861 d_loss:1.171122319996357 (f_loss=0.07292916625738144 r_loss=0.8519244194030762 GP=0.24626873433589935)
[Training] epoch:441 step:300 g_loss:0.9979889392852783 d_loss:1.1889821588993073 (f_loss=0.07128947973251343 r_loss=0.8719093799591064 GP=0.24578329920768738)
[Training] epoch:442 step:0 g_loss:0.9200732707977295 d_loss:1.4685237249359488 (f_loss=0.010224505327641964 r_loss=0.8056184649467468 GP=0.6526807546615601)
[Training] epoch:442 step:100 g_loss:0.9628133177757263 d_loss:1.1715698540210724 (f_loss=0.05097964406013489 r_loss=0.7771860957145691 GP=0.3434041142463684)
[Training] epoch:442 step:200 g_loss:0.9489543437957764 d_loss:1.2064279615879059 (f_loss=0.04981023073196411 r_loss=0.8657509088516235 GP=0.29086682200431824)
[Training] epoch:442 step:300 g_loss:0.96177738904953 d_loss:1.3138628900051117 (f_loss=-0.005256354808807373 r_loss=0.9220137000083923 GP=0.39710554480552673)
[Training] epoch:443 step:0 g_loss:0.973906397819519 d_loss:1.0228106509894133 (f_loss=0.02122451178729534 r_loss=0.8897082209587097 GP=0.1118779182434082)
[Training] epoch:443 step:100 g_loss:0.9996495842933655 d_loss:1.1835665106773376 (f_loss=0.04697194695472717 r_loss=0.8658111095428467 GP=0.2707834541797638)
[Training] epoch:443 step:200 g_loss:0.9421907663345337 d_loss:1.7629859149456024 (f_loss=0.1131419837474823 r_loss=0.9280118942260742 GP=0.7218320369720459)
[Training] epoch:443 step:300 g_loss:0.9787588119506836 d_loss:1.6017513312399387 (f_loss=0.05065310373902321 r_loss=0.7629427313804626 GP=0.7881554961204529)
[Training] epoch:444 step:0 g_loss:1.002727746963501 d_loss:1.0181149244308472 (f_loss=-0.01813530921936035 r_loss=0.8422904014587402 GP=0.19395983219146729)
[Training] epoch:444 step:100 g_loss:0.9997742176055908 d_loss:1.604348849505186 (f_loss=0.05963505432009697 r_loss=0.8001534342765808 GP=0.7445603609085083)
[Training] epoch:444 step:200 g_loss:0.9601171016693115 d_loss:1.6110143959522247 (f_loss=0.010976165533065796 r_loss=0.7453750967979431 GP=0.8546631336212158)
[Training] epoch:444 step:300 g_loss:0.949520468711853 d_loss:1.3453655317425728 (f_loss=0.05516607314348221 r_loss=0.8599013686180115 GP=0.4302980899810791)
[Training] epoch:445 step:0 g_loss:0.9659309983253479 d_loss:1.3377576656639576 (f_loss=0.02329309657216072 r_loss=0.7189525365829468 GP=0.5955120325088501)
[Training] epoch:445 step:100 g_loss:0.9279134273529053 d_loss:1.2511968053877354 (f_loss=0.03229248896241188 r_loss=0.8646506071090698 GP=0.35425370931625366)
[Training] epoch:445 step:200 g_loss:0.9908089637756348 d_loss:1.3642101474106312 (f_loss=0.05914269760251045 r_loss=0.8556710481643677 GP=0.44939640164375305)
[Training] epoch:445 step:300 g_loss:0.975899875164032 d_loss:2.011531986296177 (f_loss=0.04651389271020889 r_loss=0.7849250435829163 GP=1.1800930500030518)
[Training] epoch:446 step:0 g_loss:0.9860629439353943 d_loss:1.204283207654953 (f_loss=0.053655028343200684 r_loss=0.9358454942703247 GP=0.2147826850414276)
[Training] epoch:446 step:100 g_loss:1.0695778131484985 d_loss:2.146110825240612 (f_loss=0.045939020812511444 r_loss=0.724102258682251 GP=1.3760695457458496)
[Training] epoch:446 step:200 g_loss:0.9718060493469238 d_loss:1.454107865691185 (f_loss=0.07923351228237152 r_loss=0.8237377405166626 GP=0.5511366128921509)
[Training] epoch:446 step:300 g_loss:0.9785805344581604 d_loss:1.541373685002327 (f_loss=-0.022984132170677185 r_loss=0.848656952381134 GP=0.7157008647918701)
[Training] epoch:447 step:0 g_loss:0.9501440525054932 d_loss:1.8051265235990286 (f_loss=0.014317905530333519 r_loss=0.8018597960472107 GP=0.9889488220214844)
[Training] epoch:447 step:100 g_loss:0.9047226905822754 d_loss:1.8445070311427116 (f_loss=-0.0009103491902351379 r_loss=0.8540285229682922 GP=0.9913888573646545)
[Training] epoch:447 step:200 g_loss:0.9282664060592651 d_loss:1.9015786200761795 (f_loss=0.044415488839149475 r_loss=0.7451499104499817 GP=1.1120132207870483)
[Training] epoch:447 step:300 g_loss:0.9102993011474609 d_loss:1.7132178395986557 (f_loss=0.03689830005168915 r_loss=0.8470036387443542 GP=0.8293159008026123)
[Training] epoch:448 step:0 g_loss:0.9748477935791016 d_loss:0.9739354252815247 (f_loss=0.03763318061828613 r_loss=0.839790403842926 GP=0.0965118408203125)
[Training] epoch:448 step:100 g_loss:0.9696294069290161 d_loss:1.549426332116127 (f_loss=0.067273810505867 r_loss=0.7115148305892944 GP=0.7706376910209656)
[Training] epoch:448 step:200 g_loss:0.9748284220695496 d_loss:1.281794162467122 (f_loss=0.02275538630783558 r_loss=0.9041235446929932 GP=0.35491523146629333)
[Training] epoch:448 step:300 g_loss:0.9774094820022583 d_loss:2.03164990991354 (f_loss=0.07533486932516098 r_loss=0.6901735067367554 GP=1.2661415338516235)
[Training] epoch:449 step:0 g_loss:0.9924795627593994 d_loss:1.565436989068985 (f_loss=0.09974333643913269 r_loss=0.9216380715370178 GP=0.5440555810928345)
[Training] epoch:449 step:100 g_loss:1.0208064317703247 d_loss:1.9619487505406141 (f_loss=0.031090734526515007 r_loss=0.669846773147583 GP=1.2610112428665161)
[Training] epoch:449 step:200 g_loss:1.008531928062439 d_loss:2.159687675535679 (f_loss=0.03160998970270157 r_loss=0.7231943011283875 GP=1.4048833847045898)
[Training] epoch:449 step:300 g_loss:1.0087952613830566 d_loss:1.9888226445764303 (f_loss=0.023302024230360985 r_loss=0.8341760635375977 GP=1.1313445568084717)
[Training] epoch:450 step:0 g_loss:0.9540714025497437 d_loss:2.19444252923131 (f_loss=0.04794396832585335 r_loss=0.9201751947402954 GP=1.2263233661651611)

[Training] epoch:450 step:100 g_loss:0.899746835231781 d_loss:1.2096273489296436 (f_loss=0.02843581512570381 r_loss=0.8294280171394348 GP=0.351763516664505)
[Training] epoch:450 step:200 g_loss:0.9754490256309509 d_loss:1.9381993189454079 (f_loss=0.05674002319574356 r_loss=0.5764055848121643 GP=1.3050537109375)
[Training] epoch:450 step:300 g_loss:0.9783642888069153 d_loss:1.4223148114979267 (f_loss=-0.01957697793841362 r_loss=0.6997707486152649 GP=0.7421210408210754)
[Training] epoch:451 step:0 g_loss:1.0010707378387451 d_loss:1.2309721298515797 (f_loss=0.010855216532945633 r_loss=0.7828972935676575 GP=0.43721961975097656)
[Training] epoch:451 step:100 g_loss:0.9313611388206482 d_loss:3.1041908599436283 (f_loss=-0.013313259929418564 r_loss=0.8304765224456787 GP=2.287027597427368)
[Training] epoch:451 step:200 g_loss:0.9088926911354065 d_loss:1.289226196706295 (f_loss=0.04280134290456772 r_loss=0.876271665096283 GP=0.37015318870544434)
[Training] epoch:451 step:300 g_loss:0.954190731048584 d_loss:1.7114395443350077 (f_loss=-0.009220784530043602 r_loss=0.8429681062698364 GP=0.8776922225952148)
[Training] epoch:452 step:0 g_loss:1.0136048793792725 d_loss:1.1582252122461796 (f_loss=-0.0012807957828044891 r_loss=0.9206359386444092 GP=0.2388700693845749)
[Training] epoch:452 step:100 g_loss:0.9865099787712097 d_loss:1.3899799585342407 (f_loss=0.09224259853363037 r_loss=0.9596475958824158 GP=0.3380897641181946)
[Training] epoch:452 step:200 g_loss:0.9697133898735046 d_loss:1.821308970451355 (f_loss=0.07416880130767822 r_loss=0.8290061950683594 GP=0.9181339740753174)
[Training] epoch:452 step:300 g_loss:0.9236106276512146 d_loss:1.1601087301969528 (f_loss=0.037082359194755554 r_loss=0.849547266960144 GP=0.2734791040420532)
[Training] epoch:453 step:0 g_loss:1.040088415145874 d_loss:2.247214011847973 (f_loss=0.04236840456724167 r_loss=0.9295985102653503 GP=1.2752470970153809)
[Training] epoch:453 step:100 g_loss:0.9750326871871948 d_loss:1.9846242740750313 (f_loss=-0.008416466414928436 r_loss=0.8135597109794617 GP=1.179481029510498)
[Training] epoch:453 step:200 g_loss:0.9526743292808533 d_loss:1.3139015045017004 (f_loss=0.022002985700964928 r_loss=0.8651518821716309 GP=0.4267466366291046)
[Training] epoch:453 step:300 g_loss:0.9829110503196716 d_loss:1.759329617023468 (f_loss=0.0273856520652771 r_loss=0.8424873352050781 GP=0.8894566297531128)
[Training] epoch:454 step:0 g_loss:0.9918598532676697 d_loss:3.050664961338043 (f_loss=0.036724746227264404 r_loss=0.5507732629776001 GP=2.4631669521331787)
[Training] epoch:454 step:100 g_loss:1.0014262199401855 d_loss:1.250029232352972 (f_loss=-0.02171934023499489 r_loss=0.9598239064216614 GP=0.31192466616630554)
[Training] epoch:454 step:200 g_loss:0.9870219826698303 d_loss:1.2647329345345497 (f_loss=-0.05636738985776901 r_loss=0.9242530465126038 GP=0.39684727787971497)
[Training] epoch:454 step:300 g_loss:0.9602364301681519 d_loss:1.2176099475473166 (f_loss=-0.020858341827988625 r_loss=0.8869513869285583 GP=0.3515169024467468)
[Training] epoch:455 step:0 g_loss:0.9942213296890259 d_loss:2.4314039926975965 (f_loss=-0.02026456780731678 r_loss=0.7801993489265442 GP=1.6714692115783691)
[Training] epoch:455 step:100 g_loss:0.920661211013794 d_loss:1.2530936151742935 (f_loss=0.055427566170692444 r_loss=0.7831748723983765 GP=0.4144911766052246)
[Training] epoch:455 step:200 g_loss:0.9605589509010315 d_loss:1.7000600397586823 (f_loss=0.043794721364974976 r_loss=0.9520067572593689 GP=0.7042585611343384)
[Training] epoch:455 step:300 g_loss:0.9853984713554382 d_loss:1.0329345688223839 (f_loss=-0.06734005361795425 r_loss=0.8808139562606812 GP=0.21946066617965698)
[Training] epoch:456 step:0 g_loss:1.002964735031128 d_loss:1.2253246419131756 (f_loss=0.023779403418302536 r_loss=0.8744192719459534 GP=0.3271259665489197)
[Training] epoch:456 step:100 g_loss:0.9832831621170044 d_loss:1.9352055341005325 (f_loss=0.054497793316841125 r_loss=0.85198974609375 GP=1.0287179946899414)
[Training] epoch:456 step:200 g_loss:0.9865298867225647 d_loss:2.8517473600804806 (f_loss=0.019807007163763046 r_loss=0.7177054286003113 GP=2.1142349243164062)
[Training] epoch:456 step:300 g_loss:1.032447338104248 d_loss:3.3933751191943884 (f_loss=-0.025263825431466103 r_loss=0.5274918079376221 GP=2.8911471366882324)
[Training] epoch:457 step:0 g_loss:0.9899565577507019 d_loss:1.7399160899221897 (f_loss=0.0502396859228611 r_loss=0.9434012174606323 GP=0.7462751865386963)
[Training] epoch:457 step:100 g_loss:1.012834072113037 d_loss:1.2002391293644905 (f_loss=0.03262705355882645 r_loss=0.942225456237793 GP=0.2253866195678711)
[Training] epoch:457 step:200 g_loss:1.0140787363052368 d_loss:1.5933906137943268 (f_loss=0.0842348039150238 r_loss=0.8743374347686768 GP=0.6348183751106262)
[Training] epoch:457 step:300 g_loss:1.0253371000289917 d_loss:1.2558119110763073 (f_loss=0.005245130509138107 r_loss=0.9761987924575806 GP=0.2743679881095886)
[Training] epoch:458 step:0 g_loss:1.014465093612671 d_loss:1.0643790271133184 (f_loss=0.0057053472846746445 r_loss=0.8767008185386658 GP=0.18197286128997803)
[Training] epoch:458 step:100 g_loss:1.0287351608276367 d_loss:1.4739368315786123 (f_loss=0.01780310831964016 r_loss=0.8561050891876221 GP=0.6000286340713501)
[Training] epoch:458 step:200 g_loss:0.955339252948761 d_loss:1.1787896621972322 (f_loss=0.02806870825588703 r_loss=0.8796793818473816 GP=0.2710415720939636)
[Training] epoch:458 step:300 g_loss:0.9815391898155212 d_loss:1.1451346352696419 (f_loss=0.05351025611162186 r_loss=0.9321759343147278 GP=0.15944844484329224)
[Training] epoch:459 step:0 g_loss:0.9728221297264099 d_loss:1.207605466246605 (f_loss=0.050104811787605286 r_loss=0.9090765118598938 GP=0.24842414259910583)
[Training] epoch:459 step:100 g_loss:0.9472679495811462 d_loss:1.4609711691737175 (f_loss=0.059001706540584564 r_loss=0.9209949970245361 GP=0.4809744656085968)
[Training] epoch:459 step:200 g_loss:1.029992938041687 d_loss:1.766792442649603 (f_loss=0.03843274340033531 r_loss=0.9053739905357361 GP=0.8229857087135315)
[Training] epoch:459 step:300 g_loss:0.9976885914802551 d_loss:1.4356997273862362 (f_loss=0.06247987970709801 r_loss=0.8441555500030518 GP=0.5290642976760864)
[Training] epoch:460 step:0 g_loss:0.9873670935630798 d_loss:1.4033261314034462 (f_loss=0.01092085987329483 r_loss=0.9894284009933472 GP=0.4029768705368042)

[Training] epoch:460 step:100 g_loss:0.9805383086204529 d_loss:1.8756847456097603 (f_loss=0.04934550076723099 r_loss=0.8501482009887695 GP=0.9761910438537598)
[Training] epoch:460 step:200 g_loss:0.9888430237770081 d_loss:1.4056507982313633 (f_loss=-0.01349073275923729 r_loss=0.9261595010757446 GP=0.49298202991485596)
[Training] epoch:460 step:300 g_loss:0.9301408529281616 d_loss:1.5121539905667305 (f_loss=0.035077162086963654 r_loss=0.88321453332901 GP=0.5938622951507568)
[Training] epoch:461 step:0 g_loss:0.9681069850921631 d_loss:1.4318276569247246 (f_loss=-0.0004994943737983704 r_loss=0.8819650411605835 GP=0.5503621101379395)
[Training] epoch:461 step:100 g_loss:1.0015703439712524 d_loss:1.1586415879428387 (f_loss=0.00881333276629448 r_loss=0.8095425963401794 GP=0.34028565883636475)
[Training] epoch:461 step:200 g_loss:0.9800336956977844 d_loss:1.5157116428017616 (f_loss=-0.006412826478481293 r_loss=0.749241292476654 GP=0.7728831768035889)
[Training] epoch:461 step:300 g_loss:0.9718195199966431 d_loss:1.1825747638940811 (f_loss=-0.003960937261581421 r_loss=0.9451057314872742 GP=0.24142996966838837)
[Training] epoch:462 step:0 g_loss:0.947527289390564 d_loss:2.095875918865204 (f_loss=-0.039528489112854004 r_loss=0.5274409651756287 GP=1.6079634428024292)
[Training] epoch:462 step:100 g_loss:0.9761318564414978 d_loss:1.3241267800331116 (f_loss=0.028624653816223145 r_loss=0.8724244832992554 GP=0.42307764291763306)
[Training] epoch:462 step:200 g_loss:1.0241066217422485 d_loss:1.2395172119140625 (f_loss=-0.06289404630661011 r_loss=0.9413468241691589 GP=0.36106443405151367)
[Training] epoch:462 step:300 g_loss:1.0398212671279907 d_loss:1.232068233191967 (f_loss=0.03901069611310959 r_loss=0.9231114983558655 GP=0.26994603872299194)
[Training] epoch:463 step:0 g_loss:0.9797905087471008 d_loss:1.3869941756129265 (f_loss=-0.02291763573884964 r_loss=0.81850266456604 GP=0.5914091467857361)
[Training] epoch:463 step:100 g_loss:0.9975423812866211 d_loss:1.28635473549366 (f_loss=-0.09866128861904144 r_loss=0.9315954446792603 GP=0.45342057943344116)
[Training] epoch:463 step:200 g_loss:1.0037680864334106 d_loss:1.1665609031915665 (f_loss=-0.0036843419075012207 r_loss=0.9740012884140015 GP=0.19624395668506622)
[Training] epoch:463 step:300 g_loss:1.0150532722473145 d_loss:1.1480537205934525 (f_loss=0.0726146250963211 r_loss=0.9487279653549194 GP=0.12671113014221191)
[Training] epoch:464 step:0 g_loss:0.9810375571250916 d_loss:1.561473447829485 (f_loss=0.0028541870415210724 r_loss=0.7380988597869873 GP=0.8205204010009766)
[Training] epoch:464 step:100 g_loss:0.9961504936218262 d_loss:1.4077901300042868 (f_loss=0.012837117537856102 r_loss=0.8152000308036804 GP=0.5797529816627502)
[Training] epoch:464 step:200 g_loss:0.9561372399330139 d_loss:1.186992160975933 (f_loss=-0.008609898388385773 r_loss=0.8124688863754272 GP=0.3831331729888916)
[Training] epoch:464 step:300 g_loss:1.080629825592041 d_loss:1.2161205559968948 (f_loss=-0.015581473708152771 r_loss=0.8814586997032166 GP=0.35024333000183105)
[Training] epoch:465 step:0 g_loss:0.9447731375694275 d_loss:1.4723397213965654 (f_loss=-0.010722188279032707 r_loss=0.8430330753326416 GP=0.6400288343429565)
[Training] epoch:465 step:100 g_loss:1.0643916130065918 d_loss:1.770076610147953 (f_loss=0.09413657337427139 r_loss=0.7782958745956421 GP=0.8976441621780396)
[Training] epoch:465 step:200 g_loss:0.9791831374168396 d_loss:1.3569070026278496 (f_loss=0.021720819175243378 r_loss=0.9310572147369385 GP=0.4041289687156677)
[Training] epoch:465 step:300 g_loss:0.9950847029685974 d_loss:1.4845530465245247 (f_loss=0.006676562130451202 r_loss=0.8378345966339111 GP=0.6400418877601624)
[Training] epoch:466 step:0 g_loss:0.9570966958999634 d_loss:1.1921867551282048 (f_loss=-0.006160515360534191 r_loss=0.894994854927063 GP=0.303352415561676)
[Training] epoch:466 step:100 g_loss:0.9560145735740662 d_loss:1.3988933078944683 (f_loss=-0.022763419896364212 r_loss=0.9163432121276855 GP=0.505313515663147)
[Training] epoch:466 step:200 g_loss:0.9832011461257935 d_loss:1.3892218004912138 (f_loss=0.013603700324892998 r_loss=0.7964024543762207 GP=0.5792156457901001)
[Training] epoch:466 step:300 g_loss:1.0296748876571655 d_loss:1.1047264225780964 (f_loss=0.011595088988542557 r_loss=0.9765467047691345 GP=0.11658462882041931)
[Training] epoch:467 step:0 g_loss:1.029312252998352 d_loss:1.6712919045239687 (f_loss=-0.027075571939349174 r_loss=0.9152342081069946 GP=0.7831332683563232)
[Training] epoch:467 step:100 g_loss:0.987702488899231 d_loss:1.1468203216791153 (f_loss=-0.06981624662876129 r_loss=0.9308127760887146 GP=0.285823792219162)
[Training] epoch:467 step:200 g_loss:1.021926760673523 d_loss:1.2143479958176613 (f_loss=0.03734559565782547 r_loss=0.9571624398231506 GP=0.21983996033668518)
[Training] epoch:467 step:300 g_loss:1.039023995399475 d_loss:1.2926046326756477 (f_loss=0.03374094516038895 r_loss=0.942112922668457 GP=0.31675076484680176)
[Training] epoch:468 step:0 g_loss:1.0136886835098267 d_loss:1.3375464528799057 (f_loss=0.047543689608573914 r_loss=0.8090065717697144 GP=0.48099619150161743)
[Training] epoch:468 step:100 g_loss:1.0212494134902954 d_loss:1.9887543842196465 (f_loss=0.08446943014860153 r_loss=0.6985244750976562 GP=1.2057604789733887)
[Training] epoch:468 step:200 g_loss:0.9642906188964844 d_loss:1.3333335295319557 (f_loss=0.00956515222787857 r_loss=0.8115982413291931 GP=0.512170135974884)
[Training] epoch:468 step:300 g_loss:1.0195677280426025 d_loss:1.5163241866976023 (f_loss=-0.007093166932463646 r_loss=0.8725268244743347 GP=0.6508905291557312)
[Training] epoch:469 step:0 g_loss:0.9942421317100525 d_loss:1.3119169063866138 (f_loss=-0.017362337559461594 r_loss=0.8190760016441345 GP=0.5102032423019409)
[Training] epoch:469 step:100 g_loss:1.1174447536468506 d_loss:2.0169192757457495 (f_loss=0.01572396419942379 r_loss=0.8171223402023315 GP=1.1840729713439941)
[Training] epoch:469 step:200 g_loss:1.0341814756393433 d_loss:1.7753655277192593 (f_loss=0.002020653337240219 r_loss=0.827001690864563 GP=0.946343183517456)
[Training] epoch:469 step:300 g_loss:0.9926056861877441 d_loss:2.084323301911354 (f_loss=0.049577370285987854 r_loss=0.7881853580474854 GP=1.2465605735778809)
[Training] epoch:470 step:0 g_loss:1.0142321586608887 d_loss:1.264735758304596 (f_loss=0.06432768702507019 r_loss=0.8000779151916504 GP=0.40033015608787537)

[Training] epoch:470 step:100 g_loss:0.9370068311691284 d_loss:1.5451026372611523 (f_loss=0.025574367493391037 r_loss=0.7978126406669617 GP=0.7217156291007996)
[Training] epoch:470 step:200 g_loss:1.0026346445083618 d_loss:1.6575375124812126 (f_loss=0.02188580483198166 r_loss=0.8634263277053833 GP=0.7722253799438477)
[Training] epoch:470 step:300 g_loss:1.0349125862121582 d_loss:1.1036587003618479 (f_loss=0.020230049267411232 r_loss=0.792994499206543 GP=0.2904341518878937)
[Training] epoch:471 step:0 g_loss:1.037402868270874 d_loss:1.2645378299057484 (f_loss=0.045923907309770584 r_loss=0.9247225522994995 GP=0.29389137029647827)
[Training] epoch:471 step:100 g_loss:1.0242478847503662 d_loss:1.2955917865037918 (f_loss=0.022996410727500916 r_loss=1.0152443647384644 GP=0.25735101103782654)
[Training] epoch:471 step:200 g_loss:1.0636322498321533 d_loss:1.517532430589199 (f_loss=0.05910523980855942 r_loss=0.9043456315994263 GP=0.5540815591812134)
[Training] epoch:471 step:300 g_loss:0.9899300336837769 d_loss:1.6101808696985245 (f_loss=0.026473358273506165 r_loss=0.8766041994094849 GP=0.7071033120155334)
[Training] epoch:472 step:0 g_loss:1.0227036476135254 d_loss:1.450362142175436 (f_loss=0.0069273971021175385 r_loss=0.9737018346786499 GP=0.4697329103946686)
[Training] epoch:472 step:100 g_loss:1.059695839881897 d_loss:1.2146891318261623 (f_loss=0.030013706535100937 r_loss=0.8891336917877197 GP=0.2955417335033417)
[Training] epoch:472 step:200 g_loss:1.0096759796142578 d_loss:1.076642632484436 (f_loss=-0.0650184154510498 r_loss=0.9758666157722473 GP=0.16579443216323853)
[Training] epoch:472 step:300 g_loss:1.0425715446472168 d_loss:1.3089509047567844 (f_loss=-0.0006065331399440765 r_loss=0.8658431768417358 GP=0.4437142610549927)
[Training] epoch:473 step:0 g_loss:0.9816110134124756 d_loss:1.5464219562709332 (f_loss=0.018671762198209763 r_loss=0.92698734998703 GP=0.6007628440856934)
[Training] epoch:473 step:100 g_loss:1.0246868133544922 d_loss:1.3444086238741875 (f_loss=-0.04075951129198074 r_loss=0.9490838646888733 GP=0.4360842704772949)
[Training] epoch:473 step:200 g_loss:1.020220398902893 d_loss:1.4021078906953335 (f_loss=-0.012875262647867203 r_loss=0.9631954431533813 GP=0.45178771018981934)
[Training] epoch:473 step:300 g_loss:1.0439435243606567 d_loss:1.696369044482708 (f_loss=-0.011934883892536163 r_loss=0.8803787231445312 GP=0.8279252052307129)
[Training] epoch:474 step:0 g_loss:0.981708824634552 d_loss:1.5594995636492968 (f_loss=-0.030200837180018425 r_loss=0.8096299767494202 GP=0.780070424079895)
[Training] epoch:474 step:100 g_loss:1.0306566953659058 d_loss:1.3236262053251266 (f_loss=-0.03610272705554962 r_loss=0.9929977655410767 GP=0.3667311668395996)
[Training] epoch:474 step:200 g_loss:1.0622750520706177 d_loss:1.1166291758418083 (f_loss=-0.11685258895158768 r_loss=0.9104281663894653 GP=0.32305359840393066)
[Training] epoch:474 step:300 g_loss:1.0109586715698242 d_loss:0.9873288497328758 (f_loss=-0.08092347532510757 r_loss=0.8640046715736389 GP=0.20424765348434448)
[Training] epoch:475 step:0 g_loss:0.9560732245445251 d_loss:1.50140131264925 (f_loss=-0.03409617394208908 r_loss=0.8849819302558899 GP=0.6505155563354492)
[Training] epoch:475 step:100 g_loss:1.0523079633712769 d_loss:1.0757771264761686 (f_loss=-0.01657159812748432 r_loss=0.9240676164627075 GP=0.16828110814094543)
[Training] epoch:475 step:200 g_loss:0.9797493815422058 d_loss:1.1398751102387905 (f_loss=0.01775200292468071 r_loss=0.9773184061050415 GP=0.1448047012090683)
[Training] epoch:475 step:300 g_loss:1.0101618766784668 d_loss:1.2883770875632763 (f_loss=-0.004723507910966873 r_loss=0.9481040835380554 GP=0.34499651193618774)
[Training] epoch:476 step:0 g_loss:1.0182294845581055 d_loss:1.7878132089972496 (f_loss=0.02125062793493271 r_loss=0.9168453216552734 GP=0.8497172594070435)
[Training] epoch:476 step:100 g_loss:1.0642688274383545 d_loss:1.2273573987185955 (f_loss=0.03628019616007805 r_loss=0.9258743524551392 GP=0.2652028501033783)
[Training] epoch:476 step:200 g_loss:1.0794442892074585 d_loss:1.2279694750905037 (f_loss=-0.028296731412410736 r_loss=0.9359311461448669 GP=0.3203350603580475)
[Training] epoch:476 step:300 g_loss:1.0243855714797974 d_loss:1.0591729655861855 (f_loss=-0.07451342791318893 r_loss=0.9641659259796143 GP=0.16952046751976013)
[Training] epoch:477 step:0 g_loss:1.0201188325881958 d_loss:1.520915649831295 (f_loss=0.03198268264532089 r_loss=0.8718686103820801 GP=0.617064356803894)
[Training] epoch:477 step:100 g_loss:0.972776472568512 d_loss:1.4007454961538315 (f_loss=-0.03184641897678375 r_loss=0.8635387420654297 GP=0.5690531730651855)
[Training] epoch:477 step:200 g_loss:1.0143766403198242 d_loss:1.2490245904773474 (f_loss=0.0119223203510046 r_loss=0.8375011682510376 GP=0.3996011018753052)
[Training] epoch:477 step:300 g_loss:1.0330848693847656 d_loss:1.726435150951147 (f_loss=0.003486182540655136 r_loss=0.9209405183792114 GP=0.8020084500312805)
[Training] epoch:478 step:0 g_loss:1.0407187938690186 d_loss:1.292454557493329 (f_loss=0.009998815134167671 r_loss=0.8832582235336304 GP=0.399197518825531)
[Training] epoch:478 step:100 g_loss:1.0408369302749634 d_loss:0.9964346364140511 (f_loss=-0.05194278806447983 r_loss=0.8866145014762878 GP=0.16176292300224304)
[Training] epoch:478 step:200 g_loss:1.0142806768417358 d_loss:1.3799745365977287 (f_loss=0.0036042258143424988 r_loss=0.8796634078025818 GP=0.49670690298080444)
[Training] epoch:478 step:300 g_loss:1.0364348888397217 d_loss:1.0670148879289627 (f_loss=-0.03779987990856171 r_loss=0.9414030313491821 GP=0.16341173648834229)
[Training] epoch:479 step:0 g_loss:1.0350947380065918 d_loss:1.3838243000209332 (f_loss=0.06044415757060051 r_loss=0.8825348019599915 GP=0.4408453404903412)
[Training] epoch:479 step:100 g_loss:1.0092661380767822 d_loss:1.3535807272419333 (f_loss=0.0004972359165549278 r_loss=0.8361716270446777 GP=0.5169118642807007)
[Training] epoch:479 step:200 g_loss:1.0118886232376099 d_loss:1.2153797782957554 (f_loss=-0.03886684402823448 r_loss=0.9993539452552795 GP=0.2548926770687103)
[Training] epoch:479 step:300 g_loss:1.0515660047531128 d_loss:1.447859212756157 (f_loss=-0.0017657428979873657 r_loss=0.913234531879425 GP=0.5363904237747192)
[Training] epoch:480 step:0 g_loss:1.020393967628479 d_loss:1.6403589770197868 (f_loss=-0.01644635945558548 r_loss=0.862385094165802 GP=0.7944202423095703)

[Training] epoch:480 step:100 g_loss:1.018730878829956 d_loss:1.4735820926725864 (f_loss=0.029871169477701187 r_loss=0.7504369020462036 GP=0.6932740211486816)
[Training] epoch:480 step:200 g_loss:1.0302354097366333 d_loss:1.474508736282587 (f_loss=-0.035167302936315536 r_loss=0.8345261812210083 GP=0.6751498579978943)
[Training] epoch:480 step:300 g_loss:1.0440285205841064 d_loss:1.1468479335308075 (f_loss=-0.08902934193611145 r_loss=0.8423858880996704 GP=0.39349138736724854)
[Training] epoch:481 step:0 g_loss:1.0878956317901611 d_loss:1.3877181336283684 (f_loss=-0.013597317039966583 r_loss=0.8758766055107117 GP=0.5254388451576233)
[Training] epoch:481 step:100 g_loss:1.032851219177246 d_loss:1.416613094508648 (f_loss=-0.04808289557695389 r_loss=0.9222272038459778 GP=0.542468786239624)
[Training] epoch:481 step:200 g_loss:0.9962192177772522 d_loss:1.2921466082334518 (f_loss=0.06491760909557343 r_loss=0.9739429354667664 GP=0.25328606367111206)
[Training] epoch:481 step:300 g_loss:1.033686876296997 d_loss:1.4633838832378387 (f_loss=-0.0029046237468719482 r_loss=1.0061460733413696 GP=0.46014243364334106)
[Training] epoch:482 step:0 g_loss:1.0697486400604248 d_loss:1.485716450959444 (f_loss=0.028482843190431595 r_loss=0.8179264068603516 GP=0.6393072009086609)
[Training] epoch:482 step:100 g_loss:1.046826720237732 d_loss:1.030030444264412 (f_loss=-0.09379686415195465 r_loss=0.8632931709289551 GP=0.2605341374874115)
[Training] epoch:482 step:200 g_loss:1.0600005388259888 d_loss:2.0556116588413715 (f_loss=-0.018796037882566452 r_loss=0.8476186990737915 GP=1.2267889976501465)
[Training] epoch:482 step:300 g_loss:1.1076288223266602 d_loss:1.1916575729846954 (f_loss=-0.05175596475601196 r_loss=0.9330307245254517 GP=0.31038281321525574)
[Training] epoch:483 step:0 g_loss:0.9656206965446472 d_loss:1.5568062998354435 (f_loss=0.030236098915338516 r_loss=0.9320685863494873 GP=0.5945016145706177)
[Training] epoch:483 step:100 g_loss:1.0993003845214844 d_loss:1.3653689995408058 (f_loss=-0.02808668464422226 r_loss=0.8500455617904663 GP=0.5434101223945618)
[Training] epoch:483 step:200 g_loss:1.0682023763656616 d_loss:1.6266764961183071 (f_loss=0.0005152188241481781 r_loss=0.8096277713775635 GP=0.8165335059165955)
[Training] epoch:483 step:300 g_loss:1.0664055347442627 d_loss:1.0924301147460938 (f_loss=-0.0813334733247757 r_loss=0.9514726996421814 GP=0.22229088842868805)
[Training] epoch:484 step:0 g_loss:1.0140351057052612 d_loss:1.2687499672174454 (f_loss=-0.06358514726161957 r_loss=0.9182427525520325 GP=0.41409236192703247)
[Training] epoch:484 step:100 g_loss:1.0608831644058228 d_loss:1.1931303702294827 (f_loss=0.004342850297689438 r_loss=0.9070878028869629 GP=0.2816997170448303)
[Training] epoch:484 step:200 g_loss:1.0201069116592407 d_loss:1.2409202381968498 (f_loss=-0.05244136601686478 r_loss=0.8984343409538269 GP=0.3949272632598877)
[Training] epoch:484 step:300 g_loss:1.0608662366867065 d_loss:1.306744061410427 (f_loss=-0.045700229704380035 r_loss=1.0182682275772095 GP=0.33417606353759766)
[Training] epoch:485 step:0 g_loss:1.017787218093872 d_loss:1.5249774903059006 (f_loss=-0.06396891176700592 r_loss=0.9054462313652039 GP=0.6835001707077026)
[Training] epoch:485 step:100 g_loss:1.013218641281128 d_loss:1.2474576951935887 (f_loss=0.004287225194275379 r_loss=0.9421432018280029 GP=0.3010272681713104)
[Training] epoch:485 step:200 g_loss:1.0344196557998657 d_loss:1.2642752937972546 (f_loss=0.062017302960157394 r_loss=0.9680389761924744 GP=0.2342190146446228)
[Training] epoch:485 step:300 g_loss:1.0122605562210083 d_loss:1.3099126145243645 (f_loss=-0.003689594566822052 r_loss=0.9304380416870117 GP=0.3831641674041748)
[Training] epoch:486 step:0 g_loss:0.9904188513755798 d_loss:1.3843072056770325 (f_loss=-0.03683638572692871 r_loss=0.9726259708404541 GP=0.4485176205635071)
[Training] epoch:486 step:100 g_loss:1.0303150415420532 d_loss:1.277776800096035 (f_loss=0.0015278086066246033 r_loss=0.9567770957946777 GP=0.31947189569473267)
[Training] epoch:486 step:200 g_loss:1.033159852027893 d_loss:1.2650707941502333 (f_loss=-0.030532153323292732 r_loss=0.9046764969825745 GP=0.39092645049095154)
[Training] epoch:486 step:300 g_loss:1.0656020641326904 d_loss:1.2986340373754501 (f_loss=-0.03469230234622955 r_loss=0.8988734483718872 GP=0.4344528913497925)
[Training] epoch:487 step:0 g_loss:0.9962950348854065 d_loss:1.3117297627031803 (f_loss=-0.045429881662130356 r_loss=0.9532613158226013 GP=0.40389832854270935)
[Training] epoch:487 step:100 g_loss:0.9907801151275635 d_loss:1.4722105041146278 (f_loss=-0.059349559247493744 r_loss=0.8618991374969482 GP=0.6696609258651733)
[Training] epoch:487 step:200 g_loss:0.9983955025672913 d_loss:1.3824439980089664 (f_loss=-0.025501754134893417 r_loss=0.9512180089950562 GP=0.4567277431488037)
[Training] epoch:487 step:300 g_loss:1.0615780353546143 d_loss:1.5500458516180515 (f_loss=-0.020073171705007553 r_loss=1.013917326927185 GP=0.556201696395874)
[Training] epoch:488 step:0 g_loss:1.0409517288208008 d_loss:1.1257942616939545 (f_loss=-0.07238128781318665 r_loss=0.9394923448562622 GP=0.2586832046508789)
[Training] epoch:488 step:100 g_loss:0.9958326816558838 d_loss:1.4096792414784431 (f_loss=-0.0493655726313591 r_loss=0.9294356107711792 GP=0.529609203338623)
[Training] epoch:488 step:200 g_loss:1.060250997543335 d_loss:1.366991102695465 (f_loss=-0.06482499837875366 r_loss=0.880282461643219 GP=0.5515336394309998)
[Training] epoch:488 step:300 g_loss:1.0773993730545044 d_loss:1.6459559053182602 (f_loss=0.014595672488212585 r_loss=0.9476349949836731 GP=0.6837252378463745)
[Training] epoch:489 step:0 g_loss:1.0494452714920044 d_loss:2.4525572899729013 (f_loss=-0.01214817725121975 r_loss=0.8657670021057129 GP=1.5989384651184082)
[Training] epoch:489 step:100 g_loss:1.0511966943740845 d_loss:1.4185813926160336 (f_loss=-0.04540661349892616 r_loss=0.986130952835083 GP=0.4778570532798767)
[Training] epoch:489 step:200 g_loss:1.0630229711532593 d_loss:1.064984604716301 (f_loss=-0.0686846524477005 r_loss=0.931985080242157 GP=0.20168417692184448)
[Training] epoch:489 step:300 g_loss:1.0847433805465698 d_loss:1.0171926207840443 (f_loss=-0.03468625620007515 r_loss=0.9286503791809082 GP=0.12322849780321121)
[Training] epoch:490 step:0 g_loss:1.0156099796295166 d_loss:1.720935184508562 (f_loss=-0.03934125229716301 r_loss=0.9227445125579834 GP=0.8375319242477417)

[Training] epoch:490 step:100 g_loss:1.004979133605957 d_loss:1.289165634661913 (f_loss=-0.024178069084882736 r_loss=0.875906765460968 GP=0.43743693828582764)
[Training] epoch:490 step:200 g_loss:1.0815471410751343 d_loss:1.4834157582372427 (f_loss=-0.0076095107942819595 r_loss=0.9358938336372375 GP=0.5551314353942871)
[Training] epoch:490 step:300 g_loss:1.0038093328475952 d_loss:1.536613717675209 (f_loss=-0.04717729985713959 r_loss=1.0070388317108154 GP=0.5767521858215332)
[Training] epoch:491 step:0 g_loss:1.03572678565979 d_loss:1.5401781350374222 (f_loss=-0.05754964053630829 r_loss=0.9326932430267334 GP=0.6650345325469971)
[Training] epoch:491 step:100 g_loss:1.0416419506072998 d_loss:1.1575656458735466 (f_loss=0.011358894407749176 r_loss=0.9359551072120667 GP=0.21025164425373077)
[Training] epoch:491 step:200 g_loss:1.1106128692626953 d_loss:1.3308881372213364 (f_loss=-0.021997317671775818 r_loss=0.9255369901657104 GP=0.42734846472740173)
[Training] epoch:491 step:300 g_loss:1.0961718559265137 d_loss:1.4308963418006897 (f_loss=-0.07689857482910156 r_loss=0.9718999266624451 GP=0.5358949899673462)
[Training] epoch:492 step:0 g_loss:1.0096633434295654 d_loss:1.1173217557370663 (f_loss=-0.03671574965119362 r_loss=0.915285050868988 GP=0.23875245451927185)
[Training] epoch:492 step:100 g_loss:1.1018877029418945 d_loss:1.6574103944003582 (f_loss=-0.024956215173006058 r_loss=0.9699398279190063 GP=0.7124267816543579)
[Training] epoch:492 step:200 g_loss:1.0706688165664673 d_loss:1.244757761247456 (f_loss=-0.0004652542993426323 r_loss=0.8747565746307373 GP=0.3704664409160614)
[Training] epoch:492 step:300 g_loss:1.0497485399246216 d_loss:1.1471708118915558 (f_loss=-0.12753626704216003 r_loss=0.9306913018226624 GP=0.34401577711105347)
[Training] epoch:493 step:0 g_loss:0.9879910945892334 d_loss:2.147557482123375 (f_loss=-0.09514017403125763 r_loss=0.8845934271812439 GP=1.3581042289733887)
[Training] epoch:493 step:100 g_loss:0.9777555465698242 d_loss:1.3688431633636355 (f_loss=-0.011634145863354206 r_loss=0.7681353092193604 GP=0.6123420000076294)
[Training] epoch:493 step:200 g_loss:1.049882411956787 d_loss:1.1926443427801132 (f_loss=-0.08317889273166656 r_loss=0.9064288139343262 GP=0.3693944215774536)
[Training] epoch:493 step:300 g_loss:1.0708866119384766 d_loss:1.6807540897279978 (f_loss=-0.029485082253813744 r_loss=0.8151991367340088 GP=0.8950400352478027)
[Training] epoch:494 step:0 g_loss:1.0412644147872925 d_loss:1.0844349563121796 (f_loss=-0.04491029679775238 r_loss=0.9254496693611145 GP=0.20389558374881744)
[Training] epoch:494 step:100 g_loss:0.9845260977745056 d_loss:1.7695672884583473 (f_loss=-0.04756750911474228 r_loss=0.9568555951118469 GP=0.8602792024612427)
[Training] epoch:494 step:200 g_loss:1.0453215837478638 d_loss:1.4776676297187805 (f_loss=-0.05440002679824829 r_loss=0.9026527404785156 GP=0.6294149160385132)
[Training] epoch:494 step:300 g_loss:1.0470277070999146 d_loss:1.7017018496990204 (f_loss=-0.0770358145236969 r_loss=0.8462646007537842 GP=0.9324730634689331)
[Training] epoch:495 step:0 g_loss:1.0374782085418701 d_loss:2.056456595659256 (f_loss=-0.054809898138046265 r_loss=0.9117633104324341 GP=1.1995031833648682)
[Training] epoch:495 step:100 g_loss:1.018431305885315 d_loss:1.676369771361351 (f_loss=0.02200697362422943 r_loss=0.8691027164459229 GP=0.7852600812911987)
[Training] epoch:495 step:200 g_loss:1.0214567184448242 d_loss:1.1794182024896145 (f_loss=0.006338100880384445 r_loss=0.9331271648406982 GP=0.2399529367685318)
[Training] epoch:495 step:300 g_loss:1.0223926305770874 d_loss:1.070362325757742 (f_loss=-0.04660748317837715 r_loss=0.9446662664413452 GP=0.17230354249477386)
[Training] epoch:496 step:0 g_loss:1.0105819702148438 d_loss:1.1150729609653354 (f_loss=-0.012556989677250385 r_loss=0.9713730812072754 GP=0.15625686943531036)
[Training] epoch:496 step:100 g_loss:0.9491010904312134 d_loss:1.3009514436125755 (f_loss=0.003149770200252533 r_loss=1.038152813911438 GP=0.259648859500885)
[Training] epoch:496 step:200 g_loss:1.0316863059997559 d_loss:1.835243597626686 (f_loss=-0.04549364745616913 r_loss=0.8235377669334412 GP=1.057199478149414)
[Training] epoch:496 step:300 g_loss:1.0280070304870605 d_loss:1.1657376661896706 (f_loss=-0.04370956867933273 r_loss=0.8717514276504517 GP=0.33769580721855164)
[Training] epoch:497 step:0 g_loss:1.057177186012268 d_loss:2.0563173070549965 (f_loss=-0.06024505943059921 r_loss=0.8385117053985596 GP=1.2780506610870361)
[Training] epoch:497 step:100 g_loss:1.0425735712051392 d_loss:1.4207796081900597 (f_loss=-0.029720701277256012 r_loss=0.7680184245109558 GP=0.6824818849563599)
[Training] epoch:497 step:200 g_loss:1.029402732849121 d_loss:1.4206027295440435 (f_loss=-0.018408456817269325 r_loss=0.9661062955856323 GP=0.47290489077568054)
[Training] epoch:497 step:300 g_loss:1.070481300354004 d_loss:1.7328971438109875 (f_loss=-0.0406390018761158 r_loss=0.9382173418998718 GP=0.8353188037872314)
[Training] epoch:498 step:0 g_loss:1.1167593002319336 d_loss:1.402488600462675 (f_loss=-0.04733665660023689 r_loss=0.9629263877868652 GP=0.48689886927604675)
[Training] epoch:498 step:100 g_loss:1.0040324926376343 d_loss:1.1032110340893269 (f_loss=-0.06235545501112938 r_loss=0.959391176700592 GP=0.2061753123998642)
[Training] epoch:498 step:200 g_loss:1.0770014524459839 d_loss:1.367798164486885 (f_loss=-0.040744349360466 r_loss=0.9744725823402405 GP=0.4340699315071106)
[Training] epoch:498 step:300 g_loss:0.9928228259086609 d_loss:1.3287420868873596 (f_loss=-0.06750839948654175 r_loss=1.0172115564346313 GP=0.37903892993927)
[Training] epoch:499 step:0 g_loss:1.0879024267196655 d_loss:1.590040646493435 (f_loss=-0.05009964853525162 r_loss=0.9053932428359985 GP=0.734747052192688)
[Training] epoch:499 step:100 g_loss:1.0302387475967407 d_loss:1.2729941457509995 (f_loss=-0.005121603608131409 r_loss=0.9076738357543945 GP=0.37044191360473633)
[Training] epoch:499 step:200 g_loss:0.9897531867027283 d_loss:1.4529905300587416 (f_loss=0.012078193947672844 r_loss=0.9424740076065063 GP=0.4984383285045624)
[Training] epoch:499 step:300 g_loss:1.0828115940093994 d_loss:1.231244757771492 (f_loss=-0.06814570724964142 r_loss=1.0304735898971558 GP=0.26891687512397766)
[Training] epoch:500 step:0 g_loss:1.0617313385009766 d_loss:1.2125354781746864 (f_loss=-0.09830015152692795 r_loss=0.993388295173645 GP=0.31744733452796936)

[Training] epoch:500 step:100 g_loss:1.0594266653060913 d_loss:2.31069521792233 (f_loss=-0.000795973464846611 r_loss=0.9966753125190735 GP=1.314815878868103)
[Training] epoch:500 step:200 g_loss:1.053441047668457 d_loss:1.4452734738588333 (f_loss=-0.07781998813152313 r_loss=0.9024572372436523 GP=0.6206362247467041)
[Training] epoch:500 step:300 g_loss:1.075476884841919 d_loss:2.1342761740088463 (f_loss=-0.0340595617890358 r_loss=0.849729597568512 GP=1.3186061382293701)
[Training] epoch:501 step:0 g_loss:1.0829514265060425 d_loss:1.1169185191392899 (f_loss=-0.06929092109203339 r_loss=0.970235288143158 GP=0.21597415208816528)
[Training] epoch:501 step:100 g_loss:1.0032323598861694 d_loss:1.1600467786192894 (f_loss=-0.07573313266038895 r_loss=0.9833943843841553 GP=0.25238552689552307)
[Training] epoch:501 step:200 g_loss:1.1157512664794922 d_loss:1.5853312723338604 (f_loss=-0.04649536684155464 r_loss=0.8075789213180542 GP=0.8242477178573608)
[Training] epoch:501 step:300 g_loss:1.0257858037948608 d_loss:1.7541898638010025 (f_loss=-0.03855518996715546 r_loss=0.8690110445022583 GP=0.9237340092658997)
[Training] epoch:502 step:0 g_loss:1.0244938135147095 d_loss:1.296764511615038 (f_loss=-0.01352311298251152 r_loss=0.9335023760795593 GP=0.3767852485179901)
[Training] epoch:502 step:100 g_loss:1.131083607673645 d_loss:1.6457798853516579 (f_loss=0.002231813967227936 r_loss=1.0180631875991821 GP=0.6254848837852478)
[Training] epoch:502 step:200 g_loss:1.064355731010437 d_loss:1.5624212883412838 (f_loss=0.009753670543432236 r_loss=0.8998240232467651 GP=0.6528435945510864)
[Training] epoch:502 step:300 g_loss:1.043089747428894 d_loss:2.441284019500017 (f_loss=-0.05962405726313591 r_loss=0.8506709933280945 GP=1.6502370834350586)
[Training] epoch:503 step:0 g_loss:1.0167999267578125 d_loss:1.0888643376529217 (f_loss=-0.03260638192296028 r_loss=0.9721165299415588 GP=0.14935418963432312)
[Training] epoch:503 step:100 g_loss:1.0894532203674316 d_loss:1.510374240577221 (f_loss=-0.10051602870225906 r_loss=0.876491904258728 GP=0.734398365020752)
[Training] epoch:503 step:200 g_loss:1.0781742334365845 d_loss:1.3974367380142212 (f_loss=-0.059676557779312134 r_loss=0.9839129447937012 GP=0.47320035099983215)
[Training] epoch:503 step:300 g_loss:1.022354245185852 d_loss:1.0662816241383553 (f_loss=-0.11712335795164108 r_loss=1.024500846862793 GP=0.15890413522720337)
[Training] epoch:504 step:0 g_loss:1.021012783050537 d_loss:1.1828490942716599 (f_loss=-0.11130489408969879 r_loss=0.9603604674339294 GP=0.3337935209274292)
[Training] epoch:504 step:100 g_loss:1.0281158685684204 d_loss:1.6146083902567625 (f_loss=-0.0308810044080019 r_loss=0.7698231339454651 GP=0.8756662607192993)
[Training] epoch:504 step:200 g_loss:1.0911648273468018 d_loss:1.585299912840128 (f_loss=-0.001119907945394516 r_loss=0.9519823789596558 GP=0.6344374418258667)
[Training] epoch:504 step:300 g_loss:1.1035724878311157 d_loss:1.494870875030756 (f_loss=-0.03517421707510948 r_loss=0.953448474407196 GP=0.5765966176986694)
[Training] epoch:505 step:0 g_loss:0.9969045519828796 d_loss:2.591861754655838 (f_loss=-0.0702696144580841 r_loss=0.8016194701194763 GP=1.8605118989944458)
[Training] epoch:505 step:100 g_loss:1.0298274755477905 d_loss:1.094556212425232 (f_loss=-0.0067801326513290405 r_loss=0.9776760935783386 GP=0.12366025149822235)
[Training] epoch:505 step:200 g_loss:1.0580693483352661 d_loss:1.6428752290084958 (f_loss=-0.0028931749984622 r_loss=0.945559024810791 GP=0.700209379196167)
[Training] epoch:505 step:300 g_loss:1.0244500637054443 d_loss:1.6127519011497498 (f_loss=-0.04243594408035278 r_loss=0.9604045152664185 GP=0.6947833299636841)
[Training] epoch:506 step:0 g_loss:1.0785599946975708 d_loss:1.5701801180839539 (f_loss=-0.05461770296096802 r_loss=0.7794343829154968 GP=0.845363438129425)
[Training] epoch:506 step:100 g_loss:1.0554249286651611 d_loss:1.4667588025331497 (f_loss=-0.05734585225582123 r_loss=0.8940089344978333 GP=0.6300957202911377)
[Training] epoch:506 step:200 g_loss:1.0890700817108154 d_loss:1.4230926297605038 (f_loss=-0.02114257588982582 r_loss=1.0867615938186646 GP=0.35747361183166504)
[Training] epoch:506 step:300 g_loss:1.0438764095306396 d_loss:1.2109197601675987 (f_loss=-0.05248317867517471 r_loss=0.9055064916610718 GP=0.35789644718170166)
[Training] epoch:507 step:0 g_loss:1.008041501045227 d_loss:1.6227064654231071 (f_loss=-0.10481531172990799 r_loss=0.8211658596992493 GP=0.9063559174537659)
[Training] epoch:507 step:100 g_loss:1.0766808986663818 d_loss:1.226843237876892 (f_loss=-0.09497237205505371 r_loss=0.9692773818969727 GP=0.35253822803497314)
[Training] epoch:507 step:200 g_loss:0.9978987574577332 d_loss:1.2210412845015526 (f_loss=-0.0065661147236824036 r_loss=1.0062741041183472 GP=0.22133329510688782)
[Training] epoch:507 step:300 g_loss:1.0876383781433105 d_loss:1.247337982058525 (f_loss=-0.05115233361721039 r_loss=0.9692522883415222 GP=0.32923802733421326)
[Training] epoch:508 step:0 g_loss:1.0392626523971558 d_loss:1.1442267149686813 (f_loss=-0.06472466886043549 r_loss=1.0201417207717896 GP=0.18880966305732727)
[Training] epoch:508 step:100 g_loss:0.987168550491333 d_loss:1.583151251077652 (f_loss=-0.08597108721733093 r_loss=0.8796340823173523 GP=0.7894882559776306)
[Training] epoch:508 step:200 g_loss:1.0693809986114502 d_loss:1.4336980395019054 (f_loss=-0.04100813344120979 r_loss=0.9518986344337463 GP=0.5228075385093689)
[Training] epoch:508 step:300 g_loss:1.1253857612609863 d_loss:1.7963111698627472 (f_loss=-0.12520566582679749 r_loss=0.9748632907867432 GP=0.9466535449028015)
[Training] epoch:509 step:0 g_loss:1.07938814163208 d_loss:1.1325363740324974 (f_loss=-0.06360094994306564 r_loss=0.9821909070014954 GP=0.2139464169740677)
[Training] epoch:509 step:100 g_loss:1.0964230298995972 d_loss:1.2610119367018342 (f_loss=-0.009102902375161648 r_loss=0.8863723278045654 GP=0.3837425112724304)
[Training] epoch:509 step:200 g_loss:1.113250494003296 d_loss:1.302275910973549 (f_loss=-0.05417381227016449 r_loss=1.004164457321167 GP=0.3522852659225464)
[Training] epoch:509 step:300 g_loss:1.072744369506836 d_loss:2.1064231246709824 (f_loss=-0.06155230104923248 r_loss=0.9867631196975708 GP=1.181212306022644)
[Training] epoch:510 step:0 g_loss:1.0179831981658936 d_loss:1.2471682168543339 (f_loss=-0.053467120975255966 r_loss=0.9567521810531616 GP=0.3438831567764282)

[Training] epoch:510 step:100 g_loss:1.0619854927062988 d_loss:1.2795428559184074 (f_loss=-0.09314502030611038 r_loss=1.0679322481155396 GP=0.30475562810897827)
[Training] epoch:510 step:200 g_loss:1.0602748394012451 d_loss:1.4109506327658892 (f_loss=-0.015753058716654778 r_loss=1.0099319219589233 GP=0.4167717695236206)
[Training] epoch:510 step:300 g_loss:1.0406014919281006 d_loss:1.1870615035295486 (f_loss=-0.041749030351638794 r_loss=0.9858757853507996 GP=0.24293474853038788)
[Training] epoch:511 step:0 g_loss:1.0234673023223877 d_loss:1.2132937014102936 (f_loss=-0.03468960523605347 r_loss=0.8839756846427917 GP=0.3640076220035553)
[Training] epoch:511 step:100 g_loss:1.0827643871307373 d_loss:1.3563317693769932 (f_loss=-0.024321194738149643 r_loss=0.8535872101783752 GP=0.5270657539367676)
[Training] epoch:511 step:200 g_loss:1.0977826118469238 d_loss:1.2781109064817429 (f_loss=-0.08100910484790802 r_loss=0.9834622740745544 GP=0.37565773725509644)
[Training] epoch:511 step:300 g_loss:1.0892363786697388 d_loss:1.4144447594881058 (f_loss=-0.09215806424617767 r_loss=0.8303276300430298 GP=0.6762751936912537)
[Training] epoch:512 step:0 g_loss:1.0376088619232178 d_loss:2.0543295107781887 (f_loss=-0.061056021600961685 r_loss=0.9699544906616211 GP=1.1454310417175293)
[Training] epoch:512 step:100 g_loss:1.0397545099258423 d_loss:1.7419862542301416 (f_loss=-0.003703674301505089 r_loss=0.9895240068435669 GP=0.7561659216880798)
[Training] epoch:512 step:200 g_loss:1.0891042947769165 d_loss:1.5404497757554054 (f_loss=-0.007264040410518646 r_loss=0.8735532164573669 GP=0.6741605997085571)
[Training] epoch:512 step:300 g_loss:1.0620959997177124 d_loss:1.6956560239195824 (f_loss=-0.051653243601322174 r_loss=0.8650976419448853 GP=0.8822116255760193)
[Training] epoch:513 step:0 g_loss:1.0887115001678467 d_loss:1.7639374658465385 (f_loss=-0.07288987189531326 r_loss=0.863013744354248 GP=0.9738135933876038)
[Training] epoch:513 step:100 g_loss:1.0904361009597778 d_loss:1.2157847583293915 (f_loss=-0.07310912013053894 r_loss=1.0303053855895996 GP=0.2585884928703308)
[Training] epoch:513 step:200 g_loss:1.0535809993743896 d_loss:1.5788198038935661 (f_loss=-0.028737910091876984 r_loss=1.0904772281646729 GP=0.5170804858207703)
[Training] epoch:513 step:300 g_loss:1.0977239608764648 d_loss:1.6991968005895615 (f_loss=-0.07057560980319977 r_loss=0.9401600360870361 GP=0.8296123743057251)
[Training] epoch:514 step:0 g_loss:1.0716217756271362 d_loss:1.7608926594257355 (f_loss=-0.053271204233169556 r_loss=0.9665936231613159 GP=0.8475702404975891)
[Training] epoch:514 step:100 g_loss:1.0128034353256226 d_loss:1.316909745335579 (f_loss=-0.08777405321598053 r_loss=0.9751423001289368 GP=0.4295414984226227)
[Training] epoch:514 step:200 g_loss:1.093325138092041 d_loss:1.3313624747097492 (f_loss=-0.04200134798884392 r_loss=0.9495565891265869 GP=0.4238072335720062)
[Training] epoch:514 step:300 g_loss:1.0799740552902222 d_loss:1.0785947106778622 (f_loss=-0.032395217567682266 r_loss=0.92357337474823 GP=0.18741655349731445)
[Training] epoch:515 step:0 g_loss:1.100679636001587 d_loss:1.2628445327281952 (f_loss=-0.01807171106338501 r_loss=0.9810239672660828 GP=0.29989227652549744)
[Training] epoch:515 step:100 g_loss:1.0701904296875 d_loss:1.2736679464578629 (f_loss=-0.09078146517276764 r_loss=0.9803734421730042 GP=0.38407596945762634)
[Training] epoch:515 step:200 g_loss:1.107460856437683 d_loss:1.3633896969258785 (f_loss=-0.04969135299324989 r_loss=1.0158360004425049 GP=0.39724504947662354)
[Training] epoch:515 step:300 g_loss:1.1071735620498657 d_loss:1.4704281203448772 (f_loss=-0.04203836992383003 r_loss=1.0391995906829834 GP=0.4732668995857239)
[Training] epoch:516 step:0 g_loss:1.0667076110839844 d_loss:1.1437127888202667 (f_loss=-0.10887369513511658 r_loss=0.9206679463386536 GP=0.33191853761672974)
[Training] epoch:516 step:100 g_loss:1.0136377811431885 d_loss:1.5352365300059319 (f_loss=-0.09663558751344681 r_loss=0.9027252793312073 GP=0.7291468381881714)
[Training] epoch:516 step:200 g_loss:1.0881109237670898 d_loss:1.0993957594037056 (f_loss=-0.07030723243951797 r_loss=0.9738365411758423 GP=0.1958664506673813)
[Training] epoch:516 step:300 g_loss:1.0326926708221436 d_loss:1.8594539277255535 (f_loss=-0.04775111749768257 r_loss=0.9480238556861877 GP=0.9591811895370483)
[Training] epoch:517 step:0 g_loss:1.077141523361206 d_loss:1.2751787528395653 (f_loss=-0.06707803159952164 r_loss=1.0048365592956543 GP=0.3374202251434326)
[Training] epoch:517 step:100 g_loss:1.066609263420105 d_loss:1.1972366645932198 (f_loss=-0.07749374955892563 r_loss=0.97450852394104 GP=0.30022189021110535)
[Training] epoch:517 step:200 g_loss:1.0647032260894775 d_loss:1.429236352443695 (f_loss=-0.08109700679779053 r_loss=0.9369509220123291 GP=0.5733824372291565)
[Training] epoch:517 step:300 g_loss:1.0486522912979126 d_loss:1.3253371566534042 (f_loss=-0.06261362135410309 r_loss=0.9333484768867493 GP=0.45460230112075806)
[Training] epoch:518 step:0 g_loss:1.0675314664840698 d_loss:1.2036715596914291 (f_loss=-0.07048015296459198 r_loss=0.8927106261253357 GP=0.3814410865306854)
[Training] epoch:518 step:100 g_loss:1.0191270112991333 d_loss:1.4949873387813568 (f_loss=-0.11520275473594666 r_loss=1.0319929122924805 GP=0.578197181224823)
[Training] epoch:518 step:200 g_loss:1.029628038406372 d_loss:1.2566739320755005 (f_loss=-0.024559929966926575 r_loss=1.034523606300354 GP=0.24671025574207306)
[Training] epoch:518 step:300 g_loss:1.0869390964508057 d_loss:2.258034773170948 (f_loss=-0.10706429928541183 r_loss=0.8616920709609985 GP=1.5034070014953613)
[Training] epoch:519 step:0 g_loss:1.006434440612793 d_loss:1.7837147936224937 (f_loss=-0.08448628336191177 r_loss=0.7986916899681091 GP=1.0695093870162964)
[Training] epoch:519 step:100 g_loss:1.100265383720398 d_loss:1.9262664169073105 (f_loss=-0.07872720062732697 r_loss=0.9936469197273254 GP=1.011346697807312)
[Training] epoch:519 step:200 g_loss:1.096234917640686 d_loss:1.571270190179348 (f_loss=-0.07833615690469742 r_loss=0.7939814329147339 GP=0.8556249141693115)
[Training] epoch:519 step:300 g_loss:1.039624810218811 d_loss:2.181247517466545 (f_loss=-0.07822103798389435 r_loss=0.9640786647796631 GP=1.2953898906707764)
[Training] epoch:520 step:0 g_loss:0.9866045713424683 d_loss:1.0488920584321022 (f_loss=-0.08485416322946548 r_loss=0.9423720836639404 GP=0.19137413799762726)

[Training] epoch:520 step:100 g_loss:1.0860270261764526 d_loss:1.4982406347990036 (f_loss=-0.07285673916339874 r_loss=0.8969649076461792 GP=0.6741324663162231)
[Training] epoch:520 step:200 g_loss:1.032631516456604 d_loss:1.2029052525758743 (f_loss=-0.09614013135433197 r_loss=1.0044420957565308 GP=0.29460328817367554)
[Training] epoch:520 step:300 g_loss:1.081018328666687 d_loss:1.2604903727769852 (f_loss=-0.0811256617307663 r_loss=1.039146900177002 GP=0.3024691343307495)
[Training] epoch:521 step:0 g_loss:0.9916158318519592 d_loss:1.1224667876958847 (f_loss=-0.0768858790397644 r_loss=0.9509516358375549 GP=0.24840103089809418)
[Training] epoch:521 step:100 g_loss:1.0719751119613647 d_loss:1.8116691038012505 (f_loss=-0.06870842725038528 r_loss=0.8787083625793457 GP=1.00166916847229)
[Training] epoch:521 step:200 g_loss:0.9572787284851074 d_loss:1.9105069115757942 (f_loss=-0.052077822387218475 r_loss=0.8903741836547852 GP=1.0722105503082275)
[Training] epoch:521 step:300 g_loss:1.0640989542007446 d_loss:1.2515563517808914 (f_loss=-0.08253185451030731 r_loss=0.9334842562675476 GP=0.4006039500236511)
[Training] epoch:522 step:0 g_loss:1.1526612043380737 d_loss:1.3874955102801323 (f_loss=-0.07251454144716263 r_loss=0.9162544012069702 GP=0.5437556505203247)
[Training] epoch:522 step:100 g_loss:1.0663387775421143 d_loss:1.117462381720543 (f_loss=-0.12579648196697235 r_loss=1.0844372510910034 GP=0.15882161259651184)
[Training] epoch:522 step:200 g_loss:1.0566624402999878 d_loss:1.7828291503246874 (f_loss=0.0009124127682298422 r_loss=1.0315346717834473 GP=0.7503820657730103)
[Training] epoch:522 step:300 g_loss:1.0000945329666138 d_loss:1.6425135284662247 (f_loss=-0.10834638774394989 r_loss=0.8610789179801941 GP=0.8897809982299805)
[Training] epoch:523 step:0 g_loss:1.0596708059310913 d_loss:1.4431028366088867 (f_loss=-0.09745049476623535 r_loss=0.9048378467559814 GP=0.6357154846191406)
[Training] epoch:523 step:100 g_loss:1.0387663841247559 d_loss:1.5159855410456657 (f_loss=-0.06625653058290482 r_loss=0.9405838847160339 GP=0.6416581869125366)
[Training] epoch:523 step:200 g_loss:1.0465588569641113 d_loss:1.7337338104844093 (f_loss=-0.06336840242147446 r_loss=0.9852541089057922 GP=0.8118481040000916)
[Training] epoch:523 step:300 g_loss:1.0686402320861816 d_loss:2.0616289526224136 (f_loss=-0.11947040259838104 r_loss=0.8789183497428894 GP=1.3021810054779053)
[Training] epoch:524 step:0 g_loss:1.0670832395553589 d_loss:1.159931629896164 (f_loss=-0.10759463906288147 r_loss=1.0795778036117554 GP=0.18794846534729004)
[Training] epoch:524 step:100 g_loss:1.0318503379821777 d_loss:2.8956591486930847 (f_loss=-0.11947554349899292 r_loss=0.8195270299911499 GP=2.1956076622009277)
[Training] epoch:524 step:200 g_loss:1.0510687828063965 d_loss:1.2148221880197525 (f_loss=-0.10232992470264435 r_loss=1.019221544265747 GP=0.2979305684566498)
[Training] epoch:524 step:300 g_loss:1.074523687362671 d_loss:1.0930701792240143 (f_loss=-0.07966673374176025 r_loss=1.0234898328781128 GP=0.14924708008766174)
[Training] epoch:525 step:0 g_loss:1.066908359527588 d_loss:1.775271713733673 (f_loss=-0.04611414670944214 r_loss=0.8572876453399658 GP=0.9640982151031494)
[Training] epoch:525 step:100 g_loss:1.0749386548995972 d_loss:1.8055895566940308 (f_loss=-0.10693055391311646 r_loss=0.8122826218605042 GP=1.100237488746643)
[Training] epoch:525 step:200 g_loss:1.0994832515716553 d_loss:1.2223300784826279 (f_loss=-0.09485118091106415 r_loss=0.9488223195075989 GP=0.36835893988609314)
[Training] epoch:525 step:300 g_loss:1.0590325593948364 d_loss:1.23604716360569 (f_loss=-0.10804657638072968 r_loss=0.9588450789451599 GP=0.38524866104125977)
[Training] epoch:526 step:0 g_loss:1.086116075515747 d_loss:1.196290735155344 (f_loss=-0.0331035815179348 r_loss=0.9708823561668396 GP=0.2585119605064392)
[Training] epoch:526 step:100 g_loss:1.0957682132720947 d_loss:1.2779599875211716 (f_loss=-0.06473641097545624 r_loss=0.984747588634491 GP=0.35794880986213684)
[Training] epoch:526 step:200 g_loss:1.1035785675048828 d_loss:1.5405005663633347 (f_loss=-0.09852613508701324 r_loss=0.9206531047821045 GP=0.7183735966682434)
[Training] epoch:526 step:300 g_loss:1.11937415599823 d_loss:1.2049733437597752 (f_loss=-0.05247938260436058 r_loss=0.9325641393661499 GP=0.32488858699798584)
[Training] epoch:527 step:0 g_loss:1.0687000751495361 d_loss:1.6272694170475006 (f_loss=-0.11905571818351746 r_loss=1.0370513200759888 GP=0.7092738151550293)
[Training] epoch:527 step:100 g_loss:1.0959641933441162 d_loss:3.096870996057987 (f_loss=-0.09964974969625473 r_loss=0.8536953330039978 GP=2.342825412750244)
[Training] epoch:527 step:200 g_loss:1.1098533868789673 d_loss:1.36357881128788 (f_loss=-0.08476243913173676 r_loss=0.9998412132263184 GP=0.44850003719329834)
[Training] epoch:527 step:300 g_loss:1.0955297946929932 d_loss:1.968785099685192 (f_loss=-0.1109667494893074 r_loss=0.9625856876373291 GP=1.1171661615371704)
[Training] epoch:528 step:0 g_loss:1.0871102809906006 d_loss:1.2087065503001213 (f_loss=-0.11115584522485733 r_loss=1.026269555091858 GP=0.2935928404331207)
[Training] epoch:528 step:100 g_loss:1.0964939594268799 d_loss:1.579316407442093 (f_loss=-0.1388448178768158 r_loss=0.8427624106407166 GP=0.8753988146781921)
[Training] epoch:528 step:200 g_loss:1.1026023626327515 d_loss:1.359537996351719 (f_loss=-0.10085686296224594 r_loss=0.9549893736839294 GP=0.5054054856300354)
[Training] epoch:528 step:300 g_loss:1.0788743495941162 d_loss:1.9647219777107239 (f_loss=-0.1473340392112732 r_loss=0.8943262100219727 GP=1.2177298069000244)
[Training] epoch:529 step:0 g_loss:1.0752846002578735 d_loss:1.2258181720972061 (f_loss=-0.07036636769771576 r_loss=0.9600070714950562 GP=0.3361774682998657)
[Training] epoch:529 step:100 g_loss:1.0725226402282715 d_loss:2.234415289014578 (f_loss=-0.04008394852280617 r_loss=0.8874813914299011 GP=1.387017846107483)
[Training] epoch:529 step:200 g_loss:1.056243896484375 d_loss:1.7505043670535088 (f_loss=-0.07298804074525833 r_loss=1.0363532304763794 GP=0.7871391773223877)
[Training] epoch:529 step:300 g_loss:1.041162133216858 d_loss:3.1903486140072346 (f_loss=-0.05058540031313896 r_loss=0.920857310295105 GP=2.3200767040252686)
[Training] epoch:530 step:0 g_loss:1.084864854812622 d_loss:1.1176531501114368 (f_loss=-0.06207312270998955 r_loss=1.0187684297561646 GP=0.16095784306526184)

[Training] epoch:530 step:100 g_loss:1.0172616243362427 d_loss:1.3655165135860443 (f_loss=-0.16200122237205505 r_loss=0.9965858459472656 GP=0.5309318900108337)
[Training] epoch:530 step:200 g_loss:1.0844249725341797 d_loss:1.2485972195863724 (f_loss=-0.09410257637500763 r_loss=0.9746727347373962 GP=0.36802706122398376)
[Training] epoch:530 step:300 g_loss:1.0875624418258667 d_loss:3.319853290915489 (f_loss=-0.1006106287240982 r_loss=0.7079724073410034 GP=2.712491512298584)
[Training] epoch:531 step:0 g_loss:1.0645878314971924 d_loss:1.9607193022966385 (f_loss=-0.08712653815746307 r_loss=1.0264256000518799 GP=1.0214202404022217)
[Training] epoch:531 step:100 g_loss:1.1204612255096436 d_loss:2.1051808446645737 (f_loss=-0.09595741331577301 r_loss=0.8679478168487549 GP=1.3331904411315918)
[Training] epoch:531 step:200 g_loss:1.0499193668365479 d_loss:1.4309484474360943 (f_loss=-0.049270618706941605 r_loss=0.8832897543907166 GP=0.5969293117523193)
[Training] epoch:531 step:300 g_loss:1.0650131702423096 d_loss:1.2639567703008652 (f_loss=-0.056166306138038635 r_loss=1.0109046697616577 GP=0.3092184066772461)
[Training] epoch:532 step:0 g_loss:1.1163935661315918 d_loss:1.2766548842191696 (f_loss=-0.09381081163883209 r_loss=1.0085190534591675 GP=0.36194664239883423)
[Training] epoch:532 step:100 g_loss:1.0733392238616943 d_loss:1.5737914890050888 (f_loss=-0.10910417139530182 r_loss=0.987940788269043 GP=0.6949548721313477)
[Training] epoch:532 step:200 g_loss:1.0692516565322876 d_loss:1.420158013701439 (f_loss=-0.06769250333309174 r_loss=1.003777027130127 GP=0.4840734899044037)
[Training] epoch:532 step:300 g_loss:1.06033194065094 d_loss:1.4860298484563828 (f_loss=-0.08578230440616608 r_loss=1.0146939754486084 GP=0.5571181774139404)
[Training] epoch:533 step:0 g_loss:1.043184757232666 d_loss:1.3573762997984886 (f_loss=-0.07214153558015823 r_loss=0.9672726392745972 GP=0.4622451961040497)
[Training] epoch:533 step:100 g_loss:1.1136679649353027 d_loss:1.5755528826266527 (f_loss=0.0008970517665147781 r_loss=0.9151446223258972 GP=0.6595112085342407)
[Training] epoch:533 step:200 g_loss:1.0987743139266968 d_loss:1.1722161024808884 (f_loss=-0.13709546625614166 r_loss=1.0075833797454834 GP=0.30172818899154663)
[Training] epoch:533 step:300 g_loss:1.035212755203247 d_loss:2.102822370827198 (f_loss=-0.09953492134809494 r_loss=0.904460072517395 GP=1.297897219657898)
[Training] epoch:534 step:0 g_loss:1.090154767036438 d_loss:1.521363452076912 (f_loss=-0.09560666978359222 r_loss=0.9654180407524109 GP=0.6515520811080933)
[Training] epoch:534 step:100 g_loss:1.062255859375 d_loss:2.145543247461319 (f_loss=-0.10845771431922913 r_loss=0.9626175761222839 GP=1.2913833856582642)
[Training] epoch:534 step:200 g_loss:1.09016752243042 d_loss:1.2093544602394104 (f_loss=-0.09362360835075378 r_loss=0.9966244697570801 GP=0.3063535988330841)
[Training] epoch:534 step:300 g_loss:1.1179189682006836 d_loss:1.4206067472696304 (f_loss=-0.08633308112621307 r_loss=0.9808822870254517 GP=0.5260575413703918)
[Training] epoch:535 step:0 g_loss:1.1960119009017944 d_loss:1.4526505172252655 (f_loss=-0.11668971180915833 r_loss=1.0385160446166992 GP=0.5308241844177246)
[Training] epoch:535 step:100 g_loss:1.0618469715118408 d_loss:1.7114056497812271 (f_loss=-0.17375116050243378 r_loss=1.00076425075531 GP=0.8843925595283508)
[Training] epoch:535 step:200 g_loss:1.0870217084884644 d_loss:1.555432803928852 (f_loss=-0.10976909846067429 r_loss=0.9318333864212036 GP=0.7333685159683228)
[Training] epoch:535 step:300 g_loss:1.0648540258407593 d_loss:1.4974604099988937 (f_loss=-0.07654418051242828 r_loss=0.9214521050453186 GP=0.6525524854660034)
[Training] epoch:536 step:0 g_loss:1.0629359483718872 d_loss:1.6360622942447662 (f_loss=-0.07902947068214417 r_loss=0.9100034832954407 GP=0.8050882816314697)
[Training] epoch:536 step:100 g_loss:1.080833911895752 d_loss:1.4695657044649124 (f_loss=-0.09298096597194672 r_loss=0.955249011516571 GP=0.6072976589202881)
[Training] epoch:536 step:200 g_loss:1.0267122983932495 d_loss:1.8215286135673523 (f_loss=-0.12655234336853027 r_loss=0.904397189617157 GP=1.0436837673187256)
[Training] epoch:536 step:300 g_loss:1.0821254253387451 d_loss:2.6437413841485977 (f_loss=-0.11691735684871674 r_loss=0.8473355770111084 GP=1.913323163986206)
[Training] epoch:537 step:0 g_loss:1.0557557344436646 d_loss:1.2139816731214523 (f_loss=-0.11778153479099274 r_loss=1.0396558046340942 GP=0.29210740327835083)
[Training] epoch:537 step:100 g_loss:1.0985190868377686 d_loss:1.6446138694882393 (f_loss=-0.064365915954113 r_loss=1.05336594581604 GP=0.6556138396263123)
[Training] epoch:537 step:200 g_loss:1.1121975183486938 d_loss:1.363748550415039 (f_loss=-0.13520485162734985 r_loss=0.9606031179428101 GP=0.5383502840995789)
[Training] epoch:537 step:300 g_loss:1.122100591659546 d_loss:1.1933164298534393 (f_loss=-0.10802927613258362 r_loss=1.0607342720031738 GP=0.24061143398284912)
[Training] epoch:538 step:0 g_loss:1.1051329374313354 d_loss:1.72213576734066 (f_loss=-0.07825292646884918 r_loss=0.9656044840812683 GP=0.834784209728241)
[Training] epoch:538 step:100 g_loss:1.1300699710845947 d_loss:2.328482910990715 (f_loss=-0.09704764187335968 r_loss=0.8722604513168335 GP=1.5532701015472412)
[Training] epoch:538 step:200 g_loss:1.0764397382736206 d_loss:1.255166843533516 (f_loss=-0.11753378808498383 r_loss=0.9365966320037842 GP=0.4361039996147156)
[Training] epoch:538 step:300 g_loss:1.082098126411438 d_loss:1.8964677453041077 (f_loss=-0.06402397155761719 r_loss=0.9033918976783752 GP=1.0570998191833496)
[Training] epoch:539 step:0 g_loss:1.1494214534759521 d_loss:1.8774971067905426 (f_loss=-0.07052162289619446 r_loss=0.9795562028884888 GP=0.9684625267982483)
[Training] epoch:539 step:100 g_loss:1.1367721557617188 d_loss:1.4335580915212631 (f_loss=-0.11977596580982208 r_loss=0.9954125881195068 GP=0.5579214692115784)
[Training] epoch:539 step:200 g_loss:1.0601105690002441 d_loss:1.5431111007928848 (f_loss=-0.07735393941402435 r_loss=0.9891266226768494 GP=0.6313384175300598)
[Training] epoch:539 step:300 g_loss:1.034198522567749 d_loss:1.2862987965345383 (f_loss=-0.07121680676937103 r_loss=0.9882748126983643 GP=0.36924079060554504)
[Training] epoch:540 step:0 g_loss:1.137072205543518 d_loss:1.1845179349184036 (f_loss=-0.1387062817811966 r_loss=0.9672946333885193 GP=0.35592958331108093)

[Training] epoch:540 step:100 g_loss:1.094374418258667 d_loss:1.5582706332206726 (f_loss=-0.07607269287109375 r_loss=0.9572795033454895 GP=0.6770638227462769)
[Training] epoch:540 step:200 g_loss:1.1262023448944092 d_loss:1.8383597806096077 (f_loss=-0.11546462029218674 r_loss=0.9235398769378662 GP=1.0302845239639282)
[Training] epoch:540 step:300 g_loss:1.0917134284973145 d_loss:1.6790733933448792 (f_loss=-0.11271768808364868 r_loss=1.029805064201355 GP=0.7619860172271729)
[Training] epoch:541 step:0 g_loss:1.1202155351638794 d_loss:1.1870445609092712 (f_loss=-0.1262771189212799 r_loss=1.0110375881195068 GP=0.3022840917110443)
[Training] epoch:541 step:100 g_loss:1.084917664527893 d_loss:1.2494329661130905 (f_loss=-0.16365890204906464 r_loss=1.0774849653244019 GP=0.3356069028377533)
[Training] epoch:541 step:200 g_loss:1.0787434577941895 d_loss:1.1476476415991783 (f_loss=-0.06580986827611923 r_loss=0.9668915867805481 GP=0.24656592309474945)
[Training] epoch:541 step:300 g_loss:1.043068289756775 d_loss:1.6911949589848518 (f_loss=-0.11322050541639328 r_loss=0.9905695915222168 GP=0.8138458728790283)
[Training] epoch:542 step:0 g_loss:1.1628000736236572 d_loss:1.2164652198553085 (f_loss=-0.14695106446743011 r_loss=0.9092859625816345 GP=0.4541303217411041)
[Training] epoch:542 step:100 g_loss:1.0897455215454102 d_loss:1.8249970227479935 (f_loss=-0.10954581201076508 r_loss=0.9448695778846741 GP=0.9896732568740845)
[Training] epoch:542 step:200 g_loss:1.087314486503601 d_loss:1.5523964315652847 (f_loss=-0.0904196947813034 r_loss=0.9844713807106018 GP=0.6583447456359863)
[Training] epoch:542 step:300 g_loss:1.1110360622406006 d_loss:1.3420266062021255 (f_loss=-0.11636839807033539 r_loss=1.0638760328292847 GP=0.39451897144317627)
[Training] epoch:543 step:0 g_loss:1.153158187866211 d_loss:1.4208372980356216 (f_loss=-0.08018063008785248 r_loss=1.0027711391448975 GP=0.49824678897857666)
[Training] epoch:543 step:100 g_loss:1.1123175621032715 d_loss:1.0691729933023453 (f_loss=-0.14163491129875183 r_loss=1.0529704093933105 GP=0.15783749520778656)
[Training] epoch:543 step:200 g_loss:1.106698751449585 d_loss:1.3927780836820602 (f_loss=-0.117780402302742 r_loss=1.1021535396575928 GP=0.4084049463272095)
[Training] epoch:543 step:300 g_loss:1.1391429901123047 d_loss:1.1907733976840973 (f_loss=-0.11179745197296143 r_loss=1.0201715230941772 GP=0.28239932656288147)
[Training] epoch:544 step:0 g_loss:1.1414659023284912 d_loss:1.8607679158449173 (f_loss=-0.123857781291008 r_loss=0.7908167839050293 GP=1.193808913230896)
[Training] epoch:544 step:100 g_loss:1.1133251190185547 d_loss:1.4617639929056168 (f_loss=-0.09505318105220795 r_loss=0.860689640045166 GP=0.6961275339126587)
[Training] epoch:544 step:200 g_loss:1.0967934131622314 d_loss:2.6266596242785454 (f_loss=-0.1213233545422554 r_loss=0.9212585687637329 GP=1.8267244100570679)
[Training] epoch:544 step:300 g_loss:1.1094285249710083 d_loss:1.326802983880043 (f_loss=-0.07739852368831635 r_loss=1.092417597770691 GP=0.31178390979766846)
[Training] epoch:545 step:0 g_loss:1.119946002960205 d_loss:1.7766529694199562 (f_loss=-0.06619074195623398 r_loss=0.8880254626274109 GP=0.9548182487487793)
[Training] epoch:545 step:100 g_loss:1.1542243957519531 d_loss:1.1361941397190094 (f_loss=-0.14276334643363953 r_loss=0.9399564266204834 GP=0.3390010595321655)
[Training] epoch:545 step:200 g_loss:1.1131839752197266 d_loss:2.8743947818875313 (f_loss=-0.0847892090678215 r_loss=0.8157108426094055 GP=2.1434731483459473)
[Training] epoch:545 step:300 g_loss:1.134192943572998 d_loss:2.0628103837370872 (f_loss=-0.0875261202454567 r_loss=0.9326101541519165 GP=1.2177263498306274)
[Training] epoch:546 step:0 g_loss:1.1004157066345215 d_loss:1.4496568739414215 (f_loss=-0.1349720060825348 r_loss=0.9223288893699646 GP=0.6622999906539917)
[Training] epoch:546 step:100 g_loss:1.0942566394805908 d_loss:1.2602111250162125 (f_loss=-0.13678519427776337 r_loss=1.029220461845398 GP=0.3677758574485779)
[Training] epoch:546 step:200 g_loss:1.063891887664795 d_loss:1.3984688743948936 (f_loss=-0.10874218493700027 r_loss=1.0360709428787231 GP=0.4711401164531708)
[Training] epoch:546 step:300 g_loss:1.1173187494277954 d_loss:1.9555382207036018 (f_loss=-0.10167115181684494 r_loss=1.0319736003875732 GP=1.0252357721328735)
[Training] epoch:547 step:0 g_loss:1.1063607931137085 d_loss:1.6681003645062447 (f_loss=-0.11984293907880783 r_loss=0.9150875806808472 GP=0.8728557229042053)
[Training] epoch:547 step:100 g_loss:1.1079771518707275 d_loss:1.6351531855762005 (f_loss=-0.056056369096040726 r_loss=0.917826771736145 GP=0.7733827829360962)
[Training] epoch:547 step:200 g_loss:1.0758638381958008 d_loss:1.2386012077331543 (f_loss=-0.1439952850341797 r_loss=1.040238380432129 GP=0.3423581123352051)
[Training] epoch:547 step:300 g_loss:1.0382459163665771 d_loss:1.3679673075675964 (f_loss=-0.10981708765029907 r_loss=0.9280294179916382 GP=0.5497549772262573)
[Training] epoch:548 step:0 g_loss:1.1290335655212402 d_loss:1.446414977312088 (f_loss=-0.14070335030555725 r_loss=0.9470742344856262 GP=0.640044093132019)
[Training] epoch:548 step:100 g_loss:1.1019818782806396 d_loss:1.2547675669193268 (f_loss=-0.07009300589561462 r_loss=1.0468449592590332 GP=0.2780156135559082)
[Training] epoch:548 step:200 g_loss:1.1613893508911133 d_loss:1.8050657510757446 (f_loss=-0.15273386240005493 r_loss=1.015990138053894 GP=0.9418094754219055)
[Training] epoch:548 step:300 g_loss:1.034421443939209 d_loss:1.0824859887361526 (f_loss=-0.13390739262104034 r_loss=0.9723895788192749 GP=0.2440038025379181)
[Training] epoch:549 step:0 g_loss:1.1535733938217163 d_loss:1.973786324262619 (f_loss=-0.14176854491233826 r_loss=0.8903798460960388 GP=1.2251750230789185)
[Training] epoch:549 step:100 g_loss:1.1057641506195068 d_loss:1.3095632418990135 (f_loss=-0.10144452005624771 r_loss=0.9854801893234253 GP=0.42552757263183594)
[Training] epoch:549 step:200 g_loss:1.1158238649368286 d_loss:1.464553788304329 (f_loss=-0.07971398532390594 r_loss=0.9678317308425903 GP=0.5764360427856445)
[Training] epoch:549 step:300 g_loss:1.1364271640777588 d_loss:1.696930080652237 (f_loss=-0.13501301407814026 r_loss=0.947955846786499 GP=0.8839872479438782)
[Training] epoch:550 step:0 g_loss:1.0468297004699707 d_loss:3.019729256629944 (f_loss=-0.1071159839630127 r_loss=0.9551552534103394 GP=2.171689987182617)

[Training] epoch:550 step:100 g_loss:1.047143816947937 d_loss:2.6632338240742683 (f_loss=-0.09398537129163742 r_loss=0.8925341367721558 GP=1.86468505859375)
[Training] epoch:550 step:200 g_loss:1.138081669807434 d_loss:1.3037725612521172 (f_loss=-0.06432027369737625 r_loss=0.9718393683433533 GP=0.39625346660614014)
[Training] epoch:550 step:300 g_loss:1.0447367429733276 d_loss:1.6790674403309822 (f_loss=-0.09783565253019333 r_loss=0.9807739853858948 GP=0.7961291074752808)
[Training] epoch:551 step:0 g_loss:1.1276345252990723 d_loss:1.364072322845459 (f_loss=-0.1490929126739502 r_loss=1.0603818893432617 GP=0.45278334617614746)
[Training] epoch:551 step:100 g_loss:1.0500725507736206 d_loss:2.5819329768419266 (f_loss=-0.09015648066997528 r_loss=0.9079161882400513 GP=1.7641732692718506)
[Training] epoch:551 step:200 g_loss:1.1132960319519043 d_loss:1.5078226700425148 (f_loss=-0.08335699886083603 r_loss=0.9452837705612183 GP=0.6458958983421326)
[Training] epoch:551 step:300 g_loss:1.0772291421890259 d_loss:1.1179795116186142 (f_loss=-0.1336764395236969 r_loss=1.0541692972183228 GP=0.19748665392398834)
[Training] epoch:552 step:0 g_loss:1.1509137153625488 d_loss:2.324261412024498 (f_loss=-0.0942545086145401 r_loss=1.0512094497680664 GP=1.3673064708709717)
[Training] epoch:552 step:100 g_loss:1.1307337284088135 d_loss:0.9569159746170044 (f_loss=-0.14796124398708344 r_loss=0.9805407524108887 GP=0.12433646619319916)
[Training] epoch:552 step:200 g_loss:1.123225450515747 d_loss:1.3167912662029266 (f_loss=-0.1337694525718689 r_loss=1.0585731267929077 GP=0.3919875919818878)
[Training] epoch:552 step:300 g_loss:0.9930851459503174 d_loss:1.2271099090576172 (f_loss=-0.12545815110206604 r_loss=1.0242981910705566 GP=0.3282698690891266)
[Training] epoch:553 step:0 g_loss:1.059632420539856 d_loss:1.599839523434639 (f_loss=-0.15368036925792694 r_loss=0.9148172736167908 GP=0.8387026190757751)
[Training] epoch:553 step:100 g_loss:1.1495170593261719 d_loss:1.524805709719658 (f_loss=-0.10541875660419464 r_loss=0.9421513676643372 GP=0.6880730986595154)
[Training] epoch:553 step:200 g_loss:1.0671435594558716 d_loss:1.4842187836766243 (f_loss=-0.10843157023191452 r_loss=0.9952423572540283 GP=0.5974079966545105)
[Training] epoch:553 step:300 g_loss:1.0326448678970337 d_loss:1.1247795075178146 (f_loss=-0.11259737610816956 r_loss=1.1068261861801147 GP=0.13055069744586945)
[Training] epoch:554 step:0 g_loss:1.0817376375198364 d_loss:1.8062178939580917 (f_loss=-0.10991968214511871 r_loss=0.8598521947860718 GP=1.0562853813171387)
[Training] epoch:554 step:100 g_loss:1.0443843603134155 d_loss:1.3444078229367733 (f_loss=-0.061631206423044205 r_loss=0.9604226350784302 GP=0.44561639428138733)
[Training] epoch:554 step:200 g_loss:1.1572784185409546 d_loss:1.400598719716072 (f_loss=-0.09892593324184418 r_loss=1.057202696800232 GP=0.4423219561576843)
[Training] epoch:554 step:300 g_loss:1.0728572607040405 d_loss:1.3162949532270432 (f_loss=-0.10661144554615021 r_loss=1.0295898914337158 GP=0.39331650733947754)
[Training] epoch:555 step:0 g_loss:1.0919909477233887 d_loss:1.944284364581108 (f_loss=-0.1470879465341568 r_loss=0.9418187737464905 GP=1.1495535373687744)
[Training] epoch:555 step:100 g_loss:1.1604725122451782 d_loss:2.462354004383087 (f_loss=-0.1287439465522766 r_loss=1.0769885778427124 GP=1.5141093730926514)
[Training] epoch:555 step:200 g_loss:1.0284305810928345 d_loss:1.5105305016040802 (f_loss=-0.08625689148902893 r_loss=0.9931933283805847 GP=0.6035940647125244)
[Training] epoch:555 step:300 g_loss:1.124679446220398 d_loss:1.1357110813260078 (f_loss=-0.11868292838335037 r_loss=1.0360454320907593 GP=0.21834857761859894)
[Training] epoch:556 step:0 g_loss:1.1045039892196655 d_loss:1.5183349400758743 (f_loss=-0.09141390025615692 r_loss=0.9799580574035645 GP=0.6297907829284668)
[Training] epoch:556 step:100 g_loss:1.1314809322357178 d_loss:1.3334922939538956 (f_loss=-0.13474155962467194 r_loss=0.9987842440605164 GP=0.46944960951805115)
[Training] epoch:556 step:200 g_loss:1.1217193603515625 d_loss:1.571807123720646 (f_loss=-0.10280134528875351 r_loss=0.9443913102149963 GP=0.7302171587944031)
[Training] epoch:556 step:300 g_loss:1.1260172128677368 d_loss:1.221553310751915 (f_loss=-0.11959077417850494 r_loss=1.0776238441467285 GP=0.2635202407836914)
[Training] epoch:557 step:0 g_loss:1.0929796695709229 d_loss:1.3605814278125763 (f_loss=-0.159308522939682 r_loss=1.0956882238388062 GP=0.42420172691345215)
[Training] epoch:557 step:100 g_loss:1.1197898387908936 d_loss:1.163788303732872 (f_loss=-0.14540670812129974 r_loss=1.0600812435150146 GP=0.2491137683391571)
[Training] epoch:557 step:200 g_loss:1.120261788368225 d_loss:1.2070514783263206 (f_loss=-0.06473556905984879 r_loss=1.019810676574707 GP=0.2519763708114624)
[Training] epoch:557 step:300 g_loss:1.0928486585617065 d_loss:1.2290521636605263 (f_loss=-0.12060945481061935 r_loss=1.0352402925491333 GP=0.31442132592201233)
[Training] epoch:558 step:0 g_loss:1.1285024881362915 d_loss:1.5573302134871483 (f_loss=-0.12113646417856216 r_loss=0.8739401698112488 GP=0.8045265078544617)
[Training] epoch:558 step:100 g_loss:1.0650595426559448 d_loss:1.4324845299124718 (f_loss=-0.07813171297311783 r_loss=1.0662860870361328 GP=0.4443301558494568)
[Training] epoch:558 step:200 g_loss:1.0415582656860352 d_loss:1.382912129163742 (f_loss=-0.11105719208717346 r_loss=1.0966763496398926 GP=0.39729297161102295)
[Training] epoch:558 step:300 g_loss:1.111646294593811 d_loss:2.295337200164795 (f_loss=-0.1704387664794922 r_loss=1.0615650415420532 GP=1.4042109251022339)
[Training] epoch:559 step:0 g_loss:1.0929577350616455 d_loss:1.6884420216083527 (f_loss=-0.15311148762702942 r_loss=1.0487664937973022 GP=0.7927870154380798)
[Training] epoch:559 step:100 g_loss:1.113336443901062 d_loss:1.2432448714971542 (f_loss=-0.12710575759410858 r_loss=1.000637173652649 GP=0.3697134554386139)
[Training] epoch:559 step:200 g_loss:1.1752903461456299 d_loss:1.480429746210575 (f_loss=-0.1104673370718956 r_loss=1.0154849290847778 GP=0.5754121541976929)
[Training] epoch:559 step:300 g_loss:1.1509310007095337 d_loss:1.4715994223952293 (f_loss=-0.09322533756494522 r_loss=0.8733859062194824 GP=0.6914388537406921)
[Training] epoch:560 step:0 g_loss:1.1088244915008545 d_loss:1.206199437379837 (f_loss=-0.15731406211853027 r_loss=0.980226993560791 GP=0.3832865059375763)

[Training] epoch:560 step:100 g_loss:1.1479202508926392 d_loss:1.7674238085746765 (f_loss=-0.11434262990951538 r_loss=0.875786304473877 GP=1.005980134010315)
[Training] epoch:560 step:200 g_loss:1.1663458347320557 d_loss:1.1042265444993973 (f_loss=-0.1478518694639206 r_loss=0.9491461515426636 GP=0.3029322624206543)
[Training] epoch:560 step:300 g_loss:1.176077961921692 d_loss:1.2491903454065323 (f_loss=-0.16479839384555817 r_loss=1.0206634998321533 GP=0.39332523941993713)
[Training] epoch:561 step:0 g_loss:1.1081581115722656 d_loss:1.3741394206881523 (f_loss=-0.0777878537774086 r_loss=1.0615921020507812 GP=0.39033517241477966)
[Training] epoch:561 step:100 g_loss:1.122697114944458 d_loss:1.1156211122870445 (f_loss=-0.11106004565954208 r_loss=0.9826502799987793 GP=0.2440308779478073)
[Training] epoch:561 step:200 g_loss:1.109395980834961 d_loss:1.6118645742535591 (f_loss=-0.09465908259153366 r_loss=1.0538731813430786 GP=0.6526504755020142)
[Training] epoch:561 step:300 g_loss:1.1361452341079712 d_loss:2.3326172083616257 (f_loss=-0.10403676331043243 r_loss=0.9475537538528442 GP=1.4891002178192139)
[Training] epoch:562 step:0 g_loss:1.1451869010925293 d_loss:1.7597310543060303 (f_loss=-0.07300776243209839 r_loss=1.0271567106246948 GP=0.8055821061134338)
[Training] epoch:562 step:100 g_loss:1.1886401176452637 d_loss:1.5808509290218353 (f_loss=-0.14620837569236755 r_loss=0.9731332063674927 GP=0.7539260983467102)
[Training] epoch:562 step:200 g_loss:1.1062994003295898 d_loss:1.547077588737011 (f_loss=-0.09456074982881546 r_loss=0.9256455302238464 GP=0.71599280834198)
[Training] epoch:562 step:300 g_loss:1.094902753829956 d_loss:1.2182367891073227 (f_loss=-0.17591343820095062 r_loss=1.126479148864746 GP=0.2676710784435272)
[Training] epoch:563 step:0 g_loss:1.1156262159347534 d_loss:1.110834851861 (f_loss=-0.1655263453722 r_loss=1.0606282949447632 GP=0.2157329022884369)
[Training] epoch:563 step:100 g_loss:1.1506850719451904 d_loss:1.7291772365570068 (f_loss=-0.13370084762573242 r_loss=0.8891717195510864 GP=0.9737063646316528)
[Training] epoch:563 step:200 g_loss:1.191469430923462 d_loss:1.6018192172050476 (f_loss=-0.14532822370529175 r_loss=0.9075841307640076 GP=0.8395633101463318)
[Training] epoch:563 step:300 g_loss:1.12162446975708 d_loss:1.67683757096529 (f_loss=-0.10654198378324509 r_loss=0.9890456199645996 GP=0.7943339347839355)
[Training] epoch:564 step:0 g_loss:1.0869152545928955 d_loss:1.698872447013855 (f_loss=-0.09201031923294067 r_loss=0.9544078707695007 GP=0.8364748954772949)
[Training] epoch:564 step:100 g_loss:1.204111933708191 d_loss:1.733285903930664 (f_loss=-0.1401153802871704 r_loss=1.0373826026916504 GP=0.8360186815261841)
[Training] epoch:564 step:200 g_loss:1.066789984703064 d_loss:1.296399086713791 (f_loss=-0.17580530047416687 r_loss=1.0167107582092285 GP=0.45549362897872925)
[Training] epoch:564 step:300 g_loss:1.1450858116149902 d_loss:1.5717255026102066 (f_loss=-0.12538205087184906 r_loss=1.0829814672470093 GP=0.6141260862350464)
[Training] epoch:565 step:0 g_loss:1.0850547552108765 d_loss:1.5959921926259995 (f_loss=-0.1552400141954422 r_loss=1.0346505641937256 GP=0.7165816426277161)
[Training] epoch:565 step:100 g_loss:1.1486940383911133 d_loss:2.2658827900886536 (f_loss=-0.11260426044464111 r_loss=0.9108527302742004 GP=1.4676343202590942)
[Training] epoch:565 step:200 g_loss:1.167667269706726 d_loss:1.367276668548584 (f_loss=-0.17013418674468994 r_loss=1.0356316566467285 GP=0.5017791986465454)
[Training] epoch:565 step:300 g_loss:1.093489170074463 d_loss:1.4681700766086578 (f_loss=-0.17865583300590515 r_loss=0.9933264255523682 GP=0.6534994840621948)
[Training] epoch:566 step:0 g_loss:1.0254827737808228 d_loss:1.3316280245780945 (f_loss=-0.1370093822479248 r_loss=1.0308538675308228 GP=0.43778353929519653)
[Training] epoch:566 step:100 g_loss:1.140091896057129 d_loss:1.0855530947446823 (f_loss=-0.12384003400802612 r_loss=1.0312355756759644 GP=0.17815755307674408)
[Training] epoch:566 step:200 g_loss:1.0833967924118042 d_loss:1.3153736293315887 (f_loss=-0.1452023684978485 r_loss=1.0761750936508179 GP=0.3844009041786194)
[Training] epoch:566 step:300 g_loss:1.1272872686386108 d_loss:1.901202343404293 (f_loss=-0.1171291247010231 r_loss=0.9367617964744568 GP=1.0815696716308594)
[Training] epoch:567 step:0 g_loss:1.1175806522369385 d_loss:1.5616619102656841 (f_loss=-0.013400483876466751 r_loss=1.0094839334487915 GP=0.5655784606933594)
[Training] epoch:567 step:100 g_loss:1.1119892597198486 d_loss:1.8916171789169312 (f_loss=-0.12588107585906982 r_loss=0.9579061269760132 GP=1.0595921277999878)
[Training] epoch:567 step:200 g_loss:1.1317775249481201 d_loss:1.797418013215065 (f_loss=-0.1288471668958664 r_loss=0.9983605742454529 GP=0.9279046058654785)
[Training] epoch:567 step:300 g_loss:1.089547038078308 d_loss:1.6197840571403503 (f_loss=-0.12377893924713135 r_loss=1.030214548110962 GP=0.7133484482765198)
[Training] epoch:568 step:0 g_loss:1.1399604082107544 d_loss:1.1523426249623299 (f_loss=-0.0879548117518425 r_loss=1.062270164489746 GP=0.17802727222442627)
[Training] epoch:568 step:100 g_loss:1.1695266962051392 d_loss:1.574682042002678 (f_loss=-0.15217866003513336 r_loss=0.9959099888801575 GP=0.7309507131576538)
[Training] epoch:568 step:200 g_loss:1.1127967834472656 d_loss:1.6688991785049438 (f_loss=-0.08147108554840088 r_loss=0.9875085949897766 GP=0.7628616690635681)
[Training] epoch:568 step:300 g_loss:1.091848611831665 d_loss:1.5649757385253906 (f_loss=-0.13678157329559326 r_loss=0.9744023084640503 GP=0.7273550033569336)
[Training] epoch:569 step:0 g_loss:1.1393662691116333 d_loss:1.2863768637180328 (f_loss=-0.12513133883476257 r_loss=1.087249517440796 GP=0.3242586851119995)
[Training] epoch:569 step:100 g_loss:1.1150106191635132 d_loss:1.551227867603302 (f_loss=-0.12942689657211304 r_loss=1.067427635192871 GP=0.613227128982544)
[Training] epoch:569 step:200 g_loss:1.1290881633758545 d_loss:1.2422930151224136 (f_loss=-0.1984073966741562 r_loss=1.0456348657608032 GP=0.3950655460357666)
[Training] epoch:569 step:300 g_loss:1.124049186706543 d_loss:1.2212404757738113 (f_loss=-0.11544989049434662 r_loss=1.1070923805236816 GP=0.22959798574447632)
[Training] epoch:570 step:0 g_loss:1.1748709678649902 d_loss:2.6754675209522247 (f_loss=-0.1563577950000763 r_loss=0.8988068699836731 GP=1.933018445968628)

[Training] epoch:570 step:100 g_loss:1.1190910339355469 d_loss:2.6072131991386414 (f_loss=-0.2125217318534851 r_loss=0.8813701868057251 GP=1.9383647441864014)
[Training] epoch:570 step:200 g_loss:1.1961781978607178 d_loss:1.7790319174528122 (f_loss=-0.15881671011447906 r_loss=0.9905447363853455 GP=0.9473038911819458)
[Training] epoch:570 step:300 g_loss:1.1365981101989746 d_loss:1.1150193810462952 (f_loss=-0.17292165756225586 r_loss=1.0500848293304443 GP=0.2378562092781067)
[Training] epoch:571 step:0 g_loss:1.1140364408493042 d_loss:1.2630929425358772 (f_loss=-0.12304698675870895 r_loss=1.068255066871643 GP=0.3178848624229431)
[Training] epoch:571 step:100 g_loss:1.1454397439956665 d_loss:1.235107183456421 (f_loss=-0.13961690664291382 r_loss=0.9627388715744019 GP=0.41198521852493286)
[Training] epoch:571 step:200 g_loss:1.147260308265686 d_loss:1.4152888655662537 (f_loss=-0.12226629257202148 r_loss=1.0259431600570679 GP=0.5116119980812073)
[Training] epoch:571 step:300 g_loss:1.2114633321762085 d_loss:1.235460489988327 (f_loss=-0.11451995372772217 r_loss=0.9982896447181702 GP=0.35169079899787903)
[Training] epoch:572 step:0 g_loss:1.2039802074432373 d_loss:1.1927801743149757 (f_loss=-0.12080585211515427 r_loss=1.0550442934036255 GP=0.2585417330265045)
[Training] epoch:572 step:100 g_loss:1.1455979347229004 d_loss:1.2576405555009842 (f_loss=-0.16416139900684357 r_loss=1.0788564682006836 GP=0.34294548630714417)
[Training] epoch:572 step:200 g_loss:1.0478827953338623 d_loss:1.541318565607071 (f_loss=-0.16392436623573303 r_loss=1.0696792602539062 GP=0.6355636715888977)
[Training] epoch:572 step:300 g_loss:1.126595377922058 d_loss:1.3437913954257965 (f_loss=-0.13133007287979126 r_loss=1.048208236694336 GP=0.42691323161125183)
[Training] epoch:573 step:0 g_loss:1.1342195272445679 d_loss:1.7318731248378754 (f_loss=-0.16100171208381653 r_loss=1.0505008697509766 GP=0.8423739671707153)
[Training] epoch:573 step:100 g_loss:1.1261062622070312 d_loss:1.7938750982284546 (f_loss=-0.1298162341117859 r_loss=1.0964250564575195 GP=0.827266275882721)
[Training] epoch:573 step:200 g_loss:1.1757372617721558 d_loss:2.067686140537262 (f_loss=-0.13477849960327148 r_loss=0.8725610375404358 GP=1.3299036026000977)
[Training] epoch:573 step:300 g_loss:1.1812210083007812 d_loss:1.3105771243572235 (f_loss=-0.12931880354881287 r_loss=1.0702701807022095 GP=0.3696257472038269)
[Training] epoch:574 step:0 g_loss:1.0737589597702026 d_loss:1.144981563091278 (f_loss=-0.13623949885368347 r_loss=1.015479326248169 GP=0.2657417356967926)
[Training] epoch:574 step:100 g_loss:1.1576344966888428 d_loss:1.2903492003679276 (f_loss=-0.1276751607656479 r_loss=1.0677905082702637 GP=0.35023385286331177)
[Training] epoch:574 step:200 g_loss:1.1634143590927124 d_loss:1.3497198075056076 (f_loss=-0.13310326635837555 r_loss=1.1122045516967773 GP=0.3706185221672058)
[Training] epoch:574 step:300 g_loss:1.1545684337615967 d_loss:1.1094717010855675 (f_loss=-0.10656467825174332 r_loss=1.0625203847885132 GP=0.1535159945487976)
[Training] epoch:575 step:0 g_loss:1.0643960237503052 d_loss:1.7453043758869171 (f_loss=-0.1236545741558075 r_loss=1.0037516355514526 GP=0.865207314491272)
[Training] epoch:575 step:100 g_loss:1.173478126525879 d_loss:1.754787728190422 (f_loss=-0.0903209000825882 r_loss=1.009478211402893 GP=0.8356304168701172)
[Training] epoch:575 step:200 g_loss:1.1265019178390503 d_loss:1.549483746290207 (f_loss=-0.14122429490089417 r_loss=0.9720114469528198 GP=0.7186965942382812)
[Training] epoch:575 step:300 g_loss:1.1184405088424683 d_loss:1.5382368192076683 (f_loss=-0.058633364737033844 r_loss=1.0816125869750977 GP=0.5152575969696045)
[Training] epoch:576 step:0 g_loss:1.1537197828292847 d_loss:1.8118973672389984 (f_loss=-0.20527204871177673 r_loss=0.9391689896583557 GP=1.0780004262924194)
[Training] epoch:576 step:100 g_loss:1.1121355295181274 d_loss:1.8580374717712402 (f_loss=-0.2194221019744873 r_loss=1.0659884214401245 GP=1.011471152305603)
[Training] epoch:576 step:200 g_loss:1.1823910474777222 d_loss:1.1221682652831078 (f_loss=-0.11777574568986893 r_loss=1.0104625225067139 GP=0.22948148846626282)
[Training] epoch:576 step:300 g_loss:1.1308022737503052 d_loss:1.3667138814926147 (f_loss=-0.21550536155700684 r_loss=1.0416944026947021 GP=0.5405248403549194)
[Training] epoch:577 step:0 g_loss:1.1594516038894653 d_loss:1.2767702117562294 (f_loss=-0.0952664241194725 r_loss=1.053317666053772 GP=0.31871896982192993)
[Training] epoch:577 step:100 g_loss:1.1446722745895386 d_loss:2.1684045791625977 (f_loss=-0.11437869071960449 r_loss=0.9738006591796875 GP=1.3089826107025146)
[Training] epoch:577 step:200 g_loss:1.1118800640106201 d_loss:1.8145338743925095 (f_loss=-0.14070011675357819 r_loss=1.0055359601974487 GP=0.9496980309486389)
[Training] epoch:577 step:300 g_loss:1.1167031526565552 d_loss:1.568441465497017 (f_loss=-0.10188697278499603 r_loss=0.8771688342094421 GP=0.7931596040725708)
[Training] epoch:578 step:0 g_loss:1.1544806957244873 d_loss:1.3118125945329666 (f_loss=-0.12501011788845062 r_loss=1.0184921026229858 GP=0.4183306097984314)
[Training] epoch:578 step:100 g_loss:1.1477330923080444 d_loss:1.7328447550535202 (f_loss=-0.19263382256031036 r_loss=0.9076031446456909 GP=1.0178754329681396)
[Training] epoch:578 step:200 g_loss:1.1671420335769653 d_loss:1.103609025478363 (f_loss=-0.14857301115989685 r_loss=0.9806169867515564 GP=0.2715650498867035)
[Training] epoch:578 step:300 g_loss:1.1330158710479736 d_loss:1.1755981147289276 (f_loss=-0.14005258679389954 r_loss=0.9781209230422974 GP=0.3375297784805298)
[Training] epoch:579 step:0 g_loss:1.1089963912963867 d_loss:1.2381039559841156 (f_loss=-0.175165057182312 r_loss=1.036177396774292 GP=0.3770916163921356)
[Training] epoch:579 step:100 g_loss:1.1453725099563599 d_loss:2.253641292452812 (f_loss=-0.09960772097110748 r_loss=0.8398228287696838 GP=1.5134261846542358)
[Training] epoch:579 step:200 g_loss:1.1068907976150513 d_loss:1.0410784184932709 (f_loss=-0.10549509525299072 r_loss=1.0196833610534668 GP=0.1268901526927948)
[Training] epoch:579 step:300 g_loss:1.115783452987671 d_loss:1.1626707315444946 (f_loss=-0.1630305051803589 r_loss=1.0433052778244019 GP=0.28239595890045166)
[Training] epoch:580 step:0 g_loss:1.0966062545776367 d_loss:2.443656325340271 (f_loss=-0.16534864902496338 r_loss=0.9002960920333862 GP=1.7087088823318481)

[Training] epoch:580 step:100 g_loss:1.191575527191162 d_loss:1.4695755243301392 (f_loss=-0.1905604600906372 r_loss=0.9933450222015381 GP=0.6667909622192383)
[Training] epoch:580 step:200 g_loss:1.1593190431594849 d_loss:1.3186149597167969 (f_loss=-0.18513116240501404 r_loss=1.0633913278579712 GP=0.4403547942638397)
[Training] epoch:580 step:300 g_loss:1.121425986289978 d_loss:1.4411005899310112 (f_loss=-0.08167756348848343 r_loss=0.9836897850036621 GP=0.5390883684158325)
[Training] epoch:581 step:0 g_loss:1.201245903968811 d_loss:2.897553026676178 (f_loss=-0.2360963225364685 r_loss=1.003366470336914 GP=2.1302828788757324)
[Training] epoch:581 step:100 g_loss:1.164202332496643 d_loss:1.8743446320295334 (f_loss=-0.16928012669086456 r_loss=0.9808664321899414 GP=1.0627583265304565)
[Training] epoch:581 step:200 g_loss:1.177438735961914 d_loss:1.1900682151317596 (f_loss=-0.19923213124275208 r_loss=1.0828487873077393 GP=0.30645155906677246)
[Training] epoch:581 step:300 g_loss:1.075695514678955 d_loss:1.7371110022068024 (f_loss=-0.17384853959083557 r_loss=0.9732009172439575 GP=0.9377586245536804)
[Training] epoch:582 step:0 g_loss:1.0937663316726685 d_loss:1.4064641296863556 (f_loss=-0.13928210735321045 r_loss=1.1065301895141602 GP=0.4392160475254059)
[Training] epoch:582 step:100 g_loss:1.1437546014785767 d_loss:1.6152247041463852 (f_loss=-0.0989571362733841 r_loss=0.9853944182395935 GP=0.7287874221801758)
[Training] epoch:582 step:200 g_loss:1.1452113389968872 d_loss:1.7616851925849915 (f_loss=-0.09677612781524658 r_loss=0.973037838935852 GP=0.885423481464386)
[Training] epoch:582 step:300 g_loss:1.0800611972808838 d_loss:1.237017571926117 (f_loss=-0.14136141538619995 r_loss=0.9528092741966248 GP=0.42556971311569214)
[Training] epoch:583 step:0 g_loss:1.1211227178573608 d_loss:1.3999238461256027 (f_loss=-0.15833236277103424 r_loss=1.0521469116210938 GP=0.5061092972755432)
[Training] epoch:583 step:100 g_loss:1.1159225702285767 d_loss:1.5918412655591965 (f_loss=-0.16119278967380524 r_loss=1.0510261058807373 GP=0.7020079493522644)
[Training] epoch:583 step:200 g_loss:1.1266965866088867 d_loss:1.5079542845487595 (f_loss=-0.196640744805336 r_loss=1.0681824684143066 GP=0.6364125609397888)
[Training] epoch:583 step:300 g_loss:1.150424838066101 d_loss:1.2513221204280853 (f_loss=-0.19871705770492554 r_loss=1.0244399309158325 GP=0.42559924721717834)
[Training] epoch:584 step:0 g_loss:1.1750246286392212 d_loss:1.7759275436401367 (f_loss=-0.2152256965637207 r_loss=1.103640079498291 GP=0.8875131607055664)
[Training] epoch:584 step:100 g_loss:1.1436322927474976 d_loss:1.5295921713113785 (f_loss=-0.1260535567998886 r_loss=1.0138100385665894 GP=0.6418356895446777)
[Training] epoch:584 step:200 g_loss:1.229019045829773 d_loss:1.613686978816986 (f_loss=-0.14803677797317505 r_loss=1.0329735279083252 GP=0.7287502288818359)
[Training] epoch:584 step:300 g_loss:1.1901980638504028 d_loss:1.8407643735408783 (f_loss=-0.15635916590690613 r_loss=1.0340197086334229 GP=0.9631038308143616)
[Training] epoch:585 step:0 g_loss:1.1511913537979126 d_loss:2.10811510682106 (f_loss=-0.12524661421775818 r_loss=0.9110040664672852 GP=1.3223576545715332)
[Training] epoch:585 step:100 g_loss:1.182167410850525 d_loss:2.4052903801202774 (f_loss=-0.14160136878490448 r_loss=0.7724164128303528 GP=1.774475336074829)
[Training] epoch:585 step:200 g_loss:1.1588290929794312 d_loss:1.3821461349725723 (f_loss=-0.15920989215373993 r_loss=0.9556860327720642 GP=0.585669994354248)
[Training] epoch:585 step:300 g_loss:1.1463017463684082 d_loss:1.2777145355939865 (f_loss=-0.2010253220796585 r_loss=1.0394548177719116 GP=0.4392850399017334)
[Training] epoch:586 step:0 g_loss:1.2252764701843262 d_loss:1.4653578400611877 (f_loss=-0.1523260474205017 r_loss=0.9484861493110657 GP=0.6691977381706238)
[Training] epoch:586 step:100 g_loss:1.2069981098175049 d_loss:1.169709324836731 (f_loss=-0.15189211070537567 r_loss=1.0952907800674438 GP=0.22631065547466278)
[Training] epoch:586 step:200 g_loss:1.2034015655517578 d_loss:1.5392204374074936 (f_loss=-0.17661811411380768 r_loss=1.0249673128128052 GP=0.6908712387084961)
[Training] epoch:586 step:300 g_loss:1.192487120628357 d_loss:2.029452219605446 (f_loss=-0.14626698195934296 r_loss=0.9726168513298035 GP=1.2031023502349854)
[Training] epoch:587 step:0 g_loss:1.1095356941223145 d_loss:1.1970677822828293 (f_loss=-0.16633228957653046 r_loss=1.0560089349746704 GP=0.30739113688468933)
[Training] epoch:587 step:100 g_loss:1.1589854955673218 d_loss:1.527249813079834 (f_loss=-0.13347280025482178 r_loss=0.9438272714614868 GP=0.716895341873169)
[Training] epoch:587 step:200 g_loss:1.1064785718917847 d_loss:1.8169938325881958 (f_loss=-0.15406811237335205 r_loss=1.0977357625961304 GP=0.8733261823654175)
[Training] epoch:587 step:300 g_loss:1.1412115097045898 d_loss:1.3617848455905914 (f_loss=-0.1411798596382141 r_loss=1.0351409912109375 GP=0.46782371401786804)
[Training] epoch:588 step:0 g_loss:1.2104836702346802 d_loss:1.1961355656385422 (f_loss=-0.1890348345041275 r_loss=1.0817573070526123 GP=0.3034130930900574)
[Training] epoch:588 step:100 g_loss:1.1808093786239624 d_loss:1.2877356112003326 (f_loss=-0.13042134046554565 r_loss=1.079742193222046 GP=0.3384147584438324)
[Training] epoch:588 step:200 g_loss:1.1967809200286865 d_loss:1.0887064337730408 (f_loss=-0.1589108407497406 r_loss=1.0856341123580933 GP=0.1619831621646881)
[Training] epoch:588 step:300 g_loss:1.145987868309021 d_loss:1.2533486783504486 (f_loss=-0.14026153087615967 r_loss=1.0321694612503052 GP=0.3614407479763031)
[Training] epoch:589 step:0 g_loss:1.105674386024475 d_loss:1.8798544853925705 (f_loss=-0.12778402864933014 r_loss=1.0096698999404907 GP=0.9979686141014099)
[Training] epoch:589 step:100 g_loss:1.1994218826293945 d_loss:1.2927301526069641 (f_loss=-0.09684121608734131 r_loss=1.0686676502227783 GP=0.3209037184715271)
[Training] epoch:589 step:200 g_loss:1.1966959238052368 d_loss:1.051515057682991 (f_loss=-0.13320159912109375 r_loss=1.0921168327331543 GP=0.09259982407093048)
[Training] epoch:589 step:300 g_loss:1.1404027938842773 d_loss:1.4756246656179428 (f_loss=-0.13295890390872955 r_loss=1.1028647422790527 GP=0.5057188272476196)
[Training] epoch:590 step:0 g_loss:1.2183594703674316 d_loss:1.7324194461107254 (f_loss=-0.13041476905345917 r_loss=0.977058470249176 GP=0.8857757449150085)

[Training] epoch:590 step:100 g_loss:1.1450872421264648 d_loss:1.224812164902687 (f_loss=-0.21182210743427277 r_loss=0.9605461955070496 GP=0.4760880768299103)
[Training] epoch:590 step:200 g_loss:1.139353632926941 d_loss:2.144129455089569 (f_loss=-0.09080928564071655 r_loss=1.0012725591659546 GP=1.233666181564331)
[Training] epoch:590 step:300 g_loss:1.2233177423477173 d_loss:1.6268321871757507 (f_loss=-0.14667224884033203 r_loss=1.0231648683547974 GP=0.7503395676612854)
[Training] epoch:591 step:0 g_loss:1.174371361732483 d_loss:1.386094056069851 (f_loss=-0.1087038591504097 r_loss=1.0696022510528564 GP=0.4251956641674042)
[Training] epoch:591 step:100 g_loss:1.1493678092956543 d_loss:1.5025827884674072 (f_loss=-0.17797183990478516 r_loss=1.0981664657592773 GP=0.582388162612915)
[Training] epoch:591 step:200 g_loss:1.081286907196045 d_loss:2.3117429316043854 (f_loss=-0.14427432417869568 r_loss=1.1569024324417114 GP=1.2991148233413696)
[Training] epoch:591 step:300 g_loss:1.1330349445343018 d_loss:2.8721148520708084 (f_loss=-0.15335766971111298 r_loss=1.137948989868164 GP=1.8875235319137573)
[Training] epoch:592 step:0 g_loss:1.1644365787506104 d_loss:1.1791416108608246 (f_loss=-0.20256197452545166 r_loss=1.0941702127456665 GP=0.28753337264060974)
[Training] epoch:592 step:100 g_loss:1.1445897817611694 d_loss:1.371870517730713 (f_loss=-0.09527188539505005 r_loss=1.1169986724853516 GP=0.3501437306404114)
[Training] epoch:592 step:200 g_loss:1.1422942876815796 d_loss:1.88182333111763 (f_loss=-0.1943396031856537 r_loss=1.057309865951538 GP=1.0188530683517456)
[Training] epoch:592 step:300 g_loss:1.177851915359497 d_loss:1.1506949216127396 (f_loss=-0.18826545774936676 r_loss=1.0397560596466064 GP=0.2992043197154999)
[Training] epoch:593 step:0 g_loss:1.1816209554672241 d_loss:1.2312997877597809 (f_loss=-0.15132611989974976 r_loss=1.0268529653549194 GP=0.3557729423046112)
[Training] epoch:593 step:100 g_loss:1.1177068948745728 d_loss:1.4407550394535065 (f_loss=-0.11196854710578918 r_loss=1.000417947769165 GP=0.5523056387901306)
[Training] epoch:593 step:200 g_loss:1.1977298259735107 d_loss:1.575158454477787 (f_loss=-0.12155332416296005 r_loss=0.8832545280456543 GP=0.8134572505950928)
[Training] epoch:593 step:300 g_loss:1.1565680503845215 d_loss:2.1646795868873596 (f_loss=-0.13821160793304443 r_loss=0.9975473284721375 GP=1.3053438663482666)
[Training] epoch:594 step:0 g_loss:1.1435226202011108 d_loss:1.3278364539146423 (f_loss=-0.15658676624298096 r_loss=1.1520899534225464 GP=0.3323332667350769)
[Training] epoch:594 step:100 g_loss:1.1860496997833252 d_loss:1.5064087808132172 (f_loss=-0.12894433736801147 r_loss=1.1439568996429443 GP=0.4913962185382843)
[Training] epoch:594 step:200 g_loss:1.1607850790023804 d_loss:1.23468117415905 (f_loss=-0.15067769587039948 r_loss=1.0644704103469849 GP=0.3208884596824646)
[Training] epoch:594 step:300 g_loss:1.1778408288955688 d_loss:1.407298281788826 (f_loss=-0.12449844181537628 r_loss=1.098781943321228 GP=0.43301478028297424)
[Training] epoch:595 step:0 g_loss:1.1639231443405151 d_loss:1.470912128686905 (f_loss=-0.16425737738609314 r_loss=1.0045692920684814 GP=0.6306002140045166)
[Training] epoch:595 step:100 g_loss:1.1443170309066772 d_loss:1.4212601780891418 (f_loss=-0.16279137134552002 r_loss=1.0870634317398071 GP=0.49698811769485474)
[Training] epoch:595 step:200 g_loss:1.2321919202804565 d_loss:1.310595840215683 (f_loss=-0.2469610869884491 r_loss=1.1127936840057373 GP=0.4447632431983948)
[Training] epoch:595 step:300 g_loss:1.2509804964065552 d_loss:1.5861079022288322 (f_loss=-0.1212470605969429 r_loss=1.0918071269989014 GP=0.6155478358268738)
[Training] epoch:596 step:0 g_loss:1.134397268295288 d_loss:1.5274923890829086 (f_loss=-0.11250276863574982 r_loss=0.9760047197341919 GP=0.6639904379844666)
[Training] epoch:596 step:100 g_loss:1.1410908699035645 d_loss:1.2686199992895126 (f_loss=-0.14230723679065704 r_loss=1.1444509029388428 GP=0.2664763331413269)
[Training] epoch:596 step:200 g_loss:1.1889448165893555 d_loss:1.4230466187000275 (f_loss=-0.18310001492500305 r_loss=1.0848013162612915 GP=0.521345317363739)
[Training] epoch:596 step:300 g_loss:1.1240358352661133 d_loss:1.2472505569458008 (f_loss=-0.15796127915382385 r_loss=1.0337001085281372 GP=0.3715117275714874)
[Training] epoch:597 step:0 g_loss:1.133189082145691 d_loss:2.183453842997551 (f_loss=-0.10867877304553986 r_loss=1.0288186073303223 GP=1.2633140087127686)
[Training] epoch:597 step:100 g_loss:1.1607881784439087 d_loss:2.683905154466629 (f_loss=-0.197636216878891 r_loss=0.9793497323989868 GP=1.9021916389465332)
[Training] epoch:597 step:200 g_loss:1.1920806169509888 d_loss:1.4135304689407349 (f_loss=-0.12677538394927979 r_loss=1.0835509300231934 GP=0.4567549228668213)
[Training] epoch:597 step:300 g_loss:1.1607608795166016 d_loss:1.5132514238357544 (f_loss=-0.13527923822402954 r_loss=1.043747901916504 GP=0.60478276014328)
[Training] epoch:598 step:0 g_loss:1.1538466215133667 d_loss:1.3170127719640732 (f_loss=-0.12934307754039764 r_loss=1.089919924736023 GP=0.3564359247684479)
[Training] epoch:598 step:100 g_loss:1.101309895515442 d_loss:1.4858239889144897 (f_loss=-0.14382189512252808 r_loss=1.0610758066177368 GP=0.568570077419281)
[Training] epoch:598 step:200 g_loss:1.0704569816589355 d_loss:1.520205870270729 (f_loss=-0.09593759477138519 r_loss=1.0624370574951172 GP=0.5537064075469971)
[Training] epoch:598 step:300 g_loss:1.1648151874542236 d_loss:1.1607580482959747 (f_loss=-0.16086351871490479 r_loss=0.9330732226371765 GP=0.388548344373703)
[Training] epoch:599 step:0 g_loss:1.2051358222961426 d_loss:1.1190075278282166 (f_loss=-0.14127779006958008 r_loss=1.0960880517959595 GP=0.16419726610183716)
[Training] epoch:599 step:100 g_loss:1.1700356006622314 d_loss:1.6541180163621902 (f_loss=-0.1773562878370285 r_loss=0.9027600288391113 GP=0.9287142753601074)
[Training] epoch:599 step:200 g_loss:1.1911264657974243 d_loss:1.676258623600006 (f_loss=-0.12813448905944824 r_loss=0.9966148734092712 GP=0.8077782392501831)
[Training] epoch:599 step:300 g_loss:1.1948270797729492 d_loss:1.476019911468029 (f_loss=-0.12238378077745438 r_loss=1.0545209646224976 GP=0.5438827276229858)
[Training] epoch:600 step:0 g_loss:1.1488888263702393 d_loss:1.4704793691635132 (f_loss=-0.17353802919387817 r_loss=1.1213942766189575 GP=0.5226231217384338)

[Training] epoch:600 step:100 g_loss:1.17880117893219 d_loss:2.2945321649312973 (f_loss=-0.14562292397022247 r_loss=0.895386278629303 GP=1.5447688102722168)
[Training] epoch:600 step:200 g_loss:1.1211930513381958 d_loss:1.9977880716323853 (f_loss=-0.1527271270751953 r_loss=0.9563990831375122 GP=1.1941161155700684)
[Training] epoch:600 step:300 g_loss:1.1188465356826782 d_loss:1.7559087574481964 (f_loss=-0.15017297863960266 r_loss=1.0937128067016602 GP=0.8123689293861389)
[Training] epoch:601 step:0 g_loss:1.1111416816711426 d_loss:1.1475083231925964 (f_loss=-0.2241046130657196 r_loss=1.137477159500122 GP=0.23413577675819397)
[Training] epoch:601 step:100 g_loss:1.113931655883789 d_loss:1.5278018712997437 (f_loss=-0.12986677885055542 r_loss=1.0789512395858765 GP=0.5787174105644226)
[Training] epoch:601 step:200 g_loss:1.1475094556808472 d_loss:2.109756588935852 (f_loss=-0.184073805809021 r_loss=0.8428984880447388 GP=1.4509319067001343)
[Training] epoch:601 step:300 g_loss:1.1618614196777344 d_loss:1.9389942735433578 (f_loss=-0.1389569193124771 r_loss=1.022753119468689 GP=1.055198073387146)
[Training] epoch:602 step:0 g_loss:1.136699914932251 d_loss:1.5906606018543243 (f_loss=-0.16168412566184998 r_loss=1.012939691543579 GP=0.7394050359725952)
[Training] epoch:602 step:100 g_loss:1.116142749786377 d_loss:2.1527312099933624 (f_loss=-0.09021958708763123 r_loss=0.8777812719345093 GP=1.3651695251464844)
[Training] epoch:602 step:200 g_loss:1.1448421478271484 d_loss:1.242981418967247 (f_loss=-0.17113123834133148 r_loss=1.0148414373397827 GP=0.3992712199687958)
[Training] epoch:602 step:300 g_loss:1.1540753841400146 d_loss:1.4156381785869598 (f_loss=-0.1519949734210968 r_loss=1.142794132232666 GP=0.4248390197753906)
[Training] epoch:603 step:0 g_loss:1.2153265476226807 d_loss:2.993586428463459 (f_loss=-0.08889304846525192 r_loss=0.8279581069946289 GP=2.254521369934082)
[Training] epoch:603 step:100 g_loss:1.1554323434829712 d_loss:2.5799745321273804 (f_loss=-0.17311006784439087 r_loss=0.9886383414268494 GP=1.7644462585449219)
[Training] epoch:603 step:200 g_loss:1.1746470928192139 d_loss:1.4190775901079178 (f_loss=-0.18094502389431 r_loss=1.0007251501083374 GP=0.5992974638938904)
[Training] epoch:603 step:300 g_loss:1.1817691326141357 d_loss:1.259591743350029 (f_loss=-0.1620461791753769 r_loss=1.1173961162567139 GP=0.304241806268692)
[Training] epoch:604 step:0 g_loss:1.1455662250518799 d_loss:1.4775330722332 (f_loss=-0.16568538546562195 r_loss=1.1070164442062378 GP=0.5362020134925842)
[Training] epoch:604 step:100 g_loss:1.1466412544250488 d_loss:1.3983856588602066 (f_loss=-0.1668940633535385 r_loss=0.9764521718025208 GP=0.5888275504112244)
[Training] epoch:604 step:200 g_loss:1.1562280654907227 d_loss:1.0591027289628983 (f_loss=-0.14639844000339508 r_loss=1.0873639583587646 GP=0.11813721060752869)
[Training] epoch:604 step:300 g_loss:1.1794630289077759 d_loss:1.5146721303462982 (f_loss=-0.16960754990577698 r_loss=1.1150836944580078 GP=0.5691959857940674)
[Training] epoch:605 step:0 g_loss:1.1746814250946045 d_loss:1.2258004993200302 (f_loss=-0.21577520668506622 r_loss=1.0759367942810059 GP=0.3656389117240906)
[Training] epoch:605 step:100 g_loss:1.223767638206482 d_loss:1.59637913107872 (f_loss=-0.10111883282661438 r_loss=1.0494391918182373 GP=0.6480587720870972)
[Training] epoch:605 step:200 g_loss:1.1697094440460205 d_loss:1.5013431757688522 (f_loss=-0.1710207611322403 r_loss=1.1392035484313965 GP=0.533160388469696)
[Training] epoch:605 step:300 g_loss:1.1851638555526733 d_loss:1.594176009297371 (f_loss=-0.14019159972667694 r_loss=1.0362005233764648 GP=0.698167085647583)
[Training] epoch:606 step:0 g_loss:1.1537355184555054 d_loss:1.6239392161369324 (f_loss=-0.18544501066207886 r_loss=1.0876717567443848 GP=0.7217124700546265)
[Training] epoch:606 step:100 g_loss:1.1936341524124146 d_loss:1.1641747653484344 (f_loss=-0.2195737063884735 r_loss=1.1727675199508667 GP=0.21098095178604126)
[Training] epoch:606 step:200 g_loss:1.1388273239135742 d_loss:1.2632845342159271 (f_loss=-0.19452634453773499 r_loss=1.1319353580474854 GP=0.32587552070617676)
[Training] epoch:606 step:300 g_loss:1.1752526760101318 d_loss:1.9599505364894867 (f_loss=-0.18596604466438293 r_loss=1.056146502494812 GP=1.0897700786590576)
[Training] epoch:607 step:0 g_loss:1.118904709815979 d_loss:1.6880377233028412 (f_loss=-0.18471136689186096 r_loss=1.0425043106079102 GP=0.830244779586792)
[Training] epoch:607 step:100 g_loss:1.114188551902771 d_loss:1.3181121498346329 (f_loss=-0.1469591110944748 r_loss=1.1018457412719727 GP=0.363225519657135)
[Training] epoch:607 step:200 g_loss:1.1300288438796997 d_loss:1.3421015590429306 (f_loss=-0.15262989699840546 r_loss=1.0576390027999878 GP=0.43709245324134827)
[Training] epoch:607 step:300 g_loss:1.1438238620758057 d_loss:1.1783922016620636 (f_loss=-0.194954976439476 r_loss=1.1339364051818848 GP=0.23941077291965485)
[Training] epoch:608 step:0 g_loss:1.1268181800842285 d_loss:1.7257383316755295 (f_loss=-0.06610311567783356 r_loss=0.9136066436767578 GP=0.8782348036766052)
[Training] epoch:608 step:100 g_loss:1.181748390197754 d_loss:1.5056743770837784 (f_loss=-0.13533978164196014 r_loss=1.0804107189178467 GP=0.5606034398078918)
[Training] epoch:608 step:200 g_loss:1.2071963548660278 d_loss:2.262631803750992 (f_loss=-0.1420477330684662 r_loss=0.9433283805847168 GP=1.4613511562347412)
[Training] epoch:608 step:300 g_loss:1.1712477207183838 d_loss:1.2409953624010086 (f_loss=-0.1269162893295288 r_loss=1.127377986907959 GP=0.24053366482257843)
[Training] epoch:609 step:0 g_loss:1.1160260438919067 d_loss:1.1607278436422348 (f_loss=-0.19232749938964844 r_loss=1.1250417232513428 GP=0.22801361978054047)
[Training] epoch:609 step:100 g_loss:1.1377023458480835 d_loss:1.6427988409996033 (f_loss=-0.173508882522583 r_loss=1.0686535835266113 GP=0.747654139995575)
[Training] epoch:609 step:200 g_loss:1.1317574977874756 d_loss:2.8181822448968887 (f_loss=-0.15521453320980072 r_loss=0.8381171226501465 GP=2.135279655456543)
[Training] epoch:609 step:300 g_loss:1.15274977684021 d_loss:1.3079249262809753 (f_loss=-0.1793614625930786 r_loss=1.0956072807312012 GP=0.3916791081428528)
[Training] epoch:610 step:0 g_loss:1.1548559665679932 d_loss:2.5308519154787064 (f_loss=-0.1629801243543625 r_loss=1.0557254552841187 GP=1.6381065845489502)

[Training] epoch:610 step:100 g_loss:1.2161343097686768 d_loss:1.2845652997493744 (f_loss=-0.1356818974018097 r_loss=1.0886119604110718 GP=0.3316352367401123)
[Training] epoch:610 step:200 g_loss:1.1678699254989624 d_loss:1.6677308678627014 (f_loss=-0.09899318218231201 r_loss=0.9734966158866882 GP=0.7932274341583252)
[Training] epoch:610 step:300 g_loss:1.1573574542999268 d_loss:1.9861053675413132 (f_loss=-0.16450126469135284 r_loss=1.130358099937439 GP=1.020248532295227)
[Training] epoch:611 step:0 g_loss:1.10117769241333 d_loss:1.9242799580097198 (f_loss=-0.1760018765926361 r_loss=1.078253984451294 GP=1.022027850151062)
[Training] epoch:611 step:100 g_loss:1.136900544166565 d_loss:1.3274035155773163 (f_loss=-0.17230066657066345 r_loss=1.0048240423202515 GP=0.49488013982772827)
[Training] epoch:611 step:200 g_loss:1.1863600015640259 d_loss:1.838611900806427 (f_loss=-0.18939048051834106 r_loss=1.0014050006866455 GP=1.0265973806381226)
[Training] epoch:611 step:300 g_loss:1.194492220878601 d_loss:1.8961273282766342 (f_loss=-0.13867338001728058 r_loss=1.0405142307281494 GP=0.9942864775657654)
[Training] epoch:612 step:0 g_loss:1.1523914337158203 d_loss:1.4280141741037369 (f_loss=-0.13321910798549652 r_loss=0.9802711009979248 GP=0.5809621810913086)
[Training] epoch:612 step:100 g_loss:1.124302864074707 d_loss:1.8499629497528076 (f_loss=-0.2132788896560669 r_loss=1.0292561054229736 GP=1.0339857339859009)
[Training] epoch:612 step:200 g_loss:1.2785894870758057 d_loss:1.3113391697406769 (f_loss=-0.15253382921218872 r_loss=1.0790297985076904 GP=0.38484320044517517)
[Training] epoch:612 step:300 g_loss:1.1045491695404053 d_loss:1.353139266371727 (f_loss=-0.19320745766162872 r_loss=1.0654399394989014 GP=0.48090678453445435)
[Training] epoch:613 step:0 g_loss:1.1471233367919922 d_loss:1.9552794396877289 (f_loss=-0.20898917317390442 r_loss=0.8234460353851318 GP=1.3408225774765015)
[Training] epoch:613 step:100 g_loss:1.1259273290634155 d_loss:1.6521692723035812 (f_loss=-0.13571478426456451 r_loss=1.0329194068908691 GP=0.7549646496772766)
[Training] epoch:613 step:200 g_loss:1.1387858390808105 d_loss:1.9144975394010544 (f_loss=-0.13890881836414337 r_loss=1.0195614099502563 GP=1.0338449478149414)
[Training] epoch:613 step:300 g_loss:1.1568002700805664 d_loss:1.8889970555901527 (f_loss=-0.0877319797873497 r_loss=1.0190465450286865 GP=0.9576824903488159)
[Training] epoch:614 step:0 g_loss:1.1301097869873047 d_loss:2.556803971529007 (f_loss=-0.12437966465950012 r_loss=0.9494877457618713 GP=1.7316958904266357)
[Training] epoch:614 step:100 g_loss:1.2391819953918457 d_loss:1.647389680147171 (f_loss=-0.17644789814949036 r_loss=1.0807503461837769 GP=0.7430872321128845)
[Training] epoch:614 step:200 g_loss:1.1933374404907227 d_loss:1.3291010558605194 (f_loss=-0.22426947951316833 r_loss=1.1847611665725708 GP=0.36860936880111694)
[Training] epoch:614 step:300 g_loss:1.1768407821655273 d_loss:1.3080832064151764 (f_loss=-0.1554524302482605 r_loss=1.0895284414291382 GP=0.3740071952342987)
[Training] epoch:615 step:0 g_loss:1.2050931453704834 d_loss:1.8636976182460785 (f_loss=-0.1429378092288971 r_loss=0.9355671405792236 GP=1.071068286895752)
[Training] epoch:615 step:100 g_loss:1.197531819343567 d_loss:2.7267307490110397 (f_loss=-0.19754917919635773 r_loss=0.8716485500335693 GP=2.052631378173828)
[Training] epoch:615 step:200 g_loss:1.2089452743530273 d_loss:1.2753294706344604 (f_loss=-0.11394995450973511 r_loss=1.1176824569702148 GP=0.2715969681739807)
[Training] epoch:615 step:300 g_loss:1.2055134773254395 d_loss:1.7290799021720886 (f_loss=-0.18714046478271484 r_loss=1.0859625339508057 GP=0.8302578330039978)
[Training] epoch:616 step:0 g_loss:1.1879868507385254 d_loss:1.5217882990837097 (f_loss=-0.20465368032455444 r_loss=1.1094040870666504 GP=0.6170378923416138)
[Training] epoch:616 step:100 g_loss:1.1816363334655762 d_loss:2.455230191349983 (f_loss=-0.14023719727993011 r_loss=0.9858928322792053 GP=1.609574556350708)
[Training] epoch:616 step:200 g_loss:1.118964672088623 d_loss:1.467735379934311 (f_loss=-0.1094302237033844 r_loss=0.9179375767707825 GP=0.6592280268669128)
[Training] epoch:616 step:300 g_loss:1.2811403274536133 d_loss:1.613590657711029 (f_loss=-0.18466562032699585 r_loss=1.0186834335327148 GP=0.7795728445053101)
[Training] epoch:617 step:0 g_loss:1.2024885416030884 d_loss:3.3423355147242546 (f_loss=-0.10616499930620193 r_loss=0.9176257848739624 GP=2.530874729156494)
[Training] epoch:617 step:100 g_loss:1.150687575340271 d_loss:1.8490126430988312 (f_loss=-0.1236630380153656 r_loss=0.9545066356658936 GP=1.0181690454483032)
[Training] epoch:617 step:200 g_loss:1.1579424142837524 d_loss:1.2796603739261627 (f_loss=-0.2057461440563202 r_loss=1.101969838142395 GP=0.3834366798400879)
[Training] epoch:617 step:300 g_loss:1.1949245929718018 d_loss:1.4031321108341217 (f_loss=-0.1906590759754181 r_loss=1.0154911279678345 GP=0.5783000588417053)
[Training] epoch:618 step:0 g_loss:1.2046270370483398 d_loss:1.4167835414409637 (f_loss=-0.15981265902519226 r_loss=0.9284864068031311 GP=0.6481097936630249)
[Training] epoch:618 step:100 g_loss:1.2063214778900146 d_loss:1.2493722438812256 (f_loss=-0.1625666320323944 r_loss=1.0802111625671387 GP=0.3317277133464813)
[Training] epoch:618 step:200 g_loss:1.168445110321045 d_loss:1.7988574355840683 (f_loss=-0.1716839224100113 r_loss=1.026554822921753 GP=0.9439865350723267)
[Training] epoch:618 step:300 g_loss:1.1838116645812988 d_loss:1.5503004342317581 (f_loss=-0.14646558463573456 r_loss=1.101111888885498 GP=0.5956541299819946)
[Training] epoch:619 step:0 g_loss:1.1563527584075928 d_loss:1.3751661777496338 (f_loss=-0.13120323419570923 r_loss=1.0733518600463867 GP=0.4330175518989563)
[Training] epoch:619 step:100 g_loss:1.0329985618591309 d_loss:1.8893575966358185 (f_loss=-0.1537550985813141 r_loss=1.053604006767273 GP=0.9895086884498596)
[Training] epoch:619 step:200 g_loss:1.1487033367156982 d_loss:1.530783861875534 (f_loss=-0.16634920239448547 r_loss=1.078818678855896 GP=0.6183143854141235)
[Training] epoch:619 step:300 g_loss:1.1924962997436523 d_loss:1.455166757106781 (f_loss=-0.15365499258041382 r_loss=1.088032603263855 GP=0.5207891464233398)
[Training] epoch:620 step:0 g_loss:1.1846604347229004 d_loss:1.7409145087003708 (f_loss=-0.1371299773454666 r_loss=1.120457410812378 GP=0.7575870752334595)

[Training] epoch:620 step:100 g_loss:1.2436667680740356 d_loss:1.424782633781433 (f_loss=-0.21986627578735352 r_loss=1.0811958312988281 GP=0.5634530782699585)
[Training] epoch:620 step:200 g_loss:1.173909068107605 d_loss:1.246295690536499 (f_loss=-0.16554045677185059 r_loss=1.1659115552902222 GP=0.24592459201812744)
[Training] epoch:620 step:300 g_loss:1.1238068342208862 d_loss:2.1886346638202667 (f_loss=-0.1795271337032318 r_loss=0.9722747802734375 GP=1.395887017250061)
[Training] epoch:621 step:0 g_loss:1.199713945388794 d_loss:1.2073880285024643 (f_loss=-0.21268542110919952 r_loss=1.0571224689483643 GP=0.36295098066329956)
[Training] epoch:621 step:100 g_loss:1.1908633708953857 d_loss:1.0347271859645844 (f_loss=-0.1997152864933014 r_loss=1.0937926769256592 GP=0.14064979553222656)
[Training] epoch:621 step:200 g_loss:1.1586030721664429 d_loss:2.4629340320825577 (f_loss=-0.11009518802165985 r_loss=0.9382293820381165 GP=1.634799838066101)
[Training] epoch:621 step:300 g_loss:1.20809006690979 d_loss:1.7564109861850739 (f_loss=-0.15670648217201233 r_loss=1.0664081573486328 GP=0.8467093110084534)
[Training] epoch:622 step:0 g_loss:1.16524076461792 d_loss:1.298880621790886 (f_loss=-0.22526390850543976 r_loss=1.1508349180221558 GP=0.3733096122741699)
[Training] epoch:622 step:100 g_loss:1.2291886806488037 d_loss:1.3947631865739822 (f_loss=-0.18594856560230255 r_loss=1.0973517894744873 GP=0.4833599627017975)
[Training] epoch:622 step:200 g_loss:1.188440203666687 d_loss:2.334901809692383 (f_loss=-0.1919804811477661 r_loss=1.0761213302612305 GP=1.4507609605789185)
[Training] epoch:622 step:300 g_loss:1.2406623363494873 d_loss:1.9505394846200943 (f_loss=-0.2031741589307785 r_loss=0.956312358379364 GP=1.1974012851715088)
[Training] epoch:623 step:0 g_loss:1.1977144479751587 d_loss:1.4037401527166367 (f_loss=-0.1759195476770401 r_loss=1.0545501708984375 GP=0.5251095294952393)
[Training] epoch:623 step:100 g_loss:1.174368977546692 d_loss:3.53384867310524 (f_loss=-0.2800414264202118 r_loss=1.0538958311080933 GP=2.7599942684173584)
[Training] epoch:623 step:200 g_loss:1.1778173446655273 d_loss:1.5077187269926071 (f_loss=-0.168103888630867 r_loss=1.096611499786377 GP=0.5792111158370972)
[Training] epoch:623 step:300 g_loss:1.1735401153564453 d_loss:1.2752697169780731 (f_loss=-0.17083436250686646 r_loss=1.1764823198318481 GP=0.26962175965309143)
[Training] epoch:624 step:0 g_loss:1.1528985500335693 d_loss:2.5486854910850525 (f_loss=-0.1442837119102478 r_loss=1.0025326013565063 GP=1.690436601638794)
[Training] epoch:624 step:100 g_loss:1.1911543607711792 d_loss:1.6934078335762024 (f_loss=-0.18866831064224243 r_loss=1.054517388343811 GP=0.8275587558746338)
[Training] epoch:624 step:200 g_loss:1.1744287014007568 d_loss:1.843259572982788 (f_loss=-0.18024837970733643 r_loss=1.0070116519927979 GP=1.0164963006973267)
[Training] epoch:624 step:300 g_loss:1.171242594718933 d_loss:1.2439728528261185 (f_loss=-0.2269686907529831 r_loss=1.0904473066329956 GP=0.38049423694610596)
[Training] epoch:625 step:0 g_loss:1.1784913539886475 d_loss:1.4362719655036926 (f_loss=-0.1793540120124817 r_loss=1.1804544925689697 GP=0.4351714849472046)
[Training] epoch:625 step:100 g_loss:1.1639598608016968 d_loss:4.1955031752586365 (f_loss=-0.19944971799850464 r_loss=0.7529710531234741 GP=3.641981840133667)
[Training] epoch:625 step:200 g_loss:1.1678396463394165 d_loss:1.9499913230538368 (f_loss=-0.10871138423681259 r_loss=1.0031890869140625 GP=1.055513620376587)
[Training] epoch:625 step:300 g_loss:1.1423319578170776 d_loss:1.7489920407533646 (f_loss=-0.21755556762218475 r_loss=1.0921790599822998 GP=0.8743685483932495)
[Training] epoch:626 step:0 g_loss:1.1827806234359741 d_loss:1.3076535910367966 (f_loss=-0.213540717959404 r_loss=1.0678273439407349 GP=0.4533669650554657)
[Training] epoch:626 step:100 g_loss:1.1983693838119507 d_loss:1.4277710169553757 (f_loss=-0.20305348932743073 r_loss=1.1183078289031982 GP=0.5125166773796082)
[Training] epoch:626 step:200 g_loss:1.2324507236480713 d_loss:1.282914012670517 (f_loss=-0.17196306586265564 r_loss=0.9731659293174744 GP=0.48171114921569824)
[Training] epoch:626 step:300 g_loss:1.2767505645751953 d_loss:4.580443382263184 (f_loss=-0.16522222757339478 r_loss=0.7295961976051331 GP=4.016069412231445)
[Training] epoch:627 step:0 g_loss:1.1374646425247192 d_loss:1.1174999475479126 (f_loss=-0.17982250452041626 r_loss=1.1156370639801025 GP=0.18168538808822632)
[Training] epoch:627 step:100 g_loss:1.1765797138214111 d_loss:1.6590924710035324 (f_loss=-0.18709726631641388 r_loss=1.0960584878921509 GP=0.7501312494277954)
[Training] epoch:627 step:200 g_loss:1.1923573017120361 d_loss:1.7507544159889221 (f_loss=-0.20497971773147583 r_loss=1.024035930633545 GP=0.931698203086853)
[Training] epoch:627 step:300 g_loss:1.2323189973831177 d_loss:1.475106656551361 (f_loss=-0.1335015892982483 r_loss=1.1080149412155151 GP=0.5005933046340942)
[Training] epoch:628 step:0 g_loss:1.2000309228897095 d_loss:1.450735181570053 (f_loss=-0.18837466835975647 r_loss=1.0832387208938599 GP=0.5558711290359497)
[Training] epoch:628 step:100 g_loss:1.1493679285049438 d_loss:1.3713071197271347 (f_loss=-0.208253875374794 r_loss=1.012587547302246 GP=0.5669734477996826)
[Training] epoch:628 step:200 g_loss:1.1726887226104736 d_loss:1.532246083021164 (f_loss=-0.15326228737831116 r_loss=0.9935845732688904 GP=0.6919237971305847)
[Training] epoch:628 step:300 g_loss:1.1708461046218872 d_loss:1.584962084889412 (f_loss=-0.2223760336637497 r_loss=1.0953923463821411 GP=0.7119457721710205)
[Training] epoch:629 step:0 g_loss:1.216388463973999 d_loss:2.191791847348213 (f_loss=-0.1280829757452011 r_loss=0.8175753951072693 GP=1.502299427986145)
[Training] epoch:629 step:100 g_loss:1.2673946619033813 d_loss:1.2509773075580597 (f_loss=-0.1811642348766327 r_loss=1.0901975631713867 GP=0.34194397926330566)
[Training] epoch:629 step:200 g_loss:1.2005494832992554 d_loss:1.3793651759624481 (f_loss=-0.136389821767807 r_loss=1.0302765369415283 GP=0.4854784607887268)
[Training] epoch:629 step:300 g_loss:1.1789283752441406 d_loss:1.6343629211187363 (f_loss=-0.2137826830148697 r_loss=1.0508919954299927 GP=0.7972536087036133)
[Training] epoch:630 step:0 g_loss:1.2442622184753418 d_loss:1.2393832206726074 (f_loss=-0.18059003353118896 r_loss=1.0574443340301514 GP=0.362528920173645)

[Training] epoch:630 step:100 g_loss:1.1557354927062988 d_loss:1.142263501882553 (f_loss=-0.2020171582698822 r_loss=1.1196016073226929 GP=0.22467905282974243)
[Training] epoch:630 step:200 g_loss:1.2238883972167969 d_loss:1.5234730690717697 (f_loss=-0.2217884212732315 r_loss=1.1211552619934082 GP=0.624106228351593)
[Training] epoch:630 step:300 g_loss:1.1246622800827026 d_loss:1.2620670348405838 (f_loss=-0.20316092669963837 r_loss=1.0548166036605835 GP=0.41041135787963867)
[Training] epoch:631 step:0 g_loss:1.2311327457427979 d_loss:1.1482564210891724 (f_loss=-0.15049465000629425 r_loss=1.1820597648620605 GP=0.11669130623340607)
[Training] epoch:631 step:100 g_loss:1.1777158975601196 d_loss:1.882645845413208 (f_loss=-0.1754193902015686 r_loss=0.9913428425788879 GP=1.0667223930358887)
[Training] epoch:631 step:200 g_loss:1.1896045207977295 d_loss:1.9043002724647522 (f_loss=-0.23724079132080078 r_loss=0.9668645262718201 GP=1.174676537513733)
[Training] epoch:631 step:300 g_loss:1.238389492034912 d_loss:1.3448261618614197 (f_loss=-0.19653090834617615 r_loss=1.1008386611938477 GP=0.44051840901374817)
[Training] epoch:632 step:0 g_loss:1.2637300491333008 d_loss:1.5118223428726196 (f_loss=-0.17622101306915283 r_loss=1.1504669189453125 GP=0.53757643699646)
[Training] epoch:632 step:100 g_loss:1.21876859664917 d_loss:1.4626536071300507 (f_loss=-0.19429907202720642 r_loss=0.9409416317939758 GP=0.7160110473632812)
[Training] epoch:632 step:200 g_loss:1.1978192329406738 d_loss:1.4295561611652374 (f_loss=-0.24376007914543152 r_loss=1.1558148860931396 GP=0.5175013542175293)
[Training] epoch:632 step:300 g_loss:1.2208685874938965 d_loss:1.340688705444336 (f_loss=-0.1726962924003601 r_loss=1.126589059829712 GP=0.38679593801498413)
[Training] epoch:633 step:0 g_loss:1.2623322010040283 d_loss:1.188046172261238 (f_loss=-0.2306671291589737 r_loss=1.1469346284866333 GP=0.2717786729335785)
[Training] epoch:633 step:100 g_loss:1.2640933990478516 d_loss:1.693245679140091 (f_loss=-0.17284539341926575 r_loss=0.9567617177963257 GP=0.909329354763031)
[Training] epoch:633 step:200 g_loss:1.1717232465744019 d_loss:1.3762589991092682 (f_loss=-0.19168242812156677 r_loss=1.1207743883132935 GP=0.4471670389175415)
[Training] epoch:633 step:300 g_loss:1.1809723377227783 d_loss:1.274424284696579 (f_loss=-0.09699967503547668 r_loss=1.1174447536468506 GP=0.2539792060852051)
[Training] epoch:634 step:0 g_loss:1.1711019277572632 d_loss:1.3424844443798065 (f_loss=-0.23228931427001953 r_loss=1.146162748336792 GP=0.42861101031303406)
[Training] epoch:634 step:100 g_loss:1.1989712715148926 d_loss:1.373411014676094 (f_loss=-0.21597962081432343 r_loss=1.1164090633392334 GP=0.4729815721511841)
[Training] epoch:634 step:200 g_loss:1.1553075313568115 d_loss:1.252202332019806 (f_loss=-0.1961955428123474 r_loss=0.9953877329826355 GP=0.4530101418495178)
[Training] epoch:634 step:300 g_loss:1.2244501113891602 d_loss:1.8451780825853348 (f_loss=-0.18832318484783173 r_loss=1.0848780870437622 GP=0.9486231803894043)
[Training] epoch:635 step:0 g_loss:1.1592142581939697 d_loss:1.758373200893402 (f_loss=-0.18495279550552368 r_loss=1.1020172834396362 GP=0.8413087129592896)
[Training] epoch:635 step:100 g_loss:1.2708659172058105 d_loss:1.365364447236061 (f_loss=-0.11922003328800201 r_loss=1.0029888153076172 GP=0.4815956652164459)
[Training] epoch:635 step:200 g_loss:1.1511982679367065 d_loss:1.2190915495157242 (f_loss=-0.22075973451137543 r_loss=1.0543200969696045 GP=0.3855311870574951)
[Training] epoch:635 step:300 g_loss:1.2392303943634033 d_loss:1.4111315459012985 (f_loss=-0.19641239941120148 r_loss=1.0832433700561523 GP=0.5243005752563477)
[Training] epoch:636 step:0 g_loss:1.178183913230896 d_loss:1.317943349480629 (f_loss=-0.2364293783903122 r_loss=1.027908444404602 GP=0.5264642834663391)
[Training] epoch:636 step:100 g_loss:1.1665163040161133 d_loss:2.4206331223249435 (f_loss=-0.19259865581989288 r_loss=1.024754285812378 GP=1.5884774923324585)
[Training] epoch:636 step:200 g_loss:1.201451063156128 d_loss:1.200020283460617 (f_loss=-0.20709803700447083 r_loss=1.0637078285217285 GP=0.3434104919433594)
[Training] epoch:636 step:300 g_loss:1.152613878250122 d_loss:1.3821288645267487 (f_loss=-0.20913216471672058 r_loss=1.0881174802780151 GP=0.5031435489654541)
[Training] epoch:637 step:0 g_loss:1.169731855392456 d_loss:1.390988051891327 (f_loss=-0.1984061598777771 r_loss=1.0916428565979004 GP=0.4977513551712036)
[Training] epoch:637 step:100 g_loss:1.1992706060409546 d_loss:3.0154901146888733 (f_loss=-0.20156866312026978 r_loss=1.0294824838638306 GP=2.1875762939453125)
[Training] epoch:637 step:200 g_loss:1.2321131229400635 d_loss:1.150730311870575 (f_loss=-0.15246322751045227 r_loss=1.0515292882919312 GP=0.25166425108909607)
[Training] epoch:637 step:300 g_loss:1.2038383483886719 d_loss:3.4621459990739822 (f_loss=-0.19549457728862762 r_loss=1.0160855054855347 GP=2.641555070877075)
[Training] epoch:638 step:0 g_loss:1.1681549549102783 d_loss:1.1993268877267838 (f_loss=-0.24491514265537262 r_loss=1.1134517192840576 GP=0.33079031109809875)
[Training] epoch:638 step:100 g_loss:1.192270278930664 d_loss:1.3340052515268326 (f_loss=-0.1687360256910324 r_loss=1.1644816398620605 GP=0.33825963735580444)
[Training] epoch:638 step:200 g_loss:1.1878716945648193 d_loss:1.7468120157718658 (f_loss=-0.22474369406700134 r_loss=1.0895402431488037 GP=0.8820154666900635)
[Training] epoch:638 step:300 g_loss:1.1890220642089844 d_loss:1.460661843419075 (f_loss=-0.19350604712963104 r_loss=1.0878174304962158 GP=0.5663504600524902)
[Training] epoch:639 step:0 g_loss:1.1962759494781494 d_loss:1.9285119771957397 (f_loss=-0.158086359500885 r_loss=0.9578453898429871 GP=1.1287529468536377)
[Training] epoch:639 step:100 g_loss:1.1866508722305298 d_loss:1.2237989902496338 (f_loss=-0.19263365864753723 r_loss=1.0784533023834229 GP=0.33797934651374817)
[Training] epoch:639 step:200 g_loss:1.214496374130249 d_loss:1.7894501090049744 (f_loss=-0.19317901134490967 r_loss=1.1336551904678345 GP=0.8489739298820496)
[Training] epoch:639 step:300 g_loss:1.2302957773208618 d_loss:1.9395149946212769 (f_loss=-0.24481821060180664 r_loss=0.9552597999572754 GP=1.229073405265808)
[Training] epoch:640 step:0 g_loss:1.1874442100524902 d_loss:1.995841383934021 (f_loss=-0.23734724521636963 r_loss=1.0265154838562012 GP=1.2066731452941895)

[Training] epoch:640 step:100 g_loss:1.1332889795303345 d_loss:1.7901495695114136 (f_loss=-0.1999216079711914 r_loss=1.1117351055145264 GP=0.8783360719680786)
[Training] epoch:640 step:200 g_loss:1.1571848392486572 d_loss:1.089477926492691 (f_loss=-0.18440666794776917 r_loss=1.06727933883667 GP=0.20660525560379028)
[Training] epoch:640 step:300 g_loss:1.187819480895996 d_loss:1.4671202600002289 (f_loss=-0.20512104034423828 r_loss=1.1948606967926025 GP=0.4773806035518646)
[Training] epoch:641 step:0 g_loss:1.2281132936477661 d_loss:1.9295234084129333 (f_loss=-0.2104831337928772 r_loss=0.9729797840118408 GP=1.1670267581939697)
[Training] epoch:641 step:100 g_loss:1.225494384765625 d_loss:1.2904595136642456 (f_loss=-0.1800428330898285 r_loss=1.1277318000793457 GP=0.3427705466747284)
[Training] epoch:641 step:200 g_loss:1.154392957687378 d_loss:1.3520392179489136 (f_loss=-0.2355840504169464 r_loss=1.0914889574050903 GP=0.49613431096076965)
[Training] epoch:641 step:300 g_loss:1.1460844278335571 d_loss:1.599884107708931 (f_loss=-0.20398102700710297 r_loss=1.0855132341384888 GP=0.7183519005775452)
[Training] epoch:642 step:0 g_loss:1.152819275856018 d_loss:1.396767795085907 (f_loss=-0.2058042287826538 r_loss=1.0718748569488525 GP=0.5306971669197083)
[Training] epoch:642 step:100 g_loss:1.2359684705734253 d_loss:1.57085382938385 (f_loss=-0.17915797233581543 r_loss=1.068710446357727 GP=0.6813013553619385)
[Training] epoch:642 step:200 g_loss:1.2236058712005615 d_loss:1.6744577586650848 (f_loss=-0.15241196751594543 r_loss=1.0761849880218506 GP=0.7506847381591797)
[Training] epoch:642 step:300 g_loss:1.167640209197998 d_loss:2.040866941213608 (f_loss=-0.2060774862766266 r_loss=1.2157135009765625 GP=1.0312309265136719)
[Training] epoch:643 step:0 g_loss:1.201620101928711 d_loss:1.2259095907211304 (f_loss=-0.2574021816253662 r_loss=1.050072193145752 GP=0.43323957920074463)
[Training] epoch:643 step:100 g_loss:1.213411569595337 d_loss:1.3118351995944977 (f_loss=-0.16777047514915466 r_loss=1.1001925468444824 GP=0.3794131278991699)
[Training] epoch:643 step:200 g_loss:1.1088734865188599 d_loss:1.4532152265310287 (f_loss=-0.15724177658557892 r_loss=1.1472408771514893 GP=0.4632161259651184)
[Training] epoch:643 step:300 g_loss:1.2492964267730713 d_loss:1.5038332641124725 (f_loss=-0.1772306263446808 r_loss=1.0894067287445068 GP=0.5916571617126465)
[Training] epoch:644 step:0 g_loss:1.1928765773773193 d_loss:1.2102177739143372 (f_loss=-0.21825510263442993 r_loss=1.110528588294983 GP=0.3179442882537842)
[Training] epoch:644 step:100 g_loss:1.1985366344451904 d_loss:2.1493920981884003 (f_loss=-0.21504035592079163 r_loss=0.9263505935668945 GP=1.4380818605422974)
[Training] epoch:644 step:200 g_loss:1.1750086545944214 d_loss:1.3966587483882904 (f_loss=-0.19817206263542175 r_loss=0.9465715885162354 GP=0.6482592225074768)
[Training] epoch:644 step:300 g_loss:1.1789491176605225 d_loss:1.6460625529289246 (f_loss=-0.19854992628097534 r_loss=1.0766419172286987 GP=0.7679705619812012)
[Training] epoch:645 step:0 g_loss:1.2675881385803223 d_loss:2.263730466365814 (f_loss=-0.17704921960830688 r_loss=1.0388588905334473 GP=1.4019207954406738)
[Training] epoch:645 step:100 g_loss:1.1648668050765991 d_loss:1.1317417472600937 (f_loss=-0.18889687955379486 r_loss=1.0605313777923584 GP=0.26010724902153015)
[Training] epoch:645 step:200 g_loss:1.180741310119629 d_loss:1.5887203812599182 (f_loss=-0.1405206322669983 r_loss=1.0974189043045044 GP=0.6318221092224121)
[Training] epoch:645 step:300 g_loss:1.2579761743545532 d_loss:1.3009659945964813 (f_loss=-0.19580063223838806 r_loss=1.145928144454956 GP=0.35083848237991333)
[Training] epoch:646 step:0 g_loss:1.2273750305175781 d_loss:1.2034874558448792 (f_loss=-0.22041702270507812 r_loss=1.1594164371490479 GP=0.2644880414009094)
[Training] epoch:646 step:100 g_loss:1.1457055807113647 d_loss:1.2278092801570892 (f_loss=-0.20663926005363464 r_loss=1.096356749534607 GP=0.33809179067611694)
[Training] epoch:646 step:200 g_loss:1.2215584516525269 d_loss:1.4472055286169052 (f_loss=-0.1839718371629715 r_loss=1.1170443296432495 GP=0.5141330361366272)
[Training] epoch:646 step:300 g_loss:1.1813784837722778 d_loss:1.8774627596139908 (f_loss=-0.19618158042430878 r_loss=1.0929487943649292 GP=0.9806955456733704)
[Training] epoch:647 step:0 g_loss:1.1733163595199585 d_loss:1.3907287567853928 (f_loss=-0.19603772461414337 r_loss=1.0154643058776855 GP=0.5713021755218506)
[Training] epoch:647 step:100 g_loss:1.2042392492294312 d_loss:1.7250146865844727 (f_loss=-0.2264542579650879 r_loss=1.0984382629394531 GP=0.8530306816101074)
[Training] epoch:647 step:200 g_loss:1.2786794900894165 d_loss:1.8540171086788177 (f_loss=-0.20811119675636292 r_loss=1.0134907960891724 GP=1.0486375093460083)
[Training] epoch:647 step:300 g_loss:1.2061455249786377 d_loss:1.2939040660858154 (f_loss=-0.17219585180282593 r_loss=1.1163171529769897 GP=0.3497827649116516)
[Training] epoch:648 step:0 g_loss:1.2088780403137207 d_loss:1.277868241071701 (f_loss=-0.19659093022346497 r_loss=1.0398530960083008 GP=0.43460607528686523)
[Training] epoch:648 step:100 g_loss:1.1375285387039185 d_loss:1.5847812741994858 (f_loss=-0.21934159100055695 r_loss=1.089582085609436 GP=0.7145407795906067)
[Training] epoch:648 step:200 g_loss:1.257548451423645 d_loss:1.5796071588993073 (f_loss=-0.2714272439479828 r_loss=1.1412432193756104 GP=0.7097911834716797)
[Training] epoch:648 step:300 g_loss:1.2049943208694458 d_loss:1.7993750870227814 (f_loss=-0.22578856348991394 r_loss=1.0841752290725708 GP=0.9409884214401245)
[Training] epoch:649 step:0 g_loss:1.1811259984970093 d_loss:1.3612460792064667 (f_loss=-0.23747137188911438 r_loss=1.1308417320251465 GP=0.46787571907043457)
[Training] epoch:649 step:100 g_loss:1.2130990028381348 d_loss:1.5339651554822922 (f_loss=-0.2289685159921646 r_loss=1.159776210784912 GP=0.6031574606895447)
[Training] epoch:649 step:200 g_loss:1.21867835521698 d_loss:1.6850571036338806 (f_loss=-0.22896718978881836 r_loss=1.1231504678726196 GP=0.7908738255500793)
[Training] epoch:649 step:300 g_loss:1.2364904880523682 d_loss:1.4772314727306366 (f_loss=-0.22613206505775452 r_loss=1.1176050901412964 GP=0.5857584476470947)
[Training] epoch:650 step:0 g_loss:1.1955552101135254 d_loss:1.691338524222374 (f_loss=-0.17941249907016754 r_loss=1.0161515474319458 GP=0.8545994758605957)

[Training] epoch:650 step:100 g_loss:1.2564009428024292 d_loss:1.4089308083057404 (f_loss=-0.21582183241844177 r_loss=1.0261520147323608 GP=0.5986006259918213)
[Training] epoch:650 step:200 g_loss:1.2513108253479004 d_loss:1.5014299303293228 (f_loss=-0.2060566395521164 r_loss=1.0898447036743164 GP=0.6176418662071228)
[Training] epoch:650 step:300 g_loss:1.241858959197998 d_loss:1.5325725674629211 (f_loss=-0.26725590229034424 r_loss=1.087141752243042 GP=0.7126867175102234)
[Training] epoch:651 step:0 g_loss:1.2366528511047363 d_loss:1.550658941268921 (f_loss=-0.2146751880645752 r_loss=1.0465527772903442 GP=0.7187813520431519)
[Training] epoch:651 step:100 g_loss:1.2587740421295166 d_loss:1.371386006474495 (f_loss=-0.21991567313671112 r_loss=1.0828213691711426 GP=0.5084803104400635)
[Training] epoch:651 step:200 g_loss:1.134092926979065 d_loss:2.6691699624061584 (f_loss=-0.1731223464012146 r_loss=0.968549370765686 GP=1.873742938041687)
[Training] epoch:651 step:300 g_loss:1.2538342475891113 d_loss:2.192487135529518 (f_loss=-0.24665527045726776 r_loss=0.8991139531135559 GP=1.54002845287323)
[Training] epoch:652 step:0 g_loss:1.169212818145752 d_loss:1.7882757484912872 (f_loss=-0.17900392413139343 r_loss=0.9982195496559143 GP=0.9690601229667664)
[Training] epoch:652 step:100 g_loss:1.1325682401657104 d_loss:1.5288849174976349 (f_loss=-0.17945554852485657 r_loss=1.09903883934021 GP=0.6093016266822815)
[Training] epoch:652 step:200 g_loss:1.2204688787460327 d_loss:1.5743708312511444 (f_loss=-0.24297699332237244 r_loss=1.1250261068344116 GP=0.6923217177391052)
[Training] epoch:652 step:300 g_loss:1.2039426565170288 d_loss:1.8761973679065704 (f_loss=-0.22331765294075012 r_loss=1.1257926225662231 GP=0.9737223982810974)
[Training] epoch:653 step:0 g_loss:1.2518723011016846 d_loss:2.5629011392593384 (f_loss=-0.20574581623077393 r_loss=0.9375534057617188 GP=1.8310935497283936)
[Training] epoch:653 step:100 g_loss:1.2671867609024048 d_loss:1.5596317797899246 (f_loss=-0.22268550097942352 r_loss=1.1974952220916748 GP=0.5848220586776733)
[Training] epoch:653 step:200 g_loss:1.1853797435760498 d_loss:1.4466468393802643 (f_loss=-0.18012699484825134 r_loss=1.0697253942489624 GP=0.5570484399795532)
[Training] epoch:653 step:300 g_loss:1.221651554107666 d_loss:1.7507432997226715 (f_loss=-0.26726624369621277 r_loss=1.0801588296890259 GP=0.9378507137298584)
[Training] epoch:654 step:0 g_loss:1.1722389459609985 d_loss:1.7680211514234543 (f_loss=-0.19154579937458038 r_loss=1.1292489767074585 GP=0.8303179740905762)
[Training] epoch:654 step:100 g_loss:1.2091299295425415 d_loss:1.4293934553861618 (f_loss=-0.2044723778963089 r_loss=1.1227443218231201 GP=0.5111215114593506)
[Training] epoch:654 step:200 g_loss:1.266822099685669 d_loss:3.424384370446205 (f_loss=-0.2212897390127182 r_loss=1.0828098058700562 GP=2.562864303588867)
[Training] epoch:654 step:300 g_loss:1.2351030111312866 d_loss:1.2139879167079926 (f_loss=-0.18553078174591064 r_loss=1.151613473892212 GP=0.24790522456169128)
[Training] epoch:655 step:0 g_loss:1.211860179901123 d_loss:1.296438068151474 (f_loss=-0.22452354431152344 r_loss=1.0988417863845825 GP=0.4221198260784149)
[Training] epoch:655 step:100 g_loss:1.193037509918213 d_loss:1.574126422405243 (f_loss=-0.20944899320602417 r_loss=1.0804047584533691 GP=0.703170657157898)
[Training] epoch:655 step:200 g_loss:1.2142200469970703 d_loss:1.3116503953933716 (f_loss=-0.1846051812171936 r_loss=1.144333004951477 GP=0.35192257165908813)
[Training] epoch:655 step:300 g_loss:1.1944139003753662 d_loss:2.2193972021341324 (f_loss=-0.15695463120937347 r_loss=1.093739628791809 GP=1.2826122045516968)
[Training] epoch:656 step:0 g_loss:1.155212163925171 d_loss:1.4671354442834854 (f_loss=-0.17860053479671478 r_loss=0.9887155294418335 GP=0.6570204496383667)
[Training] epoch:656 step:100 g_loss:1.2363612651824951 d_loss:1.5089533030986786 (f_loss=-0.21732011437416077 r_loss=1.1141213178634644 GP=0.612152099609375)
[Training] epoch:656 step:200 g_loss:1.236290693283081 d_loss:1.268450677394867 (f_loss=-0.15801028907299042 r_loss=1.17966890335083 GP=0.24679206311702728)
[Training] epoch:656 step:300 g_loss:1.2193950414657593 d_loss:2.1628723442554474 (f_loss=-0.18882855772972107 r_loss=1.0459704399108887 GP=1.3057304620742798)
[Training] epoch:657 step:0 g_loss:1.2066974639892578 d_loss:2.531778186559677 (f_loss=-0.2388228476047516 r_loss=0.957054615020752 GP=1.8135464191436768)
[Training] epoch:657 step:100 g_loss:1.238877773284912 d_loss:1.3911037892103195 (f_loss=-0.19054187834262848 r_loss=1.0628817081451416 GP=0.5187639594078064)
[Training] epoch:657 step:200 g_loss:1.2112996578216553 d_loss:1.6941878199577332 (f_loss=-0.26577478647232056 r_loss=1.0190225839614868 GP=0.9409400224685669)
[Training] epoch:657 step:300 g_loss:1.2489681243896484 d_loss:1.4200969338417053 (f_loss=-0.23376566171646118 r_loss=1.1308846473693848 GP=0.5229779481887817)
[Training] epoch:658 step:0 g_loss:1.0910406112670898 d_loss:1.1797229200601578 (f_loss=-0.18008726835250854 r_loss=1.1453112363815308 GP=0.21449895203113556)
[Training] epoch:658 step:100 g_loss:1.2325809001922607 d_loss:1.9459103643894196 (f_loss=-0.20728537440299988 r_loss=1.0956906080245972 GP=1.0575051307678223)
[Training] epoch:658 step:200 g_loss:1.244750738143921 d_loss:1.1281295716762543 (f_loss=-0.26765990257263184 r_loss=1.1275726556777954 GP=0.2682168185710907)
[Training] epoch:658 step:300 g_loss:1.2116634845733643 d_loss:1.528795450925827 (f_loss=-0.24352601170539856 r_loss=1.1490461826324463 GP=0.6232752799987793)
[Training] epoch:659 step:0 g_loss:1.2485791444778442 d_loss:1.582945555448532 (f_loss=-0.24371513724327087 r_loss=1.02571439743042 GP=0.8009462952613831)
[Training] epoch:659 step:100 g_loss:1.234971046447754 d_loss:1.4721015691757202 (f_loss=-0.1976192593574524 r_loss=1.0525482892990112 GP=0.6171725392341614)
[Training] epoch:659 step:200 g_loss:1.2654324769973755 d_loss:1.3648759424686432 (f_loss=-0.2047557532787323 r_loss=1.0085692405700684 GP=0.5610624551773071)
[Training] epoch:659 step:300 g_loss:1.200225830078125 d_loss:1.6835784912109375 (f_loss=-0.2814015746116638 r_loss=1.0776444673538208 GP=0.8873355984687805)
[Training] epoch:660 step:0 g_loss:1.2219473123550415 d_loss:2.1082069873809814 (f_loss=-0.22202199697494507 r_loss=0.9836603999137878 GP=1.3465685844421387)

[Training] epoch:660 step:100 g_loss:1.232438325881958 d_loss:1.6023045778274536 (f_loss=-0.170729398727417 r_loss=1.0978885889053345 GP=0.6751453876495361)
[Training] epoch:660 step:200 g_loss:1.277423620223999 d_loss:1.5251437276601791 (f_loss=-0.2472837120294571 r_loss=1.1300499439239502 GP=0.642377495765686)
[Training] epoch:660 step:300 g_loss:1.1736977100372314 d_loss:1.5393564701080322 (f_loss=-0.14734303951263428 r_loss=1.1021348237991333 GP=0.5845646858215332)
[Training] epoch:661 step:0 g_loss:1.2706186771392822 d_loss:1.3775160163640976 (f_loss=-0.17139331996440887 r_loss=1.1009290218353271 GP=0.4479803144931793)
[Training] epoch:661 step:100 g_loss:1.1971452236175537 d_loss:1.7257844060659409 (f_loss=-0.17584116756916046 r_loss=1.0981394052505493 GP=0.803486168384552)
[Training] epoch:661 step:200 g_loss:1.2091354131698608 d_loss:1.2811891436576843 (f_loss=-0.14657199382781982 r_loss=1.1272677183151245 GP=0.30049341917037964)
[Training] epoch:661 step:300 g_loss:1.2435152530670166 d_loss:1.8895430862903595 (f_loss=-0.178664892911911 r_loss=1.061606764793396 GP=1.0066012144088745)
[Training] epoch:662 step:0 g_loss:1.2015541791915894 d_loss:1.6587663888931274 (f_loss=-0.2181965708732605 r_loss=0.9441231489181519 GP=0.9328398108482361)
[Training] epoch:662 step:100 g_loss:1.235689401626587 d_loss:1.1340672373771667 (f_loss=-0.2193240523338318 r_loss=1.0807756185531616 GP=0.2726156711578369)
[Training] epoch:662 step:200 g_loss:1.1948410272598267 d_loss:1.4500603526830673 (f_loss=-0.22792769968509674 r_loss=1.1020573377609253 GP=0.5759307146072388)
[Training] epoch:662 step:300 g_loss:1.1991941928863525 d_loss:1.4039021581411362 (f_loss=-0.2449214607477188 r_loss=1.119349718093872 GP=0.5294739007949829)
[Training] epoch:663 step:0 g_loss:1.2608455419540405 d_loss:1.321136549115181 (f_loss=-0.13589800894260406 r_loss=0.9671125411987305 GP=0.48992201685905457)
[Training] epoch:663 step:100 g_loss:1.246629238128662 d_loss:1.4073722958564758 (f_loss=-0.23122113943099976 r_loss=1.0508644580841064 GP=0.5877289772033691)
[Training] epoch:663 step:200 g_loss:1.2586569786071777 d_loss:2.552356481552124 (f_loss=-0.18062245845794678 r_loss=1.00278902053833 GP=1.7301899194717407)
[Training] epoch:663 step:300 g_loss:1.2173302173614502 d_loss:2.2515808790922165 (f_loss=-0.23195572197437286 r_loss=1.0091174840927124 GP=1.474419116973877)
[Training] epoch:664 step:0 g_loss:1.176086187362671 d_loss:1.2758897989988327 (f_loss=-0.19585029780864716 r_loss=1.1275596618652344 GP=0.3441804349422455)
[Training] epoch:664 step:100 g_loss:1.2291667461395264 d_loss:2.0362786948680878 (f_loss=-0.28192761540412903 r_loss=1.079028844833374 GP=1.2391774654388428)
[Training] epoch:664 step:200 g_loss:1.2017383575439453 d_loss:5.465276658535004 (f_loss=-0.23513787984848022 r_loss=0.841791033744812 GP=4.858623504638672)
[Training] epoch:664 step:300 g_loss:1.2275160551071167 d_loss:2.0203835368156433 (f_loss=-0.18826550245285034 r_loss=1.0675413608551025 GP=1.1411076784133911)
[Training] epoch:665 step:0 g_loss:1.1667002439498901 d_loss:1.4332246482372284 (f_loss=-0.21152958273887634 r_loss=1.112042784690857 GP=0.5327114462852478)
[Training] epoch:665 step:100 g_loss:1.198596477508545 d_loss:1.1853578239679337 (f_loss=-0.2402750700712204 r_loss=1.0548018217086792 GP=0.37083107233047485)
[Training] epoch:665 step:200 g_loss:1.2393779754638672 d_loss:1.9681180566549301 (f_loss=-0.16731573641300201 r_loss=1.099847435951233 GP=1.0355863571166992)
[Training] epoch:665 step:300 g_loss:1.234356164932251 d_loss:1.2303827702999115 (f_loss=-0.27463987469673157 r_loss=1.1018515825271606 GP=0.4031710624694824)
[Training] epoch:666 step:0 g_loss:1.151202917098999 d_loss:2.138446494936943 (f_loss=-0.23629875481128693 r_loss=1.0582915544509888 GP=1.3164536952972412)
[Training] epoch:666 step:100 g_loss:1.1887478828430176 d_loss:2.593567505478859 (f_loss=-0.20608298480510712 r_loss=0.9340217709541321 GP=1.865628719329834)
[Training] epoch:666 step:200 g_loss:1.232623815536499 d_loss:2.6621737629175186 (f_loss=-0.23460452258586884 r_loss=0.9284177422523499 GP=1.9683605432510376)
[Training] epoch:666 step:300 g_loss:1.193014144897461 d_loss:1.5367592722177505 (f_loss=-0.20680849254131317 r_loss=1.1386104822158813 GP=0.6049572825431824)
[Training] epoch:667 step:0 g_loss:1.2299257516860962 d_loss:1.571291595697403 (f_loss=-0.18748560547828674 r_loss=1.1868414878845215 GP=0.5719357132911682)
[Training] epoch:667 step:100 g_loss:1.1791338920593262 d_loss:1.4185466766357422 (f_loss=-0.23008829355239868 r_loss=1.1133922338485718 GP=0.5352427363395691)
[Training] epoch:667 step:200 g_loss:1.2017676830291748 d_loss:1.779243215918541 (f_loss=-0.22225643694400787 r_loss=1.1078819036483765 GP=0.8936177492141724)
[Training] epoch:667 step:300 g_loss:1.200880765914917 d_loss:1.6047287732362747 (f_loss=-0.19442151486873627 r_loss=1.2014029026031494 GP=0.5977473855018616)
[Training] epoch:668 step:0 g_loss:1.2125120162963867 d_loss:1.2472822964191437 (f_loss=-0.2539720833301544 r_loss=1.0280768871307373 GP=0.4731774926185608)
[Training] epoch:668 step:100 g_loss:1.235320806503296 d_loss:1.21062371134758 (f_loss=-0.2956463396549225 r_loss=1.081823468208313 GP=0.42444658279418945)
[Training] epoch:668 step:200 g_loss:1.2398914098739624 d_loss:2.4639113694429398 (f_loss=-0.20779065787792206 r_loss=1.0863807201385498 GP=1.585321307182312)
[Training] epoch:668 step:300 g_loss:1.2026735544204712 d_loss:2.5186203122138977 (f_loss=-0.2608874440193176 r_loss=0.8791686296463013 GP=1.900339126586914)
[Training] epoch:669 step:0 g_loss:1.2602349519729614 d_loss:1.6005026698112488 (f_loss=-0.25256896018981934 r_loss=1.1407570838928223 GP=0.7123145461082458)
[Training] epoch:669 step:100 g_loss:1.2162925004959106 d_loss:1.4336223602294922 (f_loss=-0.16340911388397217 r_loss=1.0834859609603882 GP=0.5135455131530762)
[Training] epoch:669 step:200 g_loss:1.234449863433838 d_loss:2.4834306836128235 (f_loss=-0.24911242723464966 r_loss=1.0392698049545288 GP=1.6932733058929443)
[Training] epoch:669 step:300 g_loss:1.228956699371338 d_loss:1.211637258529663 (f_loss=-0.2297339141368866 r_loss=1.0959140062332153 GP=0.34545716643333435)
[Training] epoch:670 step:0 g_loss:1.16698157787323 d_loss:2.149072840809822 (f_loss=-0.22328977286815643 r_loss=0.9780967235565186 GP=1.39426589012146)

[Training] epoch:670 step:100 g_loss:1.2172973155975342 d_loss:1.3793761134147644 (f_loss=-0.24661999940872192 r_loss=1.109323501586914 GP=0.5166726112365723)
[Training] epoch:670 step:200 g_loss:1.2346851825714111 d_loss:1.3671217560768127 (f_loss=-0.17668065428733826 r_loss=1.1328617334365845 GP=0.41094067692756653)
[Training] epoch:670 step:300 g_loss:1.2055168151855469 d_loss:1.369856283068657 (f_loss=-0.20206047594547272 r_loss=1.0424869060516357 GP=0.5294298529624939)
[Training] epoch:671 step:0 g_loss:1.2106717824935913 d_loss:1.9049231708049774 (f_loss=-0.15503016114234924 r_loss=1.1351943016052246 GP=0.924759030342102)
[Training] epoch:671 step:100 g_loss:1.2677665948867798 d_loss:1.495071455836296 (f_loss=-0.22739221155643463 r_loss=1.064672827720642 GP=0.6577908396720886)
[Training] epoch:671 step:200 g_loss:1.2970248460769653 d_loss:2.4575366228818893 (f_loss=-0.23231501877307892 r_loss=0.9243234395980835 GP=1.7655282020568848)
[Training] epoch:671 step:300 g_loss:1.2765954732894897 d_loss:1.6249233186244965 (f_loss=-0.1869470775127411 r_loss=1.15109121799469 GP=0.6607791781425476)
[Training] epoch:672 step:0 g_loss:1.218976616859436 d_loss:1.2733238339424133 (f_loss=-0.23627522587776184 r_loss=1.1747385263442993 GP=0.33486053347587585)
[Training] epoch:672 step:100 g_loss:1.177199363708496 d_loss:1.3098831474781036 (f_loss=-0.23335906863212585 r_loss=1.164520263671875 GP=0.3787219524383545)
[Training] epoch:672 step:200 g_loss:1.1953110694885254 d_loss:1.5474029183387756 (f_loss=-0.26389217376708984 r_loss=1.1743162870407104 GP=0.636978805065155)
[Training] epoch:672 step:300 g_loss:1.2542004585266113 d_loss:1.3053790926933289 (f_loss=-0.27069318294525146 r_loss=1.0946968793869019 GP=0.48137539625167847)
[Training] epoch:673 step:0 g_loss:1.2508630752563477 d_loss:2.2301437854766846 (f_loss=-0.2524014115333557 r_loss=0.968623697757721 GP=1.5139214992523193)
[Training] epoch:673 step:100 g_loss:1.161304235458374 d_loss:1.7164754569530487 (f_loss=-0.295301228761673 r_loss=1.0242234468460083 GP=0.9875532388687134)
[Training] epoch:673 step:200 g_loss:1.1938164234161377 d_loss:1.8951686769723892 (f_loss=-0.2286728471517563 r_loss=1.1414400339126587 GP=0.9824014902114868)
[Training] epoch:673 step:300 g_loss:1.2754180431365967 d_loss:1.475081354379654 (f_loss=-0.2664184272289276 r_loss=1.1516205072402954 GP=0.5898792743682861)
[Training] epoch:674 step:0 g_loss:1.1876225471496582 d_loss:4.00766958296299 (f_loss=-0.2133689969778061 r_loss=1.1317777633666992 GP=3.0892608165740967)
[Training] epoch:674 step:100 g_loss:1.258047103881836 d_loss:2.2101498544216156 (f_loss=-0.2544231712818146 r_loss=1.1484342813491821 GP=1.316138744354248)
[Training] epoch:674 step:200 g_loss:1.2421116828918457 d_loss:2.968931645154953 (f_loss=-0.23051682114601135 r_loss=1.0067511796951294 GP=2.192697286605835)
[Training] epoch:674 step:300 g_loss:1.2014245986938477 d_loss:1.9197620451450348 (f_loss=-0.17580947279930115 r_loss=1.0492579936981201 GP=1.0463135242462158)
[Training] epoch:675 step:0 g_loss:1.1228528022766113 d_loss:1.405683010816574 (f_loss=-0.13766655325889587 r_loss=1.0919219255447388 GP=0.4514276385307312)
[Training] epoch:675 step:100 g_loss:1.300796627998352 d_loss:1.7625614255666733 (f_loss=-0.2169194370508194 r_loss=1.1341336965560913 GP=0.8453471660614014)
[Training] epoch:675 step:200 g_loss:1.2027497291564941 d_loss:1.818796306848526 (f_loss=-0.2336805760860443 r_loss=1.1169681549072266 GP=0.9355087280273438)
[Training] epoch:675 step:300 g_loss:1.1281623840332031 d_loss:1.4825239181518555 (f_loss=-0.20123028755187988 r_loss=1.160295844078064 GP=0.5234583616256714)
[Training] epoch:676 step:0 g_loss:1.2525285482406616 d_loss:1.4884615540504456 (f_loss=-0.2386772632598877 r_loss=1.1181856393814087 GP=0.6089531779289246)
[Training] epoch:676 step:100 g_loss:1.3024952411651611 d_loss:1.6846561431884766 (f_loss=-0.1563810110092163 r_loss=1.1343896389007568 GP=0.706647515296936)
[Training] epoch:676 step:200 g_loss:1.2675870656967163 d_loss:1.8015728443861008 (f_loss=-0.18168504536151886 r_loss=1.1601816415786743 GP=0.8230762481689453)
[Training] epoch:676 step:300 g_loss:1.1673777103424072 d_loss:1.7159063816070557 (f_loss=-0.29152631759643555 r_loss=1.0483007431030273 GP=0.9591319561004639)
[Training] epoch:677 step:0 g_loss:1.2054555416107178 d_loss:2.916180431842804 (f_loss=-0.26693427562713623 r_loss=0.9161548018455505 GP=2.2669599056243896)
[Training] epoch:677 step:100 g_loss:1.2546696662902832 d_loss:2.041265547275543 (f_loss=-0.20438772439956665 r_loss=1.1375031471252441 GP=1.1081501245498657)
[Training] epoch:677 step:200 g_loss:1.2441176176071167 d_loss:1.2768997848033905 (f_loss=-0.2989565432071686 r_loss=1.0449323654174805 GP=0.5309239625930786)
[Training] epoch:677 step:300 g_loss:1.1882479190826416 d_loss:1.659000113606453 (f_loss=-0.1998237818479538 r_loss=1.1533938646316528 GP=0.7054300308227539)
[Training] epoch:678 step:0 g_loss:1.2660338878631592 d_loss:2.537242203950882 (f_loss=-0.23431643843650818 r_loss=1.000267744064331 GP=1.771290898323059)
[Training] epoch:678 step:100 g_loss:1.2337772846221924 d_loss:1.6130612194538116 (f_loss=-0.24059543013572693 r_loss=1.0740952491760254 GP=0.7795614004135132)
[Training] epoch:678 step:200 g_loss:1.247112512588501 d_loss:1.1381667107343674 (f_loss=-0.2446412593126297 r_loss=1.1855082511901855 GP=0.19729971885681152)
[Training] epoch:678 step:300 g_loss:1.2816998958587646 d_loss:2.1520896553993225 (f_loss=-0.287547767162323 r_loss=1.0412957668304443 GP=1.3983416557312012)
[Training] epoch:679 step:0 g_loss:1.274616003036499 d_loss:2.9103915989398956 (f_loss=-0.21710875630378723 r_loss=0.9556785225868225 GP=2.1718218326568604)
[Training] epoch:679 step:100 g_loss:1.2712972164154053 d_loss:2.302539676427841 (f_loss=-0.1829533874988556 r_loss=1.1874021291732788 GP=1.298090934753418)
[Training] epoch:679 step:200 g_loss:1.1441891193389893 d_loss:1.9685445576906204 (f_loss=-0.20427493751049042 r_loss=1.0284408330917358 GP=1.144378662109375)
[Training] epoch:679 step:300 g_loss:1.2493590116500854 d_loss:2.0046037286520004 (f_loss=-0.19196130335330963 r_loss=1.0501331090927124 GP=1.1464319229125977)
[Training] epoch:680 step:0 g_loss:1.1812235116958618 d_loss:1.5104605704545975 (f_loss=-0.23267106711864471 r_loss=1.196887493133545 GP=0.5462441444396973)

[Training] epoch:680 step:100 g_loss:1.1202800273895264 d_loss:1.5966436862945557 (f_loss=-0.1912161111831665 r_loss=1.1537820100784302 GP=0.634077787399292)
[Training] epoch:680 step:200 g_loss:1.2382123470306396 d_loss:1.2024528086185455 (f_loss=-0.2086191177368164 r_loss=1.0902974605560303 GP=0.32077446579933167)
[Training] epoch:680 step:300 g_loss:1.2468434572219849 d_loss:1.4654383659362793 (f_loss=-0.2508068084716797 r_loss=1.1954004764556885 GP=0.5208446979522705)
[Training] epoch:681 step:0 g_loss:1.1948447227478027 d_loss:1.5818513631820679 (f_loss=-0.26743823289871216 r_loss=1.1118745803833008 GP=0.7374150156974792)
[Training] epoch:681 step:100 g_loss:1.2598408460617065 d_loss:1.4914933145046234 (f_loss=-0.25478795170783997 r_loss=1.121549129486084 GP=0.6247321367263794)
[Training] epoch:681 step:200 g_loss:1.1368567943572998 d_loss:1.2379505038261414 (f_loss=-0.21672499179840088 r_loss=1.1485601663589478 GP=0.3061153292655945)
[Training] epoch:681 step:300 g_loss:1.1734009981155396 d_loss:2.2320443093776703 (f_loss=-0.19737878441810608 r_loss=1.2042396068572998 GP=1.2251834869384766)
[Training] epoch:682 step:0 g_loss:1.228355884552002 d_loss:2.1461194157600403 (f_loss=-0.1867179274559021 r_loss=1.0524741411209106 GP=1.2803632020950317)
[Training] epoch:682 step:100 g_loss:1.220812439918518 d_loss:1.973386436700821 (f_loss=-0.23372790217399597 r_loss=1.010703206062317 GP=1.1964111328125)
[Training] epoch:682 step:200 g_loss:1.2286007404327393 d_loss:1.0970297753810883 (f_loss=-0.23612383008003235 r_loss=1.1738390922546387 GP=0.15931451320648193)
[Training] epoch:682 step:300 g_loss:1.2049157619476318 d_loss:1.1918905675411224 (f_loss=-0.2617402672767639 r_loss=1.159927487373352 GP=0.2937033474445343)
[Training] epoch:683 step:0 g_loss:1.234750509262085 d_loss:1.699150800704956 (f_loss=-0.20729851722717285 r_loss=1.12624192237854 GP=0.7802073955535889)
[Training] epoch:683 step:100 g_loss:1.2848914861679077 d_loss:1.5924184024333954 (f_loss=-0.2508257329463959 r_loss=1.1252021789550781 GP=0.7180419564247131)
[Training] epoch:683 step:300 g_loss:1.2178778648376465 d_loss:1.631644606590271 (f_loss=-0.281883180141449 r_loss=1.171236515045166 GP=0.742291271686554)
[Training] epoch:684 step:0 g_loss:1.228623867034912 d_loss:1.6375829875469208 (f_loss=-0.1844135820865631 r_loss=1.147931694984436 GP=0.6740648746490479)
[Training] epoch:684 step:100 g_loss:1.1759241819381714 d_loss:2.409579649567604 (f_loss=-0.1470395177602768 r_loss=1.025479793548584 GP=1.5311393737792969)
[Training] epoch:684 step:200 g_loss:1.1654366254806519 d_loss:1.3292829990386963 (f_loss=-0.17606636881828308 r_loss=1.1322946548461914 GP=0.37305471301078796)
[Training] epoch:684 step:300 g_loss:1.2378275394439697 d_loss:2.1312113404273987 (f_loss=-0.2183271050453186 r_loss=1.0012366771697998 GP=1.3483017683029175)
[Training] epoch:685 step:0 g_loss:1.2476754188537598 d_loss:1.4289811253547668 (f_loss=-0.1815427541732788 r_loss=1.1150197982788086 GP=0.49550408124923706)
[Training] epoch:685 step:100 g_loss:1.200615406036377 d_loss:1.0884423404932022 (f_loss=-0.18879038095474243 r_loss=1.1242891550064087 GP=0.15294356644153595)
[Training] epoch:685 step:200 g_loss:1.198912262916565 d_loss:2.0715483725070953 (f_loss=-0.2401171624660492 r_loss=1.1085056066513062 GP=1.2031599283218384)
[Training] epoch:685 step:300 g_loss:1.2245182991027832 d_loss:1.0326756089925766 (f_loss=-0.263319194316864 r_loss=1.1715489625930786 GP=0.124445840716362)
[Training] epoch:686 step:0 g_loss:1.2562600374221802 d_loss:2.0927799940109253 (f_loss=-0.20437288284301758 r_loss=1.0886731147766113 GP=1.2084797620773315)
[Training] epoch:686 step:100 g_loss:1.2640348672866821 d_loss:1.5094457566738129 (f_loss=-0.2070707380771637 r_loss=1.1263701915740967 GP=0.5901463031768799)
[Training] epoch:686 step:200 g_loss:1.250286340713501 d_loss:2.0557819306850433 (f_loss=-0.1876181662082672 r_loss=1.1393450498580933 GP=1.1040550470352173)
[Training] epoch:686 step:300 g_loss:1.2233527898788452 d_loss:1.4047808200120926 (f_loss=-0.18937335908412933 r_loss=1.1930981874465942 GP=0.4010559916496277)
[Training] epoch:687 step:0 g_loss:1.1833810806274414 d_loss:1.815040409564972 (f_loss=-0.19985783100128174 r_loss=1.2048496007919312 GP=0.8100486397743225)
[Training] epoch:687 step:100 g_loss:1.1914854049682617 d_loss:1.7778183817863464 (f_loss=-0.27525681257247925 r_loss=1.035277247428894 GP=1.0177979469299316)
[Training] epoch:687 step:200 g_loss:1.2366448640823364 d_loss:1.2718224972486496 (f_loss=-0.22129972279071808 r_loss=1.1371922492980957 GP=0.355929970741272)
[Training] epoch:687 step:300 g_loss:1.1949131488800049 d_loss:1.8417162597179413 (f_loss=-0.27187076210975647 r_loss=1.097097635269165 GP=1.0164893865585327)
[Training] epoch:688 step:0 g_loss:1.2419712543487549 d_loss:1.6610908806324005 (f_loss=-0.19615527987480164 r_loss=1.1566659212112427 GP=0.7005802392959595)
[Training] epoch:688 step:100 g_loss:1.2159721851348877 d_loss:1.1430347859859467 (f_loss=-0.2807009816169739 r_loss=1.1963540315628052 GP=0.22738173604011536)
[Training] epoch:688 step:200 g_loss:1.2085896730422974 d_loss:2.581843838095665 (f_loss=-0.23375298082828522 r_loss=1.08899986743927 GP=1.7265969514846802)
[Training] epoch:688 step:300 g_loss:1.2487385272979736 d_loss:1.1576248854398727 (f_loss=-0.2377033680677414 r_loss=1.1579959392547607 GP=0.2373323142528534)
[Training] epoch:689 step:0 g_loss:1.2673643827438354 d_loss:1.211418628692627 (f_loss=-0.19779667258262634 r_loss=1.099387526512146 GP=0.3098277747631073)
[Training] epoch:689 step:100 g_loss:1.254226565361023 d_loss:1.4341912418603897 (f_loss=-0.14533720910549164 r_loss=1.1678845882415771 GP=0.4116438627243042)
[Training] epoch:689 step:200 g_loss:1.2226626873016357 d_loss:1.592225968837738 (f_loss=-0.24709361791610718 r_loss=1.1008410453796387 GP=0.7384785413742065)
[Training] epoch:689 step:300 g_loss:1.2076318264007568 d_loss:1.624734029173851 (f_loss=-0.2475956827402115 r_loss=1.0504518747329712 GP=0.8218778371810913)
[Training] epoch:690 step:0 g_loss:1.2477591037750244 d_loss:1.1617427170276642 (f_loss=-0.2552782893180847 r_loss=1.1238540410995483 GP=0.29316696524620056)

[Training] epoch:690 step:100 g_loss:1.2274543046951294 d_loss:2.304947108030319 (f_loss=-0.2562585175037384 r_loss=1.0067570209503174 GP=1.5544486045837402)
[Training] epoch:690 step:200 g_loss:1.241426706314087 d_loss:1.2138067930936813 (f_loss=-0.2095607966184616 r_loss=1.2607976198196411 GP=0.16256996989250183)
[Training] epoch:690 step:300 g_loss:1.2011812925338745 d_loss:1.2233496010303497 (f_loss=-0.245076984167099 r_loss=1.1348427534103394 GP=0.3335838317871094)
[Training] epoch:691 step:0 g_loss:1.2224432229995728 d_loss:1.6230713576078415 (f_loss=-0.23541052639484406 r_loss=1.2249165773391724 GP=0.6335653066635132)
[Training] epoch:691 step:100 g_loss:1.20051109790802 d_loss:1.416538953781128 (f_loss=-0.22484111785888672 r_loss=1.0814059972763062 GP=0.5599740743637085)
[Training] epoch:691 step:200 g_loss:1.1568423509597778 d_loss:2.21054707467556 (f_loss=-0.18629993498325348 r_loss=1.0946030616760254 GP=1.302243947982788)
[Training] epoch:691 step:300 g_loss:1.1468669176101685 d_loss:1.6507651805877686 (f_loss=-0.21283984184265137 r_loss=1.1212010383605957 GP=0.7424039840698242)
[Training] epoch:692 step:0 g_loss:1.1528089046478271 d_loss:1.5823247581720352 (f_loss=-0.24229441583156586 r_loss=1.2064108848571777 GP=0.6182082891464233)
[Training] epoch:692 step:100 g_loss:1.2261192798614502 d_loss:1.0738307535648346 (f_loss=-0.24331586062908173 r_loss=1.093363642692566 GP=0.2237829715013504)
[Training] epoch:692 step:200 g_loss:1.1952998638153076 d_loss:1.7384683787822723 (f_loss=-0.23950448632240295 r_loss=1.1754088401794434 GP=0.8025640249252319)
[Training] epoch:692 step:300 g_loss:1.1810575723648071 d_loss:1.62108114361763 (f_loss=-0.2356833517551422 r_loss=1.2275561094284058 GP=0.6292083859443665)
[Training] epoch:693 step:0 g_loss:1.2164088487625122 d_loss:2.2703192830085754 (f_loss=-0.26225221157073975 r_loss=0.9865054488182068 GP=1.5460660457611084)
[Training] epoch:693 step:100 g_loss:1.2039343118667603 d_loss:2.4031283259391785 (f_loss=-0.23299676179885864 r_loss=1.0268924236297607 GP=1.6092326641082764)
[Training] epoch:693 step:200 g_loss:1.2540013790130615 d_loss:1.620312362909317 (f_loss=-0.16309276223182678 r_loss=1.2067666053771973 GP=0.5766385197639465)
[Training] epoch:693 step:300 g_loss:1.2562434673309326 d_loss:1.6752375066280365 (f_loss=-0.24232783913612366 r_loss=1.226205587387085 GP=0.6913597583770752)
[Training] epoch:694 step:0 g_loss:1.2024937868118286 d_loss:1.5098509043455124 (f_loss=-0.2291097790002823 r_loss=1.1667406558990479 GP=0.5722200274467468)
[Training] epoch:694 step:100 g_loss:1.2416526079177856 d_loss:1.2707476913928986 (f_loss=-0.25804805755615234 r_loss=1.1756517887115479 GP=0.35314396023750305)
[Training] epoch:694 step:200 g_loss:1.2321739196777344 d_loss:1.558501809835434 (f_loss=-0.2598287761211395 r_loss=1.1391401290893555 GP=0.679190456867218)
[Training] epoch:694 step:300 g_loss:1.264963984489441 d_loss:1.164674550294876 (f_loss=-0.10893529653549194 r_loss=1.132591724395752 GP=0.1410181224346161)
[Training] epoch:695 step:0 g_loss:1.223127841949463 d_loss:1.9580103158950806 (f_loss=-0.18268370628356934 r_loss=1.1349658966064453 GP=1.0057281255722046)
[Training] epoch:695 step:100 g_loss:1.193071722984314 d_loss:1.5264840424060822 (f_loss=-0.26686349511146545 r_loss=1.1835376024246216 GP=0.609809935092926)
[Training] epoch:695 step:200 g_loss:1.2073968648910522 d_loss:1.5323737859725952 (f_loss=-0.22077929973602295 r_loss=1.110559105873108 GP=0.6425939798355103)
[Training] epoch:695 step:300 g_loss:1.1638195514678955 d_loss:1.9719114899635315 (f_loss=-0.2683200240135193 r_loss=1.1401197910308838 GP=1.100111722946167)
[Training] epoch:696 step:0 g_loss:1.2835488319396973 d_loss:2.099919840693474 (f_loss=-0.13190241158008575 r_loss=1.0667452812194824 GP=1.1650769710540771)
[Training] epoch:696 step:100 g_loss:1.2059584856033325 d_loss:3.006137192249298 (f_loss=-0.2432991862297058 r_loss=1.102409839630127 GP=2.147026538848877)
[Training] epoch:696 step:200 g_loss:1.2657064199447632 d_loss:3.5531541109085083 (f_loss=-0.12463504076004028 r_loss=0.9138955473899841 GP=2.7638936042785645)
[Training] epoch:696 step:300 g_loss:1.2207647562026978 d_loss:1.9929746687412262 (f_loss=-0.24684879183769226 r_loss=1.0887304544448853 GP=1.1510930061340332)
[Training] epoch:697 step:0 g_loss:1.2262285947799683 d_loss:1.6316083073616028 (f_loss=-0.15183430910110474 r_loss=1.1355412006378174 GP=0.6479014158248901)
[Training] epoch:697 step:100 g_loss:1.3091306686401367 d_loss:1.4276087582111359 (f_loss=-0.23242402076721191 r_loss=1.177551031112671 GP=0.4824817478656769)
[Training] epoch:697 step:200 g_loss:1.1925232410430908 d_loss:1.5769882500171661 (f_loss=-0.19378510117530823 r_loss=1.1390230655670166 GP=0.6317502856254578)
[Training] epoch:697 step:300 g_loss:1.2064645290374756 d_loss:1.229621335864067 (f_loss=-0.23892493546009064 r_loss=1.160313367843628 GP=0.3082329034805298)
[Training] epoch:698 step:0 g_loss:1.3184058666229248 d_loss:1.83388152718544 (f_loss=-0.2019178569316864 r_loss=1.132421851158142 GP=0.9033775329589844)
[Training] epoch:698 step:100 g_loss:1.2312599420547485 d_loss:1.024979829788208 (f_loss=-0.27385419607162476 r_loss=1.1016764640808105 GP=0.19715756177902222)
[Training] epoch:698 step:200 g_loss:1.2911098003387451 d_loss:1.472514659166336 (f_loss=-0.21355882287025452 r_loss=1.1313122510910034 GP=0.5547612309455872)
[Training] epoch:698 step:300 g_loss:1.2001937627792358 d_loss:2.508855402469635 (f_loss=-0.20299261808395386 r_loss=1.0724014043807983 GP=1.6394466161727905)
[Training] epoch:699 step:0 g_loss:1.2418882846832275 d_loss:1.4388589560985565 (f_loss=-0.1840290129184723 r_loss=1.1031445264816284 GP=0.5197434425354004)
[Training] epoch:699 step:100 g_loss:1.2210392951965332 d_loss:1.8068963587284088 (f_loss=-0.26164355874061584 r_loss=1.2239044904708862 GP=0.8446354269981384)
[Training] epoch:699 step:200 g_loss:1.2097258567810059 d_loss:1.4808935821056366 (f_loss=-0.22561302781105042 r_loss=1.266735315322876 GP=0.43977129459381104)
[Training] epoch:699 step:300 g_loss:1.281693935394287 d_loss:1.9641103148460388 (f_loss=-0.2289751172065735 r_loss=1.0966839790344238 GP=1.0964014530181885)
[Training] epoch:700 step:0 g_loss:1.2475157976150513 d_loss:2.1513674557209015 (f_loss=-0.2669561803340912 r_loss=1.081425428390503 GP=1.3368982076644897)

[Training] epoch:700 step:100 g_loss:1.2317945957183838 d_loss:1.4817073941230774 (f_loss=-0.22059732675552368 r_loss=1.1082674264907837 GP=0.5940372943878174)
[Training] epoch:700 step:200 g_loss:1.2560970783233643 d_loss:2.1458095610141754 (f_loss=-0.3086394965648651 r_loss=1.0917974710464478 GP=1.3626515865325928)
[Training] epoch:700 step:300 g_loss:1.2108097076416016 d_loss:1.3477519154548645 (f_loss=-0.25103098154067993 r_loss=1.214134931564331 GP=0.3846479654312134)
[Training] epoch:701 step:0 g_loss:1.2735273838043213 d_loss:1.5177173018455505 (f_loss=-0.260675847530365 r_loss=1.168070673942566 GP=0.6103224754333496)
[Training] epoch:701 step:100 g_loss:1.2190355062484741 d_loss:1.4626924693584442 (f_loss=-0.1879340410232544 r_loss=1.2219911813735962 GP=0.4286353290081024)
[Training] epoch:701 step:200 g_loss:1.214916706085205 d_loss:1.4839043021202087 (f_loss=-0.26951342821121216 r_loss=1.2430001497268677 GP=0.5104175806045532)
[Training] epoch:701 step:300 g_loss:1.2128355503082275 d_loss:1.4503934383392334 (f_loss=-0.2642756700515747 r_loss=1.0805753469467163 GP=0.6340937614440918)
[Training] epoch:702 step:0 g_loss:1.2089985609054565 d_loss:1.335740402340889 (f_loss=-0.18764559924602509 r_loss=1.0925205945968628 GP=0.43086540699005127)
[Training] epoch:702 step:100 g_loss:1.249772071838379 d_loss:1.4580441415309906 (f_loss=-0.30603888630867004 r_loss=1.1465493440628052 GP=0.6175336837768555)
[Training] epoch:702 step:200 g_loss:1.3091915845870972 d_loss:1.3217300772666931 (f_loss=-0.21024078130722046 r_loss=1.238673448562622 GP=0.2932974100112915)
[Training] epoch:702 step:300 g_loss:1.2631299495697021 d_loss:1.4130921065807343 (f_loss=-0.20461639761924744 r_loss=1.1819024085998535 GP=0.4358060956001282)
[Training] epoch:703 step:0 g_loss:1.1810039281845093 d_loss:1.5983785837888718 (f_loss=-0.1978771835565567 r_loss=1.2107003927230835 GP=0.585555374622345)
[Training] epoch:703 step:100 g_loss:1.2521554231643677 d_loss:1.5548920184373856 (f_loss=-0.2358066290616989 r_loss=1.1977490186691284 GP=0.592949628829956)
[Training] epoch:703 step:200 g_loss:1.2108893394470215 d_loss:1.6493940949440002 (f_loss=-0.2261562943458557 r_loss=1.161088466644287 GP=0.7144619226455688)
[Training] epoch:703 step:300 g_loss:1.2317945957183838 d_loss:1.2590319514274597 (f_loss=-0.1644720733165741 r_loss=1.1502633094787598 GP=0.27324071526527405)
[Training] epoch:704 step:0 g_loss:1.2403507232666016 d_loss:1.829223245382309 (f_loss=-0.25497135519981384 r_loss=0.9103742241859436 GP=1.1738203763961792)
[Training] epoch:704 step:100 g_loss:1.2401738166809082 d_loss:2.142740771174431 (f_loss=-0.18499524891376495 r_loss=1.1127874851226807 GP=1.2149485349655151)
[Training] epoch:704 step:200 g_loss:1.2012932300567627 d_loss:1.7767983675003052 (f_loss=-0.2913053035736084 r_loss=1.0463361740112305 GP=1.021767497062683)
[Training] epoch:704 step:300 g_loss:1.2849197387695312 d_loss:1.3750969171524048 (f_loss=-0.24631330370903015 r_loss=1.162570834159851 GP=0.45883938670158386)
[Training] epoch:705 step:0 g_loss:1.2082113027572632 d_loss:1.6691781878471375 (f_loss=-0.27629995346069336 r_loss=1.1360310316085815 GP=0.8094471096992493)
[Training] epoch:705 step:100 g_loss:1.3083667755126953 d_loss:2.2029921412467957 (f_loss=-0.21320337057113647 r_loss=1.1081984043121338 GP=1.3079971075057983)
[Training] epoch:705 step:200 g_loss:1.207335352897644 d_loss:1.923343077301979 (f_loss=-0.24083684384822845 r_loss=1.0070586204528809 GP=1.1571213006973267)
[Training] epoch:705 step:300 g_loss:1.235740065574646 d_loss:2.585867166519165 (f_loss=-0.2961174249649048 r_loss=1.026463270187378 GP=1.855521321296692)
[Training] epoch:706 step:0 g_loss:1.1899778842926025 d_loss:1.4550812989473343 (f_loss=-0.20714716613292694 r_loss=1.1474841833114624 GP=0.5147442817687988)
[Training] epoch:706 step:100 g_loss:1.249272108078003 d_loss:2.285502105951309 (f_loss=-0.19729921221733093 r_loss=1.0171916484832764 GP=1.4656096696853638)
[Training] epoch:706 step:200 g_loss:1.2381359338760376 d_loss:1.2560060322284698 (f_loss=-0.2555624544620514 r_loss=1.1499632596969604 GP=0.3616052269935608)
[Training] epoch:706 step:300 g_loss:1.2226405143737793 d_loss:2.1980141401290894 (f_loss=-0.19554787874221802 r_loss=0.9677122235298157 GP=1.4258497953414917)
[Training] epoch:707 step:0 g_loss:1.2375588417053223 d_loss:1.9155392050743103 (f_loss=-0.23737794160842896 r_loss=1.0734171867370605 GP=1.0794999599456787)
[Training] epoch:707 step:100 g_loss:1.2782986164093018 d_loss:1.2050777077674866 (f_loss=-0.21816349029541016 r_loss=1.1891010999679565 GP=0.23414009809494019)
[Training] epoch:707 step:200 g_loss:1.2187508344650269 d_loss:1.9986040592193604 (f_loss=-0.2092912197113037 r_loss=1.0047883987426758 GP=1.2031068801879883)
[Training] epoch:707 step:300 g_loss:1.1937562227249146 d_loss:1.4405470788478851 (f_loss=-0.2260056436061859 r_loss=1.1623271703720093 GP=0.5042255520820618)
[Training] epoch:708 step:0 g_loss:1.2372190952301025 d_loss:2.449300915002823 (f_loss=-0.24791809916496277 r_loss=1.0910812616348267 GP=1.606137752532959)
[Training] epoch:708 step:100 g_loss:1.2137055397033691 d_loss:2.1033918410539627 (f_loss=-0.18762902915477753 r_loss=1.064402461051941 GP=1.2266184091567993)
[Training] epoch:708 step:200 g_loss:1.251883864402771 d_loss:1.445229321718216 (f_loss=-0.2510369122028351 r_loss=1.1203572750091553 GP=0.5759089589118958)
[Training] epoch:708 step:300 g_loss:1.233613133430481 d_loss:1.5399411022663116 (f_loss=-0.1626405417919159 r_loss=1.0177810192108154 GP=0.6848006248474121)
[Training] epoch:709 step:0 g_loss:1.2210088968276978 d_loss:1.2713222205638885 (f_loss=-0.28592362999916077 r_loss=1.1250584125518799 GP=0.43218743801116943)
[Training] epoch:709 step:100 g_loss:1.2241626977920532 d_loss:1.3098627924919128 (f_loss=-0.227572500705719 r_loss=1.1387228965759277 GP=0.3987123966217041)
[Training] epoch:709 step:200 g_loss:1.2023460865020752 d_loss:1.236641213297844 (f_loss=-0.20829764008522034 r_loss=1.2045540809631348 GP=0.2403847724199295)
[Training] epoch:709 step:300 g_loss:1.232818603515625 d_loss:2.89693945646286 (f_loss=-0.19479399919509888 r_loss=1.159740686416626 GP=1.931992769241333)
[Training] epoch:710 step:0 g_loss:1.2585344314575195 d_loss:1.204357087612152 (f_loss=-0.2848217487335205 r_loss=1.0682790279388428 GP=0.42089980840682983)

[Training] epoch:710 step:100 g_loss:1.240290641784668 d_loss:1.6191329210996628 (f_loss=-0.24336309731006622 r_loss=1.0534738302230835 GP=0.8090221881866455)
[Training] epoch:710 step:200 g_loss:1.2932593822479248 d_loss:1.4144991338253021 (f_loss=-0.288969486951828 r_loss=0.966770589351654 GP=0.7366980314254761)
[Training] epoch:710 step:300 g_loss:1.2455918788909912 d_loss:1.3214862048625946 (f_loss=-0.21682095527648926 r_loss=1.171872854232788 GP=0.3664343059062958)
[Training] epoch:711 step:0 g_loss:1.2799263000488281 d_loss:3.7350747138261795 (f_loss=-0.15564267337322235 r_loss=0.9653786420822144 GP=2.9253387451171875)
[Training] epoch:711 step:100 g_loss:1.198285460472107 d_loss:1.0719433426856995 (f_loss=-0.2779477834701538 r_loss=1.1776982545852661 GP=0.17219287157058716)
[Training] epoch:711 step:200 g_loss:1.2487645149230957 d_loss:1.1486794650554657 (f_loss=-0.24431586265563965 r_loss=1.0827242136001587 GP=0.31027111411094666)
[Training] epoch:711 step:300 g_loss:1.233440637588501 d_loss:1.5026283860206604 (f_loss=-0.24361246824264526 r_loss=1.0328243970870972 GP=0.7134164571762085)
[Training] epoch:712 step:0 g_loss:1.2337467670440674 d_loss:1.1136353611946106 (f_loss=-0.2767961323261261 r_loss=1.087973952293396 GP=0.3024575412273407)
[Training] epoch:712 step:100 g_loss:1.2452679872512817 d_loss:1.5371707379817963 (f_loss=-0.23643144965171814 r_loss=1.1138964891433716 GP=0.6597056984901428)
[Training] epoch:712 step:200 g_loss:1.2779890298843384 d_loss:1.2700557559728622 (f_loss=-0.22479958832263947 r_loss=1.159471035003662 GP=0.3353843092918396)
[Training] epoch:712 step:300 g_loss:1.2645909786224365 d_loss:1.1482024788856506 (f_loss=-0.3135618269443512 r_loss=1.1024307012557983 GP=0.3593336045742035)
[Training] epoch:713 step:0 g_loss:1.2216559648513794 d_loss:1.7023796141147614 (f_loss=-0.26912936568260193 r_loss=1.216482162475586 GP=0.7550268173217773)
[Training] epoch:713 step:100 g_loss:1.21666419506073 d_loss:1.4758893847465515 (f_loss=-0.2932817339897156 r_loss=1.1282464265823364 GP=0.6409246921539307)
[Training] epoch:713 step:200 g_loss:1.231073260307312 d_loss:1.9544633328914642 (f_loss=-0.2509966194629669 r_loss=0.928176999092102 GP=1.277282953262329)
[Training] epoch:713 step:300 g_loss:1.3428248167037964 d_loss:2.4692946523427963 (f_loss=-0.20387770235538483 r_loss=1.0983341932296753 GP=1.5748381614685059)
[Training] epoch:714 step:0 g_loss:1.2491748332977295 d_loss:2.3246080577373505 (f_loss=-0.27453771233558655 r_loss=1.196298599243164 GP=1.402847170829773)
[Training] epoch:714 step:100 g_loss:1.3088736534118652 d_loss:1.443341702222824 (f_loss=-0.21394690871238708 r_loss=1.1896671056747437 GP=0.46762150526046753)
[Training] epoch:714 step:200 g_loss:1.199859857559204 d_loss:1.397079885005951 (f_loss=-0.22739827632904053 r_loss=1.0801652669906616 GP=0.5443128943443298)
[Training] epoch:714 step:300 g_loss:1.1965422630310059 d_loss:1.3552122116088867 (f_loss=-0.27933767437934875 r_loss=1.1424627304077148 GP=0.49208715558052063)
[Training] epoch:715 step:0 g_loss:1.2652064561843872 d_loss:1.896014392375946 (f_loss=-0.23835772275924683 r_loss=1.0615354776382446 GP=1.0728366374969482)
[Training] epoch:715 step:100 g_loss:1.2141165733337402 d_loss:3.3340077698230743 (f_loss=-0.2067168653011322 r_loss=1.0429884195327759 GP=2.4977362155914307)
[Training] epoch:715 step:200 g_loss:1.2333064079284668 d_loss:1.4495198428630829 (f_loss=-0.2030295431613922 r_loss=1.1051135063171387 GP=0.5474358797073364)
[Training] epoch:715 step:300 g_loss:1.1391934156417847 d_loss:2.446271985769272 (f_loss=-0.27021387219429016 r_loss=1.0876699686050415 GP=1.6288158893585205)
[Training] epoch:716 step:0 g_loss:1.2510125637054443 d_loss:1.991636499762535 (f_loss=-0.22934044897556305 r_loss=1.0552188158035278 GP=1.1657581329345703)
[Training] epoch:716 step:100 g_loss:1.2330632209777832 d_loss:1.2830623984336853 (f_loss=-0.2085644006729126 r_loss=1.1305203437805176 GP=0.3611064553260803)
[Training] epoch:716 step:200 g_loss:1.2429649829864502 d_loss:1.5588628053665161 (f_loss=-0.20270216464996338 r_loss=1.0377336740493774 GP=0.723831295967102)
[Training] epoch:716 step:300 g_loss:1.2470035552978516 d_loss:1.2139497995376587 (f_loss=-0.3090243339538574 r_loss=1.1638826131820679 GP=0.35909152030944824)
[Training] epoch:717 step:0 g_loss:1.2523881196975708 d_loss:1.135273814201355 (f_loss=-0.2029874324798584 r_loss=1.134725570678711 GP=0.20353567600250244)
[Training] epoch:717 step:100 g_loss:1.1741288900375366 d_loss:1.499282419681549 (f_loss=-0.2819939851760864 r_loss=1.171129584312439 GP=0.6101468205451965)
[Training] epoch:717 step:200 g_loss:1.2291462421417236 d_loss:1.5374117642641068 (f_loss=-0.20687858760356903 r_loss=1.1344714164733887 GP=0.6098189353942871)
[Training] epoch:717 step:300 g_loss:1.2744144201278687 d_loss:1.8419866561889648 (f_loss=-0.22296971082687378 r_loss=1.1084949970245361 GP=0.9564613699913025)
[Training] epoch:718 step:0 g_loss:1.265432357788086 d_loss:1.3144818395376205 (f_loss=-0.17320598661899567 r_loss=1.1509289741516113 GP=0.3367588520050049)
[Training] epoch:718 step:100 g_loss:1.2475258111953735 d_loss:1.074030414223671 (f_loss=-0.18473827838897705 r_loss=1.1425660848617554 GP=0.11620260775089264)
[Training] epoch:718 step:200 g_loss:1.2156071662902832 d_loss:2.7675126791000366 (f_loss=-0.24907124042510986 r_loss=1.0488479137420654 GP=1.967736005783081)
[Training] epoch:718 step:300 g_loss:1.1893123388290405 d_loss:1.336876630783081 (f_loss=-0.29901793599128723 r_loss=1.1580077409744263 GP=0.477886825799942)
[Training] epoch:719 step:0 g_loss:1.2452200651168823 d_loss:2.514559179544449 (f_loss=-0.21792075037956238 r_loss=1.0518536567687988 GP=1.6806262731552124)
[Training] epoch:719 step:100 g_loss:1.227494478225708 d_loss:1.7624801248311996 (f_loss=-0.21396441757678986 r_loss=0.995021402835846 GP=0.9814231395721436)
[Training] epoch:719 step:200 g_loss:1.2400848865509033 d_loss:2.0490441620349884 (f_loss=-0.25992414355278015 r_loss=1.135777235031128 GP=1.1731910705566406)
[Training] epoch:719 step:300 g_loss:1.2668207883834839 d_loss:1.6210392117500305 (f_loss=-0.25978052616119385 r_loss=1.1149483919143677 GP=0.7658713459968567)
[Training] epoch:720 step:0 g_loss:1.2056015729904175 d_loss:1.9618990123271942 (f_loss=-0.21708348393440247 r_loss=1.1330816745758057 GP=1.045900821685791)

[Training] epoch:720 step:100 g_loss:1.2666399478912354 d_loss:1.5598288625478745 (f_loss=-0.21832700073719025 r_loss=1.1691049337387085 GP=0.6090509295463562)
[Training] epoch:720 step:200 g_loss:1.2887364625930786 d_loss:1.8491462469100952 (f_loss=-0.21582907438278198 r_loss=1.128965139389038 GP=0.9360101819038391)
[Training] epoch:720 step:300 g_loss:1.2569572925567627 d_loss:1.121936559677124 (f_loss=-0.23583942651748657 r_loss=1.1027499437332153 GP=0.25502604246139526)
[Training] epoch:721 step:0 g_loss:1.2839288711547852 d_loss:1.942162185907364 (f_loss=-0.2374267280101776 r_loss=1.0475677251815796 GP=1.132021188735962)
[Training] epoch:721 step:100 g_loss:1.2577404975891113 d_loss:2.0252610445022583 (f_loss=-0.2753918170928955 r_loss=1.0699552297592163 GP=1.2306976318359375)
[Training] epoch:721 step:200 g_loss:1.2146553993225098 d_loss:1.411363124847412 (f_loss=-0.2506416440010071 r_loss=1.133751392364502 GP=0.5282533764839172)
[Training] epoch:721 step:300 g_loss:1.1617695093154907 d_loss:1.235740214586258 (f_loss=-0.2606402635574341 r_loss=1.1781820058822632 GP=0.31819847226142883)
[Training] epoch:722 step:0 g_loss:1.2366752624511719 d_loss:1.931080400943756 (f_loss=-0.21395957469940186 r_loss=0.9483441710472107 GP=1.1966958045959473)
[Training] epoch:722 step:100 g_loss:1.1843153238296509 d_loss:1.4358913600444794 (f_loss=-0.18835636973381042 r_loss=1.1523631811141968 GP=0.471884548664093)
[Training] epoch:722 step:200 g_loss:1.2504160404205322 d_loss:1.409033179283142 (f_loss=-0.22099682688713074 r_loss=1.1405109167099 GP=0.4895190894603729)
[Training] epoch:722 step:300 g_loss:1.2831993103027344 d_loss:1.1545308530330658 (f_loss=-0.2183617651462555 r_loss=1.1402413845062256 GP=0.2326512336730957)
[Training] epoch:723 step:0 g_loss:1.2049742937088013 d_loss:1.337027296423912 (f_loss=-0.23555107414722443 r_loss=1.0293736457824707 GP=0.5432047247886658)
[Training] epoch:723 step:100 g_loss:1.2647464275360107 d_loss:1.499930500984192 (f_loss=-0.200170636177063 r_loss=1.1036840677261353 GP=0.5964170694351196)
[Training] epoch:723 step:200 g_loss:1.2817188501358032 d_loss:1.3734518885612488 (f_loss=-0.19744092226028442 r_loss=1.1904523372650146 GP=0.38044047355651855)
[Training] epoch:723 step:300 g_loss:1.295639157295227 d_loss:1.6674917936325073 (f_loss=-0.2409067153930664 r_loss=1.1199332475662231 GP=0.7884652614593506)
[Training] epoch:724 step:0 g_loss:1.2940993309020996 d_loss:1.3121941089630127 (f_loss=-0.3076412081718445 r_loss=1.1668882369995117 GP=0.45294708013534546)
[Training] epoch:724 step:100 g_loss:1.2588614225387573 d_loss:2.3631994873285294 (f_loss=-0.21458540856838226 r_loss=1.04889976978302 GP=1.5288851261138916)
[Training] epoch:724 step:200 g_loss:1.2264139652252197 d_loss:1.6353206634521484 (f_loss=-0.23388540744781494 r_loss=1.0817774534225464 GP=0.787428617477417)
[Training] epoch:724 step:300 g_loss:1.2587809562683105 d_loss:1.562807023525238 (f_loss=-0.31057482957839966 r_loss=1.0912057161331177 GP=0.78217613697052)
[Training] epoch:725 step:0 g_loss:1.283252239227295 d_loss:1.264466717839241 (f_loss=-0.21296195685863495 r_loss=1.1545169353485107 GP=0.32291173934936523)
[Training] epoch:725 step:100 g_loss:1.2284045219421387 d_loss:1.2197370827198029 (f_loss=-0.3053652048110962 r_loss=1.1401926279067993 GP=0.38490965962409973)
[Training] epoch:725 step:200 g_loss:1.2051552534103394 d_loss:1.6306244283914566 (f_loss=-0.1992008537054062 r_loss=1.1606550216674805 GP=0.6691702604293823)
[Training] epoch:725 step:300 g_loss:1.164716362953186 d_loss:1.9184426069259644 (f_loss=-0.27854418754577637 r_loss=1.1149535179138184 GP=1.0820332765579224)
[Training] epoch:726 step:0 g_loss:1.2476272583007812 d_loss:1.8939611315727234 (f_loss=-0.21710103750228882 r_loss=1.0931636095046997 GP=1.0178985595703125)
[Training] epoch:726 step:100 g_loss:1.2346371412277222 d_loss:1.3847636878490448 (f_loss=-0.2877442538738251 r_loss=1.141046404838562 GP=0.5314615368843079)
[Training] epoch:726 step:200 g_loss:1.256935477256775 d_loss:1.619881510734558 (f_loss=-0.259573757648468 r_loss=1.1602060794830322 GP=0.7192491888999939)
[Training] epoch:726 step:300 g_loss:1.2069777250289917 d_loss:1.6312157213687897 (f_loss=-0.25700756907463074 r_loss=1.0925660133361816 GP=0.7956572771072388)
[Training] epoch:727 step:0 g_loss:1.2232252359390259 d_loss:1.4672174900770187 (f_loss=-0.19492392241954803 r_loss=1.1729722023010254 GP=0.4891692101955414)
[Training] epoch:727 step:100 g_loss:1.318721890449524 d_loss:2.6216404736042023 (f_loss=-0.25652989745140076 r_loss=1.1532244682312012 GP=1.7249459028244019)
[Training] epoch:727 step:200 g_loss:1.209854006767273 d_loss:2.037469118833542 (f_loss=-0.22647574543952942 r_loss=1.1290931701660156 GP=1.1348516941070557)
[Training] epoch:727 step:300 g_loss:1.2902123928070068 d_loss:2.0798496901988983 (f_loss=-0.21144166588783264 r_loss=1.1900299787521362 GP=1.1012613773345947)
[Training] epoch:728 step:0 g_loss:1.24253511428833 d_loss:1.4439377784729004 (f_loss=-0.2516617178916931 r_loss=1.1457958221435547 GP=0.5498036742210388)
[Training] epoch:728 step:100 g_loss:1.2659196853637695 d_loss:1.205739438533783 (f_loss=-0.241551011800766 r_loss=1.1913853883743286 GP=0.25590506196022034)
[Training] epoch:728 step:200 g_loss:1.2600183486938477 d_loss:1.579366147518158 (f_loss=-0.2592771649360657 r_loss=1.2088109254837036 GP=0.62983238697052)
[Training] epoch:728 step:300 g_loss:1.259995937347412 d_loss:3.7635703831911087 (f_loss=-0.19200651347637177 r_loss=1.0478935241699219 GP=2.9076833724975586)
[Training] epoch:729 step:0 g_loss:1.221455693244934 d_loss:2.9118143022060394 (f_loss=-0.2301737368106842 r_loss=1.0674965381622314 GP=2.074491500854492)
[Training] epoch:729 step:100 g_loss:1.1956255435943604 d_loss:2.1146948039531708 (f_loss=-0.16447928547859192 r_loss=1.1554436683654785 GP=1.1237304210662842)
[Training] epoch:729 step:200 g_loss:1.2339836359024048 d_loss:1.6338182389736176 (f_loss=-0.27792713046073914 r_loss=1.1979005336761475 GP=0.7138448357582092)
[Training] epoch:729 step:300 g_loss:1.3010808229446411 d_loss:1.6813000440597534 (f_loss=-0.24793481826782227 r_loss=1.2069729566574097 GP=0.722261905670166)
[Training] epoch:730 step:0 g_loss:1.2400484085083008 d_loss:1.6735940873622894 (f_loss=-0.21041527390480042 r_loss=1.1653425693511963 GP=0.7186667919158936)

[Training] epoch:730 step:100 g_loss:1.2571688890457153 d_loss:1.777927428483963 (f_loss=-0.16808196902275085 r_loss=1.1078777313232422 GP=0.8381316661834717)
[Training] epoch:730 step:200 g_loss:1.26260507106781 d_loss:2.6249557435512543 (f_loss=-0.22024396061897278 r_loss=1.057315707206726 GP=1.787883996963501)
[Training] epoch:730 step:300 g_loss:1.235459327697754 d_loss:1.4179294407367706 (f_loss=-0.20790913701057434 r_loss=1.1013493537902832 GP=0.5244892239570618)
[Training] epoch:731 step:0 g_loss:1.233504295349121 d_loss:1.1129735708236694 (f_loss=-0.2978944778442383 r_loss=1.1438894271850586 GP=0.2669786214828491)
[Training] epoch:731 step:100 g_loss:1.242676019668579 d_loss:1.435573160648346 (f_loss=-0.2638176679611206 r_loss=1.156043291091919 GP=0.5433475375175476)
[Training] epoch:731 step:200 g_loss:1.2181309461593628 d_loss:1.3809021711349487 (f_loss=-0.20062395930290222 r_loss=1.1627458333969116 GP=0.41878029704093933)
[Training] epoch:731 step:300 g_loss:1.2907973527908325 d_loss:1.487583190202713 (f_loss=-0.2565067708492279 r_loss=1.1561758518218994 GP=0.5879141092300415)
[Training] epoch:732 step:0 g_loss:1.1669983863830566 d_loss:1.2047092616558075 (f_loss=-0.22359153628349304 r_loss=1.139297604560852 GP=0.2890031933784485)
[Training] epoch:732 step:100 g_loss:1.2957134246826172 d_loss:2.0651170760393143 (f_loss=-0.23325268924236298 r_loss=1.1562081575393677 GP=1.1421616077423096)
[Training] epoch:732 step:200 g_loss:1.1829029321670532 d_loss:1.421080082654953 (f_loss=-0.29559996724128723 r_loss=1.0356184244155884 GP=0.6810616254806519)
[Training] epoch:732 step:300 g_loss:1.2375744581222534 d_loss:1.2797430157661438 (f_loss=-0.2239518165588379 r_loss=1.2035608291625977 GP=0.30013400316238403)
[Training] epoch:733 step:0 g_loss:1.2147424221038818 d_loss:1.8305459916591644 (f_loss=-0.2943451702594757 r_loss=1.1126506328582764 GP=1.0122405290603638)
[Training] epoch:733 step:100 g_loss:1.2947660684585571 d_loss:1.3735787868499756 (f_loss=-0.28898924589157104 r_loss=1.184249758720398 GP=0.4783182740211487)
[Training] epoch:733 step:200 g_loss:1.1990008354187012 d_loss:1.640482634305954 (f_loss=-0.3377760946750641 r_loss=1.1230639219284058 GP=0.8551948070526123)
[Training] epoch:733 step:300 g_loss:1.211458444595337 d_loss:1.9419799149036407 (f_loss=-0.24925431609153748 r_loss=1.052436113357544 GP=1.1387981176376343)
[Training] epoch:734 step:0 g_loss:1.2967097759246826 d_loss:1.536704197525978 (f_loss=-0.150196835398674 r_loss=1.226078987121582 GP=0.46082204580307007)
[Training] epoch:734 step:100 g_loss:1.166264295578003 d_loss:1.606609284877777 (f_loss=-0.2648322582244873 r_loss=1.2380355596542358 GP=0.6334059834480286)
[Training] epoch:734 step:200 g_loss:1.2189189195632935 d_loss:1.175028532743454 (f_loss=-0.27343302965164185 r_loss=1.1631419658660889 GP=0.28531959652900696)
[Training] epoch:734 step:300 g_loss:1.2153561115264893 d_loss:1.7436984181404114 (f_loss=-0.21629935503005981 r_loss=1.1611241102218628 GP=0.7988736629486084)
[Training] epoch:735 step:0 g_loss:1.2270104885101318 d_loss:1.2031042575836182 (f_loss=-0.274652898311615 r_loss=1.14787757396698 GP=0.3298795819282532)
[Training] epoch:735 step:100 g_loss:1.232661247253418 d_loss:1.7990619838237762 (f_loss=-0.24776998162269592 r_loss=1.1565303802490234 GP=0.8903015851974487)
[Training] epoch:735 step:200 g_loss:1.1840225458145142 d_loss:1.6051823645830154 (f_loss=-0.2199893444776535 r_loss=1.0043660402297974 GP=0.8208056688308716)
[Training] epoch:735 step:300 g_loss:1.1894810199737549 d_loss:1.4759561419487 (f_loss=-0.2337549924850464 r_loss=1.1201145648956299 GP=0.5895965695381165)
[Training] epoch:736 step:0 g_loss:1.2148935794830322 d_loss:3.246028020977974 (f_loss=-0.19962041079998016 r_loss=1.117013692855835 GP=2.328634738922119)
[Training] epoch:736 step:100 g_loss:1.2711050510406494 d_loss:1.8435629308223724 (f_loss=-0.26279541850090027 r_loss=1.1590890884399414 GP=0.9472692608833313)
[Training] epoch:736 step:200 g_loss:1.2602880001068115 d_loss:1.4844679236412048 (f_loss=-0.298539936542511 r_loss=1.0897701978683472 GP=0.6932376623153687)
[Training] epoch:736 step:300 g_loss:1.2701916694641113 d_loss:2.063242554664612 (f_loss=-0.3152608871459961 r_loss=1.0927824974060059 GP=1.285720944404602)
[Training] epoch:737 step:0 g_loss:1.258056879043579 d_loss:1.6204613745212555 (f_loss=-0.24650445580482483 r_loss=1.1872353553771973 GP=0.6797304749488831)
[Training] epoch:737 step:100 g_loss:1.313138723373413 d_loss:1.9722080528736115 (f_loss=-0.213996022939682 r_loss=1.1881953477859497 GP=0.9980087280273438)
[Training] epoch:737 step:200 g_loss:1.2026212215423584 d_loss:1.8276368379592896 (f_loss=-0.20009547472000122 r_loss=1.116849660873413 GP=0.9108826518058777)
[Training] epoch:737 step:300 g_loss:1.251847743988037 d_loss:1.0851401686668396 (f_loss=-0.2946236729621887 r_loss=1.1850515604019165 GP=0.19471228122711182)
[Training] epoch:738 step:0 g_loss:1.2216274738311768 d_loss:1.44766366481781 (f_loss=-0.3135110139846802 r_loss=1.146998405456543 GP=0.6141762733459473)
[Training] epoch:738 step:100 g_loss:1.2708468437194824 d_loss:1.5284374058246613 (f_loss=-0.30703243613243103 r_loss=1.1878395080566406 GP=0.6476303339004517)
[Training] epoch:738 step:200 g_loss:1.201149821281433 d_loss:1.565256342291832 (f_loss=-0.2124204784631729 r_loss=1.1225600242614746 GP=0.6551167964935303)
[Training] epoch:738 step:300 g_loss:1.223266363143921 d_loss:1.4162585139274597 (f_loss=-0.28076910972595215 r_loss=1.1129183769226074 GP=0.5841092467308044)
[Training] epoch:739 step:0 g_loss:1.2407249212265015 d_loss:1.6671745330095291 (f_loss=-0.21714340150356293 r_loss=1.117847204208374 GP=0.766470730304718)
[Training] epoch:739 step:100 g_loss:1.2463263273239136 d_loss:1.4139065891504288 (f_loss=-0.24083365499973297 r_loss=1.1668791770935059 GP=0.4878610670566559)
[Training] epoch:739 step:200 g_loss:1.2134138345718384 d_loss:1.7479065358638763 (f_loss=-0.2332824170589447 r_loss=1.1079106330871582 GP=0.8732783198356628)
[Training] epoch:739 step:300 g_loss:1.2100913524627686 d_loss:2.095272183418274 (f_loss=-0.285610556602478 r_loss=1.126983642578125 GP=1.253899097442627)
[Training] epoch:740 step:0 g_loss:1.233223795890808 d_loss:1.9466984272003174 (f_loss=-0.2206224799156189 r_loss=0.9602422118186951 GP=1.2070786952972412)

[Training] epoch:740 step:100 g_loss:1.2770826816558838 d_loss:1.6501123011112213 (f_loss=-0.1992557942867279 r_loss=1.0251224040985107 GP=0.8242456912994385)
[Training] epoch:740 step:200 g_loss:1.2908607721328735 d_loss:2.945921927690506 (f_loss=-0.2391858994960785 r_loss=1.2030251026153564 GP=1.982082724571228)
[Training] epoch:740 step:300 g_loss:1.237391710281372 d_loss:2.955059677362442 (f_loss=-0.22678396105766296 r_loss=0.9862974882125854 GP=2.1955461502075195)
[Training] epoch:741 step:0 g_loss:1.2713849544525146 d_loss:1.8201255351305008 (f_loss=-0.24441783130168915 r_loss=1.060829997062683 GP=1.0037133693695068)
[Training] epoch:741 step:100 g_loss:1.2246171236038208 d_loss:1.5717009752988815 (f_loss=-0.1996360570192337 r_loss=1.135636806488037 GP=0.6357002258300781)
[Training] epoch:741 step:200 g_loss:1.3078986406326294 d_loss:2.1351997405290604 (f_loss=-0.23499123752117157 r_loss=1.0167655944824219 GP=1.35342538356781)
[Training] epoch:741 step:300 g_loss:1.200249195098877 d_loss:4.734333425760269 (f_loss=-0.184175044298172 r_loss=0.9506086707115173 GP=3.967899799346924)
[Training] epoch:742 step:0 g_loss:1.270551085472107 d_loss:1.4967544972896576 (f_loss=-0.1544698178768158 r_loss=1.138651728630066 GP=0.5125725865364075)
[Training] epoch:742 step:100 g_loss:1.280104160308838 d_loss:2.6645033061504364 (f_loss=-0.21343353390693665 r_loss=1.0453330278396606 GP=1.8326038122177124)
[Training] epoch:742 step:200 g_loss:1.2614319324493408 d_loss:1.5640702992677689 (f_loss=-0.23568616807460785 r_loss=1.128650188446045 GP=0.6711062788963318)
[Training] epoch:742 step:300 g_loss:1.280700922012329 d_loss:1.557949423789978 (f_loss=-0.3357884883880615 r_loss=1.0778553485870361 GP=0.8158825635910034)
[Training] epoch:743 step:0 g_loss:1.330357313156128 d_loss:1.7475496530532837 (f_loss=-0.21879220008850098 r_loss=1.0855603218078613 GP=0.8807815313339233)
[Training] epoch:743 step:100 g_loss:1.302420973777771 d_loss:2.4253712594509125 (f_loss=-0.3288957178592682 r_loss=1.2102596759796143 GP=1.5440073013305664)
[Training] epoch:743 step:200 g_loss:1.2487767934799194 d_loss:1.4161808788776398 (f_loss=-0.25705066323280334 r_loss=1.1437554359436035 GP=0.5294761061668396)
[Training] epoch:743 step:300 g_loss:1.2020665407180786 d_loss:1.8223213851451874 (f_loss=-0.2990746796131134 r_loss=1.0402190685272217 GP=1.081176996231079)
[Training] epoch:744 step:0 g_loss:1.2594627141952515 d_loss:1.2462792098522186 (f_loss=-0.29489415884017944 r_loss=1.1382637023925781 GP=0.40290966629981995)
[Training] epoch:744 step:100 g_loss:1.2350950241088867 d_loss:1.3215436488389969 (f_loss=-0.23178665339946747 r_loss=1.0520925521850586 GP=0.5012377500534058)
[Training] epoch:744 step:200 g_loss:1.2046376466751099 d_loss:1.0734589993953705 (f_loss=-0.20136618614196777 r_loss=1.1583824157714844 GP=0.11644276976585388)
[Training] epoch:744 step:300 g_loss:1.2905305624008179 d_loss:1.7948672622442245 (f_loss=-0.2480427771806717 r_loss=1.1612465381622314 GP=0.8816635012626648)
[Training] epoch:745 step:0 g_loss:1.2670902013778687 d_loss:1.5240210890769958 (f_loss=-0.22855865955352783 r_loss=1.1724445819854736 GP=0.58013516664505)
[Training] epoch:745 step:100 g_loss:1.2227836847305298 d_loss:1.5983325242996216 (f_loss=-0.2723519206047058 r_loss=1.259570598602295 GP=0.6111138463020325)
[Training] epoch:745 step:200 g_loss:1.293104887008667 d_loss:2.0345692932605743 (f_loss=-0.24720141291618347 r_loss=1.0531748533248901 GP=1.2285958528518677)
[Training] epoch:745 step:300 g_loss:1.2207889556884766 d_loss:1.5105741024017334 (f_loss=-0.29188674688339233 r_loss=1.221514105796814 GP=0.5809467434883118)
[Training] epoch:746 step:0 g_loss:1.225114107131958 d_loss:2.4223635643720627 (f_loss=-0.2478543072938919 r_loss=1.173503041267395 GP=1.4967148303985596)
[Training] epoch:746 step:100 g_loss:1.2383618354797363 d_loss:1.5680074989795685 (f_loss=-0.2769638001918793 r_loss=1.1814218759536743 GP=0.6635494232177734)
[Training] epoch:746 step:200 g_loss:1.1786726713180542 d_loss:1.5281288921833038 (f_loss=-0.20510271191596985 r_loss=1.1213970184326172 GP=0.6118345856666565)
[Training] epoch:746 step:300 g_loss:1.198244333267212 d_loss:3.875545635819435 (f_loss=-0.2409002035856247 r_loss=0.9800234436988831 GP=3.1364223957061768)
[Training] epoch:747 step:0 g_loss:1.2685534954071045 d_loss:1.0549182146787643 (f_loss=-0.3010801076889038 r_loss=1.1662988662719727 GP=0.1896994560956955)
[Training] epoch:747 step:100 g_loss:1.2888215780258179 d_loss:1.8268807530403137 (f_loss=-0.2704234719276428 r_loss=1.0903737545013428 GP=1.0069304704666138)
[Training] epoch:747 step:200 g_loss:1.2458537817001343 d_loss:3.1584379076957703 (f_loss=-0.23026496171951294 r_loss=1.0824244022369385 GP=2.3062784671783447)
[Training] epoch:747 step:300 g_loss:1.2997143268585205 d_loss:1.844618409872055 (f_loss=-0.23794862627983093 r_loss=1.0845948457717896 GP=0.9979721903800964)
[Training] epoch:748 step:0 g_loss:1.2533632516860962 d_loss:1.627220407128334 (f_loss=-0.20758889615535736 r_loss=1.179080605506897 GP=0.6557286977767944)
[Training] epoch:748 step:100 g_loss:1.222848892211914 d_loss:1.808459758758545 (f_loss=-0.25523895025253296 r_loss=0.9987644553184509 GP=1.064934253692627)
[Training] epoch:748 step:200 g_loss:1.269521713256836 d_loss:3.7879139482975006 (f_loss=-0.24709376692771912 r_loss=1.1022632122039795 GP=2.9327445030212402)
[Training] epoch:748 step:300 g_loss:1.2384506464004517 d_loss:1.2291598618030548 (f_loss=-0.25240451097488403 r_loss=1.180543065071106 GP=0.3010213077068329)
[Training] epoch:749 step:0 g_loss:1.2792870998382568 d_loss:1.5182185471057892 (f_loss=-0.26656922698020935 r_loss=1.214111566543579 GP=0.5706762075424194)
[Training] epoch:749 step:100 g_loss:1.2268431186676025 d_loss:1.3575609624385834 (f_loss=-0.1941245198249817 r_loss=1.1783225536346436 GP=0.3733629286289215)
[Training] epoch:749 step:200 g_loss:1.2721338272094727 d_loss:1.494146004319191 (f_loss=-0.2212391346693039 r_loss=1.1685048341751099 GP=0.546880304813385)
[Training] epoch:749 step:300 g_loss:1.2411390542984009 d_loss:1.2610653936862946 (f_loss=-0.27667465806007385 r_loss=1.1166990995407104 GP=0.42104095220565796)
[Training] epoch:750 step:0 g_loss:1.21882963180542 d_loss:1.3459026217460632 (f_loss=-0.25022125244140625 r_loss=1.1675485372543335 GP=0.428575336933136)

[Training] epoch:750 step:100 g_loss:1.2487035989761353 d_loss:1.8349720537662506 (f_loss=-0.29948124289512634 r_loss=1.0880589485168457 GP=1.0463943481445312)
[Training] epoch:750 step:200 g_loss:1.2517330646514893 d_loss:1.1326194554567337 (f_loss=-0.2588241398334503 r_loss=1.2302223443984985 GP=0.16122125089168549)
[Training] epoch:750 step:300 g_loss:1.2205007076263428 d_loss:1.6854561269283295 (f_loss=-0.34118029475212097 r_loss=0.9525160193443298 GP=1.0741204023361206)
[Training] epoch:751 step:0 g_loss:1.2375664710998535 d_loss:1.9821346700191498 (f_loss=-0.23625758290290833 r_loss=1.1295264959335327 GP=1.0888657569885254)
[Training] epoch:751 step:100 g_loss:1.2124435901641846 d_loss:1.5064531564712524 (f_loss=-0.23219048976898193 r_loss=1.2181272506713867 GP=0.5205163955688477)
[Training] epoch:751 step:200 g_loss:1.2679187059402466 d_loss:1.7188156843185425 (f_loss=-0.2805502414703369 r_loss=1.1135313510894775 GP=0.8858345746994019)
[Training] epoch:751 step:300 g_loss:1.2536910772323608 d_loss:1.6492406129837036 (f_loss=-0.2761441469192505 r_loss=1.1182905435562134 GP=0.8070942163467407)
[Training] epoch:752 step:0 g_loss:1.310309648513794 d_loss:1.2153646498918533 (f_loss=-0.22185997664928436 r_loss=1.1395829916000366 GP=0.2976416349411011)
[Training] epoch:752 step:100 g_loss:1.2515002489089966 d_loss:1.9497652351856232 (f_loss=-0.2783641517162323 r_loss=1.1349663734436035 GP=1.093163013458252)
[Training] epoch:752 step:200 g_loss:1.235277771949768 d_loss:1.4779660403728485 (f_loss=-0.2723996341228485 r_loss=1.2573250532150269 GP=0.49304062128067017)
[Training] epoch:752 step:300 g_loss:1.2002114057540894 d_loss:1.4789296984672546 (f_loss=-0.23937588930130005 r_loss=1.117586612701416 GP=0.6007189750671387)
[Training] epoch:753 step:0 g_loss:1.220967173576355 d_loss:1.7110250294208527 (f_loss=-0.229457825422287 r_loss=1.1210192441940308 GP=0.8194636106491089)
[Training] epoch:753 step:100 g_loss:1.2558863162994385 d_loss:1.4063358008861542 (f_loss=-0.20735931396484375 r_loss=1.2038530111312866 GP=0.4098421037197113)
[Training] epoch:753 step:200 g_loss:1.215813398361206 d_loss:1.7513215392827988 (f_loss=-0.246539905667305 r_loss=1.1774970293045044 GP=0.8203644156455994)
[Training] epoch:753 step:300 g_loss:1.1823852062225342 d_loss:1.3629263639450073 (f_loss=-0.3346986770629883 r_loss=1.192800521850586 GP=0.5048245191574097)
[Training] epoch:754 step:0 g_loss:1.1877257823944092 d_loss:1.7879343926906586 (f_loss=-0.21224895119667053 r_loss=1.1865955591201782 GP=0.8135877847671509)
[Training] epoch:754 step:100 g_loss:1.2078306674957275 d_loss:3.53495055437088 (f_loss=-0.17723768949508667 r_loss=0.833381175994873 GP=2.8788070678710938)
[Training] epoch:754 step:200 g_loss:1.2544535398483276 d_loss:1.499938815832138 (f_loss=-0.27478721737861633 r_loss=1.1817612648010254 GP=0.592964768409729)
[Training] epoch:754 step:300 g_loss:1.1736314296722412 d_loss:1.91415736079216 (f_loss=-0.24860981106758118 r_loss=1.0562211275100708 GP=1.1065460443496704)
[Training] epoch:755 step:0 g_loss:1.2189505100250244 d_loss:1.3046771883964539 (f_loss=-0.269615113735199 r_loss=1.2197260856628418 GP=0.35456621646881104)
[Training] epoch:755 step:100 g_loss:1.272845983505249 d_loss:1.1516675502061844 (f_loss=-0.25241872668266296 r_loss=1.2028166055679321 GP=0.20126967132091522)
[Training] epoch:755 step:200 g_loss:1.2541239261627197 d_loss:1.390657439827919 (f_loss=-0.20761482417583466 r_loss=1.2275856733322144 GP=0.3706865906715393)
[Training] epoch:755 step:300 g_loss:1.3151731491088867 d_loss:1.3185554146766663 (f_loss=-0.3085326552391052 r_loss=1.1259857416152954 GP=0.5011023283004761)
[Training] epoch:756 step:0 g_loss:1.2628217935562134 d_loss:2.0512931048870087 (f_loss=-0.24560990929603577 r_loss=1.0629006624221802 GP=1.2340023517608643)
[Training] epoch:756 step:100 g_loss:1.2331020832061768 d_loss:1.4375601708889008 (f_loss=-0.18210098147392273 r_loss=1.10415780544281 GP=0.5155033469200134)
[Training] epoch:756 step:200 g_loss:1.267230749130249 d_loss:1.5662853419780731 (f_loss=-0.266597181558609 r_loss=1.1573182344436646 GP=0.6755642890930176)
[Training] epoch:756 step:300 g_loss:1.1960335969924927 d_loss:1.2634964287281036 (f_loss=-0.2831905782222748 r_loss=1.2232609987258911 GP=0.3234260082244873)
[Training] epoch:757 step:0 g_loss:1.2065956592559814 d_loss:1.364781603217125 (f_loss=-0.20959673821926117 r_loss=1.0900496244430542 GP=0.4843287169933319)
[Training] epoch:757 step:100 g_loss:1.2440036535263062 d_loss:1.6552567034959793 (f_loss=-0.2306535691022873 r_loss=1.1189721822738647 GP=0.7669380903244019)
[Training] epoch:757 step:200 g_loss:1.2866063117980957 d_loss:1.445764034986496 (f_loss=-0.33221563696861267 r_loss=1.123827338218689 GP=0.6541523337364197)
[Training] epoch:757 step:300 g_loss:1.3536858558654785 d_loss:1.782946065068245 (f_loss=-0.1345282644033432 r_loss=1.204683780670166 GP=0.7127905488014221)
[Training] epoch:758 step:0 g_loss:1.3077619075775146 d_loss:2.390220493078232 (f_loss=-0.25691714882850647 r_loss=1.1229485273361206 GP=1.5241891145706177)
[Training] epoch:758 step:100 g_loss:1.310576319694519 d_loss:1.296092301607132 (f_loss=-0.3066690266132355 r_loss=1.0885579586029053 GP=0.5142033696174622)
[Training] epoch:758 step:200 g_loss:1.3031688928604126 d_loss:1.1751732230186462 (f_loss=-0.25636720657348633 r_loss=1.1535266637802124 GP=0.27801376581192017)
[Training] epoch:758 step:300 g_loss:1.2456544637680054 d_loss:1.7980720102787018 (f_loss=-0.31385812163352966 r_loss=1.1925097703933716 GP=0.9194203615188599)
[Training] epoch:759 step:0 g_loss:1.2220515012741089 d_loss:1.5405238568782806 (f_loss=-0.26921311020851135 r_loss=1.21768319606781 GP=0.5920537710189819)
[Training] epoch:759 step:100 g_loss:1.2312889099121094 d_loss:1.2635472118854523 (f_loss=-0.20337411761283875 r_loss=1.169366478919983 GP=0.2975548505783081)
[Training] epoch:759 step:200 g_loss:1.307396650314331 d_loss:1.1557868719100952 (f_loss=-0.2478029727935791 r_loss=1.1854338645935059 GP=0.21815598011016846)
[Training] epoch:759 step:300 g_loss:1.245833396911621 d_loss:2.168886572122574 (f_loss=-0.252778023481369 r_loss=1.1384021043777466 GP=1.2832624912261963)
[Training] epoch:760 step:0 g_loss:1.23333740234375 d_loss:2.214194029569626 (f_loss=-0.2163483202457428 r_loss=1.1132831573486328 GP=1.3172591924667358)

[Training] epoch:760 step:100 g_loss:1.294716238975525 d_loss:2.15505388379097 (f_loss=-0.3188713490962982 r_loss=1.2692941427230835 GP=1.2046310901641846)
[Training] epoch:760 step:200 g_loss:1.231104850769043 d_loss:3.3020902574062347 (f_loss=-0.20997026562690735 r_loss=1.214340090751648 GP=2.297720432281494)
[Training] epoch:760 step:300 g_loss:1.243175983428955 d_loss:1.267008900642395 (f_loss=-0.26889994740486145 r_loss=1.179955244064331 GP=0.3559536039829254)
[Training] epoch:761 step:0 g_loss:1.2551419734954834 d_loss:1.651366412639618 (f_loss=-0.1747165322303772 r_loss=1.2594844102859497 GP=0.5665985345840454)
[Training] epoch:761 step:100 g_loss:1.19513738155365 d_loss:1.5541374683380127 (f_loss=-0.28984034061431885 r_loss=1.262436866760254 GP=0.5815409421920776)
[Training] epoch:761 step:200 g_loss:1.2713384628295898 d_loss:1.7942287921905518 (f_loss=-0.2215600609779358 r_loss=1.2522470951080322 GP=0.7635417580604553)
[Training] epoch:761 step:300 g_loss:1.284902572631836 d_loss:1.456752449274063 (f_loss=-0.2185087502002716 r_loss=1.1476731300354004 GP=0.5275880694389343)
[Training] epoch:762 step:0 g_loss:1.304229974746704 d_loss:1.6937639862298965 (f_loss=-0.21549658477306366 r_loss=1.0964329242706299 GP=0.8128276467323303)
[Training] epoch:762 step:100 g_loss:1.2542229890823364 d_loss:1.5629069209098816 (f_loss=-0.26924073696136475 r_loss=1.201570749282837 GP=0.6305769085884094)
[Training] epoch:762 step:200 g_loss:1.2085460424423218 d_loss:1.550504058599472 (f_loss=-0.21823236346244812 r_loss=1.1042718887329102 GP=0.66446453332901)
[Training] epoch:762 step:300 g_loss:1.1769272089004517 d_loss:2.0743914544582367 (f_loss=-0.3266599476337433 r_loss=1.09132981300354 GP=1.30972158908844)
[Training] epoch:763 step:0 g_loss:1.2231168746948242 d_loss:1.5091824233531952 (f_loss=-0.2483600676059723 r_loss=1.0209763050079346 GP=0.7365661859512329)
[Training] epoch:763 step:100 g_loss:1.227871298789978 d_loss:1.1788403391838074 (f_loss=-0.25112152099609375 r_loss=1.171391248703003 GP=0.2585706114768982)
[Training] epoch:763 step:200 g_loss:1.2301392555236816 d_loss:1.4759916216135025 (f_loss=-0.19952772557735443 r_loss=1.2509868144989014 GP=0.42453253269195557)
[Training] epoch:763 step:300 g_loss:1.253105640411377 d_loss:1.7943759262561798 (f_loss=-0.25761309266090393 r_loss=1.1905845403671265 GP=0.8614044785499573)
[Training] epoch:764 step:0 g_loss:1.236433982849121 d_loss:2.030278831720352 (f_loss=-0.2712068259716034 r_loss=1.102072834968567 GP=1.1994128227233887)
[Training] epoch:764 step:100 g_loss:1.2923897504806519 d_loss:1.5977817475795746 (f_loss=-0.31412503123283386 r_loss=1.2050114870071411 GP=0.7068952918052673)
[Training] epoch:764 step:200 g_loss:1.2452616691589355 d_loss:1.5396429300308228 (f_loss=-0.3044036626815796 r_loss=1.1867825984954834 GP=0.657263994216919)
[Training] epoch:764 step:300 g_loss:1.2137000560760498 d_loss:2.269422620534897 (f_loss=-0.2773825228214264 r_loss=1.0883396863937378 GP=1.4584654569625854)
[Training] epoch:765 step:0 g_loss:1.2739894390106201 d_loss:2.5636008828878403 (f_loss=-0.23224367201328278 r_loss=0.9932608604431152 GP=1.8025836944580078)
[Training] epoch:765 step:100 g_loss:1.2480955123901367 d_loss:1.5038406401872635 (f_loss=-0.23446957767009735 r_loss=1.1748034954071045 GP=0.5635067224502563)
[Training] epoch:765 step:200 g_loss:1.2159600257873535 d_loss:1.4712770581245422 (f_loss=-0.2879200577735901 r_loss=1.1602716445922852 GP=0.5989254713058472)
[Training] epoch:765 step:300 g_loss:1.360612154006958 d_loss:1.4430996477603912 (f_loss=-0.2654058635234833 r_loss=1.110504388809204 GP=0.5980011224746704)
[Training] epoch:766 step:0 g_loss:1.2019379138946533 d_loss:1.9276249706745148 (f_loss=-0.21930202841758728 r_loss=1.1101447343826294 GP=1.0367822647094727)
[Training] epoch:766 step:100 g_loss:1.2121450901031494 d_loss:1.5526423156261444 (f_loss=-0.3027940094470978 r_loss=1.110387921333313 GP=0.7450484037399292)
[Training] epoch:766 step:200 g_loss:1.2435814142227173 d_loss:1.2865029573440552 (f_loss=-0.2815735638141632 r_loss=1.2020244598388672 GP=0.3660520613193512)
[Training] epoch:766 step:300 g_loss:1.2807655334472656 d_loss:1.6185527443885803 (f_loss=-0.2627744674682617 r_loss=1.1859276294708252 GP=0.6953995823860168)
[Training] epoch:767 step:0 g_loss:1.3407158851623535 d_loss:1.717355728149414 (f_loss=-0.26409226655960083 r_loss=1.1337748765945435 GP=0.8476731181144714)
[Training] epoch:767 step:100 g_loss:1.3124127388000488 d_loss:2.1087974458932877 (f_loss=-0.23728357255458832 r_loss=1.117811679840088 GP=1.228269338607788)
[Training] epoch:767 step:200 g_loss:1.2427046298980713 d_loss:1.9437290579080582 (f_loss=-0.1858569234609604 r_loss=1.1780773401260376 GP=0.951508641242981)
[Training] epoch:767 step:300 g_loss:1.2265747785568237 d_loss:1.5820021778345108 (f_loss=-0.24962662160396576 r_loss=1.0876860618591309 GP=0.7439427375793457)
[Training] epoch:768 step:0 g_loss:1.2234327793121338 d_loss:1.967741847038269 (f_loss=-0.2579997777938843 r_loss=1.104704737663269 GP=1.1210368871688843)
[Training] epoch:768 step:100 g_loss:1.2081093788146973 d_loss:2.7603010535240173 (f_loss=-0.2770846486091614 r_loss=0.9655585289001465 GP=2.0718271732330322)
[Training] epoch:768 step:200 g_loss:1.3064026832580566 d_loss:1.460199385881424 (f_loss=-0.22332116961479187 r_loss=1.1752521991729736 GP=0.5082683563232422)
[Training] epoch:768 step:300 g_loss:1.2416006326675415 d_loss:1.4163568317890167 (f_loss=-0.2543506324291229 r_loss=1.162996768951416 GP=0.5077106952667236)
[Training] epoch:769 step:0 g_loss:1.1890761852264404 d_loss:1.788388043642044 (f_loss=-0.2413242757320404 r_loss=1.2099517583847046 GP=0.8197605609893799)
[Training] epoch:769 step:100 g_loss:1.3260986804962158 d_loss:1.5273461639881134 (f_loss=-0.2734985053539276 r_loss=1.1983611583709717 GP=0.6024835109710693)
[Training] epoch:769 step:200 g_loss:1.2560110092163086 d_loss:3.0268481373786926 (f_loss=-0.26943439245224 r_loss=1.0448336601257324 GP=2.2514488697052)
[Training] epoch:769 step:300 g_loss:1.2992963790893555 d_loss:1.4434428215026855 (f_loss=-0.29990196228027344 r_loss=1.203942894935608 GP=0.5394018888473511)
[Training] epoch:770 step:0 g_loss:1.2747184038162231 d_loss:1.3328446745872498 (f_loss=-0.2261565923690796 r_loss=1.2542825937271118 GP=0.30471867322921753)

[Training] epoch:770 step:100 g_loss:1.2812601327896118 d_loss:1.6029698252677917 (f_loss=-0.2566605806350708 r_loss=1.2606475353240967 GP=0.5989828705787659)
[Training] epoch:770 step:200 g_loss:1.3297104835510254 d_loss:1.2071640193462372 (f_loss=-0.3045409023761749 r_loss=1.1960947513580322 GP=0.3156101703643799)
[Training] epoch:770 step:300 g_loss:1.2388429641723633 d_loss:1.9610847383737564 (f_loss=-0.2306702584028244 r_loss=1.2568373680114746 GP=0.9349176287651062)
[Training] epoch:771 step:0 g_loss:1.2759026288986206 d_loss:1.787457674741745 (f_loss=-0.34744277596473694 r_loss=1.0832300186157227 GP=1.0516704320907593)
[Training] epoch:771 step:100 g_loss:1.2791754007339478 d_loss:2.0223289132118225 (f_loss=-0.2780076861381531 r_loss=0.9977761507034302 GP=1.3025604486465454)
[Training] epoch:771 step:200 g_loss:1.2395942211151123 d_loss:1.8643199503421783 (f_loss=-0.30169615149497986 r_loss=1.2268762588500977 GP=0.9391398429870605)
[Training] epoch:771 step:300 g_loss:1.2994542121887207 d_loss:2.0127844363451004 (f_loss=-0.19283847510814667 r_loss=1.1732816696166992 GP=1.0323412418365479)
[Training] epoch:772 step:0 g_loss:1.2571709156036377 d_loss:3.436851352453232 (f_loss=-0.3142741024494171 r_loss=0.9178973436355591 GP=2.83322811126709)
[Training] epoch:772 step:100 g_loss:1.2632663249969482 d_loss:1.0725564882159233 (f_loss=-0.2769421339035034 r_loss=1.228522539138794 GP=0.12097608298063278)
[Training] epoch:772 step:200 g_loss:1.1910268068313599 d_loss:1.6765936017036438 (f_loss=-0.31145942211151123 r_loss=1.1423766613006592 GP=0.8456763625144958)
[Training] epoch:772 step:300 g_loss:1.2421003580093384 d_loss:2.4561931788921356 (f_loss=-0.2219422161579132 r_loss=1.0862157344818115 GP=1.5919196605682373)
[Training] epoch:773 step:0 g_loss:1.2520567178726196 d_loss:1.556942492723465 (f_loss=-0.24281880259513855 r_loss=1.173823356628418 GP=0.6259379386901855)
[Training] epoch:773 step:100 g_loss:1.2260937690734863 d_loss:1.5689741373062134 (f_loss=-0.29943984746932983 r_loss=1.1854294538497925 GP=0.6829845309257507)
[Training] epoch:773 step:200 g_loss:1.2366197109222412 d_loss:2.1348250657320023 (f_loss=-0.2443557232618332 r_loss=1.2537699937820435 GP=1.125410795211792)
[Training] epoch:773 step:300 g_loss:1.3123657703399658 d_loss:1.4973683208227158 (f_loss=-0.22517265379428864 r_loss=1.1655436754226685 GP=0.5569972991943359)
[Training] epoch:774 step:0 g_loss:1.3115711212158203 d_loss:2.235927700996399 (f_loss=-0.29830193519592285 r_loss=1.2215285301208496 GP=1.3127011060714722)
[Training] epoch:774 step:100 g_loss:1.257420301437378 d_loss:1.3532925248146057 (f_loss=-0.3126053810119629 r_loss=1.2529637813568115 GP=0.4129341244697571)
[Training] epoch:774 step:200 g_loss:1.256995439529419 d_loss:1.7749964743852615 (f_loss=-0.2282060831785202 r_loss=1.1122515201568604 GP=0.8909510374069214)
[Training] epoch:774 step:300 g_loss:1.3311280012130737 d_loss:1.6921893060207367 (f_loss=-0.3655003607273102 r_loss=1.1019866466522217 GP=0.9557030200958252)
[Training] epoch:775 step:0 g_loss:1.201235294342041 d_loss:1.53964102268219 (f_loss=-0.20192945003509521 r_loss=1.1442663669586182 GP=0.597304105758667)
[Training] epoch:775 step:100 g_loss:1.2791709899902344 d_loss:1.342416137456894 (f_loss=-0.20801913738250732 r_loss=1.1050082445144653 GP=0.4454270303249359)
[Training] epoch:775 step:200 g_loss:1.2281574010849 d_loss:1.2331495881080627 (f_loss=-0.2454674243927002 r_loss=1.1771494150161743 GP=0.3014675974845886)
[Training] epoch:775 step:300 g_loss:1.223085880279541 d_loss:1.2615657448768616 (f_loss=-0.31266653537750244 r_loss=1.2879388332366943 GP=0.2862934470176697)
[Training] epoch:776 step:0 g_loss:1.268193006515503 d_loss:1.5250760912895203 (f_loss=-0.3203215003013611 r_loss=1.0884270668029785 GP=0.7569705247879028)
[Training] epoch:776 step:100 g_loss:1.2610050439834595 d_loss:2.1521273851394653 (f_loss=-0.2702603340148926 r_loss=1.1791828870773315 GP=1.2432048320770264)
[Training] epoch:776 step:200 g_loss:1.2547303438186646 d_loss:3.141639292240143 (f_loss=-0.28487807512283325 r_loss=1.067670464515686 GP=2.35884690284729)
[Training] epoch:776 step:300 g_loss:1.2531208992004395 d_loss:1.2908896207809448 (f_loss=-0.24789869785308838 r_loss=1.168916940689087 GP=0.3698713779449463)
[Training] epoch:777 step:0 g_loss:1.2831671237945557 d_loss:2.9555253088474274 (f_loss=-0.28345879912376404 r_loss=1.0427589416503906 GP=2.196225166320801)
[Training] epoch:777 step:100 g_loss:1.3522615432739258 d_loss:1.4066367149353027 (f_loss=-0.27042073011398315 r_loss=1.1409729719161987 GP=0.5360844731330872)
[Training] epoch:777 step:200 g_loss:1.3154553174972534 d_loss:1.933587521314621 (f_loss=-0.3132142126560211 r_loss=1.1473411321640015 GP=1.0994606018066406)
[Training] epoch:777 step:300 g_loss:1.2724354267120361 d_loss:1.3167735487222672 (f_loss=-0.2325267642736435 r_loss=1.1602120399475098 GP=0.3890882730484009)
[Training] epoch:778 step:0 g_loss:1.3479397296905518 d_loss:1.441228300333023 (f_loss=-0.3150888979434967 r_loss=1.1896758079528809 GP=0.5666413903236389)
[Training] epoch:778 step:100 g_loss:1.3059542179107666 d_loss:1.3285771906375885 (f_loss=-0.31358635425567627 r_loss=1.1468117237091064 GP=0.4953518211841583)
[Training] epoch:778 step:200 g_loss:1.2388877868652344 d_loss:1.274023950099945 (f_loss=-0.23018240928649902 r_loss=1.1863062381744385 GP=0.3179001212120056)
[Training] epoch:778 step:300 g_loss:1.276787519454956 d_loss:1.4668026566505432 (f_loss=-0.22334343194961548 r_loss=1.2413485050201416 GP=0.4487975835800171)
[Training] epoch:779 step:0 g_loss:1.347825050354004 d_loss:1.7767997533082962 (f_loss=-0.23685358464717865 r_loss=1.1903349161148071 GP=0.8233184218406677)
[Training] epoch:779 step:100 g_loss:1.2290934324264526 d_loss:1.1240679621696472 (f_loss=-0.309166818857193 r_loss=1.0898388624191284 GP=0.3433959186077118)
[Training] epoch:779 step:200 g_loss:1.2055416107177734 d_loss:1.4362156391143799 (f_loss=-0.2914925813674927 r_loss=1.1384143829345703 GP=0.5892938375473022)
[Training] epoch:779 step:300 g_loss:1.3066127300262451 d_loss:1.9024165868759155 (f_loss=-0.2285827398300171 r_loss=1.2478562593460083 GP=0.8831430673599243)
[Training] epoch:780 step:0 g_loss:1.2774282693862915 d_loss:2.7443049252033234 (f_loss=-0.2268572747707367 r_loss=1.1780567169189453 GP=1.7931054830551147)

[Training] epoch:780 step:100 g_loss:1.276839256286621 d_loss:1.9264231324195862 (f_loss=-0.27058881521224976 r_loss=1.0132774114608765 GP=1.1837345361709595)
[Training] epoch:780 step:200 g_loss:1.2685363292694092 d_loss:4.00887306034565 (f_loss=-0.22710184752941132 r_loss=1.0897146463394165 GP=3.1462602615356445)
[Training] epoch:780 step:300 g_loss:1.2022346258163452 d_loss:1.4076520204544067 (f_loss=-0.21424788236618042 r_loss=1.0623812675476074 GP=0.5595186352729797)
[Training] epoch:781 step:0 g_loss:1.262965440750122 d_loss:1.548056647181511 (f_loss=-0.2129630595445633 r_loss=1.2634918689727783 GP=0.4975278377532959)
[Training] epoch:781 step:100 g_loss:1.228352665901184 d_loss:1.311534821987152 (f_loss=-0.2565820813179016 r_loss=1.1372175216674805 GP=0.43089938163757324)
[Training] epoch:781 step:200 g_loss:1.2894904613494873 d_loss:1.5562335550785065 (f_loss=-0.2425687611103058 r_loss=1.2040188312530518 GP=0.5947834849357605)
[Training] epoch:781 step:300 g_loss:1.2596851587295532 d_loss:1.9896280467510223 (f_loss=-0.3023008406162262 r_loss=1.069992184638977 GP=1.2219367027282715)
[Training] epoch:782 step:0 g_loss:1.316839575767517 d_loss:1.8231316208839417 (f_loss=-0.308410108089447 r_loss=1.1282527446746826 GP=1.003288984298706)
[Training] epoch:782 step:100 g_loss:1.2800180912017822 d_loss:1.9172752499580383 (f_loss=-0.3029558062553406 r_loss=1.08604097366333 GP=1.1341900825500488)
[Training] epoch:782 step:200 g_loss:1.2659109830856323 d_loss:1.520784854888916 (f_loss=-0.27946633100509644 r_loss=1.1898198127746582 GP=0.6104313731193542)
[Training] epoch:782 step:300 g_loss:1.2817037105560303 d_loss:1.520749419927597 (f_loss=-0.29172149300575256 r_loss=1.0839660167694092 GP=0.7285048961639404)
[Training] epoch:783 step:0 g_loss:1.2574043273925781 d_loss:1.2611020803451538 (f_loss=-0.2908628582954407 r_loss=1.2413835525512695 GP=0.31058138608932495)
[Training] epoch:783 step:100 g_loss:1.2823008298873901 d_loss:1.612322747707367 (f_loss=-0.2866745591163635 r_loss=1.195225477218628 GP=0.7037718296051025)
[Training] epoch:783 step:200 g_loss:1.3129844665527344 d_loss:1.409038782119751 (f_loss=-0.3002840280532837 r_loss=1.210145354270935 GP=0.4991774559020996)
[Training] epoch:783 step:300 g_loss:1.2977975606918335 d_loss:1.8067502081394196 (f_loss=-0.2962261140346527 r_loss=1.0994497537612915 GP=1.0035265684127808)
[Training] epoch:784 step:0 g_loss:1.2114338874816895 d_loss:1.305431306362152 (f_loss=-0.2503095269203186 r_loss=1.203641414642334 GP=0.3520994186401367)
[Training] epoch:784 step:100 g_loss:1.2735414505004883 d_loss:1.4887394905090332 (f_loss=-0.26075655221939087 r_loss=1.1302592754364014 GP=0.6192367672920227)
[Training] epoch:784 step:200 g_loss:1.2561230659484863 d_loss:1.3022143244743347 (f_loss=-0.2894227206707001 r_loss=1.186246633529663 GP=0.4053904116153717)
[Training] epoch:784 step:300 g_loss:1.3060719966888428 d_loss:1.4829809367656708 (f_loss=-0.2778271734714508 r_loss=1.189009666442871 GP=0.5717984437942505)
[Training] epoch:785 step:0 g_loss:1.2579536437988281 d_loss:1.4994798004627228 (f_loss=-0.29054000973701477 r_loss=1.0599385499954224 GP=0.7300812602043152)
[Training] epoch:785 step:100 g_loss:1.2262191772460938 d_loss:1.5064668357372284 (f_loss=-0.2848535478115082 r_loss=1.15842604637146 GP=0.6328943371772766)
[Training] epoch:785 step:200 g_loss:1.3794466257095337 d_loss:1.7632865011692047 (f_loss=-0.3336809575557709 r_loss=1.1777349710464478 GP=0.9192324876785278)
[Training] epoch:785 step:300 g_loss:1.2973368167877197 d_loss:1.4570053815841675 (f_loss=-0.31955111026763916 r_loss=1.2557636499404907 GP=0.5207928419113159)
[Training] epoch:786 step:0 g_loss:1.2249616384506226 d_loss:1.8330282866954803 (f_loss=-0.31512942910194397 r_loss=1.1466416120529175 GP=1.0015161037445068)
[Training] epoch:786 step:100 g_loss:1.252009630203247 d_loss:1.923998400568962 (f_loss=-0.24040062725543976 r_loss=1.1521239280700684 GP=1.0122750997543335)
[Training] epoch:786 step:200 g_loss:1.3144599199295044 d_loss:2.5903653651475906 (f_loss=-0.23540715873241425 r_loss=1.051533579826355 GP=1.77423894405365)
[Training] epoch:786 step:300 g_loss:1.2301805019378662 d_loss:1.6173082292079926 (f_loss=-0.22642704844474792 r_loss=1.219364881515503 GP=0.6243703961372375)
[Training] epoch:787 step:0 g_loss:1.2811635732650757 d_loss:1.383964717388153 (f_loss=-0.3300260901451111 r_loss=1.1924421787261963 GP=0.5215486288070679)
[Training] epoch:787 step:100 g_loss:1.2604403495788574 d_loss:1.457677572965622 (f_loss=-0.2940051257610321 r_loss=1.2264683246612549 GP=0.5252143740653992)
[Training] epoch:787 step:200 g_loss:1.2886159420013428 d_loss:1.7138065695762634 (f_loss=-0.32576698064804077 r_loss=1.191093921661377 GP=0.8484796285629272)
[Training] epoch:787 step:300 g_loss:1.2953100204467773 d_loss:1.279771476984024 (f_loss=-0.2787536680698395 r_loss=1.2101161479949951 GP=0.3484089970588684)
[Training] epoch:788 step:0 g_loss:1.2435473203659058 d_loss:1.2013999223709106 (f_loss=-0.22433608770370483 r_loss=1.1982961893081665 GP=0.22743982076644897)
[Training] epoch:788 step:100 g_loss:1.2641987800598145 d_loss:2.853791445493698 (f_loss=-0.3258744776248932 r_loss=1.137245774269104 GP=2.0424201488494873)
[Training] epoch:788 step:200 g_loss:1.2560210227966309 d_loss:1.7482327073812485 (f_loss=-0.24021793901920319 r_loss=1.1355352401733398 GP=0.8529154062271118)
[Training] epoch:788 step:300 g_loss:1.2088717222213745 d_loss:1.5263065695762634 (f_loss=-0.318448007106781 r_loss=1.0721246004104614 GP=0.772629976272583)
[Training] epoch:789 step:0 g_loss:1.277708888053894 d_loss:1.625234991312027 (f_loss=-0.27995577454566956 r_loss=1.2067275047302246 GP=0.6984632611274719)
[Training] epoch:789 step:100 g_loss:1.2186028957366943 d_loss:1.669699251651764 (f_loss=-0.26524120569229126 r_loss=1.1811991930007935 GP=0.7537412643432617)
[Training] epoch:789 step:200 g_loss:1.2781280279159546 d_loss:2.6774418652057648 (f_loss=-0.22316262125968933 r_loss=1.173911452293396 GP=1.726693034172058)
[Training] epoch:789 step:300 g_loss:1.320258378982544 d_loss:1.4548318684101105 (f_loss=-0.3133713901042938 r_loss=1.254730463027954 GP=0.5134727954864502)
[Training] epoch:790 step:0 g_loss:1.2569994926452637 d_loss:2.553996503353119 (f_loss=-0.30360108613967896 r_loss=1.0763972997665405 GP=1.7812002897262573)

[Training] epoch:790 step:100 g_loss:1.2855244874954224 d_loss:4.274949848651886 (f_loss=-0.28701287508010864 r_loss=1.0767635107040405 GP=3.485199213027954)
[Training] epoch:790 step:200 g_loss:1.2635301351547241 d_loss:1.591938465833664 (f_loss=-0.2532978355884552 r_loss=1.1704061031341553 GP=0.6748301982879639)
[Training] epoch:790 step:300 g_loss:1.2916874885559082 d_loss:1.5541280508041382 (f_loss=-0.34506988525390625 r_loss=1.246180772781372 GP=0.6530171632766724)
[Training] epoch:791 step:0 g_loss:1.3357722759246826 d_loss:1.437064379453659 (f_loss=-0.27967241406440735 r_loss=1.2411844730377197 GP=0.4755523204803467)
[Training] epoch:791 step:100 g_loss:1.271109938621521 d_loss:2.241036742925644 (f_loss=-0.24050822854042053 r_loss=1.123174786567688 GP=1.3583701848983765)
[Training] epoch:791 step:200 g_loss:1.2977373600006104 d_loss:1.6933562010526657 (f_loss=-0.2369699627161026 r_loss=1.231317400932312 GP=0.6990087628364563)
[Training] epoch:791 step:300 g_loss:1.318805456161499 d_loss:1.7323062419891357 (f_loss=-0.26221275329589844 r_loss=1.0836976766586304 GP=0.9108213186264038)
[Training] epoch:792 step:0 g_loss:1.2470676898956299 d_loss:1.7124716937541962 (f_loss=-0.28983721137046814 r_loss=1.151949405670166 GP=0.8503594994544983)
[Training] epoch:792 step:100 g_loss:1.2565670013427734 d_loss:1.9036785811185837 (f_loss=-0.2253352552652359 r_loss=1.1577653884887695 GP=0.97124844789505)
[Training] epoch:792 step:200 g_loss:1.2820875644683838 d_loss:1.4462672770023346 (f_loss=-0.2497454583644867 r_loss=1.140160083770752 GP=0.5558526515960693)
[Training] epoch:792 step:300 g_loss:1.2912012338638306 d_loss:2.2258722484111786 (f_loss=-0.29326632618904114 r_loss=1.0577075481414795 GP=1.4614310264587402)
[Training] epoch:793 step:0 g_loss:1.3348963260650635 d_loss:2.1063926219940186 (f_loss=-0.28664517402648926 r_loss=1.0817484855651855 GP=1.3112893104553223)
[Training] epoch:793 step:100 g_loss:1.196354866027832 d_loss:1.4248339533805847 (f_loss=-0.24215859174728394 r_loss=1.1832754611968994 GP=0.48371708393096924)
[Training] epoch:793 step:200 g_loss:1.286144733428955 d_loss:1.4171279668807983 (f_loss=-0.24205052852630615 r_loss=1.1395021677017212 GP=0.5196763277053833)
[Training] epoch:793 step:300 g_loss:1.2513622045516968 d_loss:1.8474201261997223 (f_loss=-0.31267377734184265 r_loss=1.131843090057373 GP=1.028250813484192)
[Training] epoch:794 step:0 g_loss:1.2728158235549927 d_loss:1.4535418152809143 (f_loss=-0.27744060754776 r_loss=1.0748403072357178 GP=0.6561421155929565)
[Training] epoch:794 step:100 g_loss:1.2483056783676147 d_loss:1.6413323879241943 (f_loss=-0.25986146926879883 r_loss=1.110841155052185 GP=0.7903527021408081)
[Training] epoch:794 step:200 g_loss:1.2657476663589478 d_loss:1.549347311258316 (f_loss=-0.2829448878765106 r_loss=1.2045797109603882 GP=0.6277124881744385)
[Training] epoch:794 step:300 g_loss:1.2432801723480225 d_loss:1.355623871088028 (f_loss=-0.2627922594547272 r_loss=1.1977858543395996 GP=0.4206302762031555)
[Training] epoch:795 step:0 g_loss:1.3002735376358032 d_loss:2.3186727166175842 (f_loss=-0.2767025828361511 r_loss=1.1231179237365723 GP=1.472257375717163)
[Training] epoch:795 step:100 g_loss:1.2474104166030884 d_loss:1.8466067910194397 (f_loss=-0.2249736189842224 r_loss=1.1597074270248413 GP=0.9118729829788208)
[Training] epoch:795 step:200 g_loss:1.2651581764221191 d_loss:1.3854551315307617 (f_loss=-0.21169805526733398 r_loss=1.1286836862564087 GP=0.468469500541687)
[Training] epoch:795 step:300 g_loss:1.1884372234344482 d_loss:1.2904651314020157 (f_loss=-0.23489589989185333 r_loss=1.1780378818511963 GP=0.34732314944267273)
[Training] epoch:796 step:0 g_loss:1.1982194185256958 d_loss:1.913148358464241 (f_loss=-0.18819718062877655 r_loss=1.0839945077896118 GP=1.0173510313034058)
[Training] epoch:796 step:100 g_loss:1.268675684928894 d_loss:2.92360857129097 (f_loss=-0.23155197501182556 r_loss=1.0778526067733765 GP=2.077307939529419)
[Training] epoch:796 step:200 g_loss:1.2320380210876465 d_loss:2.9348494857549667 (f_loss=-0.20060481131076813 r_loss=1.0631448030471802 GP=2.0723094940185547)
[Training] epoch:796 step:300 g_loss:1.2551651000976562 d_loss:1.337103396654129 (f_loss=-0.2796717882156372 r_loss=1.1908230781555176 GP=0.42595210671424866)
[Training] epoch:797 step:0 g_loss:1.2701117992401123 d_loss:2.241698771715164 (f_loss=-0.3056503236293793 r_loss=1.0390180349349976 GP=1.508331060409546)
[Training] epoch:797 step:100 g_loss:1.3129053115844727 d_loss:1.4431014358997345 (f_loss=-0.19969120621681213 r_loss=1.2607355117797852 GP=0.3820571303367615)
[Training] epoch:797 step:200 g_loss:1.2010142803192139 d_loss:1.4691103547811508 (f_loss=-0.2253914624452591 r_loss=1.1117621660232544 GP=0.5827396512031555)
[Training] epoch:797 step:300 g_loss:1.2841286659240723 d_loss:1.5475207269191742 (f_loss=-0.2704680263996124 r_loss=1.1878985166549683 GP=0.6300902366638184)
[Training] epoch:798 step:0 g_loss:1.261002540588379 d_loss:1.6702466160058975 (f_loss=-0.21688126027584076 r_loss=1.1565464735031128 GP=0.7305814027786255)
[Training] epoch:798 step:100 g_loss:1.2831929922103882 d_loss:2.1020541191101074 (f_loss=-0.336736798286438 r_loss=1.052567958831787 GP=1.3862229585647583)
[Training] epoch:798 step:200 g_loss:1.2948505878448486 d_loss:1.7380441427230835 (f_loss=-0.25392627716064453 r_loss=1.2006421089172363 GP=0.7913283109664917)
[Training] epoch:798 step:300 g_loss:1.230088472366333 d_loss:1.2376594841480255 (f_loss=-0.25339195132255554 r_loss=1.2345681190490723 GP=0.2564833164215088)
[Training] epoch:799 step:0 g_loss:1.248183012008667 d_loss:2.4334878027439117 (f_loss=-0.24504026770591736 r_loss=1.1213442087173462 GP=1.557183861732483)
[Training] epoch:799 step:100 g_loss:1.2213038206100464 d_loss:1.5400499403476715 (f_loss=-0.2336479127407074 r_loss=1.2002127170562744 GP=0.5734851360321045)
[Training] epoch:799 step:200 g_loss:1.2307602167129517 d_loss:1.656758427619934 (f_loss=-0.3201490044593811 r_loss=1.182910680770874 GP=0.7939967513084412)
[Training] epoch:799 step:300 g_loss:1.2751681804656982 d_loss:2.6201778054237366 (f_loss=-0.3443841338157654 r_loss=1.1182737350463867 GP=1.8462882041931152)
[Training] epoch:800 step:0 g_loss:1.3029423952102661 d_loss:2.198439300060272 (f_loss=-0.2903854250907898 r_loss=1.2456588745117188 GP=1.2431658506393433)

[Training] epoch:800 step:100 g_loss:1.3014166355133057 d_loss:2.2301043272018433 (f_loss=-0.2446054220199585 r_loss=1.04595947265625 GP=1.4287502765655518)
[Training] epoch:800 step:200 g_loss:1.290987491607666 d_loss:1.1678406596183777 (f_loss=-0.3113386631011963 r_loss=1.1889997720718384 GP=0.2901795506477356)
[Training] epoch:800 step:300 g_loss:1.2589654922485352 d_loss:1.8673517405986786 (f_loss=-0.3517390787601471 r_loss=1.2133677005767822 GP=1.0057231187820435)
[Training] epoch:801 step:0 g_loss:1.225026249885559 d_loss:3.3635269701480865 (f_loss=-0.2654202878475189 r_loss=0.8591718673706055 GP=2.769775390625)
[Training] epoch:801 step:100 g_loss:1.2434678077697754 d_loss:1.6069194674491882 (f_loss=-0.30469584465026855 r_loss=1.076629638671875 GP=0.8349856734275818)
[Training] epoch:801 step:200 g_loss:1.2489184141159058 d_loss:1.5008328258991241 (f_loss=-0.32851406931877136 r_loss=1.2056363821029663 GP=0.6237105131149292)
[Training] epoch:801 step:300 g_loss:1.2508313655853271 d_loss:1.4232118129730225 (f_loss=-0.2638200521469116 r_loss=1.222979187965393 GP=0.464052677154541)
[Training] epoch:802 step:0 g_loss:1.269651174545288 d_loss:1.5448654890060425 (f_loss=-0.272896409034729 r_loss=1.1555829048156738 GP=0.6621789932250977)
[Training] epoch:802 step:100 g_loss:1.2691465616226196 d_loss:1.2197734713554382 (f_loss=-0.32527098059654236 r_loss=1.1353486776351929 GP=0.4096957743167877)
[Training] epoch:802 step:200 g_loss:1.1336477994918823 d_loss:2.1928424537181854 (f_loss=-0.2886158525943756 r_loss=0.9867230653762817 GP=1.4947352409362793)
[Training] epoch:802 step:300 g_loss:1.2691916227340698 d_loss:1.688966155052185 (f_loss=-0.2904745936393738 r_loss=1.243443489074707 GP=0.7359972596168518)
[Training] epoch:803 step:0 g_loss:1.2838867902755737 d_loss:1.8939557373523712 (f_loss=-0.2736831605434418 r_loss=1.1606427431106567 GP=1.0069961547851562)
[Training] epoch:803 step:100 g_loss:1.275200605392456 d_loss:1.8382917791604996 (f_loss=-0.24313877522945404 r_loss=1.2240296602249146 GP=0.8574008941650391)
[Training] epoch:803 step:200 g_loss:1.3285328149795532 d_loss:1.546147644519806 (f_loss=-0.26321226358413696 r_loss=1.1370882987976074 GP=0.6722716093063354)
[Training] epoch:803 step:300 g_loss:1.2808997631072998 d_loss:1.4730547666549683 (f_loss=-0.26740163564682007 r_loss=1.2131723165512085 GP=0.5272840857505798)
[Training] epoch:804 step:0 g_loss:1.301268458366394 d_loss:1.9097507894039154 (f_loss=-0.2651350796222687 r_loss=1.1280765533447266 GP=1.0468093156814575)
[Training] epoch:804 step:100 g_loss:1.2806305885314941 d_loss:1.2700849324464798 (f_loss=-0.2590251564979553 r_loss=1.280726671218872 GP=0.24838341772556305)
[Training] epoch:804 step:200 g_loss:1.2537410259246826 d_loss:1.528290867805481 (f_loss=-0.35568952560424805 r_loss=1.2031558752059937 GP=0.6808245182037354)
[Training] epoch:804 step:300 g_loss:1.2058316469192505 d_loss:1.2828024625778198 (f_loss=-0.2917776107788086 r_loss=1.2276545763015747 GP=0.3469254970550537)
[Training] epoch:805 step:0 g_loss:1.2437301874160767 d_loss:1.2651106715202332 (f_loss=-0.26548880338668823 r_loss=1.2019942998886108 GP=0.32860517501831055)
[Training] epoch:805 step:100 g_loss:1.2394111156463623 d_loss:1.0236885994672775 (f_loss=-0.2979673147201538 r_loss=1.2309826612472534 GP=0.09067325294017792)
[Training] epoch:805 step:200 g_loss:1.2272666692733765 d_loss:1.504101812839508 (f_loss=-0.2475312352180481 r_loss=1.1927573680877686 GP=0.5588756799697876)
[Training] epoch:805 step:300 g_loss:1.2802259922027588 d_loss:1.8464950025081635 (f_loss=-0.22042778134346008 r_loss=1.2409961223602295 GP=0.825926661491394)
[Training] epoch:806 step:0 g_loss:1.246153473854065 d_loss:1.981004387140274 (f_loss=-0.25284287333488464 r_loss=1.18352210521698 GP=1.0503251552581787)
[Training] epoch:806 step:100 g_loss:1.3203556537628174 d_loss:1.5792823731899261 (f_loss=-0.26559868454933167 r_loss=1.070191740989685 GP=0.7746893167495728)
[Training] epoch:806 step:200 g_loss:1.2319457530975342 d_loss:2.9052172750234604 (f_loss=-0.18404366075992584 r_loss=1.0665234327316284 GP=2.022737503051758)
[Training] epoch:806 step:300 g_loss:1.3634791374206543 d_loss:2.105245053768158 (f_loss=-0.265419065952301 r_loss=1.221553087234497 GP=1.149111032485962)
[Training] epoch:807 step:0 g_loss:1.3059617280960083 d_loss:2.888448715209961 (f_loss=-0.2580840587615967 r_loss=1.0707440376281738 GP=2.075788736343384)
[Training] epoch:807 step:100 g_loss:1.3015931844711304 d_loss:1.5097945034503937 (f_loss=-0.224819153547287 r_loss=1.1909273862838745 GP=0.5436862707138062)
[Training] epoch:807 step:200 g_loss:1.262070894241333 d_loss:1.5561159253120422 (f_loss=-0.2900856137275696 r_loss=1.1524741649627686 GP=0.6937273740768433)
[Training] epoch:807 step:300 g_loss:1.3232449293136597 d_loss:1.5888701677322388 (f_loss=-0.3191741704940796 r_loss=1.26958167552948 GP=0.6384626626968384)
[Training] epoch:808 step:0 g_loss:1.3189963102340698 d_loss:1.5098246932029724 (f_loss=-0.288588285446167 r_loss=1.184135913848877 GP=0.6142770648002625)
[Training] epoch:808 step:100 g_loss:1.2678825855255127 d_loss:1.5810649991035461 (f_loss=-0.28542810678482056 r_loss=1.2106873989105225 GP=0.6558057069778442)
[Training] epoch:808 step:200 g_loss:1.2698198556900024 d_loss:1.2074266970157623 (f_loss=-0.3301263451576233 r_loss=1.1641701459884644 GP=0.37338289618492126)
[Training] epoch:808 step:300 g_loss:1.183746099472046 d_loss:1.1844332069158554 (f_loss=-0.24812009930610657 r_loss=1.2078040838241577 GP=0.22474922239780426)
[Training] epoch:809 step:0 g_loss:1.3297194242477417 d_loss:1.4539567530155182 (f_loss=-0.3272607624530792 r_loss=1.1686562299728394 GP=0.6125612854957581)
[Training] epoch:809 step:100 g_loss:1.2662736177444458 d_loss:1.5226989090442657 (f_loss=-0.2816600501537323 r_loss=1.1186425685882568 GP=0.6857163906097412)
[Training] epoch:809 step:200 g_loss:1.3140898942947388 d_loss:1.323706567287445 (f_loss=-0.2641363739967346 r_loss=1.1271487474441528 GP=0.46069419384002686)
[Training] epoch:809 step:300 g_loss:1.2370307445526123 d_loss:1.2956060469150543 (f_loss=-0.26916375756263733 r_loss=1.1875451803207397 GP=0.3772246241569519)
[Training] epoch:810 step:0 g_loss:1.297093152999878 d_loss:1.8775845170021057 (f_loss=-0.296455442905426 r_loss=1.0570578575134277 GP=1.116982102394104)

[Training] epoch:810 step:100 g_loss:1.3016939163208008 d_loss:4.731324106454849 (f_loss=-0.29226264357566833 r_loss=1.13185453414917 GP=3.8917322158813477)
[Training] epoch:810 step:200 g_loss:1.2975151538848877 d_loss:1.799953669309616 (f_loss=-0.28220197558403015 r_loss=1.280973196029663 GP=0.8011824488639832)
[Training] epoch:810 step:300 g_loss:1.323791265487671 d_loss:1.5609815418720245 (f_loss=-0.2512834966182709 r_loss=1.259598970413208 GP=0.5526660680770874)
[Training] epoch:811 step:0 g_loss:1.3243775367736816 d_loss:3.6699914932250977 (f_loss=-0.2368829846382141 r_loss=0.7653296589851379 GP=3.141544818878174)
[Training] epoch:811 step:100 g_loss:1.2789067029953003 d_loss:1.400592565536499 (f_loss=-0.31724780797958374 r_loss=1.2544596195220947 GP=0.46338075399398804)
[Training] epoch:811 step:200 g_loss:1.3645672798156738 d_loss:1.69253808259964 (f_loss=-0.27268487215042114 r_loss=1.2181423902511597 GP=0.7470805644989014)
[Training] epoch:811 step:300 g_loss:1.2819857597351074 d_loss:4.2096976935863495 (f_loss=-0.29738232493400574 r_loss=0.9703261256217957 GP=3.5367538928985596)
[Training] epoch:812 step:0 g_loss:1.292039394378662 d_loss:1.4355381727218628 (f_loss=-0.32157260179519653 r_loss=1.2214831113815308 GP=0.5356276631355286)
[Training] epoch:812 step:100 g_loss:1.306364893913269 d_loss:1.4535687267780304 (f_loss=-0.29012760519981384 r_loss=1.1876811981201172 GP=0.556015133857727)
[Training] epoch:812 step:200 g_loss:1.217791199684143 d_loss:1.907816767692566 (f_loss=-0.27512693405151367 r_loss=1.1224448680877686 GP=1.060498833656311)
[Training] epoch:812 step:300 g_loss:1.2445623874664307 d_loss:1.6632481962442398 (f_loss=-0.21694670617580414 r_loss=1.202591896057129 GP=0.677603006362915)
[Training] epoch:813 step:0 g_loss:1.257694125175476 d_loss:1.7765834331512451 (f_loss=-0.3257175087928772 r_loss=1.1916903257369995 GP=0.9106106162071228)
[Training] epoch:813 step:100 g_loss:1.2481999397277832 d_loss:1.4384669959545135 (f_loss=-0.3280498683452606 r_loss=1.18424391746521 GP=0.5822729468345642)
[Training] epoch:813 step:200 g_loss:1.2984042167663574 d_loss:1.6779846549034119 (f_loss=-0.241754412651062 r_loss=1.2522192001342773 GP=0.6675198674201965)
[Training] epoch:813 step:300 g_loss:1.2715473175048828 d_loss:1.789198711514473 (f_loss=-0.24063442647457123 r_loss=1.1298108100891113 GP=0.9000223278999329)
[Training] epoch:814 step:0 g_loss:1.2043026685714722 d_loss:4.845641374588013 (f_loss=-0.2334805727005005 r_loss=1.0037087202072144 GP=4.075413227081299)
[Training] epoch:814 step:100 g_loss:1.2884441614151 d_loss:1.3394326269626617 (f_loss=-0.20345869660377502 r_loss=1.188957691192627 GP=0.3539336323738098)
[Training] epoch:814 step:200 g_loss:1.2257148027420044 d_loss:1.4973224401474 (f_loss=-0.3059973120689392 r_loss=1.2229175567626953 GP=0.5804021954536438)
[Training] epoch:814 step:300 g_loss:1.2698650360107422 d_loss:1.8112033009529114 (f_loss=-0.17462855577468872 r_loss=1.1332141160964966 GP=0.8526177406311035)
[Training] epoch:815 step:0 g_loss:1.2798683643341064 d_loss:1.3145778477191925 (f_loss=-0.3030039966106415 r_loss=1.2185872793197632 GP=0.3989945650100708)
[Training] epoch:815 step:100 g_loss:1.279326319694519 d_loss:1.2490030527114868 (f_loss=-0.31061598658561707 r_loss=1.2023383378982544 GP=0.3572807013988495)
[Training] epoch:815 step:200 g_loss:1.2372405529022217 d_loss:1.667078822851181 (f_loss=-0.3544548451900482 r_loss=1.182877779006958 GP=0.8386558890342712)
[Training] epoch:815 step:300 g_loss:1.3330039978027344 d_loss:1.965788722038269 (f_loss=-0.2832237482070923 r_loss=1.0558803081512451 GP=1.1931321620941162)
[Training] epoch:816 step:0 g_loss:1.303117036819458 d_loss:1.609163612127304 (f_loss=-0.2602320611476898 r_loss=1.1794018745422363 GP=0.6899937987327576)
[Training] epoch:816 step:100 g_loss:1.2801352739334106 d_loss:1.4187573492527008 (f_loss=-0.30761316418647766 r_loss=1.29197096824646 GP=0.4343995451927185)
[Training] epoch:816 step:200 g_loss:1.2806044816970825 d_loss:1.2582776248455048 (f_loss=-0.28462862968444824 r_loss=1.162532925605774 GP=0.3803733289241791)
[Training] epoch:816 step:300 g_loss:1.262591004371643 d_loss:1.5778213441371918 (f_loss=-0.3188249170780182 r_loss=1.1731703281402588 GP=0.7234759330749512)
[Training] epoch:817 step:0 g_loss:1.280849814414978 d_loss:1.532181903719902 (f_loss=-0.22926951944828033 r_loss=1.333878755569458 GP=0.42757266759872437)
[Training] epoch:817 step:100 g_loss:1.3082438707351685 d_loss:1.231536477804184 (f_loss=-0.2694845497608185 r_loss=1.2041155099868774 GP=0.296905517578125)
[Training] epoch:817 step:200 g_loss:1.3000833988189697 d_loss:1.273250550031662 (f_loss=-0.2745321989059448 r_loss=1.1718206405639648 GP=0.37596210837364197)
[Training] epoch:817 step:300 g_loss:1.3198237419128418 d_loss:1.1501347124576569 (f_loss=-0.3422960638999939 r_loss=1.2495630979537964 GP=0.24286767840385437)
[Training] epoch:818 step:0 g_loss:1.3133208751678467 d_loss:1.6262279450893402 (f_loss=-0.29514577984809875 r_loss=1.1900389194488525 GP=0.7313348054885864)
[Training] epoch:818 step:100 g_loss:1.372277021408081 d_loss:1.4499700218439102 (f_loss=-0.24883948266506195 r_loss=1.1857364177703857 GP=0.5130730867385864)
[Training] epoch:818 step:200 g_loss:1.2421334981918335 d_loss:1.3474074602127075 (f_loss=-0.248270183801651 r_loss=1.2843645811080933 GP=0.31131306290626526)
[Training] epoch:818 step:300 g_loss:1.285092830657959 d_loss:2.6271923780441284 (f_loss=-0.33990705013275146 r_loss=1.1592787504196167 GP=1.8078206777572632)
[Training] epoch:819 step:0 g_loss:1.337726354598999 d_loss:2.3315404653549194 (f_loss=-0.25445258617401123 r_loss=1.0818926095962524 GP=1.5041004419326782)
[Training] epoch:819 step:100 g_loss:1.2589893341064453 d_loss:2.014073073863983 (f_loss=-0.2612583041191101 r_loss=1.1713225841522217 GP=1.1040087938308716)
[Training] epoch:819 step:200 g_loss:1.2285208702087402 d_loss:1.2744163572788239 (f_loss=-0.2534727454185486 r_loss=1.2255167961120605 GP=0.3023723065853119)
[Training] epoch:819 step:300 g_loss:1.256684422492981 d_loss:1.8396732807159424 (f_loss=-0.3292694091796875 r_loss=1.1457335948944092 GP=1.0232090950012207)
[Training] epoch:820 step:0 g_loss:1.28755521774292 d_loss:1.4370149970054626 (f_loss=-0.266463965177536 r_loss=1.2089653015136719 GP=0.4945136606693268)

[Training] epoch:820 step:100 g_loss:1.2963517904281616 d_loss:2.268082559108734 (f_loss=-0.2904450297355652 r_loss=1.2302331924438477 GP=1.3282943964004517)
[Training] epoch:820 step:200 g_loss:1.3386307954788208 d_loss:1.2310901284217834 (f_loss=-0.23792342841625214 r_loss=1.2604962587356567 GP=0.20851729810237885)
[Training] epoch:820 step:300 g_loss:1.3067219257354736 d_loss:1.3320069015026093 (f_loss=-0.3382924497127533 r_loss=1.1656774282455444 GP=0.5046219229698181)
[Training] epoch:821 step:0 g_loss:1.277446985244751 d_loss:1.4103113412857056 (f_loss=-0.30106377601623535 r_loss=1.1200003623962402 GP=0.5913747549057007)
[Training] epoch:821 step:100 g_loss:1.2496968507766724 d_loss:1.5251223742961884 (f_loss=-0.2868960201740265 r_loss=1.211327075958252 GP=0.6006913185119629)
[Training] epoch:821 step:200 g_loss:1.3004724979400635 d_loss:1.1998931765556335 (f_loss=-0.29379814863204956 r_loss=1.2439923286437988 GP=0.24969899654388428)
[Training] epoch:821 step:300 g_loss:1.3357880115509033 d_loss:2.0285221338272095 (f_loss=-0.2818260192871094 r_loss=1.2600094079971313 GP=1.0503387451171875)
[Training] epoch:822 step:0 g_loss:1.2549368143081665 d_loss:1.2990546524524689 (f_loss=-0.2438984513282776 r_loss=1.1944581270217896 GP=0.3484949767589569)
[Training] epoch:822 step:100 g_loss:1.3114891052246094 d_loss:1.3096733093261719 (f_loss=-0.29197198152542114 r_loss=1.096325397491455 GP=0.5053198933601379)
[Training] epoch:822 step:200 g_loss:1.225801944732666 d_loss:1.9212740361690521 (f_loss=-0.2292090356349945 r_loss=1.260933518409729 GP=0.8895495533943176)
[Training] epoch:822 step:300 g_loss:1.244905948638916 d_loss:1.4165198802947998 (f_loss=-0.30476218461990356 r_loss=1.223311185836792 GP=0.4979708790779114)
[Training] epoch:823 step:0 g_loss:1.2435288429260254 d_loss:1.5853692591190338 (f_loss=-0.27502068877220154 r_loss=1.2695808410644531 GP=0.5908091068267822)
[Training] epoch:823 step:100 g_loss:1.2328414916992188 d_loss:1.9917209446430206 (f_loss=-0.28533586859703064 r_loss=1.2615342140197754 GP=1.0155225992202759)
[Training] epoch:823 step:200 g_loss:1.275865077972412 d_loss:2.0881759226322174 (f_loss=-0.24250182509422302 r_loss=1.2083247900009155 GP=1.122352957725525)
[Training] epoch:823 step:300 g_loss:1.2803292274475098 d_loss:1.675824522972107 (f_loss=-0.3176497220993042 r_loss=1.127889633178711 GP=0.8655846118927002)
[Training] epoch:824 step:0 g_loss:1.3290231227874756 d_loss:2.3071174025535583 (f_loss=-0.3884374499320984 r_loss=1.1503264904022217 GP=1.545228362083435)
[Training] epoch:824 step:100 g_loss:1.285971760749817 d_loss:2.0415762811899185 (f_loss=-0.23298905789852142 r_loss=1.1326652765274048 GP=1.1419000625610352)
[Training] epoch:824 step:200 g_loss:1.2540392875671387 d_loss:1.2316064089536667 (f_loss=-0.2276042103767395 r_loss=1.2153836488723755 GP=0.2438269704580307)
[Training] epoch:824 step:300 g_loss:1.333225131034851 d_loss:1.4277139008045197 (f_loss=-0.3342227637767792 r_loss=1.134543776512146 GP=0.6273928880691528)
[Training] epoch:825 step:0 g_loss:1.3115499019622803 d_loss:1.5732129514217377 (f_loss=-0.26969364285469055 r_loss=1.0937718152999878 GP=0.7491347789764404)
[Training] epoch:825 step:100 g_loss:1.3310785293579102 d_loss:1.764979988336563 (f_loss=-0.34135231375694275 r_loss=1.087712287902832 GP=1.0186200141906738)
[Training] epoch:825 step:200 g_loss:1.2758044004440308 d_loss:1.581484615802765 (f_loss=-0.30461448431015015 r_loss=1.2010796070098877 GP=0.6850194931030273)
[Training] epoch:825 step:300 g_loss:1.2467634677886963 d_loss:1.4241995513439178 (f_loss=-0.3019748032093048 r_loss=1.1021993160247803 GP=0.6239750385284424)
[Training] epoch:826 step:0 g_loss:1.304990530014038 d_loss:1.8904730379581451 (f_loss=-0.3039620816707611 r_loss=1.1467790603637695 GP=1.0476560592651367)
[Training] epoch:826 step:100 g_loss:1.2785093784332275 d_loss:2.4336286187171936 (f_loss=-0.2627754807472229 r_loss=1.2025365829467773 GP=1.4938675165176392)
[Training] epoch:826 step:200 g_loss:1.289778232574463 d_loss:1.5321178436279297 (f_loss=-0.3801209330558777 r_loss=1.1415826082229614 GP=0.770656168460846)
[Training] epoch:826 step:300 g_loss:1.290257215499878 d_loss:3.7925037145614624 (f_loss=-0.2628892660140991 r_loss=1.2151820659637451 GP=2.8402109146118164)
[Training] epoch:827 step:0 g_loss:1.2799994945526123 d_loss:1.876273274421692 (f_loss=-0.3124884366989136 r_loss=1.1088097095489502 GP=1.0799520015716553)
[Training] epoch:827 step:100 g_loss:1.3185901641845703 d_loss:1.600398063659668 (f_loss=-0.27599406242370605 r_loss=1.1798629760742188 GP=0.6965291500091553)
[Training] epoch:827 step:200 g_loss:1.3118128776550293 d_loss:1.6314982175827026 (f_loss=-0.2740898132324219 r_loss=1.1751576662063599 GP=0.7304303646087646)
[Training] epoch:827 step:300 g_loss:1.2017114162445068 d_loss:3.8236220479011536 (f_loss=-0.31090718507766724 r_loss=0.9305406808853149 GP=3.203988552093506)
[Training] epoch:828 step:0 g_loss:1.329082727432251 d_loss:2.017301321029663 (f_loss=-0.2800557613372803 r_loss=1.0327258110046387 GP=1.2646312713623047)
[Training] epoch:828 step:100 g_loss:1.3248826265335083 d_loss:1.4690621495246887 (f_loss=-0.24957424402236938 r_loss=1.0444345474243164 GP=0.6742018461227417)
[Training] epoch:828 step:200 g_loss:1.3351523876190186 d_loss:1.359597384929657 (f_loss=-0.3408336043357849 r_loss=1.0596897602081299 GP=0.640741229057312)
[Training] epoch:828 step:300 g_loss:1.303114891052246 d_loss:2.1112139225006104 (f_loss=-0.2988797426223755 r_loss=1.160295844078064 GP=1.2497978210449219)
[Training] epoch:829 step:0 g_loss:1.280747413635254 d_loss:1.5576890408992767 (f_loss=-0.3153820335865021 r_loss=1.1522523164749146 GP=0.7208187580108643)
[Training] epoch:829 step:100 g_loss:1.2989709377288818 d_loss:1.6254045963287354 (f_loss=-0.3187033534049988 r_loss=1.1508979797363281 GP=0.793209969997406)
[Training] epoch:829 step:200 g_loss:1.2953848838806152 d_loss:1.5199609398841858 (f_loss=-0.26876699924468994 r_loss=1.1087077856063843 GP=0.6800201535224915)
[Training] epoch:829 step:300 g_loss:1.2640565633773804 d_loss:1.6729235649108887 (f_loss=-0.2695918083190918 r_loss=1.1650534868240356 GP=0.7774618864059448)
[Training] epoch:830 step:0 g_loss:1.2827616930007935 d_loss:1.4030287265777588 (f_loss=-0.29700684547424316 r_loss=1.1846016645431519 GP=0.5154339075088501)

[Training] epoch:830 step:100 g_loss:1.2551188468933105 d_loss:1.6764357686042786 (f_loss=-0.29866158962249756 r_loss=0.9800448417663574 GP=0.9950525164604187)
[Training] epoch:830 step:200 g_loss:1.2281635999679565 d_loss:1.3103665709495544 (f_loss=-0.2699998617172241 r_loss=1.171205997467041 GP=0.40916043519973755)
[Training] epoch:830 step:300 g_loss:1.2417083978652954 d_loss:1.480391651391983 (f_loss=-0.21225157380104065 r_loss=1.1768771409988403 GP=0.5157660841941833)
[Training] epoch:831 step:0 g_loss:1.2803313732147217 d_loss:2.71659779548645 (f_loss=-0.2668370008468628 r_loss=0.9490116834640503 GP=2.0344231128692627)
[Training] epoch:831 step:100 g_loss:1.3089959621429443 d_loss:1.4259066581726074 (f_loss=-0.3363536596298218 r_loss=1.1904423236846924 GP=0.5718179941177368)
[Training] epoch:831 step:200 g_loss:1.2966817617416382 d_loss:3.119622766971588 (f_loss=-0.26417261362075806 r_loss=1.0669876337051392 GP=2.316807746887207)
[Training] epoch:831 step:300 g_loss:1.3404128551483154 d_loss:2.333969324827194 (f_loss=-0.33408883213996887 r_loss=1.0821363925933838 GP=1.5859217643737793)
[Training] epoch:832 step:0 g_loss:1.2742843627929688 d_loss:1.3793472647666931 (f_loss=-0.2962985038757324 r_loss=1.2702149152755737 GP=0.4054308533668518)
[Training] epoch:832 step:100 g_loss:1.232979416847229 d_loss:1.126641184091568 (f_loss=-0.2828430235385895 r_loss=1.164685845375061 GP=0.24479836225509644)
[Training] epoch:832 step:200 g_loss:1.302611231803894 d_loss:1.90228271484375 (f_loss=-0.33527684211730957 r_loss=1.1301467418670654 GP=1.1074128150939941)
[Training] epoch:832 step:300 g_loss:1.2586127519607544 d_loss:1.5561155676841736 (f_loss=-0.32771652936935425 r_loss=1.1456758975982666 GP=0.7381561994552612)
[Training] epoch:833 step:0 g_loss:1.303755760192871 d_loss:1.6198299825191498 (f_loss=-0.37584665417671204 r_loss=1.1538165807724 GP=0.8418600559234619)
[Training] epoch:833 step:100 g_loss:1.2770172357559204 d_loss:1.2301837801933289 (f_loss=-0.31408190727233887 r_loss=1.1880756616592407 GP=0.356190025806427)
[Training] epoch:833 step:200 g_loss:1.3179348707199097 d_loss:2.266274183988571 (f_loss=-0.2839261591434479 r_loss=1.2074285745620728 GP=1.3427717685699463)
[Training] epoch:833 step:300 g_loss:1.261127233505249 d_loss:1.8856930136680603 (f_loss=-0.2815156579017639 r_loss=1.1929633617401123 GP=0.9742453098297119)
[Training] epoch:834 step:0 g_loss:1.3008174896240234 d_loss:1.3099864721298218 (f_loss=-0.2951125502586365 r_loss=1.234106183052063 GP=0.37099283933639526)
[Training] epoch:834 step:100 g_loss:1.2679178714752197 d_loss:1.5168967247009277 (f_loss=-0.30403566360473633 r_loss=1.1641243696212769 GP=0.6568080186843872)
[Training] epoch:834 step:200 g_loss:1.318042516708374 d_loss:1.5122503191232681 (f_loss=-0.243888720870018 r_loss=1.2387229204177856 GP=0.5174161195755005)
[Training] epoch:834 step:300 g_loss:1.2905513048171997 d_loss:1.6464829742908478 (f_loss=-0.2996892035007477 r_loss=1.180286169052124 GP=0.7658860087394714)
[Training] epoch:835 step:0 g_loss:1.2343521118164062 d_loss:2.8194428980350494 (f_loss=-0.27165481448173523 r_loss=1.1125686168670654 GP=1.9785290956497192)
[Training] epoch:835 step:100 g_loss:1.27814781665802 d_loss:2.0299032330513 (f_loss=-0.3028293251991272 r_loss=1.059220790863037 GP=1.2735117673873901)
[Training] epoch:835 step:200 g_loss:1.2792940139770508 d_loss:1.9464121758937836 (f_loss=-0.3130106031894684 r_loss=1.1376433372497559 GP=1.121779441833496)
[Training] epoch:835 step:300 g_loss:1.2755134105682373 d_loss:1.4530810564756393 (f_loss=-0.23314101994037628 r_loss=1.1044186353683472 GP=0.5818034410476685)
[Training] epoch:836 step:0 g_loss:1.252360224723816 d_loss:1.508446365594864 (f_loss=-0.3170808255672455 r_loss=1.1517561674118042 GP=0.6737710237503052)
[Training] epoch:836 step:100 g_loss:1.2362165451049805 d_loss:1.4911832213401794 (f_loss=-0.2656779885292053 r_loss=1.0429275035858154 GP=0.7139337062835693)
[Training] epoch:836 step:200 g_loss:1.31820809841156 d_loss:2.0700585544109344 (f_loss=-0.25790753960609436 r_loss=1.1822513341903687 GP=1.1457147598266602)
[Training] epoch:836 step:300 g_loss:1.256187081336975 d_loss:2.383298635482788 (f_loss=-0.35907065868377686 r_loss=0.9980851411819458 GP=1.7442841529846191)
[Training] epoch:837 step:0 g_loss:1.2437320947647095 d_loss:2.0603501200675964 (f_loss=-0.27228063344955444 r_loss=1.0660772323608398 GP=1.266553521156311)
[Training] epoch:837 step:100 g_loss:1.314929723739624 d_loss:1.6538140177726746 (f_loss=-0.3153213858604431 r_loss=1.162496566772461 GP=0.8066388368606567)
[Training] epoch:837 step:200 g_loss:1.2828037738800049 d_loss:1.7031673789024353 (f_loss=-0.2822886109352112 r_loss=1.1475934982299805 GP=0.837862491607666)
[Training] epoch:837 step:300 g_loss:1.279090166091919 d_loss:2.1245590448379517 (f_loss=-0.2909266948699951 r_loss=0.8937921524047852 GP=1.5216935873031616)
[Training] epoch:838 step:0 g_loss:1.320704698562622 d_loss:2.054512143135071 (f_loss=-0.3394433259963989 r_loss=1.2250399589538574 GP=1.1689155101776123)
[Training] epoch:838 step:100 g_loss:1.3075823783874512 d_loss:1.1782572269439697 (f_loss=-0.32850024104118347 r_loss=1.199737787246704 GP=0.3070196807384491)
[Training] epoch:838 step:200 g_loss:1.2908096313476562 d_loss:2.6767306327819824 (f_loss=-0.24084842205047607 r_loss=1.1194950342178345 GP=1.798084020614624)
[Training] epoch:838 step:300 g_loss:1.2597267627716064 d_loss:1.020975187420845 (f_loss=-0.3440910577774048 r_loss=1.2524378299713135 GP=0.11262841522693634)
[Training] epoch:839 step:0 g_loss:1.2773079872131348 d_loss:1.6500433385372162 (f_loss=-0.3552081882953644 r_loss=1.2161693572998047 GP=0.7890821695327759)
[Training] epoch:839 step:100 g_loss:1.3228085041046143 d_loss:1.1232364773750305 (f_loss=-0.27359235286712646 r_loss=1.1886241436004639 GP=0.20820468664169312)
[Training] epoch:839 step:200 g_loss:1.3132728338241577 d_loss:1.7524259686470032 (f_loss=-0.35895562171936035 r_loss=1.1154580116271973 GP=0.9959235787391663)
[Training] epoch:839 step:300 g_loss:1.2730962038040161 d_loss:1.5337048470973969 (f_loss=-0.15709015727043152 r_loss=1.2068041563034058 GP=0.4839908480644226)
[Training] epoch:840 step:0 g_loss:1.3073346614837646 d_loss:1.589361995458603 (f_loss=-0.2699033319950104 r_loss=1.1932424306869507 GP=0.6660228967666626)

[Training] epoch:840 step:100 g_loss:1.2822502851486206 d_loss:1.5124078392982483 (f_loss=-0.26414257287979126 r_loss=1.1839122772216797 GP=0.5926381349563599)
[Training] epoch:840 step:200 g_loss:1.315212368965149 d_loss:2.259131222963333 (f_loss=-0.32610175013542175 r_loss=1.165353536605835 GP=1.41987943649292)
[Training] epoch:840 step:300 g_loss:1.2814383506774902 d_loss:2.506859838962555 (f_loss=-0.32867753505706787 r_loss=0.9563155770301819 GP=1.879221796989441)
[Training] epoch:841 step:0 g_loss:1.2831356525421143 d_loss:2.015646368265152 (f_loss=-0.2634532153606415 r_loss=0.974165678024292 GP=1.3049339056015015)
[Training] epoch:841 step:100 g_loss:1.258530616760254 d_loss:1.588806003332138 (f_loss=-0.24887493252754211 r_loss=1.1417266130447388 GP=0.6959543228149414)
[Training] epoch:841 step:200 g_loss:1.3364415168762207 d_loss:1.747949868440628 (f_loss=-0.24445518851280212 r_loss=0.960020899772644 GP=1.0323841571807861)
[Training] epoch:841 step:300 g_loss:1.2678673267364502 d_loss:1.5713324844837189 (f_loss=-0.2793370187282562 r_loss=1.1797175407409668 GP=0.6709519624710083)
[Training] epoch:842 step:0 g_loss:1.2641594409942627 d_loss:1.835637018084526 (f_loss=-0.24042649567127228 r_loss=1.0683821439743042 GP=1.0076813697814941)
[Training] epoch:842 step:100 g_loss:1.320614218711853 d_loss:2.6048844754695892 (f_loss=-0.29089418053627014 r_loss=1.1649091243743896 GP=1.7308695316314697)
[Training] epoch:842 step:200 g_loss:1.3006465435028076 d_loss:3.6065117716789246 (f_loss=-0.3444012999534607 r_loss=0.7813767194747925 GP=3.1695363521575928)
[Training] epoch:842 step:300 g_loss:1.2683957815170288 d_loss:2.2341368794441223 (f_loss=-0.20910507440567017 r_loss=1.17710280418396 GP=1.2661391496658325)
[Training] epoch:843 step:0 g_loss:1.2462049722671509 d_loss:1.3722893595695496 (f_loss=-0.34326615929603577 r_loss=1.2238764762878418 GP=0.49167904257774353)
[Training] epoch:843 step:100 g_loss:1.2740572690963745 d_loss:1.5041782855987549 (f_loss=-0.30758965015411377 r_loss=1.2106178998947144 GP=0.6011500358581543)
[Training] epoch:843 step:200 g_loss:1.295338749885559 d_loss:1.7349578440189362 (f_loss=-0.33269909024238586 r_loss=1.21034836769104 GP=0.857308566570282)
[Training] epoch:843 step:300 g_loss:1.3386050462722778 d_loss:1.6947413980960846 (f_loss=-0.29112157225608826 r_loss=1.1249297857284546 GP=0.8609331846237183)
[Training] epoch:844 step:0 g_loss:1.2903319597244263 d_loss:2.2414611876010895 (f_loss=-0.27920135855674744 r_loss=1.2038789987564087 GP=1.3167835474014282)
[Training] epoch:844 step:100 g_loss:1.3189334869384766 d_loss:1.5621803998947144 (f_loss=-0.34401023387908936 r_loss=1.1546337604522705 GP=0.7515568733215332)
[Training] epoch:844 step:200 g_loss:1.330653190612793 d_loss:1.5251178443431854 (f_loss=-0.27418920397758484 r_loss=1.183099627494812 GP=0.6162074208259583)
[Training] epoch:844 step:300 g_loss:1.352504849433899 d_loss:1.6982927322387695 (f_loss=-0.31761634349823 r_loss=1.1140166521072388 GP=0.9018924236297607)
[Training] epoch:845 step:0 g_loss:1.2505850791931152 d_loss:1.8063531517982483 (f_loss=-0.2817690968513489 r_loss=1.1531351804733276 GP=0.9349870681762695)
[Training] epoch:845 step:100 g_loss:1.2233421802520752 d_loss:2.7517325580120087 (f_loss=-0.2971784174442291 r_loss=1.1291680335998535 GP=1.9197429418563843)
[Training] epoch:845 step:200 g_loss:1.2827670574188232 d_loss:1.3779986500740051 (f_loss=-0.35920119285583496 r_loss=1.1272433996200562 GP=0.6099564433097839)
[Training] epoch:845 step:300 g_loss:1.2676918506622314 d_loss:1.2806581854820251 (f_loss=-0.27833276987075806 r_loss=1.0968495607376099 GP=0.46214139461517334)
[Training] epoch:846 step:0 g_loss:1.31388258934021 d_loss:1.3099278807640076 (f_loss=-0.3228840231895447 r_loss=1.0503103733062744 GP=0.5825015306472778)
[Training] epoch:846 step:100 g_loss:1.363260269165039 d_loss:2.6272667348384857 (f_loss=-0.2959984838962555 r_loss=1.1742839813232422 GP=1.748981237411499)
[Training] epoch:846 step:200 g_loss:1.2753775119781494 d_loss:2.5062284767627716 (f_loss=-0.2851366698741913 r_loss=1.1752235889434814 GP=1.6161415576934814)
[Training] epoch:846 step:300 g_loss:1.25655996799469 d_loss:1.6617108583450317 (f_loss=-0.28298962116241455 r_loss=1.1553027629852295 GP=0.7893977165222168)
[Training] epoch:847 step:0 g_loss:1.2643173933029175 d_loss:2.9304279685020447 (f_loss=-0.2809038758277893 r_loss=1.1009795665740967 GP=2.1103522777557373)
[Training] epoch:847 step:100 g_loss:1.2864201068878174 d_loss:2.1296835839748383 (f_loss=-0.2521578371524811 r_loss=1.2387092113494873 GP=1.143132209777832)
[Training] epoch:847 step:200 g_loss:1.259660243988037 d_loss:1.9762904345989227 (f_loss=-0.23340287804603577 r_loss=1.0545096397399902 GP=1.1551836729049683)
[Training] epoch:847 step:300 g_loss:1.2088944911956787 d_loss:1.7143943905830383 (f_loss=-0.3083922266960144 r_loss=1.203978419303894 GP=0.8188081979751587)
[Training] epoch:848 step:0 g_loss:1.314433217048645 d_loss:1.3518144190311432 (f_loss=-0.2674908936023712 r_loss=1.1919732093811035 GP=0.4273321032524109)
[Training] epoch:848 step:100 g_loss:1.290294885635376 d_loss:1.3168210983276367 (f_loss=-0.2623635530471802 r_loss=1.1784082651138306 GP=0.40077638626098633)
[Training] epoch:848 step:200 g_loss:1.2635395526885986 d_loss:1.6565686464309692 (f_loss=-0.2264966368675232 r_loss=1.0910062789916992 GP=0.7920590043067932)
[Training] epoch:848 step:300 g_loss:1.3050601482391357 d_loss:2.0209596306085587 (f_loss=-0.24236510694026947 r_loss=1.1388790607452393 GP=1.1244456768035889)
[Training] epoch:849 step:0 g_loss:1.2397494316101074 d_loss:1.6123821139335632 (f_loss=-0.3234446048736572 r_loss=1.1018993854522705 GP=0.83392733335495)
[Training] epoch:849 step:100 g_loss:1.2766942977905273 d_loss:1.280983567237854 (f_loss=-0.31783366203308105 r_loss=1.1614654064178467 GP=0.4373518228530884)
[Training] epoch:849 step:200 g_loss:1.2488783597946167 d_loss:1.3903513699769974 (f_loss=-0.2043464034795761 r_loss=1.1364595890045166 GP=0.4582381844520569)
[Training] epoch:849 step:300 g_loss:1.2712194919586182 d_loss:1.6317146122455597 (f_loss=-0.2793196141719818 r_loss=1.1413475275039673 GP=0.7696866989135742)
[Training] epoch:850 step:0 g_loss:1.256197452545166 d_loss:1.5021129250526428 (f_loss=-0.3182932734489441 r_loss=1.1674195528030396 GP=0.6529866456985474)

[Training] epoch:850 step:100 g_loss:1.322532057762146 d_loss:2.289476662874222 (f_loss=-0.27235111594200134 r_loss=1.1355384588241577 GP=1.4262893199920654)
[Training] epoch:850 step:200 g_loss:1.2506704330444336 d_loss:1.4451428949832916 (f_loss=-0.23624968528747559 r_loss=1.2124509811401367 GP=0.4689415991306305)
[Training] epoch:850 step:300 g_loss:1.3413336277008057 d_loss:1.9113123416900635 (f_loss=-0.2021409273147583 r_loss=1.163416862487793 GP=0.9500364065170288)
[Training] epoch:851 step:0 g_loss:1.2744884490966797 d_loss:1.388185292482376 (f_loss=-0.26680707931518555 r_loss=1.19088613986969 GP=0.4641062319278717)
[Training] epoch:851 step:100 g_loss:1.2594528198242188 d_loss:2.0209266543388367 (f_loss=-0.2987728714942932 r_loss=1.1979591846466064 GP=1.1217403411865234)
[Training] epoch:851 step:200 g_loss:1.2590551376342773 d_loss:1.350981444120407 (f_loss=-0.293574720621109 r_loss=1.199496865272522 GP=0.44505929946899414)
[Training] epoch:851 step:300 g_loss:1.2888987064361572 d_loss:2.206748276948929 (f_loss=-0.26026925444602966 r_loss=1.210081934928894 GP=1.2569355964660645)
[Training] epoch:852 step:0 g_loss:1.260021448135376 d_loss:2.570220708847046 (f_loss=-0.30019962787628174 r_loss=0.9582642316818237 GP=1.912156105041504)
[Training] epoch:852 step:100 g_loss:1.3060492277145386 d_loss:2.5093889832496643 (f_loss=-0.324907124042511 r_loss=1.0012744665145874 GP=1.833021640777588)
[Training] epoch:852 step:200 g_loss:1.268005132675171 d_loss:1.5519467145204544 (f_loss=-0.18673603236675262 r_loss=1.2898895740509033 GP=0.4487931728363037)
[Training] epoch:852 step:300 g_loss:1.3103883266448975 d_loss:3.2050884664058685 (f_loss=-0.2337721884250641 r_loss=1.0472393035888672 GP=2.3916213512420654)
[Training] epoch:853 step:0 g_loss:1.2783015966415405 d_loss:1.4478036165237427 (f_loss=-0.2918338179588318 r_loss=1.1745972633361816 GP=0.5650401711463928)
[Training] epoch:853 step:100 g_loss:1.2957208156585693 d_loss:1.5962520837783813 (f_loss=-0.3197133541107178 r_loss=1.034688115119934 GP=0.881277322769165)
[Training] epoch:853 step:200 g_loss:1.2631843090057373 d_loss:1.5976997017860413 (f_loss=-0.29735416173934937 r_loss=1.0766011476516724 GP=0.8184527158737183)
[Training] epoch:853 step:300 g_loss:1.2960894107818604 d_loss:1.5573760271072388 (f_loss=-0.3112668991088867 r_loss=1.1412506103515625 GP=0.727392315864563)
[Training] epoch:854 step:0 g_loss:1.2716236114501953 d_loss:2.96126189827919 (f_loss=-0.3472537696361542 r_loss=1.1146811246871948 GP=2.1938345432281494)
[Training] epoch:854 step:100 g_loss:1.249830961227417 d_loss:1.267393410205841 (f_loss=-0.31219932436943054 r_loss=1.2682952880859375 GP=0.3112974464893341)
[Training] epoch:854 step:200 g_loss:1.2337114810943604 d_loss:1.4503889828920364 (f_loss=-0.2434273213148117 r_loss=1.1735941171646118 GP=0.5202221870422363)
[Training] epoch:854 step:300 g_loss:1.2203447818756104 d_loss:1.142944574356079 (f_loss=-0.3747861385345459 r_loss=1.1227744817733765 GP=0.39495623111724854)
[Training] epoch:855 step:0 g_loss:1.248326301574707 d_loss:2.7116484493017197 (f_loss=-0.24244548380374908 r_loss=1.0007195472717285 GP=1.9533743858337402)
[Training] epoch:855 step:100 g_loss:1.2711865901947021 d_loss:1.5539296865463257 (f_loss=-0.2798255681991577 r_loss=1.1700295209884644 GP=0.663725733757019)
[Training] epoch:855 step:200 g_loss:1.2582242488861084 d_loss:2.0670814514160156 (f_loss=-0.25663983821868896 r_loss=1.1119277477264404 GP=1.2117935419082642)
[Training] epoch:855 step:300 g_loss:1.2746117115020752 d_loss:1.318983256816864 (f_loss=-0.28551799058914185 r_loss=1.2114359140396118 GP=0.39306533336639404)
[Training] epoch:856 step:0 g_loss:1.3302128314971924 d_loss:1.4671314358711243 (f_loss=-0.2776602506637573 r_loss=1.1875908374786377 GP=0.5572008490562439)
[Training] epoch:856 step:100 g_loss:1.2294085025787354 d_loss:4.307265967130661 (f_loss=-0.32815709710121155 r_loss=1.0065099000930786 GP=3.628913164138794)
[Training] epoch:856 step:200 g_loss:1.3458871841430664 d_loss:1.485554277896881 (f_loss=-0.29746538400650024 r_loss=1.088838815689087 GP=0.6941808462142944)
[Training] epoch:856 step:300 g_loss:1.3090540170669556 d_loss:1.516300618648529 (f_loss=-0.3405441641807556 r_loss=1.1570004224777222 GP=0.6998443603515625)
[Training] epoch:857 step:0 g_loss:1.2096924781799316 d_loss:2.3645252138376236 (f_loss=-0.24562416970729828 r_loss=1.107814908027649 GP=1.502334475517273)
[Training] epoch:857 step:100 g_loss:1.1954342126846313 d_loss:2.0164055228233337 (f_loss=-0.23766010999679565 r_loss=1.1287020444869995 GP=1.1253635883331299)
[Training] epoch:857 step:200 g_loss:1.2948553562164307 d_loss:3.8462550044059753 (f_loss=-0.31607943773269653 r_loss=0.9451785087585449 GP=3.217155933380127)
[Training] epoch:857 step:300 g_loss:1.2784453630447388 d_loss:1.8011995255947113 (f_loss=-0.265318900346756 r_loss=1.146484613418579 GP=0.9200338125228882)
[Training] epoch:858 step:0 g_loss:1.3314498662948608 d_loss:1.433542013168335 (f_loss=-0.2855376601219177 r_loss=1.1718716621398926 GP=0.5472080111503601)
[Training] epoch:858 step:100 g_loss:1.3225419521331787 d_loss:1.0754604190587997 (f_loss=-0.33278778195381165 r_loss=1.1728616952896118 GP=0.23538650572299957)
[Training] epoch:858 step:200 g_loss:1.3368034362792969 d_loss:1.6786370277404785 (f_loss=-0.27459782361984253 r_loss=1.2157701253890991 GP=0.7374647259712219)
[Training] epoch:858 step:300 g_loss:1.290511965751648 d_loss:1.2170913219451904 (f_loss=-0.3219061493873596 r_loss=1.0999855995178223 GP=0.4390118718147278)
[Training] epoch:859 step:0 g_loss:1.3183038234710693 d_loss:1.4308084845542908 (f_loss=-0.27885812520980835 r_loss=1.1971570253372192 GP=0.5125095844268799)
[Training] epoch:859 step:100 g_loss:1.3149147033691406 d_loss:1.8964154422283173 (f_loss=-0.29047778248786926 r_loss=1.108809232711792 GP=1.0780839920043945)
[Training] epoch:859 step:200 g_loss:1.2523534297943115 d_loss:1.7199324071407318 (f_loss=-0.23666277527809143 r_loss=1.1258528232574463 GP=0.830742359161377)
[Training] epoch:859 step:300 g_loss:1.287564992904663 d_loss:1.6836143136024475 (f_loss=-0.2739024758338928 r_loss=1.0026745796203613 GP=0.954842209815979)
[Training] epoch:860 step:0 g_loss:1.2684766054153442 d_loss:2.870980739593506 (f_loss=-0.30484479665756226 r_loss=0.9956590533256531 GP=2.180166482925415)

[Training] epoch:860 step:100 g_loss:1.268702745437622 d_loss:1.5251490473747253 (f_loss=-0.30166423320770264 r_loss=1.1798019409179688 GP=0.6470113396644592)
[Training] epoch:860 step:200 g_loss:1.2998528480529785 d_loss:1.738216757774353 (f_loss=-0.27857673168182373 r_loss=1.2137184143066406 GP=0.8030750751495361)
[Training] epoch:860 step:300 g_loss:1.3408684730529785 d_loss:1.327542930841446 (f_loss=-0.2541802227497101 r_loss=1.1887562274932861 GP=0.3929669260978699)
[Training] epoch:861 step:0 g_loss:1.263982892036438 d_loss:1.496772438287735 (f_loss=-0.2970189154148102 r_loss=1.1017316579818726 GP=0.6920596957206726)
[Training] epoch:861 step:100 g_loss:1.2724988460540771 d_loss:1.3853577375411987 (f_loss=-0.3079051971435547 r_loss=1.1356439590454102 GP=0.5576189756393433)
[Training] epoch:861 step:200 g_loss:1.2873033285140991 d_loss:2.155804067850113 (f_loss=-0.3038313090801239 r_loss=1.0986335277557373 GP=1.3610018491744995)
[Training] epoch:861 step:300 g_loss:1.2693394422531128 d_loss:1.5371817350387573 (f_loss=-0.24700921773910522 r_loss=1.2779812812805176 GP=0.506209671497345)
[Training] epoch:862 step:0 g_loss:1.2877013683319092 d_loss:3.7430759966373444 (f_loss=-0.2872924506664276 r_loss=1.0788682699203491 GP=2.951500177383423)
[Training] epoch:862 step:100 g_loss:1.3226830959320068 d_loss:1.6232346892356873 (f_loss=-0.2969139814376831 r_loss=1.0611437559127808 GP=0.8590049147605896)
[Training] epoch:862 step:200 g_loss:1.3201466798782349 d_loss:1.984790176153183 (f_loss=-0.34597471356391907 r_loss=1.1968480348587036 GP=1.1339168548583984)
[Training] epoch:862 step:300 g_loss:1.313136100769043 d_loss:1.2801624834537506 (f_loss=-0.31994226574897766 r_loss=1.2190618515014648 GP=0.3810428977012634)
[Training] epoch:863 step:0 g_loss:1.2346237897872925 d_loss:4.417881667613983 (f_loss=-0.2821444869041443 r_loss=1.110334038734436 GP=3.5896921157836914)
[Training] epoch:863 step:100 g_loss:1.3302416801452637 d_loss:1.3945970833301544 (f_loss=-0.326090544462204 r_loss=1.204737663269043 GP=0.5159499645233154)
[Training] epoch:863 step:200 g_loss:1.2289083003997803 d_loss:1.3485374748706818 (f_loss=-0.29183921217918396 r_loss=1.1255812644958496 GP=0.5147954225540161)
[Training] epoch:863 step:300 g_loss:1.2766320705413818 d_loss:2.182176351547241 (f_loss=-0.27202844619750977 r_loss=1.1860477924346924 GP=1.2681570053100586)
[Training] epoch:864 step:0 g_loss:1.2935444116592407 d_loss:2.225414663553238 (f_loss=-0.2797289788722992 r_loss=1.2559782266616821 GP=1.249165415763855)
[Training] epoch:864 step:100 g_loss:1.2413846254348755 d_loss:2.734975039958954 (f_loss=-0.25053513050079346 r_loss=0.9889984726905823 GP=1.996511697769165)
[Training] epoch:864 step:200 g_loss:1.320704698562622 d_loss:1.5677030086517334 (f_loss=-0.33831071853637695 r_loss=1.065261721611023 GP=0.8407520055770874)
[Training] epoch:864 step:300 g_loss:1.3352138996124268 d_loss:2.1754789650440216 (f_loss=-0.28065553307533264 r_loss=0.9748076796531677 GP=1.4813268184661865)
[Training] epoch:865 step:0 g_loss:1.278385043144226 d_loss:1.2858637571334839 (f_loss=-0.285813570022583 r_loss=1.113698124885559 GP=0.4579792022705078)
[Training] epoch:865 step:100 g_loss:1.309352159500122 d_loss:1.680637151002884 (f_loss=-0.24799951910972595 r_loss=1.2121403217315674 GP=0.7164963483810425)
[Training] epoch:865 step:200 g_loss:1.2660207748413086 d_loss:1.473668247461319 (f_loss=-0.34290996193885803 r_loss=1.2497129440307617 GP=0.5668652653694153)
[Training] epoch:865 step:300 g_loss:1.2784521579742432 d_loss:1.8303990364074707 (f_loss=-0.27012181282043457 r_loss=1.1956055164337158 GP=0.9049153327941895)
[Training] epoch:866 step:0 g_loss:1.2784026861190796 d_loss:1.546415537595749 (f_loss=-0.306223064661026 r_loss=1.0975208282470703 GP=0.7551177740097046)
[Training] epoch:866 step:100 g_loss:1.2924246788024902 d_loss:1.874647170305252 (f_loss=-0.26963773369789124 r_loss=1.2513444423675537 GP=0.8929404616355896)
[Training] epoch:866 step:200 g_loss:1.3110226392745972 d_loss:2.9192233979701996 (f_loss=-0.27752581238746643 r_loss=0.9721126556396484 GP=2.2246365547180176)
[Training] epoch:866 step:300 g_loss:1.311287522315979 d_loss:1.9516724944114685 (f_loss=-0.2949597239494324 r_loss=1.026067852973938 GP=1.220564365386963)
[Training] epoch:867 step:0 g_loss:1.3578095436096191 d_loss:1.696713387966156 (f_loss=-0.314838171005249 r_loss=1.090132236480713 GP=0.9214193224906921)
[Training] epoch:867 step:100 g_loss:1.2474653720855713 d_loss:1.459914743900299 (f_loss=-0.3404303193092346 r_loss=1.2729074954986572 GP=0.5274375677108765)
[Training] epoch:867 step:200 g_loss:1.325696349143982 d_loss:1.3122873604297638 (f_loss=-0.2680499255657196 r_loss=1.2799363136291504 GP=0.300400972366333)
[Training] epoch:867 step:300 g_loss:1.3735722303390503 d_loss:1.476497083902359 (f_loss=-0.3077661097049713 r_loss=1.2654080390930176 GP=0.5188551545143127)
[Training] epoch:868 step:0 g_loss:1.2903656959533691 d_loss:1.6908977031707764 (f_loss=-0.248887300491333 r_loss=1.1790024042129517 GP=0.7607825994491577)
[Training] epoch:868 step:100 g_loss:1.3212318420410156 d_loss:1.6717983335256577 (f_loss=-0.21916617453098297 r_loss=1.1805000305175781 GP=0.7104644775390625)
[Training] epoch:868 step:200 g_loss:1.2680513858795166 d_loss:2.6079715341329575 (f_loss=-0.23260368406772614 r_loss=1.00690758228302 GP=1.8336676359176636)
[Training] epoch:868 step:300 g_loss:1.2642689943313599 d_loss:2.6813763082027435 (f_loss=-0.2909391224384308 r_loss=1.1658446788787842 GP=1.8064707517623901)
[Training] epoch:869 step:0 g_loss:1.3335384130477905 d_loss:2.2326567322015762 (f_loss=-0.24300538003444672 r_loss=1.2093192338943481 GP=1.2663428783416748)
[Training] epoch:869 step:100 g_loss:1.2630000114440918 d_loss:1.5762379467487335 (f_loss=-0.27809950709342957 r_loss=1.1700623035430908 GP=0.6842751502990723)
[Training] epoch:869 step:200 g_loss:1.2734959125518799 d_loss:1.3189234137535095 (f_loss=-0.27852746844291687 r_loss=1.1974689960479736 GP=0.39998188614845276)
[Training] epoch:869 step:300 g_loss:1.273849606513977 d_loss:2.2184856235980988 (f_loss=-0.3826631009578705 r_loss=1.1309267282485962 GP=1.470221996307373)
[Training] epoch:870 step:0 g_loss:1.3488154411315918 d_loss:1.2327072322368622 (f_loss=-0.3643180727958679 r_loss=1.202099084854126 GP=0.3949262201786041)

[Training] epoch:870 step:100 g_loss:1.2107006311416626 d_loss:3.1434186398983 (f_loss=-0.3050372898578644 r_loss=0.9915784597396851 GP=2.4568774700164795)
[Training] epoch:870 step:200 g_loss:1.3259624242782593 d_loss:2.3329817950725555 (f_loss=-0.3115382492542267 r_loss=1.210679054260254 GP=1.4338409900665283)
[Training] epoch:870 step:300 g_loss:1.3140627145767212 d_loss:2.784749060869217 (f_loss=-0.23955175280570984 r_loss=1.0924224853515625 GP=1.9318783283233643)
[Training] epoch:871 step:0 g_loss:1.3484411239624023 d_loss:1.5533482432365417 (f_loss=-0.4033379554748535 r_loss=1.2689859867095947 GP=0.6877002120018005)
[Training] epoch:871 step:100 g_loss:1.2812763452529907 d_loss:2.3442488461732864 (f_loss=-0.21029429137706757 r_loss=0.9981933832168579 GP=1.556349754333496)
[Training] epoch:871 step:200 g_loss:1.2932558059692383 d_loss:1.4910616874694824 (f_loss=-0.25609922409057617 r_loss=1.1442488431930542 GP=0.6029120683670044)
[Training] epoch:871 step:300 g_loss:1.2803938388824463 d_loss:2.3708600401878357 (f_loss=-0.30713969469070435 r_loss=0.9603029489517212 GP=1.7176967859268188)
[Training] epoch:872 step:0 g_loss:1.26467764377594 d_loss:2.4675989151000977 (f_loss=-0.2804107666015625 r_loss=1.1669625043869019 GP=1.5810471773147583)
[Training] epoch:872 step:100 g_loss:1.3318006992340088 d_loss:2.8813065886497498 (f_loss=-0.2663375735282898 r_loss=1.0214942693710327 GP=2.126149892807007)
[Training] epoch:872 step:200 g_loss:1.3358099460601807 d_loss:2.1778109669685364 (f_loss=-0.2722092270851135 r_loss=1.1175893545150757 GP=1.3324308395385742)
[Training] epoch:872 step:300 g_loss:1.325161337852478 d_loss:2.0973326563835144 (f_loss=-0.31484049558639526 r_loss=1.1840369701385498 GP=1.2281361818313599)
[Training] epoch:873 step:0 g_loss:1.2658162117004395 d_loss:1.9748193323612213 (f_loss=-0.26945361495018005 r_loss=1.1883580684661865 GP=1.0559148788452148)
[Training] epoch:873 step:100 g_loss:1.2822067737579346 d_loss:1.8318957686424255 (f_loss=-0.2383367419242859 r_loss=1.1941620111465454 GP=0.876070499420166)
[Training] epoch:873 step:200 g_loss:1.2866483926773071 d_loss:1.7293480336666107 (f_loss=-0.3038259446620941 r_loss=1.084477186203003 GP=0.9486967921257019)
[Training] epoch:873 step:300 g_loss:1.2892725467681885 d_loss:1.4811002016067505 (f_loss=-0.316622257232666 r_loss=1.2458094358444214 GP=0.5519130229949951)
[Training] epoch:874 step:0 g_loss:1.2796459197998047 d_loss:1.5442180335521698 (f_loss=-0.26905348896980286 r_loss=1.1498160362243652 GP=0.6634554862976074)
[Training] epoch:874 step:100 g_loss:1.2347911596298218 d_loss:1.3528563976287842 (f_loss=-0.2943685054779053 r_loss=1.18825101852417 GP=0.45897388458251953)
[Training] epoch:874 step:200 g_loss:1.3047429323196411 d_loss:1.3117555677890778 (f_loss=-0.32760098576545715 r_loss=1.2846530675888062 GP=0.35470348596572876)
[Training] epoch:874 step:300 g_loss:1.2746825218200684 d_loss:1.3516323566436768 (f_loss=-0.27684861421585083 r_loss=1.1268587112426758 GP=0.5016222596168518)
[Training] epoch:875 step:0 g_loss:1.2167820930480957 d_loss:1.562229573726654 (f_loss=-0.3632028102874756 r_loss=1.2058621644973755 GP=0.7195702195167542)
[Training] epoch:875 step:100 g_loss:1.1900206804275513 d_loss:1.4777644872665405 (f_loss=-0.26764580607414246 r_loss=1.2491309642791748 GP=0.4962793290615082)
[Training] epoch:875 step:200 g_loss:1.2852296829223633 d_loss:1.1856260299682617 (f_loss=-0.29839247465133667 r_loss=1.108536958694458 GP=0.3754815459251404)
[Training] epoch:875 step:300 g_loss:1.3148257732391357 d_loss:1.6930399239063263 (f_loss=-0.28618547320365906 r_loss=1.2432351112365723 GP=0.7359902858734131)
[Training] epoch:876 step:0 g_loss:1.3256020545959473 d_loss:1.5959465056657791 (f_loss=-0.23711828887462616 r_loss=1.1990362405776978 GP=0.6340285539627075)
[Training] epoch:876 step:100 g_loss:1.313909888267517 d_loss:1.3507071435451508 (f_loss=-0.26993873715400696 r_loss=1.216139793395996 GP=0.4045060873031616)
[Training] epoch:876 step:200 g_loss:1.2763961553573608 d_loss:1.1500197052955627 (f_loss=-0.32221120595932007 r_loss=1.1811954975128174 GP=0.29103541374206543)
[Training] epoch:876 step:300 g_loss:1.225389838218689 d_loss:1.3819668889045715 (f_loss=-0.2718138098716736 r_loss=1.227463960647583 GP=0.4263167381286621)
[Training] epoch:877 step:0 g_loss:1.3102078437805176 d_loss:2.1643661856651306 (f_loss=-0.32261592149734497 r_loss=1.2740747928619385 GP=1.212907314300537)
[Training] epoch:877 step:100 g_loss:1.3026725053787231 d_loss:1.319243609905243 (f_loss=-0.2571858763694763 r_loss=1.2346194982528687 GP=0.3418099880218506)
[Training] epoch:877 step:200 g_loss:1.2500872611999512 d_loss:1.5972843170166016 (f_loss=-0.3302451968193054 r_loss=1.125084638595581 GP=0.8024448752403259)
[Training] epoch:877 step:300 g_loss:1.331710696220398 d_loss:1.9819316267967224 (f_loss=-0.3030034899711609 r_loss=0.9921872615814209 GP=1.2927478551864624)
[Training] epoch:878 step:0 g_loss:1.3748142719268799 d_loss:1.857714295387268 (f_loss=-0.32843053340911865 r_loss=1.0730479955673218 GP=1.113096833229065)
[Training] epoch:878 step:100 g_loss:1.3060954809188843 d_loss:1.3389299809932709 (f_loss=-0.2770381271839142 r_loss=1.251634120941162 GP=0.36433398723602295)
[Training] epoch:878 step:200 g_loss:1.3156899213790894 d_loss:1.8817118406295776 (f_loss=-0.3045426607131958 r_loss=1.1789065599441528 GP=1.0073479413986206)
[Training] epoch:878 step:300 g_loss:1.32903254032135 d_loss:1.6807063817977905 (f_loss=-0.30745309591293335 r_loss=1.2532627582550049 GP=0.734896719455719)
[Training] epoch:879 step:0 g_loss:1.378286361694336 d_loss:1.5093943774700165 (f_loss=-0.3358398973941803 r_loss=1.19758141040802 GP=0.6476528644561768)
[Training] epoch:879 step:100 g_loss:1.3765590190887451 d_loss:1.502572238445282 (f_loss=-0.35491544008255005 r_loss=1.208168864250183 GP=0.6493188142776489)
[Training] epoch:879 step:200 g_loss:1.339226484298706 d_loss:2.5465353429317474 (f_loss=-0.2631509602069855 r_loss=1.192726969718933 GP=1.6169593334197998)
[Training] epoch:879 step:300 g_loss:1.2754926681518555 d_loss:1.1322892606258392 (f_loss=-0.33086705207824707 r_loss=1.1574987173080444 GP=0.30565759539604187)
[Training] epoch:880 step:0 g_loss:1.3730497360229492 d_loss:2.0167438983917236 (f_loss=-0.33732545375823975 r_loss=1.2959396839141846 GP=1.0581296682357788)

[Training] epoch:880 step:100 g_loss:1.3347327709197998 d_loss:2.178082138299942 (f_loss=-0.2668047845363617 r_loss=1.1155781745910645 GP=1.3293087482452393)
[Training] epoch:880 step:200 g_loss:1.327515721321106 d_loss:2.150741368532181 (f_loss=-0.2887912690639496 r_loss=1.153278112411499 GP=1.2862545251846313)
[Training] epoch:880 step:300 g_loss:1.3329318761825562 d_loss:1.5375976264476776 (f_loss=-0.2656225860118866 r_loss=1.2309129238128662 GP=0.572307288646698)
[Training] epoch:881 step:0 g_loss:1.29896879196167 d_loss:1.7519099712371826 (f_loss=-0.30185526609420776 r_loss=1.2119479179382324 GP=0.841817319393158)
[Training] epoch:881 step:100 g_loss:1.3399111032485962 d_loss:1.5075545907020569 (f_loss=-0.25911539793014526 r_loss=1.2506009340286255 GP=0.5160690546035767)
[Training] epoch:881 step:200 g_loss:1.3076239824295044 d_loss:1.2835908234119415 (f_loss=-0.3349462151527405 r_loss=1.145246982574463 GP=0.4732900559902191)
[Training] epoch:881 step:300 g_loss:1.277561068534851 d_loss:1.2637206614017487 (f_loss=-0.3280673623085022 r_loss=1.1396046876907349 GP=0.452183336019516)
[Training] epoch:882 step:0 g_loss:1.176202654838562 d_loss:1.4035321474075317 (f_loss=-0.33359235525131226 r_loss=1.2270344495773315 GP=0.5100900530815125)
[Training] epoch:882 step:100 g_loss:1.2842854261398315 d_loss:1.7766271531581879 (f_loss=-0.29657813906669617 r_loss=1.142351746559143 GP=0.930853545665741)
[Training] epoch:882 step:200 g_loss:1.2976505756378174 d_loss:2.1807910203933716 (f_loss=-0.2706630229949951 r_loss=1.2185126543045044 GP=1.2329413890838623)
[Training] epoch:882 step:300 g_loss:1.2890551090240479 d_loss:1.2693096995353699 (f_loss=-0.2954409718513489 r_loss=1.1421127319335938 GP=0.422637939453125)
[Training] epoch:883 step:0 g_loss:1.2366182804107666 d_loss:1.5780432224273682 (f_loss=-0.2659081220626831 r_loss=1.1940090656280518 GP=0.6499422788619995)
[Training] epoch:883 step:100 g_loss:1.2874391078948975 d_loss:1.5964083075523376 (f_loss=-0.30775171518325806 r_loss=1.1171879768371582 GP=0.7869720458984375)
[Training] epoch:883 step:200 g_loss:1.3015302419662476 d_loss:2.033325880765915 (f_loss=-0.37261763215065 r_loss=1.1972628831863403 GP=1.2086806297302246)
[Training] epoch:883 step:300 g_loss:1.3621454238891602 d_loss:1.944941759109497 (f_loss=-0.2987680435180664 r_loss=1.2024664878845215 GP=1.041243314743042)
[[Training] epoch:884 step:0 g_loss:1.2777551412582397 d_loss:1.2855727970600128 (f_loss=-0.3443426787853241 r_loss=1.1558902263641357 GP=0.47402524948120117)
[Training] epoch:884 step:100 g_loss:1.2458840608596802 d_loss:2.2477217614650726 (f_loss=-0.32077446579933167 r_loss=1.1083767414093018 GP=1.4601194858551025)
[Training] epoch:884 step:200 g_loss:1.3324527740478516 d_loss:1.27066570520401 (f_loss=-0.35017895698547363 r_loss=1.2967510223388672 GP=0.32409363985061646)
[Training] epoch:884 step:300 g_loss:1.3112823963165283 d_loss:3.170111358165741 (f_loss=-0.32049447298049927 r_loss=1.245779037475586 GP=2.2448267936706543)
[Training] epoch:885 step:0 g_loss:1.278025507926941 d_loss:1.4629164934158325 (f_loss=-0.34328776597976685 r_loss=1.2044472694396973 GP=0.6017569899559021)
[Training] epoch:885 step:100 g_loss:1.2568638324737549 d_loss:1.6676411628723145 (f_loss=-0.29276973009109497 r_loss=1.1680139303207397 GP=0.7923969626426697)
[Training] epoch:885 step:200 g_loss:1.2626769542694092 d_loss:1.9586382508277893 (f_loss=-0.26125162839889526 r_loss=1.1516242027282715 GP=1.068265676498413)
[Training] epoch:885 step:300 g_loss:1.3555184602737427 d_loss:1.6770469844341278 (f_loss=-0.35081949830055237 r_loss=1.1911678314208984 GP=0.8366986513137817)
[Training] epoch:886 step:0 g_loss:1.334539532661438 d_loss:1.1904334723949432 (f_loss=-0.28688398003578186 r_loss=1.271438479423523 GP=0.20587897300720215)
[Training] epoch:886 step:100 g_loss:1.3486295938491821 d_loss:1.5612121224403381 (f_loss=-0.2501172423362732 r_loss=1.1942898035049438 GP=0.6170395612716675)
[Training] epoch:886 step:200 g_loss:1.385332465171814 d_loss:1.7128389179706573 (f_loss=-0.31856951117515564 r_loss=1.1749922037124634 GP=0.8564162254333496)
[Training] epoch:886 step:300 g_loss:1.2972791194915771 d_loss:2.265087813138962 (f_loss=-0.3077498972415924 r_loss=1.1653591394424438 GP=1.4074785709381104)
[Training] epoch:887 step:0 g_loss:1.289807915687561 d_loss:1.8607702553272247 (f_loss=-0.28241094946861267 r_loss=1.1983766555786133 GP=0.9448045492172241)
[Training] epoch:887 step:100 g_loss:1.2007639408111572 d_loss:2.12709978222847 (f_loss=-0.2756457030773163 r_loss=1.1561241149902344 GP=1.2466213703155518)
[Training] epoch:887 step:200 g_loss:1.3357716798782349 d_loss:2.484426259994507 (f_loss=-0.311603307723999 r_loss=1.0737677812576294 GP=1.7222617864608765)
[Training] epoch:887 step:300 g_loss:1.2551350593566895 d_loss:1.756506323814392 (f_loss=-0.3020073175430298 r_loss=1.0783042907714844 GP=0.9802093505859375)
[Training] epoch:888 step:0 g_loss:1.2841665744781494 d_loss:1.7209877669811249 (f_loss=-0.275469034910202 r_loss=1.1553888320922852 GP=0.8410679697990417)
[Training] epoch:888 step:100 g_loss:1.3187634944915771 d_loss:1.4207888543605804 (f_loss=-0.28174564242362976 r_loss=1.1845601797103882 GP=0.517974317073822)
[Training] epoch:888 step:200 g_loss:1.3343207836151123 d_loss:1.7938022017478943 (f_loss=-0.3296920657157898 r_loss=1.1341533660888672 GP=0.9893409013748169)
[Training] epoch:888 step:300 g_loss:1.2717515230178833 d_loss:1.5745461583137512 (f_loss=-0.3488052487373352 r_loss=1.159987211227417 GP=0.7633641958236694)
[Training] epoch:889 step:0 g_loss:1.299834966659546 d_loss:1.4393944144248962 (f_loss=-0.2887055277824402 r_loss=1.1461775302886963 GP=0.5819224119186401)
[Training] epoch:889 step:100 g_loss:1.3419864177703857 d_loss:1.6807830929756165 (f_loss=-0.29725414514541626 r_loss=1.142905831336975 GP=0.8351314067840576)
[Training] epoch:889 step:200 g_loss:1.3623676300048828 d_loss:1.9144020080566406 (f_loss=-0.2954046130180359 r_loss=1.2281450033187866 GP=0.9816616177558899)
[Training] epoch:889 step:300 g_loss:1.301511287689209 d_loss:1.3898406028747559 (f_loss=-0.30887627601623535 r_loss=1.3188363313674927 GP=0.37988054752349854)
[Training] epoch:890 step:0 g_loss:1.336616039276123 d_loss:4.668539822101593 (f_loss=-0.23573505878448486 r_loss=0.873628556728363 GP=4.030646324157715)
[Training] epoch:890 step:100 g_loss:1.3099639415740967 d_loss:1.2966624796390533 (f_loss=-0.28029537200927734 r_loss=1.2605829238891602 GP=0.31637492775917053)
[Training] epoch:890 step:200 g_loss:1.354495882987976 d_loss:1.086629569530487 (f_loss=-0.33883893489837646 r_loss=1.2330286502838135 GP=0.19243985414505005)
[Training] epoch:890 step:300 g_loss:1.3821229934692383 d_loss:2.625674694776535 (f_loss=-0.325776606798172 r_loss=1.169783353805542 GP=1.781667947769165)
[Training] epoch:891 step:0 g_loss:1.2947818040847778 d_loss:1.465315729379654 (f_loss=-0.1937195360660553 r_loss=1.268362045288086 GP=0.3906732201576233)
[Training] epoch:891 step:100 g_loss:1.2625242471694946 d_loss:2.5679655969142914 (f_loss=-0.233322411775589 r_loss=1.2583922147750854 GP=1.542895793914795)
[Training] epoch:891 step:200 g_loss:1.338878870010376 d_loss:1.8258819878101349 (f_loss=-0.32911571860313416 r_loss=1.0363587141036987 GP=1.1186389923095703)
[Training] epoch:891 step:300 g_loss:1.298856258392334 d_loss:1.9211451411247253 (f_loss=-0.366119921207428 r_loss=1.2964049577713013 GP=0.990860104560852)
[Training] epoch:892 step:0 g_loss:1.2891762256622314 d_loss:1.5261043310165405 (f_loss=-0.30468475818634033 r_loss=1.2759703397750854 GP=0.5548187494277954)
[Training] epoch:892 step:100 g_loss:1.299952507019043 d_loss:1.2238491773605347 (f_loss=-0.35765528678894043 r_loss=1.3127195835113525 GP=0.26878488063812256)
[Training] epoch:892 step:200 g_loss:1.2723755836486816 d_loss:1.6649454534053802 (f_loss=-0.3717478811740875 r_loss=1.252245545387268 GP=0.7844477891921997)
[Training] epoch:892 step:300 g_loss:1.2772713899612427 d_loss:1.8961332738399506 (f_loss=-0.32122042775154114 r_loss=1.207780361175537 GP=1.0095733404159546)
[Training] epoch:893 step:0 g_loss:1.3391010761260986 d_loss:2.63030543923378 (f_loss=-0.3034556806087494 r_loss=1.1368463039398193 GP=1.79691481590271)
[Training] epoch:893 step:100 g_loss:1.34678316116333 d_loss:1.5200735926628113 (f_loss=-0.2750548720359802 r_loss=1.210584282875061 GP=0.5845441818237305)
[Training] epoch:893 step:200 g_loss:1.3151075839996338 d_loss:1.3741624355316162 (f_loss=-0.30183327198028564 r_loss=1.2618600130081177 GP=0.4141356945037842)
[Training] epoch:893 step:300 g_loss:1.3427777290344238 d_loss:1.3020674884319305 (f_loss=-0.37009793519973755 r_loss=1.2396273612976074 GP=0.43253806233406067)
[Training] epoch:894 step:0 g_loss:1.3320350646972656 d_loss:1.746833086013794 (f_loss=-0.3012878894805908 r_loss=1.2385313510894775 GP=0.8095896244049072)
[Training] epoch:894 step:100 g_loss:1.2811689376831055 d_loss:1.4067049622535706 (f_loss=-0.28421980142593384 r_loss=1.2890533208847046 GP=0.4018714427947998)
[Training] epoch:894 step:200 g_loss:1.2907930612564087 d_loss:1.7326708734035492 (f_loss=-0.31513264775276184 r_loss=1.2891509532928467 GP=0.7586525678634644)
[Training] epoch:894 step:300 g_loss:1.246068000793457 d_loss:1.636438637971878 (f_loss=-0.2959366738796234 r_loss=1.1584125757217407 GP=0.7739627361297607)
[Training] epoch:895 step:0 g_loss:1.3721626996994019 d_loss:1.2522015869617462 (f_loss=-0.34257954359054565 r_loss=1.2340766191482544 GP=0.3607045114040375)
[Training] epoch:895 step:100 g_loss:1.2744591236114502 d_loss:1.9842675924301147 (f_loss=-0.2513570785522461 r_loss=1.2888214588165283 GP=0.9468032121658325)
[Training] epoch:895 step:200 g_loss:1.2576277256011963 d_loss:1.700520008802414 (f_loss=-0.3213141858577728 r_loss=1.1962132453918457 GP=0.8256209492683411)
[Training] epoch:895 step:300 g_loss:1.3342485427856445 d_loss:1.576653778553009 (f_loss=-0.3667548894882202 r_loss=1.2113866806030273 GP=0.7320219874382019)
[Training] epoch:896 step:0 g_loss:1.2498952150344849 d_loss:1.9289237558841705 (f_loss=-0.2208397090435028 r_loss=1.2384393215179443 GP=0.911324143409729)
[Training] epoch:896 step:100 g_loss:1.319267749786377 d_loss:1.3167113363742828 (f_loss=-0.20336046814918518 r_loss=1.2244693040847778 GP=0.2956025004386902)
[Training] epoch:896 step:200 g_loss:1.3402373790740967 d_loss:1.8514848053455353 (f_loss=-0.25610122084617615 r_loss=1.1813253164291382 GP=0.9262607097625732)
[Training] epoch:896 step:300 g_loss:1.2762959003448486 d_loss:1.6374913156032562 (f_loss=-0.31880971789360046 r_loss=1.2518727779388428 GP=0.7044282555580139)
[Training] epoch:897 step:0 g_loss:1.3193652629852295 d_loss:1.8289323449134827 (f_loss=-0.3270357847213745 r_loss=1.1974438428878784 GP=0.9585242867469788)
[Training] epoch:897 step:100 g_loss:1.3311364650726318 d_loss:1.2068297117948532 (f_loss=-0.2822844982147217 r_loss=1.272645115852356 GP=0.21646909415721893)
[Training] epoch:897 step:200 g_loss:1.3111118078231812 d_loss:1.336932212114334 (f_loss=-0.2496281862258911 r_loss=1.2094333171844482 GP=0.377127081155777)
[Training] epoch:897 step:300 g_loss:1.2642405033111572 d_loss:2.6609351336956024 (f_loss=-0.30902937054634094 r_loss=1.1356627941131592 GP=1.8343017101287842)
[Training] epoch:898 step:0 g_loss:1.2937116622924805 d_loss:1.6295113563537598 (f_loss=-0.32165098190307617 r_loss=1.195223093032837 GP=0.755939245223999)
[Training] epoch:898 step:100 g_loss:1.3179550170898438 d_loss:1.793980896472931 (f_loss=-0.35063737630844116 r_loss=1.303819179534912 GP=0.84079909324646)
[Training] epoch:898 step:200 g_loss:1.2763025760650635 d_loss:2.584086060523987 (f_loss=-0.28617918491363525 r_loss=1.2315850257873535 GP=1.6386802196502686)
[Training] epoch:898 step:300 g_loss:1.283320665359497 d_loss:1.752501517534256 (f_loss=-0.290467232465744 r_loss=1.1175475120544434 GP=0.9254212379455566)
[Training] epoch:899 step:0 g_loss:1.3680115938186646 d_loss:2.434485971927643 (f_loss=-0.2883191704750061 r_loss=1.1353909969329834 GP=1.5874141454696655)
[Training] epoch:899 step:100 g_loss:1.3129806518554688 d_loss:1.7438318133354187 (f_loss=-0.3195517063140869 r_loss=1.2518093585968018 GP=0.8115741610527039)
[Training] epoch:899 step:200 g_loss:1.2995561361312866 d_loss:2.2221949696540833 (f_loss=-0.331667959690094 r_loss=1.2385809421539307 GP=1.3152819871902466)
[Training] epoch:899 step:300 g_loss:1.3840335607528687 d_loss:2.4037678837776184 (f_loss=-0.2595204710960388 r_loss=1.1855872869491577 GP=1.4777010679244995)
[Training] epoch:900 step:0 g_loss:1.3927209377288818 d_loss:1.6685588955879211 (f_loss=-0.3658313751220703 r_loss=1.1812493801116943 GP=0.8531408905982971)
[Training] epoch:900 step:100 g_loss:1.316772222518921 d_loss:1.549440085887909 (f_loss=-0.3555479645729065 r_loss=1.2299262285232544 GP=0.675061821937561)
[Training] epoch:900 step:200 g_loss:1.3230412006378174 d_loss:1.54201939702034 (f_loss=-0.3179391920566559 r_loss=1.2214324474334717 GP=0.6385261416435242)
[Training] epoch:900 step:300 g_loss:1.2984583377838135 d_loss:1.7089333832263947 (f_loss=-0.3609602749347687 r_loss=1.222373366355896 GP=0.8475202918052673)
[Training] epoch:901 step:0 g_loss:1.3261160850524902 d_loss:1.5610351860523224 (f_loss=-0.30995169281959534 r_loss=1.3071808815002441 GP=0.5638059973716736)
[Training] epoch:901 step:100 g_loss:1.2579004764556885 d_loss:1.5383214950561523 (f_loss=-0.3031373620033264 r_loss=1.3365967273712158 GP=0.5048621296882629)
[Training] epoch:901 step:200 g_loss:1.3224650621414185 d_loss:1.8807057738304138 (f_loss=-0.33444350957870483 r_loss=1.1809014081954956 GP=1.034247875213623)
[Training] epoch:901 step:300 g_loss:1.3447315692901611 d_loss:1.7869958877563477 (f_loss=-0.34813392162323 r_loss=1.210943579673767 GP=0.9241862297058105)
[Training] epoch:902 step:0 g_loss:1.2836109399795532 d_loss:1.5378159582614899 (f_loss=-0.36677929759025574 r_loss=1.2011021375656128 GP=0.7034931182861328)
[Training] epoch:902 step:100 g_loss:1.3139582872390747 d_loss:1.535987377166748 (f_loss=-0.3533405065536499 r_loss=1.2292838096618652 GP=0.6600440740585327)
[Training] epoch:902 step:200 g_loss:1.3676410913467407 d_loss:3.847458630800247 (f_loss=-0.34092065691947937 r_loss=1.2392539978027344 GP=2.949125289916992)
[Training] epoch:902 step:300 g_loss:1.3714709281921387 d_loss:2.921387195587158 (f_loss=-0.3057948350906372 r_loss=1.1239608526229858 GP=2.1032211780548096)
[Training] epoch:903 step:0 g_loss:1.3300025463104248 d_loss:1.3560951948165894 (f_loss=-0.37022000551223755 r_loss=1.1826728582382202 GP=0.5436423420906067)
[Training] epoch:903 step:100 g_loss:1.2753688097000122 d_loss:2.3572582602500916 (f_loss=-0.3132973313331604 r_loss=1.2545433044433594 GP=1.4160122871398926)
[Training] epoch:903 step:200 g_loss:1.338953971862793 d_loss:4.276581913232803 (f_loss=-0.3430270850658417 r_loss=1.043333649635315 GP=3.57627534866333)
[Training] epoch:903 step:300 g_loss:1.3172317743301392 d_loss:1.209384262561798 (f_loss=-0.3681565225124359 r_loss=1.2361335754394531 GP=0.3414072096347809)
[Training] epoch:904 step:0 g_loss:1.2894059419631958 d_loss:1.7336466759443283 (f_loss=-0.21052630245685577 r_loss=1.3028886318206787 GP=0.6412843465805054)
[Training] epoch:904 step:100 g_loss:1.2701576948165894 d_loss:1.5557879507541656 (f_loss=-0.3061195909976959 r_loss=1.260745882987976 GP=0.6011616587638855)
[Training] epoch:904 step:200 g_loss:1.3393398523330688 d_loss:1.6326432824134827 (f_loss=-0.28601986169815063 r_loss=1.2116942405700684 GP=0.7069689035415649)
[Training] epoch:904 step:300 g_loss:1.2390625476837158 d_loss:1.4487413465976715 (f_loss=-0.37776896357536316 r_loss=1.2668424844741821 GP=0.5596678256988525)
[Training] epoch:905 step:0 g_loss:1.2963731288909912 d_loss:1.5391898155212402 (f_loss=-0.22871840000152588 r_loss=1.164961576461792 GP=0.6029466390609741)
[Training] epoch:905 step:100 g_loss:1.3084919452667236 d_loss:1.7787786424160004 (f_loss=-0.2736380398273468 r_loss=1.2307744026184082 GP=0.821642279624939)
[Training] epoch:905 step:200 g_loss:1.2650558948516846 d_loss:2.9928134977817535 (f_loss=-0.2882513701915741 r_loss=1.158429741859436 GP=2.1226351261138916)
[Training] epoch:905 step:300 g_loss:1.2782994508743286 d_loss:1.5001055896282196 (f_loss=-0.37562087178230286 r_loss=1.2358261346817017 GP=0.6399003267288208)
[Training] epoch:906 step:0 g_loss:1.3113473653793335 d_loss:1.379780352115631 (f_loss=-0.29009318351745605 r_loss=1.2288529872894287 GP=0.44102054834365845)
[Training] epoch:906 step:100 g_loss:1.2517603635787964 d_loss:1.6111397743225098 (f_loss=-0.2816030979156494 r_loss=1.2907142639160156 GP=0.6020286083221436)
[Training] epoch:906 step:200 g_loss:1.283024549484253 d_loss:2.0749070048332214 (f_loss=-0.2405734658241272 r_loss=1.174788475036621 GP=1.1406919956207275)
[Training] epoch:906 step:300 g_loss:1.2984709739685059 d_loss:1.4243829548358917 (f_loss=-0.27228155732154846 r_loss=1.2684972286224365 GP=0.42816728353500366)
[Training] epoch:907 step:0 g_loss:1.2407925128936768 d_loss:1.9585212916135788 (f_loss=-0.23374970257282257 r_loss=1.1911571025848389 GP=1.0011138916015625)
[Training] epoch:907 step:100 g_loss:1.283909559249878 d_loss:2.480394124984741 (f_loss=-0.3191657066345215 r_loss=1.1729271411895752 GP=1.6266326904296875)
[Training] epoch:907 step:200 g_loss:1.2894840240478516 d_loss:1.4224952459335327 (f_loss=-0.2709852457046509 r_loss=1.2238727807998657 GP=0.46960771083831787)
[Training] epoch:907 step:300 g_loss:1.3210209608078003 d_loss:1.2493973672389984 (f_loss=-0.3218455910682678 r_loss=1.2311726808547974 GP=0.34007027745246887)
[Training] epoch:908 step:0 g_loss:1.3289018869400024 d_loss:1.385522872209549 (f_loss=-0.3033602833747864 r_loss=1.2146096229553223 GP=0.47427353262901306)
[Training] epoch:908 step:100 g_loss:1.347090482711792 d_loss:1.644551932811737 (f_loss=-0.27918440103530884 r_loss=1.2396929264068604 GP=0.6840434074401855)
[Training] epoch:908 step:200 g_loss:1.3362324237823486 d_loss:2.798583984375 (f_loss=-0.31081724166870117 r_loss=1.1672875881195068 GP=1.9421136379241943)
[Training] epoch:908 step:300 g_loss:1.2947190999984741 d_loss:2.184080123901367 (f_loss=-0.2661731243133545 r_loss=1.10699462890625 GP=1.3432586193084717)
[Training] epoch:909 step:0 g_loss:1.35731840133667 d_loss:1.7166740596294403 (f_loss=-0.3359151780605316 r_loss=1.2105544805526733 GP=0.8420347571372986)
[Training] epoch:909 step:100 g_loss:1.343158483505249 d_loss:1.254988044500351 (f_loss=-0.3399356007575989 r_loss=1.2204124927520752 GP=0.37451115250587463)
[Training] epoch:909 step:200 g_loss:1.2856853008270264 d_loss:2.7143764793872833 (f_loss=-0.41889020800590515 r_loss=1.1842950582504272 GP=1.9489716291427612)
[Training] epoch:909 step:300 g_loss:1.2820338010787964 d_loss:1.5998261272907257 (f_loss=-0.3327884376049042 r_loss=1.2366480827331543 GP=0.6959664821624756)
[Training] epoch:910 step:0 g_loss:1.3626595735549927 d_loss:1.946951985359192 (f_loss=-0.318023145198822 r_loss=1.322481393814087 GP=0.942493736743927)
[Training] epoch:910 step:100 g_loss:1.3412261009216309 d_loss:1.4897164404392242 (f_loss=-0.2641439139842987 r_loss=1.3040897846221924 GP=0.44977056980133057)
[Training] epoch:910 step:200 g_loss:1.2714078426361084 d_loss:2.143767923116684 (f_loss=-0.24791744351387024 r_loss=1.1955307722091675 GP=1.1961545944213867)
[Training] epoch:910 step:300 g_loss:1.2615694999694824 d_loss:2.116904079914093 (f_loss=-0.29719609022140503 r_loss=1.2264293432235718 GP=1.1876708269119263)
[Training] epoch:911 step:0 g_loss:1.3061975240707397 d_loss:2.398117244243622 (f_loss=-0.23396402597427368 r_loss=1.2739813327789307 GP=1.3580999374389648)
[Training] epoch:911 step:100 g_loss:1.2952828407287598 d_loss:1.31983382999897 (f_loss=-0.22047828137874603 r_loss=1.2409409284591675 GP=0.2993711829185486)
[Training] epoch:911 step:200 g_loss:1.3223131895065308 d_loss:1.2913765907287598 (f_loss=-0.28727802634239197 r_loss=1.2826662063598633 GP=0.29598841071128845)
[Training] epoch:911 step:300 g_loss:1.345031976699829 d_loss:1.8321188986301422 (f_loss=-0.3080919682979584 r_loss=1.2587116956710815 GP=0.881499171257019)
[Training] epoch:912 step:0 g_loss:1.3412585258483887 d_loss:3.6750494241714478 (f_loss=-0.32516658306121826 r_loss=0.9640998840332031 GP=3.036116123199463)
[Training] epoch:912 step:100 g_loss:1.3745970726013184 d_loss:3.8051615357398987 (f_loss=-0.35058337450027466 r_loss=1.1766430139541626 GP=2.9791018962860107)
[Training] epoch:912 step:200 g_loss:1.2904932498931885 d_loss:1.6060533821582794 (f_loss=-0.2546909749507904 r_loss=1.2354509830474854 GP=0.6252933740615845)
[Training] epoch:912 step:300 g_loss:1.4153599739074707 d_loss:1.794268250465393 (f_loss=-0.2793290615081787 r_loss=1.1620005369186401 GP=0.9115967750549316)
[Training] epoch:913 step:0 g_loss:1.317063331604004 d_loss:2.880083352327347 (f_loss=-0.3542648255825043 r_loss=1.09003484249115 GP=2.144313335418701)
[Training] epoch:913 step:100 g_loss:1.3030050992965698 d_loss:1.743736743927002 (f_loss=-0.3166910409927368 r_loss=1.2437533140182495 GP=0.8166744709014893)
[Training] epoch:913 step:200 g_loss:1.2206050157546997 d_loss:1.5870401561260223 (f_loss=-0.2627710998058319 r_loss=1.1589648723602295 GP=0.6908463835716248)
[Training] epoch:913 step:300 g_loss:1.3586626052856445 d_loss:1.8455034494400024 (f_loss=-0.36832094192504883 r_loss=1.1975183486938477 GP=1.0163060426712036)
[Training] epoch:914 step:0 g_loss:1.3102185726165771 d_loss:1.4726152420043945 (f_loss=-0.30481261014938354 r_loss=1.1859180927276611 GP=0.5915097594261169)
[Training] epoch:914 step:100 g_loss:1.2561562061309814 d_loss:1.6023856699466705 (f_loss=-0.2951509654521942 r_loss=1.2472479343414307 GP=0.6502887010574341)
[Training] epoch:914 step:200 g_loss:1.3797913789749146 d_loss:1.155155897140503 (f_loss=-0.3243314027786255 r_loss=1.202005386352539 GP=0.27748191356658936)
[Training] epoch:914 step:300 g_loss:1.2858227491378784 d_loss:2.2228549122810364 (f_loss=-0.3257668614387512 r_loss=1.2047001123428345 GP=1.3439216613769531)
[Training] epoch:915 step:0 g_loss:1.3076305389404297 d_loss:3.2028300166130066 (f_loss=-0.2929455637931824 r_loss=1.1830724477767944 GP=2.3127031326293945)
[Training] epoch:915 step:100 g_loss:1.309529185295105 d_loss:1.9955397248268127 (f_loss=-0.2997695803642273 r_loss=1.1903877258300781 GP=1.104921579360962)
[Training] epoch:915 step:200 g_loss:1.3561872243881226 d_loss:4.144096374511719 (f_loss=-0.37195491790771484 r_loss=0.9287691116333008 GP=3.587282180786133)
[Training] epoch:915 step:300 g_loss:1.3073164224624634 d_loss:1.4154090285301208 (f_loss=-0.3911324739456177 r_loss=1.2989935874938965 GP=0.507547914981842)
[Training] epoch:916 step:0 g_loss:1.3443292379379272 d_loss:1.473884403705597 (f_loss=-0.3730100393295288 r_loss=1.2781288623809814 GP=0.5687655806541443)
[Training] epoch:916 step:100 g_loss:1.34513258934021 d_loss:1.3587922155857086 (f_loss=-0.29709532856941223 r_loss=1.296499490737915 GP=0.3593880534172058)
[Training] epoch:916 step:200 g_loss:1.2802038192749023 d_loss:2.163947254419327 (f_loss=-0.3273634612560272 r_loss=1.0466591119766235 GP=1.4446516036987305)
[Training] epoch:916 step:300 g_loss:1.324914574623108 d_loss:1.8009533882141113 (f_loss=-0.3422691822052002 r_loss=1.277999758720398 GP=0.8652228116989136)
[Training] epoch:917 step:0 g_loss:1.3062586784362793 d_loss:1.3858222365379333 (f_loss=-0.31638646125793457 r_loss=1.1921639442443848 GP=0.5100447535514832)
[Training] epoch:917 step:100 g_loss:1.324073314666748 d_loss:1.4422796368598938 (f_loss=-0.3170838952064514 r_loss=1.1902334690093994 GP=0.5691300630569458)
[Training] epoch:917 step:200 g_loss:1.3864315748214722 d_loss:1.5418473780155182 (f_loss=-0.3052344024181366 r_loss=1.287608027458191 GP=0.5594737529754639)
[Training] epoch:917 step:300 g_loss:1.299562931060791 d_loss:1.3577366471290588 (f_loss=-0.36022835969924927 r_loss=1.3100543022155762 GP=0.40791070461273193)
[Training] epoch:918 step:0 g_loss:1.3545186519622803 d_loss:1.4600858986377716 (f_loss=-0.3043205440044403 r_loss=1.1397314071655273 GP=0.6246750354766846)
[Training] epoch:918 step:100 g_loss:1.3195748329162598 d_loss:1.4350253343582153 (f_loss=-0.28452110290527344 r_loss=1.2570068836212158 GP=0.46253955364227295)
[Training] epoch:918 step:200 g_loss:1.3316318988800049 d_loss:1.7787748575210571 (f_loss=-0.34277451038360596 r_loss=1.1206202507019043 GP=1.0009291172027588)
[Training] epoch:918 step:300 g_loss:1.3497109413146973 d_loss:1.6800623536109924 (f_loss=-0.3229520320892334 r_loss=1.268467903137207 GP=0.7345464825630188)
[Training] epoch:919 step:0 g_loss:1.307675838470459 d_loss:1.6589531898498535 (f_loss=-0.3204362392425537 r_loss=1.2676397562026978 GP=0.7117496728897095)
[Training] epoch:919 step:100 g_loss:1.3522462844848633 d_loss:1.5794463753700256 (f_loss=-0.36025041341781616 r_loss=1.31329345703125 GP=0.6264033317565918)
[Training] epoch:919 step:200 g_loss:1.3224538564682007 d_loss:1.3680124282836914 (f_loss=-0.3374614417552948 r_loss=1.280334234237671 GP=0.4251396358013153)
[Training] epoch:919 step:300 g_loss:1.3139712810516357 d_loss:1.4344076216220856 (f_loss=-0.29858630895614624 r_loss=1.3425079584121704 GP=0.3904859721660614)
[Training] epoch:920 step:0 g_loss:1.3440327644348145 d_loss:1.512055218219757 (f_loss=-0.33420419692993164 r_loss=1.2556971311569214 GP=0.5905622839927673)
[Training] epoch:920 step:100 g_loss:1.3979692459106445 d_loss:2.01735982298851 (f_loss=-0.28905633091926575 r_loss=1.1431766748428345 GP=1.1632394790649414)
[Training] epoch:920 step:200 g_loss:1.290643572807312 d_loss:1.2886714041233063 (f_loss=-0.3801729679107666 r_loss=1.2947087287902832 GP=0.3741356432437897)
[Training] epoch:920 step:300 g_loss:1.310442328453064 d_loss:1.9771649837493896 (f_loss=-0.31824779510498047 r_loss=1.2547607421875 GP=1.0406520366668701)
[Training] epoch:921 step:0 g_loss:1.2719111442565918 d_loss:1.3538244664669037 (f_loss=-0.31424710154533386 r_loss=1.271575927734375 GP=0.39649564027786255)
[Training] epoch:921 step:100 g_loss:1.3102138042449951 d_loss:1.958387315273285 (f_loss=-0.31120938062667847 r_loss=1.239951491355896 GP=1.0296452045440674)
[Training] epoch:921 step:200 g_loss:1.2745184898376465 d_loss:1.5170353651046753 (f_loss=-0.3354374170303345 r_loss=1.193437933921814 GP=0.6590348482131958)
[Training] epoch:921 step:300 g_loss:1.349571704864502 d_loss:2.2631087601184845 (f_loss=-0.29628774523735046 r_loss=1.1186819076538086 GP=1.4407145977020264)
[Training] epoch:922 step:0 g_loss:1.3413070440292358 d_loss:1.731793761253357 (f_loss=-0.30597400665283203 r_loss=1.232940435409546 GP=0.8048273324966431)
[Training] epoch:922 step:100 g_loss:1.3637065887451172 d_loss:1.541943073272705 (f_loss=-0.32174432277679443 r_loss=1.2659035921096802 GP=0.5977838039398193)
[Training] epoch:922 step:200 g_loss:1.324350118637085 d_loss:1.3907840251922607 (f_loss=-0.31849929690361023 r_loss=1.2585220336914062 GP=0.4507612884044647)
[Training] epoch:922 step:300 g_loss:1.2877388000488281 d_loss:1.3895427286624908 (f_loss=-0.3444128632545471 r_loss=1.3146543502807617 GP=0.41930124163627625)
[Training] epoch:923 step:0 g_loss:1.2927638292312622 d_loss:2.0369180142879486 (f_loss=-0.3203742802143097 r_loss=1.255946397781372 GP=1.1013458967208862)
[Training] epoch:923 step:100 g_loss:1.3103663921356201 d_loss:1.7284234166145325 (f_loss=-0.2968828082084656 r_loss=1.2613694667816162 GP=0.7639367580413818)
[Training] epoch:923 step:200 g_loss:1.3710780143737793 d_loss:1.21357661485672 (f_loss=-0.4061843156814575 r_loss=1.2654675245285034 GP=0.3542934060096741)
[Training] epoch:923 step:300 g_loss:1.3696558475494385 d_loss:3.1351771354675293 (f_loss=-0.3513631820678711 r_loss=1.1232671737670898 GP=2.3632731437683105)
[Training] epoch:924 step:0 g_loss:1.319678783416748 d_loss:1.5481833517551422 (f_loss=-0.30846694111824036 r_loss=1.2699174880981445 GP=0.586732804775238)
[Training] epoch:924 step:100 g_loss:1.274497151374817 d_loss:1.259791761636734 (f_loss=-0.3316425085067749 r_loss=1.25283682346344 GP=0.33859744668006897)
[Training] epoch:924 step:200 g_loss:1.3519322872161865 d_loss:1.5962558388710022 (f_loss=-0.3022218942642212 r_loss=1.217568039894104 GP=0.6809096932411194)
[Training] epoch:924 step:300 g_loss:1.298719882965088 d_loss:1.2624497711658478 (f_loss=-0.26429617404937744 r_loss=1.2990877628326416 GP=0.22765818238258362)
[Training] epoch:925 step:0 g_loss:1.323150873184204 d_loss:1.445482850074768 (f_loss=-0.3616299033164978 r_loss=1.2612953186035156 GP=0.5458174347877502)
[Training] epoch:925 step:100 g_loss:1.323317050933838 d_loss:2.6336230635643005 (f_loss=-0.2751985192298889 r_loss=1.2309482097625732 GP=1.6778733730316162)
[Training] epoch:925 step:200 g_loss:1.3966246843338013 d_loss:1.5512562990188599 (f_loss=-0.35016632080078125 r_loss=1.1521881818771362 GP=0.7492344379425049)
[Training] epoch:925 step:300 g_loss:1.2490960359573364 d_loss:1.5326390266418457 (f_loss=-0.34007978439331055 r_loss=1.3337455987930298 GP=0.5389732122421265)
[Training] epoch:926 step:0 g_loss:1.275861144065857 d_loss:2.2499989569187164 (f_loss=-0.3411554992198944 r_loss=1.239681363105774 GP=1.351473093032837)
[Training] epoch:926 step:100 g_loss:1.2954798936843872 d_loss:1.5943874418735504 (f_loss=-0.24552854895591736 r_loss=1.1623501777648926 GP=0.6775658130645752)
[Training] epoch:926 step:200 g_loss:1.395653486251831 d_loss:1.240965098142624 (f_loss=-0.33282193541526794 r_loss=1.3359695672988892 GP=0.23781746625900269)
[Training] epoch:926 step:300 g_loss:1.3308966159820557 d_loss:1.2587333619594574 (f_loss=-0.3140624463558197 r_loss=1.3051908016204834 GP=0.2676050066947937)
[Training] epoch:927 step:0 g_loss:1.361348032951355 d_loss:1.930709719657898 (f_loss=-0.3515350818634033 r_loss=1.0733648538589478 GP=1.2088799476623535)
[Training] epoch:927 step:100 g_loss:1.3232672214508057 d_loss:2.290167987346649 (f_loss=-0.32189518213272095 r_loss=1.2367150783538818 GP=1.3753480911254883)
[Training] epoch:927 step:200 g_loss:1.2574766874313354 d_loss:1.3863102793693542 (f_loss=-0.254629909992218 r_loss=1.206546425819397 GP=0.4343937635421753)
[Training] epoch:927 step:300 g_loss:1.3238192796707153 d_loss:1.4943247437477112 (f_loss=-0.372156023979187 r_loss=1.2436991930007935 GP=0.6227815747261047)
[Training] epoch:928 step:0 g_loss:1.2302043437957764 d_loss:1.370020717382431 (f_loss=-0.2743012011051178 r_loss=1.2080774307250977 GP=0.43624448776245117)
[Training] epoch:928 step:100 g_loss:1.3626840114593506 d_loss:1.594901204109192 (f_loss=-0.30928558111190796 r_loss=1.164736032485962 GP=0.7394507527351379)
[Training] epoch:928 step:200 g_loss:1.358347773551941 d_loss:1.5833261609077454 (f_loss=-0.4074997305870056 r_loss=1.2995604276657104 GP=0.6912654638290405)
[Training] epoch:928 step:300 g_loss:1.2899127006530762 d_loss:1.3963190615177155 (f_loss=-0.3461155593395233 r_loss=1.1725715398788452 GP=0.5698630809783936)
[Training] epoch:929 step:0 g_loss:1.3033885955810547 d_loss:2.2259697914123535 (f_loss=-0.3170967102050781 r_loss=1.0689642429351807 GP=1.474102258682251)
[Training] epoch:929 step:100 g_loss:1.2909072637557983 d_loss:2.818261533975601 (f_loss=-0.32747682929039 r_loss=1.1852946281433105 GP=1.9604437351226807)
[Training] epoch:929 step:200 g_loss:1.2930877208709717 d_loss:1.2512275278568268 (f_loss=-0.31598421931266785 r_loss=1.3135170936584473 GP=0.25369465351104736)
[Training] epoch:929 step:300 g_loss:1.3354167938232422 d_loss:2.5390861332416534 (f_loss=-0.2962838113307953 r_loss=1.1793004274368286 GP=1.6560695171356201)
[Training] epoch:930 step:0 g_loss:1.3030612468719482 d_loss:1.415761560201645 (f_loss=-0.28450652956962585 r_loss=1.2113903760910034 GP=0.48887771368026733)
[Training] epoch:930 step:100 g_loss:1.2959928512573242 d_loss:3.376579225063324 (f_loss=-0.3896661400794983 r_loss=1.01694655418396 GP=2.7492988109588623)
[Training] epoch:930 step:200 g_loss:1.3084611892700195 d_loss:1.214769721031189 (f_loss=-0.3305199146270752 r_loss=1.2717820405960083 GP=0.27350759506225586)
[Training] epoch:930 step:300 g_loss:1.2734416723251343 d_loss:1.178971067070961 (f_loss=-0.27531182765960693 r_loss=1.268040657043457 GP=0.1862422376871109)
[Training] epoch:931 step:0 g_loss:1.2818917036056519 d_loss:1.7221599221229553 (f_loss=-0.2745819687843323 r_loss=1.2788994312286377 GP=0.7178424596786499)
[Training] epoch:931 step:100 g_loss:1.3017598390579224 d_loss:1.203500360250473 (f_loss=-0.3674300014972687 r_loss=1.2987176179885864 GP=0.2722127437591553)
[Training] epoch:931 step:200 g_loss:1.3893799781799316 d_loss:1.8341642022132874 (f_loss=-0.3346490263938904 r_loss=1.1570932865142822 GP=1.0117199420928955)
[Training] epoch:931 step:300 g_loss:1.3272309303283691 d_loss:1.3808314800262451 (f_loss=-0.32470452785491943 r_loss=1.282763123512268 GP=0.4227728843688965)
[Training] epoch:932 step:0 g_loss:1.3618392944335938 d_loss:2.308939754962921 (f_loss=-0.31274956464767456 r_loss=1.2190606594085693 GP=1.4026286602020264)
[Training] epoch:932 step:100 g_loss:1.323930263519287 d_loss:1.2851325273513794 (f_loss=-0.3362623453140259 r_loss=1.2846472263336182 GP=0.3367476463317871)
[Training] epoch:932 step:200 g_loss:1.3458341360092163 d_loss:1.83590829372406 (f_loss=-0.2957814335823059 r_loss=1.2641915082931519 GP=0.8674982190132141)
[Training] epoch:932 step:300 g_loss:1.2863819599151611 d_loss:1.965377390384674 (f_loss=-0.3393017649650574 r_loss=1.1065593957901 GP=1.1981197595596313)
[Training] epoch:933 step:0 g_loss:1.321706771850586 d_loss:1.7466055750846863 (f_loss=-0.3498641848564148 r_loss=1.2245205640792847 GP=0.8719491958618164)
[Training] epoch:933 step:100 g_loss:1.3427420854568481 d_loss:1.8328895270824432 (f_loss=-0.3279992640018463 r_loss=1.251273512840271 GP=0.9096152782440186)
[Training] epoch:933 step:200 g_loss:1.3280127048492432 d_loss:1.393432468175888 (f_loss=-0.3235079348087311 r_loss=1.2693935632705688 GP=0.4475468397140503)
[Training] epoch:933 step:300 g_loss:1.2992557287216187 d_loss:1.6761933267116547 (f_loss=-0.30575916171073914 r_loss=1.2417105436325073 GP=0.7402419447898865)
[Training] epoch:934 step:0 g_loss:1.334203839302063 d_loss:1.7956673502922058 (f_loss=-0.300653338432312 r_loss=1.2319817543029785 GP=0.8643389344215393)
[Training] epoch:934 step:100 g_loss:1.284837245941162 d_loss:2.514848366379738 (f_loss=-0.21205900609493256 r_loss=1.176396369934082 GP=1.5505110025405884)
[Training] epoch:934 step:200 g_loss:1.318361759185791 d_loss:1.3193189799785614 (f_loss=-0.3430177569389343 r_loss=1.2475645542144775 GP=0.4147721827030182)
[Training] epoch:934 step:300 g_loss:1.3116748332977295 d_loss:1.4727744460105896 (f_loss=-0.35387957096099854 r_loss=1.2133997678756714 GP=0.6132542490959167)
[Training] epoch:935 step:0 g_loss:1.3122955560684204 d_loss:1.6533281803131104 (f_loss=-0.3510463833808899 r_loss=1.254588007926941 GP=0.7497865557670593)
[Training] epoch:935 step:100 g_loss:1.2984168529510498 d_loss:1.1519231349229813 (f_loss=-0.23966053128242493 r_loss=1.260244607925415 GP=0.13133905827999115)
[Training] epoch:935 step:200 g_loss:1.3574827909469604 d_loss:1.1590116769075394 (f_loss=-0.30977603793144226 r_loss=1.2340140342712402 GP=0.2347736805677414)
[Training] epoch:935 step:300 g_loss:1.3607314825057983 d_loss:1.5567393898963928 (f_loss=-0.31103241443634033 r_loss=1.2564188241958618 GP=0.6113529801368713)
[Training] epoch:936 step:0 g_loss:1.3625843524932861 d_loss:2.1790005564689636 (f_loss=-0.3472028374671936 r_loss=1.1655702590942383 GP=1.360633134841919)
[Training] epoch:936 step:100 g_loss:1.3529554605484009 d_loss:1.5367445349693298 (f_loss=-0.38183486461639404 r_loss=1.1962491273880005 GP=0.7223302721977234)
[Training] epoch:936 step:200 g_loss:1.3345614671707153 d_loss:1.917586088180542 (f_loss=-0.28656744956970215 r_loss=1.2421953678131104 GP=0.9619581699371338)
[Training] epoch:936 step:300 g_loss:1.327793836593628 d_loss:1.452220380306244 (f_loss=-0.20384210348129272 r_loss=1.3115267753601074 GP=0.3445357084274292)
[Training] epoch:937 step:0 g_loss:1.300258994102478 d_loss:1.58961683511734 (f_loss=-0.2753692865371704 r_loss=1.2858304977416992 GP=0.5791556239128113)
[Training] epoch:937 step:100 g_loss:1.296166181564331 d_loss:1.9272561967372894 (f_loss=-0.3339467942714691 r_loss=1.2762696743011475 GP=0.9849333167076111)
[Training] epoch:937 step:200 g_loss:1.3594990968704224 d_loss:2.8501155972480774 (f_loss=-0.33949702978134155 r_loss=1.1917860507965088 GP=1.9978265762329102)
[Training] epoch:937 step:300 g_loss:1.3081151247024536 d_loss:1.7731099128723145 (f_loss=-0.34017413854599 r_loss=1.2937407493591309 GP=0.8195433020591736)
[Training] epoch:938 step:0 g_loss:1.337639331817627 d_loss:3.1501384675502777 (f_loss=-0.2744225561618805 r_loss=1.035980224609375 GP=2.388580799102783)
[Training] epoch:938 step:100 g_loss:1.286259651184082 d_loss:2.7248047590255737 (f_loss=-0.29524922370910645 r_loss=1.1842453479766846 GP=1.8358086347579956)
[Training] epoch:938 step:200 g_loss:1.3435864448547363 d_loss:1.9652762115001678 (f_loss=-0.25860437750816345 r_loss=1.2421586513519287 GP=0.9817219376564026)
[Training] epoch:938 step:300 g_loss:1.317927360534668 d_loss:3.0442944765090942 (f_loss=-0.32998204231262207 r_loss=1.1627520322799683 GP=2.211524486541748)
[Training] epoch:939 step:0 g_loss:1.2126803398132324 d_loss:1.407943308353424 (f_loss=-0.25935590267181396 r_loss=1.2309988737106323 GP=0.4363003373146057)
[Training] epoch:939 step:100 g_loss:1.2832692861557007 d_loss:1.311309427022934 (f_loss=-0.3026376962661743 r_loss=1.2322295904159546 GP=0.3817175328731537)
[Training] epoch:939 step:200 g_loss:1.3370461463928223 d_loss:2.5606421530246735 (f_loss=-0.3737029731273651 r_loss=1.2318943738937378 GP=1.7024507522583008)
[Training] epoch:939 step:300 g_loss:1.280231237411499 d_loss:1.8776513934135437 (f_loss=-0.35055166482925415 r_loss=1.283785343170166 GP=0.9444177150726318)
[Training] epoch:940 step:0 g_loss:1.3361088037490845 d_loss:1.5001625716686249 (f_loss=-0.2541949450969696 r_loss=1.2324512004852295 GP=0.521906316280365)
[Training] epoch:940 step:100 g_loss:1.313643455505371 d_loss:1.351216346025467 (f_loss=-0.3042319416999817 r_loss=1.3095550537109375 GP=0.3458932340145111)
[Training] epoch:940 step:200 g_loss:1.3132574558258057 d_loss:1.2525669038295746 (f_loss=-0.3219348192214966 r_loss=1.2068599462509155 GP=0.36764177680015564)
[Training] epoch:940 step:300 g_loss:1.3031351566314697 d_loss:1.8983128070831299 (f_loss=-0.36747848987579346 r_loss=1.222907543182373 GP=1.0428837537765503)
[Training] epoch:941 step:0 g_loss:1.3203885555267334 d_loss:2.670208841562271 (f_loss=-0.2566405236721039 r_loss=1.2445738315582275 GP=1.6822755336761475)
[Training] epoch:941 step:100 g_loss:1.3477423191070557 d_loss:1.526229351758957 (f_loss=-0.35333451628685 r_loss=1.311821460723877 GP=0.5677424073219299)
[Training] epoch:941 step:200 g_loss:1.305030345916748 d_loss:1.733632892370224 (f_loss=-0.2816888391971588 r_loss=1.2741005420684814 GP=0.7412211894989014)
[Training] epoch:941 step:300 g_loss:1.2781577110290527 d_loss:2.5352907478809357 (f_loss=-0.3335563838481903 r_loss=1.0542075634002686 GP=1.8146395683288574)
[Training] epoch:942 step:0 g_loss:1.295027256011963 d_loss:1.8582789301872253 (f_loss=-0.26659709215164185 r_loss=1.1040548086166382 GP=1.020821213722229)
[Training] epoch:942 step:100 g_loss:1.309128999710083 d_loss:1.6114983558654785 (f_loss=-0.31971824169158936 r_loss=1.13687264919281 GP=0.7943439483642578)
[Training] epoch:942 step:200 g_loss:1.3115452527999878 d_loss:2.1138301491737366 (f_loss=-0.29802483320236206 r_loss=1.1996301412582397 GP=1.2122248411178589)
[Training] epoch:942 step:300 g_loss:1.2723150253295898 d_loss:1.5322639346122742 (f_loss=-0.3230893611907959 r_loss=1.1752139329910278 GP=0.6801393628120422)
[Training] epoch:943 step:0 g_loss:1.3460599184036255 d_loss:1.414811909198761 (f_loss=-0.35993582010269165 r_loss=1.215741753578186 GP=0.5590059757232666)
[Training] epoch:943 step:100 g_loss:1.3731423616409302 d_loss:2.501228302717209 (f_loss=-0.3662060797214508 r_loss=1.1546781063079834 GP=1.7127562761306763)
[Training] epoch:943 step:200 g_loss:1.3266500234603882 d_loss:1.9524065256118774 (f_loss=-0.34726548194885254 r_loss=1.259506344795227 GP=1.040165662765503)
[Training] epoch:943 step:300 g_loss:1.3658173084259033 d_loss:1.5481805503368378 (f_loss=-0.3168385326862335 r_loss=1.2163639068603516 GP=0.6486551761627197)
[Training] epoch:944 step:0 g_loss:1.306823968887329 d_loss:2.2011180222034454 (f_loss=-0.24244186282157898 r_loss=1.184262752532959 GP=1.2592971324920654)
[Training] epoch:944 step:100 g_loss:1.2911763191223145 d_loss:2.8278907537460327 (f_loss=-0.2927591800689697 r_loss=1.1815016269683838 GP=1.9391483068466187)
[Training] epoch:944 step:200 g_loss:1.411731481552124 d_loss:1.5659025013446808 (f_loss=-0.34393104910850525 r_loss=1.1187394857406616 GP=0.7910940647125244)
[Training] epoch:944 step:300 g_loss:1.2522779703140259 d_loss:1.4452782273292542 (f_loss=-0.311450719833374 r_loss=1.1979074478149414 GP=0.5588214993476868)
[Training] epoch:945 step:0 g_loss:1.2935091257095337 d_loss:1.4111918807029724 (f_loss=-0.29954981803894043 r_loss=1.2031205892562866 GP=0.5076211094856262)
[Training] epoch:945 step:100 g_loss:1.281102180480957 d_loss:1.4281468093395233 (f_loss=-0.3657217025756836 r_loss=1.308098554611206 GP=0.48576995730400085)
[Training] epoch:945 step:200 g_loss:1.277409315109253 d_loss:1.8137252032756805 (f_loss=-0.32486972212791443 r_loss=1.1708401441574097 GP=0.9677547812461853)
[Training] epoch:945 step:300 g_loss:1.3106739521026611 d_loss:2.552888363599777 (f_loss=-0.42889752984046936 r_loss=1.2514832019805908 GP=1.7303026914596558)
[Training] epoch:946 step:0 g_loss:1.371556282043457 d_loss:2.2928041219711304 (f_loss=-0.30203866958618164 r_loss=1.1820542812347412 GP=1.4127885103225708)
[Training] epoch:946 step:100 g_loss:1.3461761474609375 d_loss:4.411361873149872 (f_loss=-0.38083136081695557 r_loss=0.977593719959259 GP=3.8145995140075684)
[Training] epoch:946 step:200 g_loss:1.3164806365966797 d_loss:2.28507661819458 (f_loss=-0.3066720962524414 r_loss=1.180827021598816 GP=1.4109216928482056)
[Training] epoch:946 step:300 g_loss:1.2953565120697021 d_loss:1.126872181892395 (f_loss=-0.40221846103668213 r_loss=1.1921859979629517 GP=0.3369046449661255)
[Training] epoch:947 step:0 g_loss:1.366477131843567 d_loss:1.6727581024169922 (f_loss=-0.2981150150299072 r_loss=1.191551923751831 GP=0.7793211936950684)
[Training] epoch:947 step:100 g_loss:1.3437069654464722 d_loss:1.6107248663902283 (f_loss=-0.37660855054855347 r_loss=1.3152228593826294 GP=0.6721105575561523)
[Training] epoch:947 step:200 g_loss:1.3420966863632202 d_loss:1.6031578183174133 (f_loss=-0.32022708654403687 r_loss=1.2372078895568848 GP=0.6861770153045654)
[Training] epoch:947 step:300 g_loss:1.3911900520324707 d_loss:1.2255253791809082 (f_loss=-0.283983439207077 r_loss=1.2883455753326416 GP=0.22116324305534363)
[Training] epoch:948 step:0 g_loss:1.3526155948638916 d_loss:1.9338488280773163 (f_loss=-0.3772994577884674 r_loss=1.2520467042922974 GP=1.0591015815734863)
[Training] epoch:948 step:100 g_loss:1.3254437446594238 d_loss:1.7277201414108276 (f_loss=-0.3737483620643616 r_loss=1.2917778491973877 GP=0.8096906542778015)
[Training] epoch:948 step:200 g_loss:1.3254938125610352 d_loss:4.047339677810669 (f_loss=-0.35350608825683594 r_loss=1.1547977924346924 GP=3.2460479736328125)
[Training] epoch:948 step:300 g_loss:1.3961877822875977 d_loss:1.8079749941825867 (f_loss=-0.3379669189453125 r_loss=1.2497291564941406 GP=0.8962127566337585)
[Training] epoch:949 step:0 g_loss:1.327467918395996 d_loss:3.17453870177269 (f_loss=-0.3639815151691437 r_loss=1.0581353902816772 GP=2.4803848266601562)
[Training] epoch:949 step:100 g_loss:1.3115973472595215 d_loss:1.4623828530311584 (f_loss=-0.27685314416885376 r_loss=1.2315092086791992 GP=0.507726788520813)
[Training] epoch:949 step:200 g_loss:1.3369158506393433 d_loss:1.2162220776081085 (f_loss=-0.27118074893951416 r_loss=1.2702243328094482 GP=0.21717849373817444)
[Training] epoch:949 step:300 g_loss:1.3209738731384277 d_loss:1.615083634853363 (f_loss=-0.34390270709991455 r_loss=1.1596794128417969 GP=0.7993069291114807)
[Training] epoch:950 step:0 g_loss:1.3216392993927002 d_loss:1.9302769154310226 (f_loss=-0.22573484480381012 r_loss=1.2074220180511475 GP=0.9485897421836853)
[Training] epoch:950 step:100 g_loss:1.2414820194244385 d_loss:1.8130211234092712 (f_loss=-0.3010026216506958 r_loss=1.2727196216583252 GP=0.8413041234016418)
[Training] epoch:950 step:200 g_loss:1.3104453086853027 d_loss:2.0758211612701416 (f_loss=-0.3719804286956787 r_loss=0.9661977291107178 GP=1.4816038608551025)
[Training] epoch:950 step:300 g_loss:1.3017308712005615 d_loss:1.6053102612495422 (f_loss=-0.25006771087646484 r_loss=1.1999924182891846 GP=0.6553855538368225)
[Training] epoch:951 step:0 g_loss:1.3163442611694336 d_loss:1.8414752185344696 (f_loss=-0.3460609018802643 r_loss=1.1729527711868286 GP=1.0145833492279053)
[Training] epoch:951 step:100 g_loss:1.2941259145736694 d_loss:1.9317871034145355 (f_loss=-0.33321598172187805 r_loss=1.193206787109375 GP=1.0717962980270386)
[Training] epoch:951 step:200 g_loss:1.344353199005127 d_loss:1.542612612247467 (f_loss=-0.2863263487815857 r_loss=1.2317264080047607 GP=0.597212553024292)
[Training] epoch:951 step:300 g_loss:1.2845317125320435 d_loss:2.154128074645996 (f_loss=-0.34407055377960205 r_loss=1.2277735471725464 GP=1.2704250812530518)
[Training] epoch:952 step:0 g_loss:1.2219500541687012 d_loss:2.403300106525421 (f_loss=-0.27796560525894165 r_loss=1.2663387060165405 GP=1.4149270057678223)
[Training] epoch:952 step:100 g_loss:1.3157320022583008 d_loss:1.5954561233520508 (f_loss=-0.28396642208099365 r_loss=1.1900372505187988 GP=0.6893852949142456)
[Training] epoch:952 step:200 g_loss:1.3505994081497192 d_loss:1.5542492270469666 (f_loss=-0.3831552267074585 r_loss=1.1225510835647583 GP=0.8148533701896667)
[Training] epoch:952 step:300 g_loss:1.2933838367462158 d_loss:1.555861622095108 (f_loss=-0.33630672097206116 r_loss=1.2084864377975464 GP=0.6836819052696228)
[Training] epoch:953 step:0 g_loss:1.372187852859497 d_loss:1.2745190560817719 (f_loss=-0.45290103554725647 r_loss=1.2074936628341675 GP=0.5199264287948608)
[Training] epoch:953 step:100 g_loss:1.3701598644256592 d_loss:1.7267169952392578 (f_loss=-0.2948298454284668 r_loss=1.2951457500457764 GP=0.7264010906219482)
[Training] epoch:953 step:200 g_loss:1.3179978132247925 d_loss:1.6643021702766418 (f_loss=-0.3379310369491577 r_loss=1.2377711534500122 GP=0.7644620537757874)
[Training] epoch:953 step:300 g_loss:1.303675651550293 d_loss:1.320835530757904 (f_loss=-0.2909359931945801 r_loss=1.286899447441101 GP=0.32487207651138306)
[Training] epoch:954 step:0 g_loss:1.3620315790176392 d_loss:1.4828472137451172 (f_loss=-0.39416611194610596 r_loss=1.2159045934677124 GP=0.6611087322235107)
[Training] epoch:954 step:100 g_loss:1.3517911434173584 d_loss:2.018375962972641 (f_loss=-0.3339109718799591 r_loss=1.1547869443893433 GP=1.1974999904632568)
[Training] epoch:954 step:200 g_loss:1.349856972694397 d_loss:2.9602034389972687 (f_loss=-0.38417086005210876 r_loss=1.2175935506820679 GP=2.1267807483673096)
[Training] epoch:954 step:300 g_loss:1.3411450386047363 d_loss:1.7243108451366425 (f_loss=-0.32166650891304016 r_loss=1.1698126792907715 GP=0.8761646747589111)
[Training] epoch:955 step:0 g_loss:1.2586681842803955 d_loss:1.363783597946167 (f_loss=-0.3074420690536499 r_loss=1.2405695915222168 GP=0.4306560754776001)
[Training] epoch:955 step:100 g_loss:1.2883034944534302 d_loss:2.302729070186615 (f_loss=-0.3490498661994934 r_loss=1.1452374458312988 GP=1.5065414905548096)
[Training] epoch:955 step:200 g_loss:1.279306411743164 d_loss:2.320567160844803 (f_loss=-0.384691447019577 r_loss=1.144395112991333 GP=1.5608634948730469)
[Training] epoch:955 step:300 g_loss:1.3123784065246582 d_loss:1.4673628211021423 (f_loss=-0.31197625398635864 r_loss=1.2462825775146484 GP=0.5330564975738525)
[Training] epoch:956 step:0 g_loss:1.3294215202331543 d_loss:2.8766125440597534 (f_loss=-0.287922739982605 r_loss=1.1608517169952393 GP=2.003683567047119)
[Training] epoch:956 step:100 g_loss:1.3084861040115356 d_loss:1.1861058920621872 (f_loss=-0.29792243242263794 r_loss=1.313040852546692 GP=0.17098747193813324)
[Training] epoch:956 step:200 g_loss:1.3477847576141357 d_loss:2.1791364550590515 (f_loss=-0.38650065660476685 r_loss=1.2257086038589478 GP=1.3399285078048706)
[Training] epoch:956 step:300 g_loss:1.3295085430145264 d_loss:1.5101472735404968 (f_loss=-0.337216854095459 r_loss=1.2348175048828125 GP=0.6125466227531433)
[Training] epoch:957 step:0 g_loss:1.3101298809051514 d_loss:1.6516303420066833 (f_loss=-0.29488104581832886 r_loss=1.275618553161621 GP=0.6708928346633911)
[Training] epoch:957 step:100 g_loss:1.3111450672149658 d_loss:2.582299292087555 (f_loss=-0.3102661967277527 r_loss=1.1493293046951294 GP=1.7432361841201782)
[Training] epoch:957 step:200 g_loss:1.2946367263793945 d_loss:1.8285054862499237 (f_loss=-0.2914973795413971 r_loss=1.111443042755127 GP=1.0085598230361938)
[Training] epoch:957 step:300 g_loss:1.3959336280822754 d_loss:1.393096685409546 (f_loss=-0.3498772382736206 r_loss=1.2378062009811401 GP=0.5051677227020264)
[Training] epoch:958 step:0 g_loss:1.3263835906982422 d_loss:1.6182620525360107 (f_loss=-0.30717235803604126 r_loss=1.1884715557098389 GP=0.7369628548622131)
[Training] epoch:958 step:100 g_loss:1.3041185140609741 d_loss:1.3930084109306335 (f_loss=-0.31258994340896606 r_loss=1.2146639823913574 GP=0.4909343719482422)
[Training] epoch:958 step:200 g_loss:1.2569057941436768 d_loss:3.0925505459308624 (f_loss=-0.3474677503108978 r_loss=1.2599598169326782 GP=2.180058479309082)
[Training] epoch:958 step:300 g_loss:1.3854745626449585 d_loss:1.9150316417217255 (f_loss=-0.3734373152256012 r_loss=1.1297231912612915 GP=1.1587457656860352)
[Training] epoch:959 step:0 g_loss:1.343007206916809 d_loss:1.717810332775116 (f_loss=-0.34408968687057495 r_loss=1.2446436882019043 GP=0.8172563314437866)
[Training] epoch:959 step:100 g_loss:1.3197563886642456 d_loss:1.4765656292438507 (f_loss=-0.3835313022136688 r_loss=1.183669924736023 GP=0.6764270067214966)
[Training] epoch:959 step:200 g_loss:1.2924047708511353 d_loss:2.2253008484840393 (f_loss=-0.27989643812179565 r_loss=1.2741730213165283 GP=1.2310242652893066)
[Training] epoch:959 step:300 g_loss:1.3405210971832275 d_loss:1.5547946989536285 (f_loss=-0.34193989634513855 r_loss=1.1699156761169434 GP=0.7268189191818237)
[Training] epoch:960 step:0 g_loss:1.3438574075698853 d_loss:1.6677822768688202 (f_loss=-0.337972491979599 r_loss=1.1575735807418823 GP=0.8481811881065369)
[Training] epoch:960 step:100 g_loss:1.2990493774414062 d_loss:1.7494215667247772 (f_loss=-0.31092360615730286 r_loss=1.2128962278366089 GP=0.8474489450454712)
[Training] epoch:960 step:200 g_loss:1.3559659719467163 d_loss:1.3880214393138885 (f_loss=-0.3538675010204315 r_loss=1.2462083101272583 GP=0.49568063020706177)
[Training] epoch:960 step:300 g_loss:1.33247709274292 d_loss:2.015904575586319 (f_loss=-0.2946414649486542 r_loss=1.1706287860870361 GP=1.139917254447937)
[Training] epoch:961 step:0 g_loss:1.3220243453979492 d_loss:1.4948232471942902 (f_loss=-0.28377148509025574 r_loss=1.2450346946716309 GP=0.533560037612915)
[Training] epoch:961 step:100 g_loss:1.2789512872695923 d_loss:1.3416066467761993 (f_loss=-0.32748863101005554 r_loss=1.3292375802993774 GP=0.33985769748687744)
[Training] epoch:961 step:200 g_loss:1.348598837852478 d_loss:1.4491054713726044 (f_loss=-0.27172568440437317 r_loss=1.2208216190338135 GP=0.5000095367431641)
[Training] epoch:961 step:300 g_loss:1.2886788845062256 d_loss:3.180981397628784 (f_loss=-0.3297877311706543 r_loss=1.1184813976287842 GP=2.3922877311706543)
[Training] epoch:962 step:0 g_loss:1.2517507076263428 d_loss:1.5252083539962769 (f_loss=-0.3980206251144409 r_loss=1.2222744226455688 GP=0.7009545564651489)
[Training] epoch:962 step:100 g_loss:1.3059074878692627 d_loss:1.459560602903366 (f_loss=-0.30108341574668884 r_loss=1.1846177577972412 GP=0.5760262608528137)
[Training] epoch:962 step:200 g_loss:1.2823206186294556 d_loss:1.7583483159542084 (f_loss=-0.27385804057121277 r_loss=1.203413963317871 GP=0.82879239320755)
[Training] epoch:962 step:300 g_loss:1.3506771326065063 d_loss:1.2871827185153961 (f_loss=-0.3498654365539551 r_loss=1.3544237613677979 GP=0.28262439370155334)
[Training] epoch:963 step:0 g_loss:1.4099018573760986 d_loss:1.6849350035190582 (f_loss=-0.36119046807289124 r_loss=1.259926438331604 GP=0.7861990332603455)
[Training] epoch:963 step:100 g_loss:1.323862910270691 d_loss:1.6011832356452942 (f_loss=-0.3150848150253296 r_loss=1.2166332006454468 GP=0.699634850025177)
[Training] epoch:963 step:200 g_loss:1.300209403038025 d_loss:1.8127429783344269 (f_loss=-0.24168577790260315 r_loss=1.1305707693099976 GP=0.9238579869270325)
[Training] epoch:963 step:300 g_loss:1.3304462432861328 d_loss:1.4601113200187683 (f_loss=-0.35044121742248535 r_loss=1.2200754880905151 GP=0.5904770493507385)
[Training] epoch:964 step:0 g_loss:1.3690894842147827 d_loss:1.7768175601959229 (f_loss=-0.37520110607147217 r_loss=1.1808772087097168 GP=0.9711414575576782)
[Training] epoch:964 step:100 g_loss:1.313742756843567 d_loss:1.5423764884471893 (f_loss=-0.2497323453426361 r_loss=1.220056176185608 GP=0.5720526576042175)
[Training] epoch:964 step:200 g_loss:1.3276509046554565 d_loss:1.662473887205124 (f_loss=-0.3445052206516266 r_loss=1.3136241436004639 GP=0.6933549642562866)
[Training] epoch:964 step:300 g_loss:1.3537362813949585 d_loss:1.9708189368247986 (f_loss=-0.3244466185569763 r_loss=1.1192504167556763 GP=1.1760151386260986)
[Training] epoch:965 step:0 g_loss:1.2677152156829834 d_loss:1.4174896478652954 (f_loss=-0.3239571452140808 r_loss=1.315384864807129 GP=0.4260619282722473)
[Training] epoch:965 step:100 g_loss:1.2579197883605957 d_loss:1.4359108805656433 (f_loss=-0.3386465311050415 r_loss=1.1671115159988403 GP=0.6074458956718445)
[Training] epoch:965 step:200 g_loss:1.336315393447876 d_loss:1.37409245967865 (f_loss=-0.3081073760986328 r_loss=1.1818931102752686 GP=0.5003067255020142)
[Training] epoch:965 step:300 g_loss:1.3292220830917358 d_loss:1.7402613461017609 (f_loss=-0.2929644286632538 r_loss=1.2215523719787598 GP=0.8116734027862549)
[Training] epoch:966 step:0 g_loss:1.322140097618103 d_loss:1.5087076425552368 (f_loss=-0.29212647676467896 r_loss=1.205401062965393 GP=0.5954330563545227)
[Training] epoch:966 step:100 g_loss:1.3062878847122192 d_loss:1.8695130944252014 (f_loss=-0.298251748085022 r_loss=1.2687911987304688 GP=0.8989736437797546)
[Training] epoch:966 step:200 g_loss:1.330761194229126 d_loss:1.4574844241142273 (f_loss=-0.2856147289276123 r_loss=1.1699910163879395 GP=0.5731081366539001)
[Training] epoch:966 step:300 g_loss:1.3444766998291016 d_loss:1.378766417503357 (f_loss=-0.34836453199386597 r_loss=1.3189208507537842 GP=0.4082100987434387)
[Training] epoch:967 step:0 g_loss:1.2504061460494995 d_loss:1.8712185621261597 (f_loss=-0.3762592077255249 r_loss=1.1590158939361572 GP=1.0884618759155273)
[Training] epoch:967 step:100 g_loss:1.370443344116211 d_loss:1.3970443904399872 (f_loss=-0.31742382049560547 r_loss=1.270400047302246 GP=0.44406816363334656)
[Training] epoch:967 step:200 g_loss:1.3435518741607666 d_loss:1.3749198019504547 (f_loss=-0.32989007234573364 r_loss=1.2281641960144043 GP=0.47664567828178406)
[Training] epoch:967 step:300 g_loss:1.252726674079895 d_loss:2.395036667585373 (f_loss=-0.33749285340309143 r_loss=1.094396710395813 GP=1.6381328105926514)
[Training] epoch:968 step:0 g_loss:1.2981789112091064 d_loss:1.1525952368974686 (f_loss=-0.2694215178489685 r_loss=1.2295992374420166 GP=0.19241751730442047)
[Training] epoch:968 step:100 g_loss:1.299548625946045 d_loss:1.5324366986751556 (f_loss=-0.25963446497917175 r_loss=1.3391432762145996 GP=0.4529278874397278)
[Training] epoch:968 step:200 g_loss:1.3381080627441406 d_loss:1.408553808927536 (f_loss=-0.27649232745170593 r_loss=1.2710928916931152 GP=0.4139532446861267)
[Training] epoch:968 step:300 g_loss:1.2994310855865479 d_loss:1.7155844271183014 (f_loss=-0.3014355003833771 r_loss=1.274746298789978 GP=0.7422736287117004)
[Training] epoch:969 step:0 g_loss:1.3788282871246338 d_loss:1.6170912981033325 (f_loss=-0.4001467823982239 r_loss=1.0283401012420654 GP=0.988897979259491)
[Training] epoch:969 step:100 g_loss:1.3632831573486328 d_loss:1.3317296206951141 (f_loss=-0.2732333540916443 r_loss=1.3313871622085571 GP=0.2735758125782013)
[Training] epoch:969 step:200 g_loss:1.311216115951538 d_loss:1.2539003193378448 (f_loss=-0.350044846534729 r_loss=1.215274453163147 GP=0.3886707127094269)
[Training] epoch:969 step:300 g_loss:1.2884654998779297 d_loss:1.5325599312782288 (f_loss=-0.3443577289581299 r_loss=1.2249534130096436 GP=0.6519642472267151)
[Training] epoch:970 step:0 g_loss:1.367681860923767 d_loss:1.4781027734279633 (f_loss=-0.3654647171497345 r_loss=1.188014030456543 GP=0.6555534601211548)
[Training] epoch:970 step:100 g_loss:1.361881136894226 d_loss:1.164141684770584 (f_loss=-0.33847782015800476 r_loss=1.2357736825942993 GP=0.26684582233428955)
[Training] epoch:970 step:200 g_loss:1.2672473192214966 d_loss:1.4471233487129211 (f_loss=-0.31857216358184814 r_loss=1.229273796081543 GP=0.5364217162132263)
[Training] epoch:970 step:300 g_loss:1.377919316291809 d_loss:2.280984342098236 (f_loss=-0.31456106901168823 r_loss=1.0905342102050781 GP=1.5050112009048462)
[Training] epoch:971 step:0 g_loss:1.3177906274795532 d_loss:1.5716764628887177 (f_loss=-0.39787301421165466 r_loss=1.2628324031829834 GP=0.7067170739173889)
[Training] epoch:971 step:100 g_loss:1.362187147140503 d_loss:1.7288450598716736 (f_loss=-0.29606568813323975 r_loss=1.1789021492004395 GP=0.8460085988044739)
[Training] epoch:971 step:200 g_loss:1.3605912923812866 d_loss:2.0992704033851624 (f_loss=-0.3628787398338318 r_loss=1.1010048389434814 GP=1.3611443042755127)
[Training] epoch:971 step:300 g_loss:1.216565489768982 d_loss:2.8913905322551727 (f_loss=-0.3986654579639435 r_loss=1.1954586505889893 GP=2.094597339630127)
[Training] epoch:972 step:0 g_loss:1.3155763149261475 d_loss:1.3648476600646973 (f_loss=-0.3502686023712158 r_loss=1.339025616645813 GP=0.3760906457901001)
[Training] epoch:972 step:100 g_loss:1.2868648767471313 d_loss:1.821224331855774 (f_loss=-0.40613269805908203 r_loss=1.3158966302871704 GP=0.9114603996276855)
[Training] epoch:972 step:200 g_loss:1.3402005434036255 d_loss:1.6149948239326477 (f_loss=-0.3624194860458374 r_loss=1.2937463521957397 GP=0.6836679577827454)
[Training] epoch:972 step:300 g_loss:1.3546384572982788 d_loss:1.4706618785858154 (f_loss=-0.27039408683776855 r_loss=1.3199241161346436 GP=0.42113184928894043)
[Training] epoch:973 step:0 g_loss:1.202968716621399 d_loss:1.6580540537834167 (f_loss=-0.36170268058776855 r_loss=1.3588919639587402 GP=0.6608647704124451)
[Training] epoch:973 step:100 g_loss:1.3279953002929688 d_loss:1.3540073037147522 (f_loss=-0.3780841827392578 r_loss=1.2473963499069214 GP=0.4846951365470886)
[Training] epoch:973 step:200 g_loss:1.389238715171814 d_loss:1.7920929491519928 (f_loss=-0.36781933903694153 r_loss=1.2240890264511108 GP=0.9358232617378235)
[Training] epoch:973 step:300 g_loss:1.3214815855026245 d_loss:1.130033254623413 (f_loss=-0.3818973898887634 r_loss=1.271846890449524 GP=0.2400837540626526)
[Training] epoch:974 step:0 g_loss:1.35489022731781 d_loss:1.056145340204239 (f_loss=-0.41271597146987915 r_loss=1.30238676071167 GP=0.16647455096244812)
[Training] epoch:974 step:100 g_loss:1.2660919427871704 d_loss:2.9065035581588745 (f_loss=-0.31688177585601807 r_loss=1.263322114944458 GP=1.9600632190704346)
[Training] epoch:974 step:200 g_loss:1.3728886842727661 d_loss:2.3162978887557983 (f_loss=-0.39125335216522217 r_loss=1.2608623504638672 GP=1.4466888904571533)
[Training] epoch:974 step:300 g_loss:1.309159278869629 d_loss:2.006495237350464 (f_loss=-0.2983604669570923 r_loss=1.2858588695526123 GP=1.0189968347549438)
[Training] epoch:975 step:0 g_loss:1.3600990772247314 d_loss:1.4248597025871277 (f_loss=-0.3087104558944702 r_loss=1.228528618812561 GP=0.5050415396690369)
[Training] epoch:975 step:100 g_loss:1.3893895149230957 d_loss:1.928377628326416 (f_loss=-0.3623238801956177 r_loss=1.0638458728790283 GP=1.2268556356430054)
[Training] epoch:975 step:200 g_loss:1.2866144180297852 d_loss:2.030729651451111 (f_loss=-0.2934870719909668 r_loss=1.247607707977295 GP=1.0766090154647827)
[Training] epoch:975 step:300 g_loss:1.3605220317840576 d_loss:1.7581101059913635 (f_loss=-0.255073606967926 r_loss=1.3274500370025635 GP=0.6857336759567261)
[Training] epoch:976 step:0 g_loss:1.2917048931121826 d_loss:2.3820170760154724 (f_loss=-0.3102484345436096 r_loss=1.1421496868133545 GP=1.5501158237457275)
[Training] epoch:976 step:100 g_loss:1.356082558631897 d_loss:1.4016608893871307 (f_loss=-0.33411937952041626 r_loss=1.2542805671691895 GP=0.48149970173835754)
[Training] epoch:976 step:200 g_loss:1.3947370052337646 d_loss:1.3414527773857117 (f_loss=-0.284511923789978 r_loss=1.288405179977417 GP=0.3375595211982727)
[Training] epoch:976 step:300 g_loss:1.3507740497589111 d_loss:1.6160761713981628 (f_loss=-0.35269927978515625 r_loss=1.3121793270111084 GP=0.6565961241722107)
[Training] epoch:977 step:0 g_loss:1.3631207942962646 d_loss:2.0305136144161224 (f_loss=-0.31576529145240784 r_loss=1.3075542449951172 GP=1.038724660873413)
[Training] epoch:977 step:100 g_loss:1.340516448020935 d_loss:1.6706900596618652 (f_loss=-0.2862442135810852 r_loss=1.276723027229309 GP=0.6802112460136414)
[Training] epoch:977 step:200 g_loss:1.3697707653045654 d_loss:1.5999785959720612 (f_loss=-0.3405478894710541 r_loss=1.2945845127105713 GP=0.645941972732544)
[Training] epoch:977 step:300 g_loss:1.3037002086639404 d_loss:1.401845008134842 (f_loss=-0.3156432807445526 r_loss=1.194490671157837 GP=0.5229976177215576)
[Training] epoch:978 step:0 g_loss:1.340299129486084 d_loss:1.3392831981182098 (f_loss=-0.32978686690330505 r_loss=1.1722285747528076 GP=0.4968414902687073)
[Training] epoch:978 step:100 g_loss:1.35508394241333 d_loss:2.35481995344162 (f_loss=-0.30090445280075073 r_loss=1.188241958618164 GP=1.4674824476242065)
[Training] epoch:978 step:200 g_loss:1.357698917388916 d_loss:1.754348635673523 (f_loss=-0.3369707465171814 r_loss=1.1504013538360596 GP=0.9409180283546448)
[Training] epoch:978 step:300 g_loss:1.3220183849334717 d_loss:1.8262385129928589 (f_loss=-0.39415740966796875 r_loss=1.3030519485473633 GP=0.9173439741134644)
[Training] epoch:979 step:0 g_loss:1.3967022895812988 d_loss:2.209566652774811 (f_loss=-0.33394938707351685 r_loss=1.1621558666229248 GP=1.3813601732254028)
[Training] epoch:979 step:100 g_loss:1.3123116493225098 d_loss:1.526040643453598 (f_loss=-0.3456971347332001 r_loss=1.3183784484863281 GP=0.55335932970047)
[Training] epoch:979 step:200 g_loss:1.4084208011627197 d_loss:1.1849868595600128 (f_loss=-0.29583340883255005 r_loss=1.259289026260376 GP=0.2215312421321869)
[Training] epoch:979 step:300 g_loss:1.3247766494750977 d_loss:1.5377578437328339 (f_loss=-0.35909417271614075 r_loss=1.2203549146652222 GP=0.6764971017837524)
[Training] epoch:980 step:0 g_loss:1.3174350261688232 d_loss:1.3945018649101257 (f_loss=-0.4301832318305969 r_loss=1.283327579498291 GP=0.5413575172424316)
[Training] epoch:980 step:100 g_loss:1.4331648349761963 d_loss:3.757196754217148 (f_loss=-0.3512139618396759 r_loss=1.0046128034591675 GP=3.1037979125976562)
[Training] epoch:980 step:200 g_loss:1.3261785507202148 d_loss:1.5326841473579407 (f_loss=-0.3179599642753601 r_loss=1.271763563156128 GP=0.5788805484771729)
[Training] epoch:980 step:300 g_loss:1.276268482208252 d_loss:1.931453824043274 (f_loss=-0.35064971446990967 r_loss=1.1585485935211182 GP=1.1235549449920654)
[Training] epoch:981 step:0 g_loss:1.356937289237976 d_loss:1.5821048319339752 (f_loss=-0.2944045960903168 r_loss=1.1408460140228271 GP=0.7356634140014648)
[Training] epoch:981 step:100 g_loss:1.3086681365966797 d_loss:1.5262011289596558 (f_loss=-0.3185369372367859 r_loss=1.1630843877792358 GP=0.6816536784172058)
[Training] epoch:981 step:200 g_loss:1.294274091720581 d_loss:1.6488592028617859 (f_loss=-0.3453085422515869 r_loss=1.2137302160263062 GP=0.7804375290870667)
[Training] epoch:981 step:300 g_loss:1.2981109619140625 d_loss:1.2632330060005188 (f_loss=-0.34207016229629517 r_loss=1.270226240158081 GP=0.3350769281387329)
[Training] epoch:982 step:0 g_loss:1.3746628761291504 d_loss:2.5483442842960358 (f_loss=-0.33806928992271423 r_loss=1.2125530242919922 GP=1.6738605499267578)
[Training] epoch:982 step:100 g_loss:1.2850942611694336 d_loss:1.6751427054405212 (f_loss=-0.314014196395874 r_loss=1.2168803215026855 GP=0.7722765803337097)
[Training] epoch:982 step:200 g_loss:1.3581904172897339 d_loss:1.4693233966827393 (f_loss=-0.31712883710861206 r_loss=1.184945821762085 GP=0.6015064120292664)
[Training] epoch:982 step:300 g_loss:1.299091100692749 d_loss:2.193257123231888 (f_loss=-0.2758621871471405 r_loss=1.010108470916748 GP=1.4590108394622803)
[Training] epoch:983 step:0 g_loss:1.3753833770751953 d_loss:1.3056754171848297 (f_loss=-0.3144092857837677 r_loss=1.2155386209487915 GP=0.4045460820198059)
[Training] epoch:983 step:100 g_loss:1.335463047027588 d_loss:1.6418072283267975 (f_loss=-0.33092817664146423 r_loss=1.2994072437286377 GP=0.673328161239624)
[Training] epoch:983 step:200 g_loss:1.2850019931793213 d_loss:1.3147318363189697 (f_loss=-0.33058637380599976 r_loss=1.2715070247650146 GP=0.37381118535995483)
[Training] epoch:983 step:300 g_loss:1.3623223304748535 d_loss:1.6306122541427612 (f_loss=-0.36549365520477295 r_loss=1.3000922203063965 GP=0.6960136890411377)
[Training] epoch:984 step:0 g_loss:1.428651213645935 d_loss:2.872803807258606 (f_loss=-0.3515486717224121 r_loss=1.1764565706253052 GP=2.047895908355713)
[Training] epoch:984 step:100 g_loss:1.3803927898406982 d_loss:1.6624983251094818 (f_loss=-0.41465213894844055 r_loss=1.2342506647109985 GP=0.8428997993469238)
[Training] epoch:984 step:200 g_loss:1.388828158378601 d_loss:1.341627687215805 (f_loss=-0.36669018864631653 r_loss=1.2402021884918213 GP=0.4681156873703003)
[Training] epoch:984 step:300 g_loss:1.399567723274231 d_loss:1.5161103010177612 (f_loss=-0.3620363473892212 r_loss=1.2643309831619263 GP=0.6138156652450562)
[Training] epoch:985 step:0 g_loss:1.3377432823181152 d_loss:2.603673994541168 (f_loss=-0.35645121335983276 r_loss=1.3122570514678955 GP=1.6478681564331055)
[Training] epoch:985 step:100 g_loss:1.3836758136749268 d_loss:1.4031639099121094 (f_loss=-0.32976034283638 r_loss=1.305793046951294 GP=0.42713120579719543)
[Training] epoch:985 step:200 g_loss:1.3228938579559326 d_loss:2.0307157039642334 (f_loss=-0.373035192489624 r_loss=1.264007568359375 GP=1.1397433280944824)
[Training] epoch:985 step:300 g_loss:1.291882872581482 d_loss:2.5140967071056366 (f_loss=-0.2859572470188141 r_loss=1.1349719762802124 GP=1.6650819778442383)
[Training] epoch:986 step:0 g_loss:1.350730299949646 d_loss:1.5010572373867035 (f_loss=-0.3248003423213959 r_loss=1.256418228149414 GP=0.5694393515586853)
[Training] epoch:986 step:100 g_loss:1.3444948196411133 d_loss:1.9823707342147827 (f_loss=-0.3314608335494995 r_loss=1.1735658645629883 GP=1.140265703201294)
[Training] epoch:986 step:200 g_loss:1.3072311878204346 d_loss:2.384240299463272 (f_loss=-0.34961220622062683 r_loss=1.2278993129730225 GP=1.5059531927108765)
[Training] epoch:986 step:300 g_loss:1.3219726085662842 d_loss:1.5731003880500793 (f_loss=-0.402147114276886 r_loss=1.2070465087890625 GP=0.7682009935379028)
[Training] epoch:987 step:0 g_loss:1.2853116989135742 d_loss:1.4580942690372467 (f_loss=-0.3432473838329315 r_loss=1.1360350847244263 GP=0.665306568145752)
[Training] epoch:987 step:100 g_loss:1.3367984294891357 d_loss:1.4198348820209503 (f_loss=-0.28903329372406006 r_loss=1.3290005922317505 GP=0.3798675835132599)
[Training] epoch:987 step:200 g_loss:1.3048725128173828 d_loss:1.3918873369693756 (f_loss=-0.30799633264541626 r_loss=1.2434625625610352 GP=0.4564211070537567)
[Training] epoch:987 step:300 g_loss:1.395273208618164 d_loss:1.5587101578712463 (f_loss=-0.3174968957901001 r_loss=1.274185299873352 GP=0.6020217537879944)
[Training] epoch:988 step:0 g_loss:1.3040385246276855 d_loss:1.497241586446762 (f_loss=-0.30760064721107483 r_loss=1.194461703300476 GP=0.6103805303573608)
[Training] epoch:988 step:100 g_loss:1.3470845222473145 d_loss:2.0682284235954285 (f_loss=-0.30843979120254517 r_loss=1.2943453788757324 GP=1.0823228359222412)
[Training] epoch:988 step:200 g_loss:1.2969613075256348 d_loss:1.5235331058502197 (f_loss=-0.30755871534347534 r_loss=1.2380971908569336 GP=0.5929946303367615)
[Training] epoch:988 step:300 g_loss:1.3264577388763428 d_loss:1.8173888325691223 (f_loss=-0.31479495763778687 r_loss=1.181394338607788 GP=0.9507894515991211)
[Training] epoch:989 step:0 g_loss:1.2737016677856445 d_loss:1.8224957287311554 (f_loss=-0.42780861258506775 r_loss=1.2061834335327148 GP=1.0441209077835083)
[Training] epoch:989 step:100 g_loss:1.3278199434280396 d_loss:1.6624541580677032 (f_loss=-0.3570959270000458 r_loss=1.1778297424316406 GP=0.8417203426361084)
[Training] epoch:989 step:200 g_loss:1.3435019254684448 d_loss:1.718008428812027 (f_loss=-0.3505813777446747 r_loss=1.2459990978240967 GP=0.822590708732605)
[Training] epoch:989 step:300 g_loss:1.3649702072143555 d_loss:1.7403507828712463 (f_loss=-0.36602556705474854 r_loss=1.166979432106018 GP=0.9393969178199768)
[Training] epoch:990 step:0 g_loss:1.391517162322998 d_loss:1.4725704789161682 (f_loss=-0.3752535581588745 r_loss=1.2746992111206055 GP=0.5731248259544373)
[Training] epoch:990 step:100 g_loss:1.3790645599365234 d_loss:2.334605574607849 (f_loss=-0.4201235771179199 r_loss=1.2834272384643555 GP=1.4713019132614136)
[Training] epoch:990 step:200 g_loss:1.3554121255874634 d_loss:1.475038319826126 (f_loss=-0.3226655423641205 r_loss=1.1472474336624146 GP=0.650456428527832)
[Training] epoch:990 step:300 g_loss:1.3811228275299072 d_loss:2.3118527829647064 (f_loss=-0.3381740152835846 r_loss=1.1779279708862305 GP=1.4720988273620605)
[Training] epoch:991 step:0 g_loss:1.3126519918441772 d_loss:1.8995306342840195 (f_loss=-0.24326004087924957 r_loss=1.173448085784912 GP=0.9693425893783569)
[Training] epoch:991 step:100 g_loss:1.3811835050582886 d_loss:2.629290997982025 (f_loss=-0.3231274485588074 r_loss=1.0718952417373657 GP=1.8805232048034668)
[Training] epoch:991 step:200 g_loss:1.3168861865997314 d_loss:1.2129172682762146 (f_loss=-0.3798658549785614 r_loss=1.2667372226715088 GP=0.3260459005832672)
[Training] epoch:991 step:300 g_loss:1.4347699880599976 d_loss:1.9529320895671844 (f_loss=-0.34796562790870667 r_loss=1.2435617446899414 GP=1.0573359727859497)
[Training] epoch:992 step:0 g_loss:1.36907958984375 d_loss:3.1539230942726135 (f_loss=-0.44710999727249146 r_loss=1.0330387353897095 GP=2.5679943561553955)
[Training] epoch:992 step:100 g_loss:1.3344088792800903 d_loss:1.3656572103500366 (f_loss=-0.31321948766708374 r_loss=1.282381296157837 GP=0.39649540185928345)
[Training] epoch:992 step:200 g_loss:1.3810338973999023 d_loss:2.2010557651519775 (f_loss=-0.3162928819656372 r_loss=1.1665685176849365 GP=1.3507801294326782)
[Training] epoch:992 step:300 g_loss:1.3575334548950195 d_loss:1.4726516008377075 (f_loss=-0.44044065475463867 r_loss=1.307486891746521 GP=0.6056053638458252)
[Training] epoch:993 step:0 g_loss:1.3420010805130005 d_loss:1.9752854406833649 (f_loss=-0.28174206614494324 r_loss=1.2678812742233276 GP=0.9891462326049805)
[Training] epoch:993 step:100 g_loss:1.3733646869659424 d_loss:2.2839511334896088 (f_loss=-0.34005191922187805 r_loss=1.2492296695709229 GP=1.374773383140564)
[Training] epoch:993 step:200 g_loss:1.3735305070877075 d_loss:1.7910271286964417 (f_loss=-0.36447495222091675 r_loss=1.256425380706787 GP=0.8990767002105713)
[Training] epoch:993 step:300 g_loss:1.3177070617675781 d_loss:2.1401267051696777 (f_loss=-0.35019993782043457 r_loss=1.2346305847167969 GP=1.2556960582733154)
[Training] epoch:994 step:0 g_loss:1.2941428422927856 d_loss:3.785476952791214 (f_loss=-0.36142608523368835 r_loss=1.0795886516571045 GP=3.067314386367798)
[Training] epoch:994 step:100 g_loss:1.4112120866775513 d_loss:2.5155820548534393 (f_loss=-0.39925768971443176 r_loss=1.2486814260482788 GP=1.6661583185195923)
[Training] epoch:994 step:200 g_loss:1.2879729270935059 d_loss:1.5522804260253906 (f_loss=-0.3262331485748291 r_loss=1.2304918766021729 GP=0.6480216979980469)
[Training] epoch:994 step:300 g_loss:1.379569172859192 d_loss:1.5582739412784576 (f_loss=-0.3814087212085724 r_loss=1.2137776613235474 GP=0.7259050011634827)
[Training] epoch:995 step:0 g_loss:1.3721956014633179 d_loss:4.852812170982361 (f_loss=-0.3411834239959717 r_loss=1.1283990144729614 GP=4.065596580505371)
[Training] epoch:995 step:100 g_loss:1.4033873081207275 d_loss:1.9266228377819061 (f_loss=-0.265510231256485 r_loss=1.1555169820785522 GP=1.0366160869598389)
[Training] epoch:995 step:200 g_loss:1.3165557384490967 d_loss:2.2573669850826263 (f_loss=-0.3605736792087555 r_loss=1.203474521636963 GP=1.414466142654419)
[Training] epoch:995 step:300 g_loss:1.3212684392929077 d_loss:1.578213095664978 (f_loss=-0.31490468978881836 r_loss=1.2395204305648804 GP=0.653597354888916)
[Training] epoch:996 step:0 g_loss:1.390194058418274 d_loss:2.658172130584717 (f_loss=-0.3431664705276489 r_loss=1.1741247177124023 GP=1.8272138833999634)
[Training] epoch:996 step:100 g_loss:1.3600575923919678 d_loss:2.814622938632965 (f_loss=-0.3613815903663635 r_loss=1.1351317167282104 GP=2.040872812271118)
[Training] epoch:996 step:200 g_loss:1.3070846796035767 d_loss:1.9695435166358948 (f_loss=-0.3456866145133972 r_loss=1.179081916809082 GP=1.13614821434021)
[Training] epoch:996 step:300 g_loss:1.3730037212371826 d_loss:2.1659147441387177 (f_loss=-0.2860777676105499 r_loss=1.091695785522461 GP=1.3602967262268066)
[Training] epoch:997 step:0 g_loss:1.305888295173645 d_loss:3.0200021266937256 (f_loss=-0.36253559589385986 r_loss=1.076438307762146 GP=2.3060994148254395)
[Training] epoch:997 step:100 g_loss:1.2796411514282227 d_loss:1.5758024156093597 (f_loss=-0.34635308384895325 r_loss=1.3333630561828613 GP=0.5887924432754517)
[Training] epoch:997 step:200 g_loss:1.4104254245758057 d_loss:1.6621782779693604 (f_loss=-0.3257245421409607 r_loss=1.2547930479049683 GP=0.7331097722053528)
[Training] epoch:997 step:300 g_loss:1.3385498523712158 d_loss:1.4690747261047363 (f_loss=-0.26695579290390015 r_loss=1.2011075019836426 GP=0.5349230170249939)
[Training] epoch:998 step:0 g_loss:1.3602702617645264 d_loss:1.4360323548316956 (f_loss=-0.40067243576049805 r_loss=1.246142029762268 GP=0.5905627608299255)
[Training] epoch:998 step:100 g_loss:1.305894374847412 d_loss:2.7741160690784454 (f_loss=-0.3538883626461029 r_loss=1.2325372695922852 GP=1.8954671621322632)
[Training] epoch:998 step:200 g_loss:1.3716931343078613 d_loss:1.5751938819885254 (f_loss=-0.2916029095649719 r_loss=1.2709747552871704 GP=0.5958220362663269)
[Training] epoch:998 step:300 g_loss:1.3656411170959473 d_loss:2.177170693874359 (f_loss=-0.426502525806427 r_loss=1.1792488098144531 GP=1.424424409866333)
[Training] epoch:999 step:0 g_loss:1.3534592390060425 d_loss:1.572658747434616 (f_loss=-0.37587276101112366 r_loss=1.1045242547988892 GP=0.8440072536468506)
[Training] epoch:999 step:100 g_loss:1.36478590965271 d_loss:2.350671887397766 (f_loss=-0.3687739372253418 r_loss=1.0921694040298462 GP=1.6272764205932617)
[Training] epoch:999 step:200 g_loss:1.361676573753357 d_loss:1.202286571264267 (f_loss=-0.37908583879470825 r_loss=1.2443079948425293 GP=0.3370644152164459)
[Training] epoch:999 step:300 g_loss:1.3626906871795654 d_loss:1.509294182062149 (f_loss=-0.3783542811870575 r_loss=1.2721277475357056 GP=0.615520715713501)
[Training] epoch:1000 step:0 g_loss:1.3767849206924438 d_loss:1.4634985625743866 (f_loss=-0.3212699592113495 r_loss=1.2940363883972168 GP=0.4907321333885193)
[Training] epoch:1000 step:100 g_loss:1.3351304531097412 d_loss:1.762041985988617 (f_loss=-0.26260000467300415 r_loss=1.2279777526855469 GP=0.7966642379760742)
[Training] epoch:1000 step:200 g_loss:1.3229777812957764 d_loss:3.208904266357422 (f_loss=-0.2858976125717163 r_loss=1.0474060773849487 GP=2.4473958015441895)
[Training] epoch:1000 step:300 g_loss:1.3721818923950195 d_loss:2.732981115579605 (f_loss=-0.3374415338039398 r_loss=1.2797622680664062 GP=1.7906603813171387)
[Training] epoch:1001 step:0 g_loss:1.328432321548462 d_loss:1.3976796567440033 (f_loss=-0.37590742111206055 r_loss=1.273669958114624 GP=0.4999171197414398)
[Training] epoch:1001 step:100 g_loss:1.3500542640686035 d_loss:3.3586094677448273 (f_loss=-0.34358903765678406 r_loss=1.0958094596862793 GP=2.606389045715332)
[Training] epoch:1001 step:200 g_loss:1.3231656551361084 d_loss:1.95867121219635 (f_loss=-0.3736152648925781 r_loss=1.268673062324524 GP=1.0636134147644043)
[Training] epoch:1001 step:300 g_loss:1.2954531908035278 d_loss:1.8934952914714813 (f_loss=-0.3090682923793793 r_loss=1.3160756826400757 GP=0.8864879012107849)
[Training] epoch:1002 step:0 g_loss:1.3297688961029053 d_loss:1.3581900894641876 (f_loss=-0.3181339502334595 r_loss=1.2974129915237427 GP=0.3789110481739044)
[Training] epoch:1002 step:100 g_loss:1.3070149421691895 d_loss:1.3041194081306458 (f_loss=-0.3420097827911377 r_loss=1.336272120475769 GP=0.3098570704460144)
[Training] epoch:1002 step:200 g_loss:1.3262243270874023 d_loss:1.6836585402488708 (f_loss=-0.29105907678604126 r_loss=1.274315357208252 GP=0.7004022598266602)
[Training] epoch:1002 step:300 g_loss:1.365082025527954 d_loss:1.6379614174365997 (f_loss=-0.3337179720401764 r_loss=1.261949896812439 GP=0.7097294926643372)
[Training] epoch:1003 step:0 g_loss:1.3988614082336426 d_loss:1.9783014357089996 (f_loss=-0.3206793963909149 r_loss=1.2278636693954468 GP=1.0711171627044678)
[Training] epoch:1003 step:100 g_loss:1.3704261779785156 d_loss:1.5413392186164856 (f_loss=-0.33041471242904663 r_loss=1.231255292892456 GP=0.6404986381530762)
[Training] epoch:1003 step:200 g_loss:1.3338878154754639 d_loss:2.266847848892212 (f_loss=-0.3473513126373291 r_loss=1.1909232139587402 GP=1.4232759475708008)
[Training] epoch:1003 step:300 g_loss:1.3233420848846436 d_loss:1.6980727910995483 (f_loss=-0.24812573194503784 r_loss=1.268352746963501 GP=0.6778457760810852)
